{"posts":[{"title":"CPU使用率和负载","text":"一、Linux线程生命周期 二、CPU使用率 三、当前负载 - 活跃任务数1. 负载 - 维基 An idle computer has a load number of 0 (the idle process isn’t counted). Each process using or waiting for CPU (the ready queue or run queue) increments the load number by 1. Each process that terminates decrements it by 1. Most UNIX systems count only processes in the running (on CPU) or runnable (waiting for CPU) states. However, Linux also includes processes in uninterruptible sleep states (usually waiting for disk activity), which can lead to markedly different results if many processes remain blocked in I/O due to a busy or stalled I/O system. This, for example, includes processes blocking due to an NFS server failure or too slow media (e.g., USB 1.x storage devices). Such circumstances can result in an elevated load average which does not reflect an actual increase in CPU use (but still gives an idea of how long users have to wait). 一个空闲的电脑的负载是0（空闲进程不被统计）。每个正在使用或等待使用CPU的进程（处于就绪队列或运行队列）都会使负载加1。而随着进程结束，则会使负载减1。大部分UNIX系统只计算了这两种状态。但是Linux还统计了不可中断的睡眠态（通常在等待磁盘活动）进程，如果许多进程由于I/O系统繁忙或停止而在I/O中保持阻塞状态，则会导致明显不同的结果。 例如，这包括由于NFS服务器故障或介质（例如USB 1.x存储设备）太慢而导致的进程阻塞。这种情况可能会导致平均负载增加，而这并不反映CPU使用的实际增加（但仍然给出了用户必须等待多长时间的想法）。 2. 不可中断的睡眠态 - 维基 An uninterruptible sleep state is a sleep state that won’t handle a signal right away. It will wake only as a result of a waited-upon resource becoming available or after a time-out occurs during that wait (if specified when put to sleep). It is mostly used by device drivers waiting for disk or network IO (input/output). When the process is sleeping uninterruptibly, signals accumulated during the sleep will be noticed when the process returns from the system call or trap. In Unix-like systems the command ‘ps -l‘ uses code “D“ for the uninterruptible sleep state of a process. Such processes cannot be killed even with SIGKILL and the only non-sophisticated way to get rid of them is to reboot the system. 不可中断的睡眠状态是指不能立即处理信号的睡眠状态。它只会在等待的资源变为可用时或在等待期间发生超时（如果在进入睡眠时指定）后唤醒。它主要由等待磁盘或网络IO（输入/输出）的设备驱动程序使用。当进程处于不可中断的睡眠状态时，当进程从系统调用或调用返回时，将注意到在睡眠过程中积累的信号陷阱。 在类似于Unix的系统命令“ps-l”使用代码“D”表示进程的不间断睡眠状态。即使使用SIGKILL，也不能终止这样的进程，而摆脱它们唯一简单的方法就是重启系统。 3. 总结由以上可知Linux系统下的活跃任务数计算公式： 1active_tasks = ready_queue.length + run_queue.length + uninterruptible_sleep_state.length 四、平均负载 - 指数平滑法 很多电力公司用它来预测电力负载。 1. 指数平滑法 - MBA智库百科 指数平滑法是布朗(Robert G..Brown)所提出，布朗(Robert G..Brown)认为时间序列的态势具有稳定性或规则性，所以时间序列可被合理地顺势推延；他认为最近的过去态势，在某种程度上会持续到最近的未来，所以将较大的权数放在最近的资料。 指数平滑法是生产预测中常用的一种方法。也用于中短期经济发展趋势预测，所有预测方法中，指数平滑是用得最多的一种。简单的全期平均法是对时间数列的过去数据一个不漏地全部加以同等利用；移动平均法则不考虑较远期的数据，并在加权移动平均法中给予近期资料更大的权重；而指数平滑法则兼容了全期平均和移动平均所长，不舍弃过去的数据，但是仅给予逐渐减弱的影响程度，即随着数据的远离，赋予逐渐收敛为零的权数。 也就是说指数平滑法是在移动平均法基础上发展起来的一种时间序列分析预测法，它是通过计算指数平滑值，配合一定的时间序列预测模型对现象的未来进行预测。其原理是任一期的指数平滑值都是本期实际观察值与前一期指数平滑值的加权平均。 2. Linux负载源码注释来源：linux/kernel/sched/loadavg.c Github源码 本仓库副本 123456789101112/** * The global load average is an exponentially decaying average of nr_running + * nr_uninterruptible. * * Once every LOAD_FREQ: * * nr_active = 0; * for_each_possible_cpu(cpu) * nr_active += cpu_of(cpu)-&gt;nr_running + cpu_of(cpu)-&gt;nr_uninterruptible; * * avenrun[n] = avenrun[0] * exp_n + nr_active * (1 - exp_n) */ 参考 Process_states Uninterruptible_sleep (ps的D状态) run queue 深度好文：全面解析 Linux Load 维基 CPU Load 指数平滑法 MBA智库百科 维基 Exponential_smoothing 维基 Exponential_moving_average","link":"/2021/01/21/CPU%E4%BD%BF%E7%94%A8%E7%8E%87%E5%92%8C%E8%B4%9F%E8%BD%BD/"},{"title":"CA认证的证书为什么还需要手动导入？","text":"1. 背景昨天有商家运维提示商家证书更新，需要我方手动导入更新。可通过访问该URL发现该地址的https证书是经过CA认证的，非自签名的，如下图。 讲道理而言，经过CA认证的证书，会在SSL握手时获取证书链来验证证书有效性，但是我方调用商家URL时却出现如下错误： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788com.jd.edi.utils.exception.runtime.ProcessorRunningException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at com.jd.lsb.edi.flow.camel.processor.exception.ExceptionProcessor.process(ExceptionProcessor.java:66) at org.apache.camel.processor.DelegateSyncProcessor.process(DelegateSyncProcessor.java:63) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.FatalFallbackErrorHandler.process(FatalFallbackErrorHandler.java:82) at org.apache.camel.processor.RedeliveryErrorHandler.deliverToFailureProcessor(RedeliveryErrorHandler.java:1063) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:474) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:97) at com.jd.lsb.edi.component.jsf.utils.RouteHandler.invoke(RouteHandler.java:46) at com.sun.proxy.$Proxy111.handle(Unknown Source) at sun.reflect.GeneratedMethodAccessor1025.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at com.jd.jsf.gd.filter.ProviderInvokeFilter.reflectInvoke(ProviderInvokeFilter.java:140) at com.jd.jsf.gd.filter.ProviderInvokeFilter.invoke(ProviderInvokeFilter.java:100) at com.jd.jsf.gd.filter.ProviderSecurityFilter.invoke(ProviderSecurityFilter.java:42) at com.jd.jsf.gd.filter.ProviderConcurrentsFilter.invoke(ProviderConcurrentsFilter.java:62) at com.jd.jsf.gd.filter.ProviderTimeoutFilter.invoke(ProviderTimeoutFilter.java:39) at com.jd.jsf.gd.filter.ProviderMethodCheckFilter.invoke(ProviderMethodCheckFilter.java:78) at com.jd.jsf.gd.filter.ProviderInvokeLimitFilter.invoke(ProviderInvokeLimitFilter.java:56) at com.jd.jsf.gd.filter.ProviderHttpGWFilter.invoke(ProviderHttpGWFilter.java:47) at com.jd.jsf.gd.filter.ProviderGenericFilter.invoke(ProviderGenericFilter.java:118) at com.jd.jsf.gd.filter.ProviderContextFilter.invoke(ProviderContextFilter.java:81) at com.jd.jsf.gd.filter.ExceptionFilter.invoke(ExceptionFilter.java:44) at com.jd.jsf.gd.filter.SystemTimeCheckFilter.invoke(SystemTimeCheckFilter.java:79) at com.jd.jsf.gd.filter.FilterChain.invoke(FilterChain.java:281) at com.jd.jsf.gd.server.ProviderProxyInvoker.invoke(ProviderProxyInvoker.java:66) at com.jd.jsf.gd.server.JSFTask.doRun(JSFTask.java:129) at com.jd.jsf.gd.server.BaseTask.run(BaseTask.java:29) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)Caused by: javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.ssl.Alerts.getSSLException(Alerts.java:192) at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:302) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:296) at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1497) at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:212) at sun.security.ssl.Handshaker.processLoop(Handshaker.java:979) at sun.security.ssl.Handshaker.process_record(Handshaker.java:914) at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1062) at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387) at org.apache.http.conn.ssl.SSLConnectionSocketFactory.createLayeredSocket(SSLConnectionSocketFactory.java:396) at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:355) at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142) at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:359) at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381) at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237) at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185) at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89) at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111) at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56) at org.apache.camel.component.http4.HttpProducer.executeMethod(HttpProducer.java:334) at org.apache.camel.component.http4.HttpProducer.process(HttpProducer.java:193) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ... 31 moreCaused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:387) at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:292) at sun.security.validator.Validator.validate(Validator.java:260) at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:324) at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:229) at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:105) at com.jd.lsb.edi.service.http.common.ssl.SSLTrustManager.checkServerTrusted(SSLTrustManager.java:54) at sun.security.ssl.AbstractTrustManagerWrapper.checkServerTrusted(SSLContextImpl.java:922) at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1479) ... 55 moreCaused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.provider.certpath.SunCertPathBuilder.build(SunCertPathBuilder.java:145) at sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:131) at java.security.cert.CertPathBuilder.build(CertPathBuilder.java:280) at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:382) ... 63 more 最终，导入商家证书后解决。 2. 定位问题1）对比地址：https://sg.godaddy.com/（两者都使用 了相同的CA证书链） 2）对比结果 HttpClient可正常访问：https://sg.godaddy.com/ 通过Debug发现：正常访问时，SSL握手时HttpClient会收到一个证书链；而访问失败时，只收到了server的证书。 测试把中间的证书导入cert中后可正常访问。 123456789class T12CertificateConsumer { @Override public void consume(ConnectionContext context, ByteBuffer message) throws IOException { 。。。 // 此处访问正常时会接受到证书链，相反失败的情况是只收到了server一个证书 T12CertificateMessage cm = new T12CertificateMessage(hc, message); }} 3.结论即便是经过CA认证的证书，如果Server端没有把证书关联起来在SSL握手时一并返回，也会导致https访问异常。 4. 后续跟商家技术反馈后，他们调整了证书，经测试不导入证书也可以正常访问。 其他、浏览器可正常访问的猜测浏览器会自动从OU里下载间接证书链，如下图。 参考 https://stackoverflow.com/questions/12778012/java-sslsocket-how-to-send-full-server-cert-chain https://stackoverflow.com/questions/9299133/why-doesnt-java-send-the-client-certificate-during-ssl-handshake/9300727#9300727","link":"/2020/12/30/CA%E8%AE%A4%E8%AF%81%E7%9A%84%E8%AF%81%E4%B9%A6%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E9%9C%80%E8%A6%81%E6%89%8B%E5%8A%A8%E5%AF%BC%E5%85%A5%EF%BC%9F/"},{"title":"CPU内存模型和LOCK指令","text":"本文主要内容是对Intel CPU手册的第八章内容的简要翻译，旨在了解汇编指令Lock在CPU级别的实现机制。 一、CPU内存模型 1、数据一致性1）缓存一致性两个基本概念： I、Cache：缓存，又称快取，是弥补CPU和内存之间的速度差异而产生的中间存储，CPU内部有L1,L2,L3三级缓存，速度递减。 II、Cache Line：为提高效率，每次从内存取出放到Cache的数据单位被称为缓存行，一般为64Byte； 缓存一致性是指当处理器去访问缓存在其他处理器中的数据时，不能得到错误的数据。如果数据被修改，那么其他处理器也必须得到修改后的数据。 2）主存一致性系统内存一致性是指多个处理器同时去访问系统内存的相同地址时，cpu需要提供通讯机制或内存访问协议来保证数据的一致性，某些场景下会允许其中的一个处理器临时的锁定这个内存地址（或更大一点的内存区域）。 2、原子操作保证数据一致性IA-32的32位处理器在系统内存的位置上支持受锁定的原子操作（最近的IA-32,64处理器提供了更细粒度的锁定机制）。这些操作常会用于管理共享的数据结构（例如信号量，段描述，系统段，页表），多个处理器可能会同时去修改共享数据结构的某个相同的字段或标识。 处理器通过三种机制来共同实现受锁定的原子操作： I、cpu保证的原子操作 II、总线锁，使用LOCK#信号和LOCK指令前缀； III、缓存一致性协议，使共享的数据结构在被缓存的情况下同样保证原子性； 1）保证的原子操作cpu保证读写一个byte，word, doubleword的原子性（P6系列的处理器还会保证从缓存行中读写四个字节的原子性，且不要求内存对齐） 2）总线锁和缓存一致性 Inter 64和IA-32架构的处理器访问临界区内存时会自动声明LOCK#信号，通过锁定系统总线或等效连接。当该信号被发出后，来自其他处理器或总线Agnet的请求都会被阻塞。软件可以通过在指令前手动增加LOCK前缀来声明其他遵循锁定语义的场景。Intel386, Intel486, 和Pentium处理器遇到被锁定修饰的指令（locked instruction）会发出LOCK#信号。多个处理器在系统硬件的控制下对内存的访问，此硬件的设计者需要保证LOCK#信号的作用。对于P6或更新的处理器系列，如果被访问的内存区域已经被缓存到处理器，那么处理器就不再发出LOCK#信号，而是只锁定处理器的缓存（通过缓存一致性协议）。常见的缓存一致性协议有：MESI，MESIF（MESIF是缓存行的状态标识，M:Modified, E: Exclusive, S:Shared, I:Invalid, F: Forwad），通过标记缓存行的状态和处理器间的通讯来实现。 总线锁的两种使用方法 自动锁定：处理器会自动对一些指令增加LOCK前缀来保证原子性，例如XCHG 声明锁定：在某些特定的指令前增加LOCK前缀来保证原子性。 总线锁定无需内存对齐 总线锁的完整性不会受内存字段的对齐影响.锁定语义在必要时会持续多个总线周期来实现完整的操作。建议锁定访问在它们的自然边界上对齐，以获得更好的系统性能。 • 任意8bit的访问（不用锁定） • 被锁定的16bit访问 • 被锁定的32bit访问 • 被锁定的64bit访问 3、同步机制依赖内存有序模型在多处理器系统下，实现同步机制需要依赖一个强内存有序模型。“内存有序”指的是CPU处理器通过系统总线向系统内存发出读写操作的顺序。Intel IA-32，x64架构的cpu根据具体的架构实现会支持多种内存有序模型。 1）Intel 386处理器采用程序级别有序（一般被认为是强有序），即在所有场景下发到总线上的读写顺序与指令流的顺序一致。 2）PentiumI4，Intel Xeon，P6系列的IA-32架构CPU，为了优化指令执行的性能，提出了不同于强一致性的memory ordering，称为处理器级别有序。该模型的不同之处在于允许执行强化性能的一些乱序操作，例如，允许写缓冲之前执行读操作。这些差异都旨在保持内存一致性的前提下，加快指令的执行速度，即使是多处理器的系统。 强化或弱化的内存模型，Intel 64和IA-32架构的提供了多种机制来强化或弱化内存排序模型来应对特殊的编程情景，这些机制包括： 1）IO指令，Lock指令，Lock前缀修饰的指令，串行指令在处理器上强制增强有序性 2）栅栏指令：SFENCE,LFENCE,MFENCE指令为特定类型的内存操作提供内存排序和序列化功能。 3）MTRRs常被用于为指定的物理内存提供强化或弱化内存排序； 4）PAT常被用于为指定的内存页提供强化排序； 其中串行指令包括：INVD, INVEPT, INVLPG, INVVPID, LGDT, LIDT, LLDT, LTR, MOV (to control register, with the exception of MOV CR83), MOV (to debug register), WBINVD, and WRMSR4，CPUID, IRET, and RSM。 二、Lock指令1、LOCK指令保证原子性1）作用CPU保证被其修饰的指令的原子性。 2）实现方式I、依赖内存有序模型，来保证读取指令有序； II、通过总线锁或缓存一致性，保证被修饰指令操作的数据一致性： 当访问的数据在系统内存时，通过在总线锁实现原子性； 当访问的数据在处理器的缓存时，通过缓存一致性协议实现原子性； 举个栗子 Java的DCL中若返回的变量不加volatile修饰，则可能会由于指令重排导致另一个线程获取到一个非完全初始化的对象。当volatile修饰的变量所在的代码段成为热点，被JIT编译为汇编代码后，会增加LOCK前缀来禁止指令重拍和数据一致； 3）交换指令CMPXCHG、XCHGI、CPMXCHG 用于比较并交换操作数，CPU对CAS的原语支持 非原子性，最早用于单核CPU II、XCHG 用于交换两个操作数 具备原子性，CPU会自动加LOCK前缀 The LOCK prefix is automatically assumed for XCHG instruction.——From Intel手册 8.1.2.2 Software Controlled Bus Locking LOCK CMPXCHAGI、单核：无需加LOCK前缀，即使增加也会被替换为nop II、多核：需要加LOCK前缀 2、LOCK指令保证可见性1）优先锁缓存行I、CPU保证锁单个缓存行的原子性； II、效率高，不会阻塞总线上的信号； III、各CPU间，各内核间通过嗅探机制和MESI协议进行通讯，机制比较复杂； 2）锁总线是最后的选择I、如果变量跨缓存行，则需启用总线锁； II、开销较大，在总线锁期间总线不会响应其他信号； III、实现简单，是早期CPU的实现方式； Note： 一个缓存行一般为64byte； 常用的缓存一致性协议为MESI，标识缓存行的四种状态Modify,Exclude,Shared,Invalid; # 参考 https://stackoverflow.com/questions/27837731/is-x86-cmpxchg-atomic-if-so-why-does-it-need-lock/44273130#44273130 Intel架构手册 维基百科：MESI协议 维基百科：缓存一致性","link":"/2020/05/01/CPU%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%92%8CLOCK%E6%8C%87%E4%BB%A4/"},{"title":"CPU飚高排查","text":"一、背景近日发现EDI线上某应用为618新扩容的非公有云机器CPU经常99%，频繁触发机器CPU告警。该集群的其他机器则CPU使用率在10%以下。 二、排查步骤 1）确认该集群请求负载是否均衡在ES里，通过请求饼图发现负载均衡，且问题机器请求数并不高。 ø 本步骤结论： 排除大流量导致的CPU飚高。 2）问题机器：执行top -Hp pid和jstack pid当进程CPU为398%时，该进程CPU使用率高的线程CPU都在0.9以下。 1234567891011121314# Top展示:(如果是docker展示数据为宿主物理机整体数据,略有偏差)top - 03:15:41 up 225 days, 11:56, 0 users, load average: 14.07, 8.72, 7.11Tasks: 35 total, 2 running, 27 sleeping, 0 stopped, 6 zombie%Cpu(s): 14.7 us, 1.6 sy, 0.1 ni, 83.5 id, 0.1 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 13134801+total, 17604608 free, 34303548 used, 79439864 buff/cacheKiB Swap: 0 total, 0 free, 0 used. 72823864 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND491335 admin 20 0 23.156g 4.909g 30008 S 398.0 3.9 2103:56 java 384 admin 20 0 375008 6512 4908 S 1.0 0.0 5:10.69 deploy368428 admin 20 0 113256 3276 2996 S 1.0 0.0 0:00.01 bash 1 root 20 0 11644 2532 2332 S 0.0 0.0 0:04.34 sh 11 root 20 0 83060 3092 2220 S 0.0 0.0 0:01.33 sshd 13 root 20 0 22796 2564 1892 S 0.0 0.0 0:43.65 crond 123456789101112131415161718192021# 线程情况占用如下:%CPU PID TID TIME TTY STAT PSR 0.8 491335 495955 01:07:10 ? Sl 10 0.7 491335 495966 00:58:33 ? Sl 21 0.7 491335 495939 00:59:09 ? Sl 18 0.6 491335 495967 00:51:55 ? Sl 23 0.6 491335 495956 00:48:13 ? Sl 27 0.5 491335 495977 00:38:56 ? Sl 8 0.5 491335 495976 00:40:46 ? Sl 30 0.5 491335 491446 00:45:24 ? Sl 17 0.4 491335 495974 00:32:04 ? Sl 20 0.4 491335 495973 00:32:35 ? Sl 14 0.4 491335 495972 00:31:29 ? Sl 11 0.4 491335 495970 00:32:38 ? Sl 22 0.4 491335 495963 00:33:55 ? Sl 6 0.4 491335 495958 00:34:36 ? Sl 6 0.4 491335 495952 00:31:20 ? Sl 28 0.4 491335 495949 00:31:53 ? Sl 0 0.4 491335 495946 00:31:00 ? Sl 27 0.4 491335 495944 00:33:09 ? Sl 20 0.4 491335 495938 00:30:23 ? Sl 10 jstack中有一个明显不正常的地方是，其Parallel GC Threads线程有23个，而云上机器的GC线程数是2个。 根据文章所说，ParallelGCThreads = 8 + ((N - 8) * 5/8)，反推得出N = 32核（此处显然是获取的物理机器核数，该docker只有4C）。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&quot;VM Thread&quot; os_prio=0 tid=0x00007f0cf41cf800 nid=0x77f6a runnable &quot;Gang worker#0 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf403a800 nid=0x77f4c runnable &quot;Gang worker#1 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf403c000 nid=0x77f4d runnable &quot;Gang worker#2 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf403e000 nid=0x77f4e runnable &quot;Gang worker#3 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf403f800 nid=0x77f4f runnable &quot;Gang worker#4 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf4041800 nid=0x77f50 runnable &quot;Gang worker#5 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf4043800 nid=0x77f51 runnable &quot;Gang worker#6 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf4045000 nid=0x77f52 runnable &quot;Gang worker#7 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf4047000 nid=0x77f53 runnable &quot;Gang worker#8 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf4049000 nid=0x77f54 runnable &quot;Gang worker#9 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf404a800 nid=0x77f55 runnable &quot;Gang worker#10 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf404c800 nid=0x77f56 runnable &quot;Gang worker#11 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf404e800 nid=0x77f57 runnable &quot;Gang worker#12 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf4050000 nid=0x77f58 runnable &quot;Gang worker#13 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf4052000 nid=0x77f59 runnable &quot;Gang worker#14 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf4053800 nid=0x77f5a runnable &quot;Gang worker#15 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf4055800 nid=0x77f5b runnable &quot;Gang worker#16 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf4057800 nid=0x77f5c runnable &quot;Gang worker#17 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf4059000 nid=0x77f5d runnable &quot;Gang worker#18 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf405b000 nid=0x77f5e runnable &quot;Gang worker#19 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf405d000 nid=0x77f5f runnable &quot;Gang worker#20 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf405e800 nid=0x77f60 runnable &quot;Gang worker#21 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf4060800 nid=0x77f61 runnable &quot;Gang worker#22 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f0cf4062800 nid=0x77f62 runnable &quot;Concurrent Mark-Sweep GC Thread&quot; os_prio=0 tid=0x00007f0cf417b000 nid=0x77f69 runnable &quot;Gang worker#0 (Parallel CMS Threads)&quot; os_prio=0 tid=0x00007f0cf416f000 nid=0x77f63 runnable &quot;Gang worker#1 (Parallel CMS Threads)&quot; os_prio=0 tid=0x00007f0cf4171000 nid=0x77f64 runnable &quot;Gang worker#2 (Parallel CMS Threads)&quot; os_prio=0 tid=0x00007f0cf4172800 nid=0x77f65 runnable &quot;Gang worker#3 (Parallel CMS Threads)&quot; os_prio=0 tid=0x00007f0cf4174800 nid=0x77f66 runnable &quot;Gang worker#4 (Parallel CMS Threads)&quot; os_prio=0 tid=0x00007f0cf4176800 nid=0x77f67 runnable &quot;Gang worker#5 (Parallel CMS Threads)&quot; os_prio=0 tid=0x00007f0cf4178000 nid=0x77f68 runnable &quot;VM Periodic Task Thread&quot; os_prio=0 tid=0x00007f0cf5545000 nid=0x77f82 waiting on condition JNI global references: 702 ø 本步骤结论： 可能是GC线程数过多导致，先定位GC线程数与云主机的差异原因。 3）确认是JDK版本导致GC线程数差异经Google上文章所说JDK 8u131后才能感知到docker容器内的核数，之前是获取的物理机核数。 通过jstack的信息确定当前java版本： 非云机器——问题机器 1234567jstack信息：Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.51-b03 mixed mode):对应Java版本：java version &quot;1.8.0_51&quot;Java(TM) SE Runtime Environment (build 1.8.0_51-b16)Java HotSpot(TM) 64-Bit Server VM (build 25.51-b03, mixed mode) 云机器 1234567jstack信息：Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode):对应Java版本：java version &quot;1.8.0_212&quot;Java(TM) SE Runtime Environment (build 1.8.0_212-b27)Java HotSpot(TM) Client VM (build 25.60-b23, mixed mode) ø 本步骤结论： JDK版本不同导致Runtime.getAvailableProcessors获取的核数不同，从而使得ParallelGCThreads线程数不同。 4）问题机器：执行jstat，发现Young GC频繁通过GC日志发现其youngGC非常频繁。 123456S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 99.64 99.61 61.62 80.11 83.44 80.94 3182 82.199 53 18.932 101.131 0.00 99.25 73.17 88.17 83.44 80.94 3186 82.345 53 18.932 101.27899.87 0.00 58.43 95.48 83.44 80.94 3191 82.443 53 18.932 101.375 0.00 99.63 99.95 97.75 83.44 80.94 3192 82.464 54 18.932 101.39699.90 0.00 99.99 10.72 83.44 80.94 3194 82.501 54 19.694 102.195 ø 本步骤结论： YoungGC相当高频，先考虑把ParallelGCThreads设置docker的核数，然后再观察。 5）问题机器：设置-XX:ParallelGCThreads=4，问题未解决ø 本步骤结论： 频繁GC的原因，肯定还是程序执行的问题。肯定是程序在执行期间频繁的申请内存并释放。于是，再次观察jstack堆栈内容。 6）问题机器：再次观察其堆栈，发现logger#debug调用再次观察jstack堆栈，发现堆栈里有大量的logger#debug调用。检查外面配置的log4j2.xml的日志级别，确认是WARN级别，此时怀疑是slf4j多实现冲突导致。 12345678910111213141516171819&quot;JSF-BZ-22000-12-T-680&quot; #904 daemon prio=5 os_prio=0 tid=0x00007f0b8409c800 nid=0x79153 runnable [0x00007f088f9fd000] java.lang.Thread.State: RUNNABLE at java.util.Arrays.copyOf(Arrays.java:3332) at java.lang.AbstractStringBuilder.expandCapacity(AbstractStringBuilder.java:137) at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:121) at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:622) at java.lang.StringBuilder.append(StringBuilder.java:202) at com.xxx.xxx.toString(StandardListResponse.java:66) at java.lang.String.valueOf(String.java:2982) at java.lang.StringBuilder.append(StringBuilder.java:131) at java.util.AbstractMap.toString(AbstractMap.java:536) at org.slf4j.helpers.MessageFormatter.safeObjectAppend(MessageFormatter.java:299) at org.slf4j.helpers.MessageFormatter.deeplyAppendParameter(MessageFormatter.java:271) at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:233) at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:173) at org.slf4j.helpers.MessageFormatter.format(MessageFormatter.java:151) at org.slf4j.impl.Log4jLoggerAdapter.debug(Log4jLoggerAdapter.java:247) at org.slf4j.helpers.MarkerIgnoringBase.debug(MarkerIgnoringBase.java:79) at com.xxx.xxx.xxx(Xxx.java:35) ø 本步骤结论： logger#debug方法有调用，定位是slf4j多实现冲突导致。而debug方法开销较大，有几处debug方法会触发contexMap#toString，导致YoungGC频繁。 7）问题机器：经验证是slf4j多实现冲突验证log4j配置的日志目录及lib包，发现log4j包冲突，在云和非云机器log4j绑定的实现不一样。 ø 本步骤结论： 但slf4j有多实现包时，云主机和非云主机的表现不一致，选择的绑定实现不一致，导致了本次CPU飚高问题。 8）解决冲突，问题解决三、结论1）如果CPU是持续飚高，可以通过jstack分析原因； 2）如果CPU是间歇飚高，可以通过火眼图分析原因，火焰图可理解为jstack上增加了时间维度，偏差更小。 # 参考 https://christopher-batey.medium.com/cpu-considerations-for-java-applications-running-in-docker-and-kubernetes-7925865235b7 https://segmentfault.com/a/1190000009407521","link":"/2021/06/02/CPU%E9%A3%9A%E9%AB%98%E6%8E%92%E6%9F%A5/"},{"title":"ClassNotFound与类加载的全盘委托机制","text":"一、问题描述EDI测试环境运行时，在JSF调用时报ClassNotFound，而在商家目录B下有该依赖，通过远程断点定位到并没有走EDI自定义的类加载器。 二、原因JSF调用的参数类A是EDI平台类，由应用类加载器加载。而A中某个属性是B类，其未在应用类加载器的扫描目录A而在商家目录B下，已由EDI自定义类加载器CompositeClassLoader加载。由于类加载的全盘委托机制，导致在A中使用到B时，由加载A类的类加载器去加载B，导致加载不到，引发ClassNotFoundException。 三、解决方案把B所在的jar包放到目录A下。","link":"/2020/11/01/ClassNotFound%E4%B8%8E%E7%B1%BB%E5%8A%A0%E8%BD%BD%E7%9A%84%E5%85%A8%E7%9B%98%E5%A7%94%E6%89%98%E6%9C%BA%E5%88%B6/"},{"title":"Camel的Exchange分析","text":"本文基于Camel版本2.20.1。 一、Exchange在Route中传递地址：https://camel.apache.org/manual/latest/faq/using-getin-or-getout-methods-on-exchange.html The out message from each step is used as the in message for the next step if there is no out message then the in message is used instead For the InOut MEP the out from the last step in the route is returned to the producer. In case of InOnly the last out is thrown away NOTE：关于Exchange类型InOnly和InOut的区别只在末端处理。 二、Exchange的In和Out交换逻辑1. Pipeline#processorg.apache.camel.processor.Pipeline#process(org.apache.camel.Exchange, org.apache.camel.AsyncCallback) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public boolean process(Exchange exchange, AsyncCallback callback) { Iterator&lt;Processor&gt; processors = getProcessors().iterator(); Exchange nextExchange = exchange; boolean first = true; while (continueRouting(processors, nextExchange)) { if (first) { first = false; } else { // prepare for next run nextExchange = createNextExchange(nextExchange); } // get the next processor Processor processor = processors.next(); AsyncProcessor async = AsyncProcessorConverterHelper.convert(processor); boolean sync = process(exchange, nextExchange, callback, processors, async); // continue as long its being processed synchronously if (!sync) { LOG.trace(&quot;Processing exchangeId: {} is continued being processed asynchronously&quot;, exchange.getExchangeId()); // the remainder of the pipeline will be completed async // so we break out now, then the callback will be invoked which then continue routing from where we left here return false; } LOG.trace(&quot;Processing exchangeId: {} is continued being processed synchronously&quot;, exchange.getExchangeId()); // check for error if so we should break out if (!continueProcessing(nextExchange, &quot;so breaking out of pipeline&quot;, LOG)) { break; } } // logging nextExchange as it contains the exchange that might have altered the payload and since // we are logging the completion if will be confusing if we log the original instead // we could also consider logging the original and the nextExchange then we have *before* and *after* snapshots LOG.trace(&quot;Processing complete for exchangeId: {} &gt;&gt;&gt; {}&quot;, exchange.getExchangeId(), nextExchange); // copy results back to the original exchange ExchangeHelper.copyResults(exchange, nextExchange); callback.done(true); return true;}protected Exchange createNextExchange(Exchange previousExchange) { return PipelineHelper.createNextExchange(previousExchange); } Pipeline中的Processors是Route中的Processor链，其中createNextExchange方法用来处理Exchange在Processor调用前的准备操作。 2. PipelineHelper#createNextExchangeorg.apache.camel.processor.PipelineHelper#createNextExchange 1234567891011public static Exchange createNextExchange(Exchange previousExchange) { Exchange answer = previousExchange; // now lets set the input of the next exchange to the output of the // previous message if it is not null if (answer.hasOut()) { answer.setIn(answer.getOut()); answer.setOut(null); } return answer; } 从上面源码可知，在进行下一个Processor调用前会重置In。 三、Exchange的类图 四、message.setBody(null)后取值问题当通过*exchange.getIn().setBody(null)或者exchange.getOut().setBody(null)*后。 当Message类型为DefaultMessage时，通过message.getBody可以正常取出null值。 当Message类型为MailMessage,GenericFileMessage,HttpMessage时，由于他们重写了createBody方法，调用message.getBody时会重新初始化body为非null。 12345// GenericFileMessage#createBody@Overrideprotected Object createBody() { return file != null ? file.getBody() : super.createBody();} 举例来说，Consumer为FTP时，其会初始化Message为GenericFileMessage类型，一但其中某个processor把Message的Body设置为null，那么在此获取body时会重置为文件内容。 # 其他、关于exchange.getOut()12345678910// DefaultExchange#getOutpublic Message getOut() { // lazy create if (out == null) { out = (in != null &amp;&amp; in instanceof MessageSupport) ? ((MessageSupport)in).newInstance() : new DefaultMessage(getContext()); configureMessage(out); } return out;} 当Out不存在时，会使用In的内容创建Out。","link":"/2021/08/04/Camel%E7%9A%84Exchange%E5%88%86%E6%9E%90/"},{"title":"AQS及其实现","text":"一、AQS介绍 1、前置问题1）同步队列，等待队列和条件队列的区别？ 2）AQS和monitor区别？队列的对比？ 3）类继承结构？ 2、AQS的类注释 Doug Lea开发juc包的核心组件是AQS，是实现Semaphore，ReentrantLock，ReadWriteLock，CountDownLatch等的基础。 AQS提供了一个框架，可用于实现依赖先进先出（FIFO）等待队列的阻塞锁和相关同步器（信号量、事件等）。对于大多数依赖单个原子整数值来表示状态的同步器来说，这个类是一个有用的基础。子类必须定义用来更改此状态的受保护方法，以及定义此状态对于获取或释放此对象意味着什么。考虑到这些，这个类中的其他方法执行所有排队和阻塞机制。子类可以维护其他状态，但是必须使用方法getState,setState,compareAndSetState来原子性的更新其值，来维护同步。 子类应该被定义为一个非公共的内部类，来实现外部类的同步属性。AbstractQueuedSynchronizer没有实现任何同步接口。相反，它定义了诸如acquiredinterruptibly之类的方法，这些方法可以由具体锁和相关同步器酌情调用，以实现它们的公共方法。 这个类支持默认的独占模式和共享模式。以独占模式获取时，其他线程尝试的获取无法成功。共享模式下多线程获取可能（非必须）成功。这个类只有通过“当共享模式获取成功时，下一个等待线程（如果存在）也必须确定它是否也可以获取”的机制才能区别两者。在不同模式下等待的线程共享同一个FIFO队列。通常，实现子类只支持其中一种模式，但这两种模式也可以都支持，例如在ReadWriteLock。仅支持独占模式或共享模式的子类不需要定义支持未使用模式的方法。 本类定义了ConditionObject内部类，它可以被支持独占模式的子类(AQS子类)用作条件（Condition）实现，对于这种模式，isheldexclusly报告是否以独占方式保持与当前线程的同步，使用当前getState值调用的方法release完全释放这个对象，并且acquire，给定这个保存的状态值，最终将这个对象恢复到它以前的获取状态。(本段待优化)AQS类内没有方法会去创建条件（condition），如果无法满足此约束，请不要使用他。ConditionObject的行为当然取决于其同步器实现的语义。 这个类提供内部队列的检查、检测和监视方法，以及针对条件对象的类似方法。可以把AbstractQueuedSynchronizer导入需要的类来实现同步机制。 此类的序列化仅存储底层原子整数维护状态，因此反序列化对象具有空线程队列。需要序列化的典型子类将定义 readObject方法，该方法在反序列化时将其还原为已知的初始状态。 3、AQS$Node类注释同步队列是CLH队列的变种。CLH常用于实现自旋锁。我们用它来实现阻塞的同步器，但是使用相同的策略来保持前驱节点内线程的一些控制信息。每个结点里的“status”字段用于跟踪线程是否应该阻塞。当前驱结点release后，当前结点被唤醒。否则，队列里的每个结点都被作为特定通知类型的监视器，其内部的线程是唯一的等待线程。“status”字段不控制线程是否被授予锁等资源。当线程在队首时可以尝试去占有。但是在队首并不保证占有成功，只是由权利去竞争。所以当前被唤醒的竞争线程有可能因竞争失败而重新wait，等待下次唤醒。 要在CLH里入队一个结点，你需要原子性的把它插入队列并设为tail。出队时只需要设置head字段。 123 +------+ prev +-----+ +-----+head | | &lt;---- | | &lt;---- | | tail +------+ +-----+ +-----+ 由于插入CLH队列只需要“tail”保证原子性操作，所以在未入队到入队间有个简单的原子点界限。同样出队时只需要更新“head”。但是这期间需要多做一点工作来确定后继结点是谁，部分是为了处理由超时或中断导致的取消操作。 “prev”字段（原始的CLH中不会使用）主要用于取消场景。如果一个结点被取消，则他的后继结点会重新通过该字段连接至非取消状态的前驱结点。 我们使用“next”字段实现阻塞机制。每个结点的线程ID都被自己持有，所以前驱结点通过该字段来发送signal信号给next结点，以此来唤醒其持有的线程。决定next结点时必须避免与新入队的结点设置前驱结点的“next”字段的场景产生竞态条件。 This is solved when necessary by checking backwards from the atomically updated “tail” when a node’s successor appears to be null。 取消在基本算法中引入了保守性。因为我们必须轮询其他节点的取消，所以我们可能会忽略已取消的节点是在我们前面还是后面。常用处理的方法是一旦取消当前结点，则unpark其后继结点，使他们能找到新的前驱结点，除非我们能找到一个未取消的前驱结点来承担这一职责。 CLH队列需要一个dummy头结点。但是我们并没有一开始就创建他，因为如果不存在竞争时此举会产生多余的开销。反之，我们在第一次竞争时再创建头结点，并把head和tail指向他。 条件队列也使用此类，但是使用了额外的连接。条件只需要以简单的队列连接结点即可，因为他们仅在独占时访问。一旦await，结点便被插入条件队列。一旦signal，结点便被转移到主队列。“status”字段有个特殊的值来标识结点处于哪个队列。 4、AQS和monitor关系 AQS的同步队列相当于Object Monitor的EntrySet；AQS的条件队列和等待队列是一个东西，相当于Object Monitor的WaitSet。参考：https://www.cnblogs.com/549294286/p/3688829.html 线程特征 队列特征 线程来源 同步队列 在同步队列中等待unpark信号去竞争锁 双向链表 1）条件队列；2）新的线程获取锁失败； 条件队列 在条件队列中等待signal信号，然后转移至同步队列参与竞争 单向链表 获取锁的线程在该线程上下文对某个条件对象执行await方法 5、AQS的获取方法 6、AQS的acquire和acquireShared流程图 shouldParkAfterFailedAcquire方法流程： 检查当前结点的前驱结点的waiteStatus 1）如果是是SIGNAL，则返回true 2）如果是已取消，则在队列中剔除当前结点前连续的取消结点；返回false； 3）否则，设置前驱结点的waiteStatus为SIGNAL。返回false。 Note： 1）通过addWaiter增加的结点waitStatus=0； 会再第二次进入本方法时才返回true； 2）确保前驱结点为SIGNAL才阻塞当前线程。因为只有前驱结点的waiteStatus为SIGNAL时才会在前驱结点release或cancel时唤醒其后继结点，才不至于使线程一直下去 。 7、AQS的release方法流程图 8、Node类关键属性1234567891011121314151617181920212223242526272829303132333435static final class Node { /** Marker to indicate a node is waiting in shared mode */ static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ static final Node EXCLUSIVE = null; /** waitStatus value to indicate thread has cancelled */ static final int CANCELLED = 1; /** waitStatus value to indicate successor's thread needs unparking */ static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ static final int PROPAGATE = -3; /** * 值只可取CANCELLED（1）,SIGNAL（-1）,CONDITION（-2）,PROPAGATE（-3）,0。当值非负时意味着结点无需唤醒。 * 所以，大多数代码不需要检查特定值，只需要检查符号即可。 * 结点作为同步队列结点时初始化为0，作为条件队列结点时初始化为CONDITION（-2）。 **/ volatile int waitStatus; /** 前驱结点**/ volatile Node prev; /** 后继结点**/ volatile Node next; /** 结点持有线程**/ volatile Thread thread; /** 连接条件队列的下个结点，或者为SHARED。 * 因为条件队列只有在独占模式下保持时才被访问，所以我们只需要一个简单的链接队列来保持节点在等待条件时的状态。然后将它们转移到队列以重新获取。 * 由于条件只能是互斥的，所以我们通过使用SHARED表示共享模式。 **/ Node nextWaiter;} 9、acquire源码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889 /** * 以排他的方式去占有，且在此过程中忽略中断。实现时会至少调用一次tryAcquire方法。 * 1）若本方法返回则表示获取成功; * 2）否则，当前线程插入同步队列，状态在阻塞和非阻塞间反复转换，调用tryAcquire方法直到成功。 * * Note: 此方法可用于实现java.util.concurrent.locks.Lock#lock方法。 **/public final void acquire(int arg) { // 若tryAcquire失败，则把当前线程封装在Node中插入同步队列，入队后再尝试获取资源 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) { selfInterrupt(); }}/*** 以排他的方式去占有，该方法会查询对象的许可状态（state of the object permits）是否可以被排他的获取，如果是则成功占有。* 本方法常用于线程执行占有操作。如果本方法返回失败且线程还没有入队，则acquire方法会把当前线程插入同步队列，直到被其他线程的release信号唤醒。** Note：本方法可被用于实现java.util.concurrent.locks.Lock#tryLock方法**/protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException();}/*** 根据指定的模式和当前线程创建Node并插入同步队列**/private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // 尝试快速入队（是完整入队逻辑中的一个分支逻辑），若失败再执行完整入队逻辑 Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } // 完整入队逻辑 enq(node); return node;}/*** 把节点插入同步队列，必要时执行初始化逻辑**/private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize // 惰性初始化 if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } }}/*** 在同步队列中的线程通过排他、不中断的模式去acquire。* 本方法也可以用于条件等待方法。**/final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); }} 10、AQS的acquireShared源码12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Acquires in shared mode, ignoring interrupts. Implemented by * first invoking at least once {@link #tryAcquireShared}, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking {@link * #tryAcquireShared} until success. * * @param arg the acquire argument. This value is conveyed to * {@link #tryAcquireShared} but is otherwise uninterpreted * and can represent anything you like. */ public final void acquireShared(int arg) { if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); } private void doAcquireShared(int arg) { final Node node = addWaiter(Node.SHARED); boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head) { int r = tryAcquireShared(arg); if (r &gt;= 0) { setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; } } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } 11、AQS的release方法源码1234567891011121314151617181920212223242526272829303132333435363738394041/*** 在排他模式下release。当tryRease返回true时，unblocking一个或多个线程。* * Note: 本方法用于实现java.util.concurrent.locks.Lock#unlock方法。**/public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false;}/*** 如果存在后继节点，则唤醒后继节点**/private void unparkSuccessor(Node node) { /* * 如果状态是负数，则尝试去清除SIGNAL信号（该信号标识其后继节点需要唤醒）。 * 即使清除失败或状态已被等待的线程改变也没关系。 */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * 正常情况下被unpark的线程是其后继结点。 * 但是如果其后继结点为空或已被取消，则从tail向前回溯来发现真正的未取消的后继结点。 */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) { s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } if (s != null) LockSupport.unpark(s.thread);} 二、使用AQS的实现 以下流程图是通过阅读JDK8源码得出。 1、ReentrantLock ReentrantLock中state表示锁定次数，为0时表示未被锁定。默认使用非公平锁。 2、ReentrantReadWriteLock state为int类型，高16位用于读锁，低16位用于写锁。默认非公平锁。 3、Semaphore state表示许可数量。默认非公平锁。 4、CountDownLatch state是初始化时传入的参数。","link":"/2020/06/16/AQS%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/"},{"title":"Consistent_Hashing_and_Random_Trees翻译","text":"本文会挑拣该论文的部分章节进行翻译，旨在理解一致性hash的背景由来和原理。在此感谢百度翻译让翻译工作如此简单 一致性Hash和随机树：一种用于缓解网络热点的分布式缓存协议摘要 我们描述了一系列适用于分布式网络的缓存协议，这些协议可以用来减少或消除网络中热点的出现。我们的协议特别适用于大型网络，如Internet。因为大型网络中热点造成的延迟可能非常严重，并且不可能每个服务器都拥有有关整个网络当前状态的完整信息。本协议很容易使用现有的网络协议（如TCP/IP）实现，并且只需要很少的开销。本协议与局部控制（local control，局部控制是指cache结点可以自主处理请求，无需协调其他结点参与处理，可以理解为是无中心结构优势的一种体现）结合高效地利用现有资源，并随着网络的增长而平滑扩容。 我们的缓存协议基于一种特殊的哈希，我们称之为一致哈希。粗略地说，一致性哈希函数是一个随函数范围变化而变化最小的函数。通过开发良好的一致性哈希函数，我们能够开发缓存协议，而不需要用户对网络具有当前甚至一致的视图。我们相信，一致的散列函数最终可能被证明在其他应用程序中有用，例如分布式NameServer或仲裁系统。 1. 介绍在本文中，我们描述了分布式网络的缓存协议，可以用来减少或消除“热点”的发生。当大量客户端希望同时从单个服务器访问数据时，热点随时都会出现。如果服务器没有能力同时处理所有这些客户端的请求，那么将会导致服务降级或不可用。 我们大都经历过网络环境下的热点现象。一个Web站点可能突然变热，导致其在短时间内接收到远超其处理能力的请求数。事实上，一个站点在收到洪峰的请求时，往往会导致它服务不可用。另外，这些大量流量也会阻塞其附近的网络，干扰附近站点的流量。随着网络使用的增加，热点的发生和影响也随之增加。最近网络热点的著名例子包括苏梅克-列维9号彗星与木星的碰撞的JPL网站、IBM在Deep Blue-Kasparov国际象棋巡回赛期间的网站，以及选举当晚的几个政治网站。在其中一些情况下，一个网站长达数小时甚至数天拒绝用户访问。其他例子包括被识别为“每日网站”的网站和提供流行软件新版本的网站。 我们的工作最初是由万维网上的热点问题推动的。我们相信我们开发的工具也会与大部分的Client-Server架构模型相关，因为Internet上的集中式服务器（如域名服务器、多播服务器和内容标签服务器）也容易受到热点的影响。 1.1 过去的成果当前已经有人提出了几种克服热点的方法。大多数应用程序使用某种复制策略在整个Internet上存储热页的副本；这把为热页提供服务的工作分散到多个服务器上。在一种已经广泛使用的方法中，多个客户机共享一个代理缓存。所有的用户请求都通过代理进行转发，代理试图保留频繁请求的页面的副本。它尝试使用缓存副本来满足请求；如果失败，它会将请求转发到主服务器。这种方案的困境在于，如果有更多的用户共享同一个缓存，那么会有更多的好处，但是缓存本身很容易被淹没（被某种缓存算法清理，如LRU，LFU）。 Malpani等人通过将一组缓存作为一个整体来解决这个问题。用户对页面的请求被定向到任意缓存。如果页面存储在那里，它将返回给用户。否则，缓存会通过一个称为“IP多播”的特殊协议将请求转发给所有其他缓存。如果页面没有缓存，请求将转发到页面的主页。这种技术的缺点是，随着参与缓存的数量的增加，即使使用多播，缓存之间的消息数量也会变得不可管理。我们在本文中开发的一个工具，一致性哈希，提供了一种实现这种分布式缓存的方法，而不需要缓存一直通信。我们将在第4节中讨论这一点。 Chankhunthod等人开发了Harvest缓存，这是一种使用缓存树的更具可伸缩性的方法。用户通过询问附近的叶缓存来获取页面。如果此缓存及其同级都没有该页，则请求将转发到缓存的父级。如果树中没有缓存存储页面，则请求最终到达根目录并转发到页面的主页。缓存会把它获得的任何页面的副本都保留一段时间。缓存树的优点是缓存仅从其子级（和同级）接收页请求，从而确保不会有太多的请求同时到达。因此，短时间内对一个页面的多个请求只会导致一个请求打到该页面的主服务器，且不会使缓存过载。在理论上，至少有一个缺点是所有页都使用同一棵树，这意味着根目录对整个缓存树中请求的每个不同页至少接收一个请求。如果不同页面请求的数量增长过大，这可能会淹没根目录，这意味着此方案还存在潜在的扩展问题。 Plaxton和Rajaraman展示了如何通过使用随机化和散列来平衡所有缓存之间的负载。特别是，它们为每个页面使用一个由越来越大的“虚拟缓存站点”组成的层次结构，并使用随机哈希函数将每个虚拟站点的责任分配给网络中的实际缓存。客户端向层次结构中每个集合中的随机元素发送请求。集群接收分配给他的缓存页，但当其发现自身负载过重时，会将页复制到下一个较大集群的某些成员。这样即使对于热点页面也能给出快速响应，因为缓存该页面的最大集群不会过载。它还提供了良好的负载平衡，因为加载某个页面的小集群很可能隶属于加载另一个页面的大集群。Plaxton和Rajaraman的技术也是容错的。 然而，Plaxton/Rajaraman算法有缺点。例如，由于他们的算法将每个页面请求的一个副本发送给每个集合中的一个随机元素，因此热点页面的小集合肯定会被淹没。事实上，该算法将缓存丢失作为一种特性，因为缓存丢失用于触发复制。这在他们的同步并行系统模型中运行得很好，在同步并行系统模型中，假定一个被淹没的缓存结点只处理接收到的部分输入消息，其他消息仍按正常方式进行处理。然而，在互联网上，缓存丢失的后果要严重得多。甚至不能依靠被淹没的机器迅速恢复。此外，大量随机机器的有意涌入很可能会被这些机器的所有者视为不利因素。Plaxton/Rajaraman算法还要求所有通信都是同步的或messages具有优先级，并且可用的缓存集是固定的，并且所有用户都知道。 1.2 我们的贡献在这里，我们描述了两种数据复制工具，并使用它们给出了一种缓存算法，该算法克服了预放弃方法的缺点，并且具有一些额外的、理想的属性。 我们的第一个工具，随机缓存树，结合了Chankhunthod等人和Plaxton/Rajaraman使用的结构的各个方面。像Chankhunthod等人一样，我们使用缓存树来合并请求。与Plaxton和Rajaraman一样，我们通过为每个页面使用不同的树并通过随机哈希函数将树节点分配给缓存来平衡负载。通过将Chankhunthod等人和Plaxton/Rajaraman的最佳特性与我们自己的方法相结合，我们可以防止任何服务器被高概率淹没，这是Chankhunthod等人或Plaxton/Rajaraman都不具备的特性。此外，我们的协议还展示了如何通过只缓存请求了足够次数的页面来最小化内存需求（而不显著增加缓存未命中率）。 我们认为缓存树所引入的额外延迟在实践中应该非常小。请求页面的时间会随树的深度而倍增。但是，页面请求通常占用的时间很少，因此额外的延迟不是很大。页的返回可以通过管道进行；缓存不需要等到它接收到整个页之后才将数据发送到树中的子页。因此，返回一个页面也只需要稍微长一点。总之，用户看到的附加延迟很小。 我们的第二个工具是一个新的哈希方案，我们称之为一致的散列。这种散列方案与Plaxton/Rajaraman和其他实际系统中使用的散列方案有很大不同。典型的基于散列的方案可以很好地通过已知的固定服务器集合分散负载。然而，互联网并没有固定的机器集合。取而代之的是，机器会因崩溃或进入网络而进出集群。更糟糕的是，关于哪些机器起作用的信息在网络中传播得很慢，因此客户机可能对哪些机器可以复制数据有不兼容的“视图”。这使得标准散列变得毫无用处，因为它依赖于客户机约定哪些缓存负责为特定页面提供服务。例如，Feeley等人为工作站网络实现了一个分布式全局共享内存系统，该系统使用分布在机器之间的哈希表来解析引用。每次一台新机器加入网络时，都需要一个中央服务器将一个完全更新的哈希表重新分发给所有机器。 一致性哈希可能有助于解决此类问题。像大多数散列方案一样，一致性散列将一组项目分配给buckets，这样每个bin接收的项目数大致相同。与标准散列方案不同，bucket集合中的一个小更改不会导致Key到bucket的完全重新映射。此外，将项目散列到稍微不同的bucket集合中，只会为bucket分配稍微不同的项目。我们将一致性哈希应用到我们的缓存树方案中，并展示了即使每个客户机只知道所有缓存机器中的一小部分，该方案如何工作良好。Litwin等人提出的一种哈希函数，允许按顺序一次添加一个桶。但是，我们的哈希函数允许按任意顺序添加bucket。另一个我们可以改进的方案是Devine[2]。此外，我们认为，一致性哈希在其他应用程序（如仲裁系统或分布式名称服务器）中也很有用，在这些应用程序中，具有不同网络视图的多台计算机必须在没有通信的情况下为一个对象商定一个公共存储位置。 1.3 章节简述在第2节中，我们描述了我们的Web模型和热点问题。我们的模型必然过于简单化，但足够丰富，可以开发和分析我们认为在实践中可能有用的协议。在第3节中，我们描述了我们的随机树方法，并将其用于缓存协议中，该协议在简化模型下有效地消除了热点。独立于第3节，在第4节中，我们介绍了我们的一致散列方法，并使用它来解决不同简化模型下涉及不一致视图的热点问题。 在第5节中，我们将展示如何将这两种技术有效地结合起来。在第6节中，我们提出了一个简单的延迟模型，该模型描述了互联网上机器的分层集群。我们表明，我们的协议可以很容易地扩展到工作在这个更真实的延迟模型。在第7节和第8节中，我们分别考虑了故障和协议随时间的行为。在第9节中，我们讨论了一些扩展和开放问题。 1.4 关于随机化和散列的一点注记在一些地方，我们使用散列函数将对象映射到一个范围。为清楚起见，我们假设这些函数以真正随机的方式映射对象，即一致和独立地映射对象。实际上，具有有限独立性的哈希函数更容易实现，因为它们节省了空间和随机性。我们用类似于文献[11]的方法证明了本文的所有定理，它们只具有有限的独立性。然而，在这个扩展的摘要中，我们只说明了结果所需的独立程度。假设独立性有限的证明将出现在本文的完整版本中。 4. 一致性Hash在本节中，我们将定义一种新的哈希技术，称为一致哈希。我们通过参考一个简单的互联网数据复制方案来促生这项技术。考虑一个服务器，它有大量其他客户端可能要访问的对象。在客户机和服务器之间引入一层缓存以减少服务器上的负载是很自然的。在这种方案中，对象应该分布在各个缓存中，这样每个缓存负责大致相等的份额。此外，客户机需要知道要为特定对象查询哪个缓存。最明显的方法是散列。服务器可以使用散列函数将对象均匀分布在缓存中。客户机可以使用哈希函数来发现哪个缓存存储对象。现在考虑一下，当一组活动缓存机器发生变化时，或者当每个客户机都知道一组不同的缓存时，会发生什么（这种情况在互联网上是非常合理的）。如果分布是用一个经典的散列函数（例如，线性同余函数x -&gt; ax + b (mod p) ）完成的，这种一致性将是灾难性的。当hash函数的范围（例子中的p）发生变化，几乎所有的项都需要rehash到新的位置。这导致突然之间所有缓存的数据都失效了，因为客户机正在另一个位置查找它。 一致性哈希解决了不同“视图”的问题。我们将视图定义为特定客户机知道的缓存集。我们假设，虽然视图可能不一致，但它们是实质性的：每台机器都知道当前正在运行的缓存中有一个恒定的部分。客户机使用一致的哈希函数将对象映射到其视图中的一个缓存。我们分析并构造具有以下一致性属性的哈希函数。首先，有一个“平滑”属性。当一台机器被添加到缓存集或从缓存集中删除时，必须移动到新缓存的对象的预期比例是保持缓存间负载平衡所需的最小值。其次，在所有客户机视图中，一个对象很少会被分配到多个缓存，我们称之为“s pread”。类似地，在所有客户机视图中，一个缓存也很少接受差异较大的不同对象，我们称这个属性为“load”。 因此，一致散列解决了上面讨论的问题。“spread”属性意味着即使存在不一致的全局视图，对给定对象的引用也只指向少数缓存机器。将一个对象分发到这个小的缓存集将确保所有客户机都可以访问，而不需要使用大量的存储。“load”属性意味着没有一个缓存被分配不合理数量的对象。“平滑度”属性意味着缓存机器集的平滑变化与缓存对象位置的平滑演变相匹配。 由于有许多方法可以将上述一致性概念形式化，因此我们将不对其进行精确定义。相反，在第4.4节中，我们定义了一个“范围散列函数”，然后精确地定义了几个捕获不同“一致性”方面的量。在第4.2节中，我们构造了实际的哈希函数，在一定程度上展示了这四个函数。在第4.4节中，我们讨论了一致性哈希的其他方面，尽管与本文不同，但这表明了该理论背后的一些丰富性。 4.1 定义// TODO","link":"/2021/01/19/Consistent_Hashing_and_Random_Trees%E7%BF%BB%E8%AF%91/"},{"title":"Debian包管理","text":"一、Debian包管理图片来源 其概念可类比Maven，一样一样的。 APT包管理 Maven依赖管理 APT客户端 Maven客户端 DEB包 Java的Jar包 分发平台 Maven远程仓库 官方仓库 Maven中央仓库 额外仓库 Maven私服，非中央仓库 二、包仓库配置12345# 官方仓库/etc/apt/sources.list# ppa仓库/etc/apt/sources.list.d/*.list 三、包仓库软件Software &amp; Updates：用于配置仓库信息，自动检查更新，认证等。 Software Updater：用于检查仓库更新 四、DEB密钥管理应用场景 把某个Deb包的GPG公钥加入到Deb密钥管理库，此公钥会用来验证DEB的完整和合法性。 12# wget -O后面的-表示下载到标准输出wget -O - https://repo.fortinet.com/repo/6.4/ubuntu/DEB-GPG-KEY | sudo apt-key add - 分析 1）下载一个DEB包的GPG公钥 123456789101112131415161718192021$ wget -O tmp.gpg https://repo.fortinet.com/repo/6.4/ubuntu/DEB-GPG-KEY-----BEGIN PGP PUBLIC KEY BLOCK-----Version: GnuPG v1mQENBFst9sYBCADK9Wl8PCqSeKq75o4j7y65J8uEfvctyANV2YHqcqIC6DITnPpEhAy0AybhVGnWLXuApsCgSFvFW81lE/AWBVaZzbtTMoM8PeVTEsts13bp/Ww1VFzYZp6z7Pz9KVd4rhauHsDx9QZ+7/BNRe5YlcLfWsF56jOgxIKax5tVudC6OelAf8mLtIGGlZYDHzJD55SaRjRTgZSrK/KcLxnmYbIGrkNaCN7bW26jFbkBfM2aesu8/zgwHSTHqlJuvaup+8jiavCwIzh0kOuUO3ZLrH0f9vOu17KuEJl+9eAsGo73TI496wx1JWr9yTw/61HzJu6+MjadtBgh/sjJXggJLOBBABEBAAG0VkZvcnRpbmV0XEZvcnRpQ2xpZW50IChGb3J0aW5ldCBGb3J0aUNsaWVudCBERUIgUGFja2FnZSBTaWduaW5nKSA8c3VwcG9ydEBmb3J0aW5ldC5jb20+iQE+BBMBAgAoBQJbLfbGAhsDBQkJZgGABgsJCAcDAgYVCAIJCgsEFgIDAQIeAQIXgAAKCRAYrCY5XlRxbT6bB/0QIRM9FtOz9yMJdO/C7dYNvjdB6ynamAMIjTzaGXmd281LhHuBOKv9C7NceisJlUjbty1V365Le3gS8zjaCgr+rerH+Zx8YZVix+GmmvkqZagFUHHleDlVZV6KSJberv7TKir4EwReuabYyn93hyOmpF96Nliu9+g8nvvRzgYotANwl6PrhKKyy8emQHNcbQCxuL0PPt9iFiAxMhE9mXWaIXjXyMA6kVE6rfUy/3QJIHj0ukc+9kdScMRx4lJ/qYImT/RLDTpNbZmV1i0sRCydEcKHsTuMgW8bPigGwNfYwlT09mGplc5jQ1SfCHidI9cOmzWAy33HWmrE2K1T4Oio=pYOe-----END PGP PUBLIC KEY BLOCK----- 2）查看GPG公钥信息 –show-keys This commands takes OpenPGP keys as input and prints information about them in the same way the command –list-keys does for locally stored key. 12345# --show-keys查看导入前信息，--list-keys查看导入后的信息$ gpg --show-keys tmp.gpgpub rsa2048 2018-06-23 [SC] [expires: 2023-06-22] 264E114C6911D08D3BA6CE6C18AC26395E54716Duid Fortinet\\FortiClient (Fortinet FortiClient DEB Package Signing) &lt;support@fortinet.com&gt; 3）查看系统已信任的公钥 从Software &amp; Updates查看 命令查看 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105$ apt-key list/etc/apt/trusted.gpg--------------------pub rsa4096 2016-04-12 [SC] EB4C 1BFD 4F04 2F6D DDCC EC91 7721 F63B D38B 4796uid [ unknown] Google Inc. (Linux Packages Signing Authority) &lt;linux-packages-keymaster@google.com&gt;sub rsa4096 2019-07-22 [S] [expires: 2022-07-21]pub dsa1024 2010-03-30 [SC] C946 7A82 16C5 70CD FBAC 3AFD 331D 6DDE 7F88 40CEuid [ unknown] Scooter Software &lt;support@scootersoftware.com&gt;sub elg2048 2010-03-30 [E]pub rsa4096 2017-12-15 [SCEA] 0A0F AB86 0D48 5603 32EF B581 B754 42BB DE9E 3B09uid [ unknown] https://packagecloud.io/AtomEditor/atom (https://packagecloud.io/docs#gpg_signing) &lt;support@packagecloud.io&gt;sub rsa4096 2017-12-15 [SEA]pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid [ unknown] Docker Release (CE deb) &lt;docker@docker.com&gt;sub rsa4096 2017-02-22 [S]pub rsa4096 2018-10-08 [SCEA] 6D39 8DBD 30DD 7894 1E2C 4797 FE2A 5F8B DC28 2033uid [ unknown] https://packagecloud.io/github/git-lfs (https://packagecloud.io/docs#gpg_signing) &lt;support@packagecloud.io&gt;sub rsa4096 2018-10-08 [SEA]pub rsa2048 2016-09-25 [SC] 4AC4 41BE 68B4 ADAB 7439 FBF9 BA30 0B77 55AF CFAEuid [ unknown] Abner Lee &lt;abner@typora.io&gt;pub rsa2048 2015-06-26 [SC] 4CE5 2459 3899 65F1 DEE0 33AE 6E21 12BA CBDD C1A6uid [ unknown] Send Anywhere Linux Team &lt;support.linux@estmob.com&gt;sub rsa2048 2015-06-26 [E]pub rsa1024 2009-01-22 [SC] E1DD 2702 88B4 E603 0699 E45F A171 5D88 E1DF 1F24uid [ unknown] Launchpad PPA for Ubuntu Git Maintainerspub rsa4096 2020-05-06 [SCEA] [expires: 2030-05-04] 81BF 832E 2F19 CD2A A047 1959 294A C482 7C1A 168Auid [ unknown] Helm hosted by Balto (Repository signing) &lt;gpgsecurity@getbalto.com&gt;pub rsa4096 2017-04-11 [SC] [expired: 2019-09-28] D4CC 8597 4C31 396B 18B3 6837 D615 560B A5C7 FF72uid [ expired] Opera Software Archive Automatic Signing Key 2017 &lt;packager@opera.com&gt;pub rsa4096 2019-09-12 [SC] [expired: 2021-09-11] 68E9 B2B0 3661 EE3C 44F7 0750 4B8E C3BA ABDC 4346uid [ expired] Opera Software Archive Automatic Signing Key 2019 &lt;packager@opera.com&gt;pub rsa2048 2018-06-23 [SC] [expires: 2023-06-22] 264E 114C 6911 D08D 3BA6 CE6C 18AC 2639 5E54 716Duid [ unknown] Fortinet\\FortiClient (Fortinet FortiClient DEB Package Signing) &lt;support@fortinet.com&gt;pub rsa4096 2021-06-23 [SC] [expires: 2023-06-23] 9FBD E02F 55F2 54D7 0082 1CCC DD3C 368A 8DE1 B7A0uid [ unknown] Opera Software Archive Automatic Signing Key 2021 &lt;packager@opera.com&gt;sub rsa4096 2021-06-23 [E] [expires: 2023-06-23]pub rsa4096 2019-03-15 [SC] 8B1B C7FE CB72 59E1 430A 3AA0 26EB 3912 3AAA AA96uid [ unknown] Access Server (Access Server Package Key) &lt;packaging@openvpn.net&gt;sub rsa4096 2019-03-15 [E]pub rsa4096 2019-02-13 [SC] 8A90 3102 6374 5AEB CF58 5F02 5511 80AB 92C3 19F8uid [ unknown] OpenVPN PPA Repository Key &lt;pkg@openvpn.net&gt;sub rsa4096 2019-02-13 [E]pub rsa4096 2015-05-16 [SC] D1E5 B25F 1DC2 7EE8 8019 EA18 61FF 9694 161C E595uid [ unknown] Launchpad PPA for enaess/etc/apt/trusted.gpg.d/daniel-marynicz_ubuntu_filemanager-actions.gpg---------------------------------------------------------------------pub rsa4096 2018-05-19 [SC] 31E7 BE38 2EB4 A40B 3334 A1DF A279 F292 7618 CC1Duid [ unknown] Launchpad PPA for Daniel/etc/apt/trusted.gpg.d/eivnaes_ubuntu_network-manager-sstp.gpg--------------------------------------------------------------pub rsa4096 2015-05-16 [SC] D1E5 B25F 1DC2 7EE8 8019 EA18 61FF 9694 161C E595uid [ unknown] Launchpad PPA for enaess/etc/apt/trusted.gpg.d/fossfreedom_ubuntu_indicator-sysmonitor.gpg------------------------------------------------------------------pub rsa1024 2012-01-05 [SC] 0D87 EE08 4E8D B990 ADD3 899C 82EB 5823 F4FE 239Duid [ unknown] Launchpad PPA for fossfreedom/etc/apt/trusted.gpg.d/george-edison55_ubuntu_nitroshare.gpg------------------------------------------------------------pub rsa1024 2010-08-02 [SC] B118 CD3C 377D F930 EDD0 6C67 084E CFC5 828A B726uid [ unknown] Launchpad George Edison's PPA/etc/apt/trusted.gpg.d/linuxuprising_ubuntu_libpng12.gpg--------------------------------------------------------pub rsa4096 2018-04-06 [SC] 1CC3 D16E 460A 94EE 17FE 581C EA8C ACC0 73C3 DB2Auid [ unknown] Launchpad PPA for Linux Uprising # 参考 GPG入门教程 ubuntu中deb包签名与应用 apt-key命令","link":"/2021/09/29/Debian%E5%8C%85%E7%AE%A1%E7%90%86/"},{"title":"DNS和URL重定向","text":"一、DNS流程DNS是一种应用层协议，DNS客户端请求DNS服务器把域名解析为目标IP。 图片来源 二、Url转发流程URL转发使用http 301，302状态码响应请求端，使其redirect到另一个URL。 图片来源 三、DNS和Url转发的对比1）基于协议不同 DNS基于DNS协议 URL转发使用的HTTP协议 2）发生阶段不同 DNS发生在HTTP连接建立前，通过DNS获取目标的IP URL转发发生在HTTP连接已建立 3）功能不同 DNS主要是返回域名对应的IP URL转发至完整路径的URI，如果是不同的域名的URI，需要触发DNS再次解析域名。 NOTE：现在大部分提供DNS服务的网站，也提供了URL转发服务。如腾讯云DNS解析控制台 # 参考 https://en.wikipedia.org/wiki/URL_redirection https://en.wikipedia.org/wiki/Domain_Name_System https://zh.wikipedia.org/wiki/%E5%9F%9F%E5%90%8D%E7%B3%BB%E7%BB%9F https://zh.wikipedia.org/wiki/DNS%E8%AE%B0%E5%BD%95%E7%B1%BB%E5%9E%8B%E5%88%97%E8%A1%A8 https://aws.amazon.com/cn/route53/what-is-dns/","link":"/2021/03/22/DNS%E5%92%8CURL%E9%87%8D%E5%AE%9A%E5%90%91/"},{"title":"Debug时科学观察变量","text":"一、问题描述近日晚间有开发使用EDI的IDE开发完流程后，执行调试时，发现流程中的第一个数据转换结点的结果多出了一个属性值X-Ca-Signature-Headers。 二、原因1）第二个DT结点对第一个DT结点的输出做了修改；2）Debug视图看到的变量值是当前值，而非过去时刻的某个值； 三、Demo目的：验证Debug视图，在不同的栈帧中查看同一变量，其值都是当前值，而非程序运行到此栈帧的值。","link":"/2019/12/19/Debug%E6%97%B6%E7%A7%91%E5%AD%A6%E8%A7%82%E5%AF%9F%E5%8F%98%E9%87%8F/"},{"title":"Debug时加的观察变量影响了debug","text":"一、问题描述有这样一个流程：从FTP上下载文件后，会根据文件名读取缓存实现防重，其中缓存读取到的值会写入Camel的exchange，exchange.getIn().setBody(cacheValue);。 但是，通过日志观察该Body是一串无规律的字符，类似My8+PFNEMvPjxSRU1BUksxLz48UkMRT48TUFUTlI+QVBHTTA0OC02PC9NQVROUj48TUFLVFg+57qi6Imy5Ki75aSn5Y+36LSt54mp6KJWkVTX0RBVEE+PFNJWkU+MDAwPC9VNQVJLMi8+PFJFTUFSSzMvPjxSRU1BUks0Lz48L1NJWkVTX0RBVEE+PC9NQUlOX1RBQkxFPjwvUk9PTUFJTl9UQUJTSVpFPjxXRUlHSFQvPjxMRU5HVEgvPjxXSURUSC8+PEhFSUdIVC8+PElOQ0FTRU1FTlQvPjxFQU5VUKLPVD4D488Uk9PVC9NQUtUW。 二、排查路径1）测试缓存值非null情况 若缓存值非null，则body显示正常 若缓存不存在，Body显示为不规律字符串 2）查看运行日志 发现缓存节点执行结束时，*exchange.getIn.setBody(cacheValue)*的cacheValue变量确实是null。 但是缓存节点之后的日志节点打印的日志中，Body却是不规律字符串 3）远程断点Debug 断点设置在get-cache节点结束位置 验证了cacheValue确实是null 增加自定义变量，类似ElUtils.evaluate(“${body}”, exchange, Object,class)，观察到Body为字符串（此时产生了困惑，明明写入的是null，但是获取的body却非空） 根据断点时添加的观察变量，发现exchange.getIn()返回的是org.apache.camel.component.file.GenericFileMessage。 查看源码org.apache.camel.component.file.GenericFileMessage#setBody 源码里没有对null做特殊处理 123456789public abstract class MessageSupport implements Message, CamelContextAware, DataTypeAware { public void setBody(Object body) { this.body = body; // set data type if in use if (body != null &amp;&amp; camelContext != null &amp;&amp; camelContext.isUseDataType()) { this.dataType = new DataType(body.getClass()); } }} 断点设置在setBody方法里 观察变量this.body值，发现this.body，确实设为null 增加自定义变量，通过*ElUtils.evaluate(“${body}”, exchange, Object,class)*获取body值，发现body设为null后，然后又变为字符串 怀疑是el表达式子，最终调用的getBody方法重置了Body。 查看org.apache.camel.component.file.GenericFileMessage#getBody() 发现GenericFileMessage对null做了特殊处理，为空时会根据file重建body。 12345678910111213141516public abstract class MessageSupport implements Message, CamelContextAware, DataTypeAware { @Override public Object getBody() { if (body == null) { body = createBody(); } return body; }}public class GenericFileMessage&lt;T&gt; extends DefaultMessage { @Override protected Object createBody() { return file != null ? file.getBody() : super.createBody(); }} 三、总结此处问题的原因是，流程中FTP构造的Exchange中的message类型为GenericFileMessage，当该类型的message的body属性为空时，调用getBody方法会根据文件内容重置body属性。所以，我们看到哪些混乱的字符串实际上是FTP节点下载的文件内容的一种序列化表现。 总之，在Debug时你定义的观察变量有可能在未知处默默修改系统的运行变量，导致Debug时无法复现Run时的问题。如果有些变量因你观察而变化时，你就要评估下你的自定义变量是否隐式调用了一些修改类方法。","link":"/2021/03/11/Debug%E6%97%B6%E5%8A%A0%E7%9A%84%E8%A7%82%E5%AF%9F%E5%8F%98%E9%87%8F%E5%BD%B1%E5%93%8D%E4%BA%86debug/"},{"title":"DependencyManagment作用","text":"介绍 Dependency management：this allows project authors to directly specify the versions of artifacts to be used when they are encountered in transitive dependencies or in dependencies where no version has been specified. 从官网的描述中可以看出DependencyManagement有两个作用：1）对子pom的间接依赖的版本进行版本约束；2）对子pom中不声明版本的依赖进行版本约束； 参考 https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html https://blog.csdn.net/jiaobuchong/article/details/81842503","link":"/2020/12/16/DependencyManagment%E4%BD%9C%E7%94%A8/"},{"title":"Dubbo服务发布源码分析","text":"一、服务导出整体流程 二、ServiceConfig.export() 1234567891011121314151617public class ServiceConfig&lt;T&gt; extends ServiceConfigBase&lt;T&gt; { private static final ProxyFactory PROXY_FACTORY = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension(); private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) { // 以下为关键代码 // 通过ProxyFactory扩展点，对ref生成Invoker代理对象 Invoker&lt;?&gt; invoker = PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(EXPORT_KEY, url.toFullString())); // 对上一步生成的Invoker对象进行包装，生成DelegateProviderMetaDataInvoker DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); // 通过Protocol扩展点，执行导出逻辑 Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); exporters.add(exporter); }} 三、ProxyFactory.getInvoker()对ref进行封装1. ProxyFactory接口123456789101112@SPI(&quot;javassist&quot;)public interface ProxyFactory { // PROXY_KEY为“proxy” @Adaptive({PROXY_KEY}) &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException; @Adaptive({PROXY_KEY}) &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, boolean generic) throws RpcException; @Adaptive({PROXY_KEY}) &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) throws RpcException;} 由接口定义可知，其根据URL中的PROXY_KEY属性，即“proxy”属性作为扩点点类型获取扩展点实例。且默认扩展点类型为’javassist’。 2. ProxyFactory的自适应类通过打断点获取ProxyFactory自适应类源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142package org.apache.dubbo.rpc;import org.apache.dubbo.common.extension.ExtensionLoader;public class ProxyFactory$Adaptive implements org.apache.dubbo.rpc.ProxyFactory { public java.lang.Object getProxy(org.apache.dubbo.rpc.Invoker arg0) throws org.apache.dubbo.rpc.RpcException { if (arg0 == null) throw new IllegalArgumentException(&quot;org.apache.dubbo.rpc.Invoker argument == null&quot;); if (arg0.getUrl() == null) throw new IllegalArgumentException(&quot;org.apache.dubbo.rpc.Invoker argument getUrl() == null&quot;); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;); if (extName == null) throw new IllegalStateException(&quot;Failed to get extension (org.apache.dubbo.rpc.ProxyFactory) name from url (&quot; + url.toString() + &quot;) use keys([proxy])&quot;); org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getProxy(arg0); } public java.lang.Object getProxy(org.apache.dubbo.rpc.Invoker arg0, boolean arg1) throws org.apache.dubbo.rpc.RpcException { if (arg0 == null) throw new IllegalArgumentException(&quot;org.apache.dubbo.rpc.Invoker argument == null&quot;); if (arg0.getUrl() == null) throw new IllegalArgumentException(&quot;org.apache.dubbo.rpc.Invoker argument getUrl() == null&quot;); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;); if (extName == null) throw new IllegalStateException(&quot;Failed to get extension (org.apache.dubbo.rpc.ProxyFactory) name from url (&quot; + url.toString() + &quot;) use keys([proxy])&quot;); org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getProxy(arg0, arg1); } public org.apache.dubbo.rpc.Invoker getInvoker(java.lang.Object arg0, java.lang.Class arg1, org.apache.dubbo.common.URL arg2) throws org.apache.dubbo.rpc.RpcException { if (arg2 == null) throw new IllegalArgumentException(&quot;url == null&quot;); org.apache.dubbo.common.URL url = arg2; String extName = url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;); if (extName == null) throw new IllegalStateException(&quot;Failed to get extension (org.apache.dubbo.rpc.ProxyFactory) name from url (&quot; + url.toString() + &quot;) use keys([proxy])&quot;); org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getInvoker(arg0, arg1, arg2); } 默认情况下调用链如下： ProxyFactory$Adaptive.getInvoker() -&gt; JavassistProxyFactory.getInvoker() 通过JavassistProxyFactory把ref封装为AbstractProxyInvoker对象。 四、ServiceConfig对ProxyFactory结果再次封装DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); 五、protocol.export(wrapperInvoker)protocol是自适应Protocol类，会根据URL属性找到对应类型的扩展点执行export。 1. RegistryProtocol.export()protocol根据URL”registry://127.0.0.1:2181/org.apache.dubbo.registry.RegistryService?…”找到RegistryProtocol类型扩展点。 NOTE：外面的ProtocolListenerWrapper,ProtocolFilterWrapper,QosProtocolWwrapper为包装类。 RegistryProtocol中会复写URL为“dubbo://ip:port/接口名?…”，然后再次调用protocol自适应类找到DubboProtocol扩展点执行export。调用关系如上图所示。 12345678910111213package org.apache.dubbo.registry.integration;public class RegistryProtocol implements Protocol { // 此时providerUrl格式为“dubbo://ip:port/接口名?...” private &lt;T&gt; ExporterChangeableWrapper&lt;T&gt; doLocalExport(final Invoker&lt;T&gt; originInvoker, URL providerUrl) { String key = getCacheKey(originInvoker); return (ExporterChangeableWrapper&lt;T&gt;) bounds.computeIfAbsent(key, s -&gt; { Invoker&lt;?&gt; invokerDelegate = new InvokerDelegate&lt;&gt;(originInvoker, providerUrl); return new ExporterChangeableWrapper&lt;&gt;((Exporter&lt;T&gt;) protocol.export(invokerDelegate), originInvoker); }); }} 由上面源码可知，执行DubboProtocol#export前，RegistryProtocol会对invoker再次包装。 2. DubboProtocol.export()调用DubboProtocol#export前，需经过ProtocolListenerWrapper,ProtocolFilterWrapper,QosProtocolWwrapper包装类的处理逻辑。 1）ProtocolFilterWrapper 该包装类会为Invoker进行Filter包装，生成Filter链。 2）DubboProtocol#export Ø DubboProtocol#export方法会生成DubboExporter，并调用openServer()方法，然后返回； Ø 然后会经过包装类ProtocolListenerWrapper#export再次包装为ListenerExporterWrapper。 Ø 然后会在RegistryProtocol#doLocalExport里再次包装为ExporterChangeableWrapper。 Ø 然后会在RegistryProtocol#export里再次包装为DestroyableExporter。 六、DubboProtocol.openServerDubboProtocol.openServer中会调用createServer，该方法会调用Exchangers.bind(url, requestHandler); 其中，requestHandler是接收请求并根据请求URL从exportMap中找到对应的Exporter，然后根据Exporter获取Invoker，进行调用。 12345678910111213141516171819202122public class Exchangers { public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException { if (url == null) { throw new IllegalArgumentException(&quot;url == null&quot;); } if (handler == null) { throw new IllegalArgumentException(&quot;handler == null&quot;); } url = url.addParameterIfAbsent(Constants.CODEC_KEY, &quot;exchange&quot;); return getExchanger(url).bind(url, handler); } public static Exchanger getExchanger(URL url) { // Constants.DEFAULT_EXCHANGER值为header String type = url.getParameter(Constants.EXCHANGER_KEY, Constants.DEFAULT_EXCHANGER); return getExchanger(type); } public static Exchanger getExchanger(String type) { return ExtensionLoader.getExtensionLoader(Exchanger.class).getExtension(type); }} Exchangers.bind方法会从URL中获取exchange属性，默认值为header。一般会找到类型为”header”的扩展点HeaderExchanger，进行bind。 12345678910111213public class HeaderExchanger implements Exchanger { public static final String NAME = &quot;header&quot;; @Override public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException { return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))), true); } @Override public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException { return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler)))); }} HeaderExchanger会对requestHander进行封装HeaderExchangeHander，DecodeHander。然后再调用Trasporters进行进一步bind。 12345678910111213141516171819202122232425public class Transporters { public static RemotingServer bind(String url, ChannelHandler... handler) throws RemotingException { return bind(URL.valueOf(url), handler); } public static RemotingServer bind(URL url, ChannelHandler... handlers) throws RemotingException { if (url == null) { throw new IllegalArgumentException(&quot;url == null&quot;); } if (handlers == null || handlers.length == 0) { throw new IllegalArgumentException(&quot;handlers == null&quot;); } ChannelHandler handler; if (handlers.length == 1) { handler = handlers[0]; } else { handler = new ChannelHandlerDispatcher(handlers); } return getTransporter().bind(url, handler); } public static Transporter getTransporter() { return ExtensionLoader.getExtensionLoader(Transporter.class).getAdaptiveExtension(); }} Trasporters会通过Transporter的自适应类从URL获取server属性，默认为netty，即NettyTransporter。其会调用NettyServer构造函数。 12345public NettyServer(URL url, ChannelHandler handler) throws RemotingException { // you can customize name and type of client thread pool by THREAD_NAME_KEY and THREADPOOL_KEY in CommonConstants. // the handler will be warped: MultiMessageHandler-&gt;HeartbeatHandler-&gt;handler super(ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME), ChannelHandlers.wrap(handler, url)); } 在构造函数中，会对handler进行进一步包装。 1234protected ChannelHandler wrapInternal(ChannelHandler handler, URL url) { return new MultiMessageHandler(new HeartbeatHandler(ExtensionLoader.getExtensionLoader(Dispatcher.class) .getAdaptiveExtension().dispatch(handler, url))); } 最终，会生成如下结构。 七、服务发布最终结构 其在ZK上的注册结构内容为： /dubbo/org.apache.dubbo.demo.DemoService/providers/dubbo%3A%2F%2F192.168.199.172%3A20880%2Forg.apache.dubbo.demo.DemoService%3Fanyhost%3Dtrue%26application%3Ddubbo-demo-api-provider%26default%3Dtrue%26deprecated%3Dfalse%26dubbo%3D2.0.2%26dynamic%3Dtrue%26generic%3Dfalse%26interface%3Dorg.apache.dubbo.demo.DemoService%26methods%3DsayHello%2CsayHelloAsync%26pid%3D21327%26release%3D%26side%3Dprovider%26timestamp%3D1621957958046 URL Decode: 1/dubbo/org.apache.dubbo.demo.DemoService/providers/dubbo://192.168.199.172:20880/org.apache.dubbo.demo.DemoService?anyhost=true&amp;application=dubbo-demo-api-provider&amp;default=true&amp;deprecated=false&amp;dubbo=2.0.2&amp;dynamic=true&amp;generic=false&amp;interface=org.apache.dubbo.demo.DemoService&amp;methods=sayHello,sayHelloAsync&amp;pid=21327&amp;release=&amp;side=provider&amp;timestamp=1621957958046 # 参考 Dubbo框架设计","link":"/2021/05/15/Dubbo%E6%9C%8D%E5%8A%A1%E5%8F%91%E5%B8%83%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"ES倒排索引","text":"一、倒排索引倒排索引概念倒排索引是适用于全文检索的一种索引结构，ES使用的正是这种结构。把一段需要建立倒排索引的文本（document）进行分词，然后建立词（term）到文本（document）的一对多的映射关系。这种由document内容反向索引documentId的映射结构，称为反向索引。 与反向索引相对的是正向索引，其会根据docuemntId去索引文本内容。 书籍类比 书籍每页的内容可看作document，页码可看作documentId，关键字可看作term。 正排索引相当于书籍的目录，我们可以根据页码索引到文章： 倒排索引则相当于书籍后面的关键字索引，我们可以根据关键字索引到包含其的文档的页码。 二、ES倒排索引结构 ES的倒排索引是Index内document的field级别的(参考)。即，每个Index下document中需要建立索引的field，都会建立一个单独的倒排索引结构。 ES是Lucene的封装，底层用的是lucene存储结构，lucene存储结构链接，其所有文件类型如下： 从其文档可看出，Lucene把term位置，出现频率，term字典单独存储，然后在term字典里隐式的指向了频率文件，位置文件的位置。 下面图片（图片来源）与Lucene文件的对应关系： 1）Posting List对应.prx文件； 2）Term Dictionary对应.tis文件 3）Term Index对应.tii文件 参考 ES官方文档 —— 倒排索引 Lucene官方文档——倒排索引文件格式 stackoverflow - whats-the-difference-between-an-inverted-index-and-a-plain-old-index https://codingexplained.com/coding/elasticsearch/understanding-the-inverted-index-in-elasticsearch","link":"/2021/05/30/ES%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"},{"title":"ES_CPU飚高","text":"一、第一次CPU飚高1）执行命令查看线程 1$ GET _nodes/hot_threads hot_threads_1.txt 2）关键堆栈： 123456789org.apache.lucene.store.FSDirectory.fileLength(FSDirectory.java:243)org.elasticsearch.index.store.ByteSizeCachingDirectory.estimateSizeInBytes(ByteSizeCachingDirectory.java:55) org.elasticsearch.index.store.ByteSizeCachingDirectory.access$200(ByteSizeCachingDirectory.java:36)org.elasticsearch.index.store.ByteSizeCachingDirectory$1.refresh(ByteSizeCachingDirectory.java:89) org.elasticsearch.index.store.ByteSizeCachingDirectory$1.refresh(ByteSizeCachingDirectory.java:71) org.elasticsearch.common.util.SingleObjectCache.getOrRefresh(SingleObjectCache.java:54)org.elasticsearch.index.store.ByteSizeCachingDirectory.estimateSizeInBytes(ByteSizeCachingDirectory.java:120)org.elasticsearch.index.store.Store$StoreDirectory.estimateSize(Store.java:723)org.elasticsearch.index.store.Store.stats(Store.java:362)org.elasticsearch.index.shard.IndexShard.storeStats(IndexShard.java:971)org.elasticsearch.action.admin.indices.stats.CommonStats.&lt;init&gt;(CommonStats.java:180)org.elasticsearch.action.admin.indices.stats.TransportIndicesStatsAction.shardOperation(TransportIndicesStatsAction.java:178) org.elasticsearch.action.admin.indices.stats.TransportIndicesStatsAction.shardOperation(TransportIndicesStatsAction.java:48) 3）结论： GET /indices/_stats命令导致CPU飚高。 https://github.com/elastic/elasticsearch/issues/19313 look at this hot thread stack, it seem like you request Get /indices/_stats request to es, which would sum all index files size. And this is very expensive, for this request will make many linux system call.If you have many index, and the index’s file num is big. Get /indices/_stats will led the node’s cpu usage high. I had test this situation in my ES cluster, if have more than 100 index, and send Get /indices/_stats every second, the cpu usage will keep 80% above. 二、第二次CPU飚高1）执行命令查看线程 1$ GET _nodes/hot_threads hot_threads_2.txt 2）关键堆栈 1234567891011121314151617181920212223org.wltea.analyzer.lucene.IKTokenizer.incrementToken(IKTokenizer.java:88)org.apache.lucene.index.DefaultIndexingChain$PerField.invert(DefaultIndexingChain.java:787)org.apache.lucene.index.DefaultIndexingChain.processField(DefaultIndexingChain.java:430)org.apache.lucene.index.DefaultIndexingChain.processDocument(DefaultIndexingChain.java:394)org.apache.lucene.index.DocumentsWriterPerThread.updateDocument(DocumentsWriterPerThread.java:251)org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:494)org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1609)org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1228)org.elasticsearch.index.engine.InternalEngine.addDocs(InternalEngine.java:1125)org.elasticsearch.index.engine.InternalEngine.indexIntoLucene(InternalEngine.java:1070)org.elasticsearch.index.engine.InternalEngine.index(InternalEngine.java:897)org.elasticsearch.index.shard.IndexShard.index(IndexShard.java:772)org.elasticsearch.index.shard.IndexShard.applyIndexOperation(IndexShard.java:741)org.elasticsearch.index.shard.IndexShard.applyIndexOperationOnPrimary(IndexShard.java:705)org.elasticsearch.action.bulk.TransportShardBulkAction.lambda$executeIndexRequestOnPrimary$3(TransportShardBulkAction.java:461)org.elasticsearch.action.bulk.TransportShardBulkAction$$Lambda$2609/1493261797.get(Unknown Source)org.elasticsearch.action.bulk.TransportShardBulkAction.executeOnPrimaryWhileHandlingMappingUpdates(TransportShardBulkAction.java:483)org.elasticsearch.action.bulk.TransportShardBulkAction.executeIndexRequestOnPrimary(TransportShardBulkAction.java:459)org.elasticsearch.action.bulk.TransportShardBulkAction.executeBulkItemRequest(TransportShardBulkAction.java:216)org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:159)org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:151)org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:139)org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:79) 3）结论 设置了IK_smart分词的字段，CPU高时写入的document该字段长度过大，导致CPU飚高。","link":"/2021/10/27/ES_CPU%E9%A3%9A%E9%AB%98/"},{"title":"Dubbo速览","text":"Dubbo现在是业内广泛使用的RPC框架，通过速览其架构，概念和涉及的技术，我们可以快速理解和掌握RPC的使用及原理。 一、Dubbo架构Dubbo涉及以下几个交互组件： 1）Provider：服务提供者 2）Consumer：服务消费者 3）Registry：注册中心，用作服务注册发现 4）Monitor：监控中心，监控服务调用 二、Dubbo相关技术以下从Dubbo-用法示例中抽取的个人认为较代表性内容： 1. 关于调用路径1）负载均衡 2）路由规则 2. 关于通讯协议1）多协议支持和发布 3. 关于服务注册发现1）单注册中心 2）多注册中心 4. 关于高可用1）集群容错 2）服务降级 5. 关于运维1）动态配置中心 6. 关于泛化1）发布泛化服务 2）进行泛化调用 7. 关于同步异步1）provider异步执行 2）consumer异步调用 8. 关于连接控制1）超时设置 2）并发控制 3）连接控制 9. 关于增强1）本地存根 2）本地伪装 三、问题场景从以上Dubbo涉及的技术，我们可以想象其可能面临场景，然后去理解Dubbo是如何解决的，更能鞭辟入里。当然可能每个问题的解决方案都会有多种，有时候方案的选择只是迈左脚还是迈右脚的问题，没有高低只有左右。我们不能盲目的认为Dubbo现存的方案就是正确的，要辩证的学习。 网络故障 单注册中心下，注册中心、Provider、Consumer之间的通路随机遭遇网络中断时会发生什么？ 多注册中心下，注册中心、Provider、Consumer之间的通路随机遭遇网络中断时会发生什么？ 超时问题 provider和consumer的配置超时的区别是什么？ consumer实现控制超时的方法？（可利用此机制实现http请求总超时控制） 关于泛化 为什么要有泛化？泛化带来了什么好处？ 泛化中枚举类型是如何处理的？ provider泛化和consumer泛化的具体使用 Consumer本地缓存注册中心Provider信息 缓存的失效策略是什么？重启后是否要重新从注册中心获取。 负载均衡 为什么要均衡负载？ # 参考 https://dubbo.apache.org/zh/docs/v2.7/user/preface/architecture/","link":"/2021/05/09/Dubbo%E9%80%9F%E8%A7%88/"},{"title":"Dubbo服务引入源码分析","text":"一、服务引入整体流程 二、ReferenceConfig#get ReferenceConfig.get方法首次调用会调用init方法对ref初始化。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public class ReferenceConfig&lt;T&gt; extends ReferenceConfigBase&lt;T&gt; { public synchronized void init() { if (initialized) { return; } // 初始化启动器，主要用于获取配置中心配置放到environment，以及根据配置初始化RegistryConfig,ProtocolConfig if (bootstrap == null) { bootstrap = DubboBootstrap.getInstance(); bootstrap.init(); } // 获取Reference注解和本机的Dubbo配置，并设置配置优先级。 checkAndUpdateSubConfigs(); // 初始化serivceMetadata serviceMetadata.setVersion(version); serviceMetadata.setGroup(group); serviceMetadata.setDefaultGroup(group); serviceMetadata.setServiceType(getActualInterface()); serviceMetadata.setServiceInterfaceName(interfaceName); serviceMetadata.setServiceKey(URL.buildKey(interfaceName, group, version)); checkStubAndLocal(interfaceClass); ConfigValidationUtils.checkMock(interfaceClass, this); // === BEGIN：根据配置优先级构建初始化参数的Map === Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(SIDE_KEY, CONSUMER_SIDE); ReferenceConfigBase.appendRuntimeParameters(map); if (!ProtocolUtils.isGeneric(generic)) { String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) { map.put(REVISION_KEY, revision); } String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); if (methods.length == 0) { logger.warn(&quot;No method found in service interface &quot; + interfaceClass.getName()); map.put(METHODS_KEY, ANY_VALUE); } else { map.put(METHODS_KEY, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), COMMA_SEPARATOR)); } } map.put(INTERFACE_KEY, interfaceName); AbstractConfig.appendParameters(map, getMetrics()); AbstractConfig.appendParameters(map, getApplication()); AbstractConfig.appendParameters(map, getModule()); AbstractConfig.appendParameters(map, consumer); AbstractConfig.appendParameters(map, this); Map&lt;String, Object&gt; attributes = null; if (CollectionUtils.isNotEmpty(getMethods())) { attributes = new HashMap&lt;&gt;(); for (MethodConfig methodConfig : getMethods()) { AbstractConfig.appendParameters(map, methodConfig, methodConfig.getName()); String retryKey = methodConfig.getName() + &quot;.retry&quot;; if (map.containsKey(retryKey)) { String retryValue = map.remove(retryKey); if (&quot;false&quot;.equals(retryValue)) { map.put(methodConfig.getName() + &quot;.retries&quot;, &quot;0&quot;); } } ConsumerModel.AsyncMethodInfo asyncMethodInfo = AbstractConfig.convertMethodConfig2AsyncInfo(methodConfig); if (asyncMethodInfo != null) { attributes.put(methodConfig.getName(), asyncMethodInfo); } } } String hostToRegistry = ConfigUtils.getSystemProperty(DUBBO_IP_TO_REGISTRY); if (StringUtils.isEmpty(hostToRegistry)) { hostToRegistry = NetUtils.getLocalHost(); } else if (isInvalidLocalHost(hostToRegistry)) { throw new IllegalArgumentException(&quot;Specified invalid registry ip from property:&quot; + DUBBO_IP_TO_REGISTRY + &quot;, value:&quot; + hostToRegistry); } map.put(REGISTER_IP_KEY, hostToRegistry); serviceMetadata.getAttachments().putAll(map); ServiceRepository repository = ApplicationModel.getServiceRepository(); ServiceDescriptor serviceDescriptor = repository.registerService(interfaceClass); repository.registerConsumer( serviceMetadata.getServiceKey(), attributes, serviceDescriptor, this, null, serviceMetadata); // === END：根据配置优先级构建初始化参数的Map === // 创建ref代理对象 ref = createProxy(map); // 更新serviceMetadata serviceMetadata.setTarget(ref); serviceMetadata.addAttribute(PROXY_CLASS_REF, ref); repository.lookupReferredService(serviceMetadata.getServiceKey()).setProxyObject(ref); initialized = true; // dispatch a ReferenceConfigInitializedEvent since 2.7.4 dispatch(new ReferenceConfigInitializedEvent(this, invoker)); }} ReferenceConfig#checkAndUpdateSubConfigs设置配置优先级checkAndUpdateSubConfigs里调用this.refresh();方法进行配置优先级设定。 12345678910111213public void refresh() { Environment env = ApplicationModel.getEnvironment(); try { CompositeConfiguration compositeConfiguration = env.getConfiguration(getPrefix(), getId()); Configuration config = new ConfigConfigurationAdapter(this); if (env.isConfigCenterFirst()) { // The sequence would be: SystemConfiguration -&gt; AppExternalConfiguration -&gt; ExternalConfiguration -&gt; AbstractConfig -&gt; PropertiesConfiguration compositeConfiguration.addConfiguration(4, config); } else { // The sequence would be: SystemConfiguration -&gt; AbstractConfig -&gt; AppExternalConfiguration -&gt; ExternalConfiguration -&gt; PropertiesConfiguration compositeConfiguration.addConfiguration(2, config); }} 其中，Environment#getConfiguration 1234567891011121314151617public class Environment extends LifecycleAdapter implements FrameworkExt { public CompositeConfiguration getConfiguration(String prefix, String id) { CompositeConfiguration compositeConfiguration = new CompositeConfiguration(); // Config center has the highest priority // From System.getProperty compositeConfiguration.addConfiguration(this.getSystemConfig(prefix, id)); // From System.getenv compositeConfiguration.addConfiguration(this.getEnvironmentConfig(prefix, id)); // From ConfigCenter compositeConfiguration.addConfiguration(this.getAppExternalConfig(prefix, id)); // From ConfigCenter compositeConfiguration.addConfiguration(this.getExternalConfig(prefix, id)); // From dubbo.properties compositeConfiguration.addConfiguration(this.getPropertiesConfig(prefix, id)); return compositeConfiguration; }} 三、ReferenceConfig#createProxy（一）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public class ReferenceConfig&lt;T&gt; extends ReferenceConfigBase&lt;T&gt; { private static final Protocol REF_PROTOCOL = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); private T createProxy(Map&lt;String, String&gt; map) { // JVM内直接Refer if (shouldJvmRefer(map)) { URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map); invoker = REF_PROTOCOL.refer(interfaceClass, url); } else { urls.clear(); if (url != null &amp;&amp; url.length() &gt; 0) { // 使用用户指定的URL，可能是通过IP直调的URL，或者是注册中心地址 String[] us = SEMICOLON_SPLIT_PATTERN.split(url); if (us != null &amp;&amp; us.length &gt; 0) { for (String u : us) { URL url = URL.valueOf(u); if (StringUtils.isEmpty(url.getPath())) { url = url.setPath(interfaceName); } if (UrlUtils.isRegistry(url)) { urls.add(url.addParameterAndEncoded(REFER_KEY, StringUtils.toQueryString(map))); } else { urls.add(ClusterUtils.mergeUrl(url, map)); } } } } else { // 从注册中心的配置构建URL if (!LOCAL_PROTOCOL.equalsIgnoreCase(getProtocol())) { checkRegistry(); List&lt;URL&gt; us = ConfigValidationUtils.loadRegistries(this, false); if (CollectionUtils.isNotEmpty(us)) { for (URL u : us) { URL monitorUrl = ConfigValidationUtils.loadMonitor(this, u); if (monitorUrl != null) { map.put(MONITOR_KEY, URL.encode(monitorUrl.toFullString())); } urls.add(u.addParameterAndEncoded(REFER_KEY, StringUtils.toQueryString(map))); } } if (urls.isEmpty()) { throw new IllegalStateException(&quot;No such any registry to reference, please config &lt;dubbo:registry address=\\&quot;...\\&quot; /&gt; to your spring config.&quot;); } } } if (urls.size() == 1) { // 单注册中心 // === 重点，通过PROTOCOL扩展点对制定接口执行refer === invoker = REF_PROTOCOL.refer(interfaceClass, urls.get(0)); } else { // 多注册中心 List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;(); URL registryURL = null; for (URL url : urls) { invokers.add(REF_PROTOCOL.refer(interfaceClass, url)); if (UrlUtils.isRegistry(url)) { registryURL = url; // use last registry url } } if (registryURL != null) { // registry url is available // for multi-subscription scenario, use 'zone-aware' policy by default URL u = registryURL.addParameterIfAbsent(CLUSTER_KEY, ZoneAwareCluster.NAME); // The invoker wrap relation would be like: ZoneAwareClusterInvoker(StaticDirectory) -&gt; FailoverClusterInvoker(RegistryDirectory, routing happens here) -&gt; Invoker invoker = CLUSTER.join(new StaticDirectory(u, invokers)); } else { // not a registry url, must be direct invoke. invoker = CLUSTER.join(new StaticDirectory(invokers)); } } } if (shouldCheck() &amp;&amp; !invoker.isAvailable()) { throw new IllegalStateException(&quot;No provider available for the service&quot;); } // create service proxy return (T) PROXY_FACTORY.getProxy(invoker); }} 四、REF_PROTOCOL#referREF_PROTOCOL是Protoco扩展点的自适应类。其会根据URL的protocol属性获取实现类 1Protocol REF_PROTOCOL = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 正常通过注册中心进行refer时，url格式类似，其会获取RegistryProtocol类并调用refer方法： 1registry://127.0.0.1:2181/org.apache.dubbo.registry.RegistryService?application=dubbo-demo-api-consumer&amp;dubbo=2.0.2&amp;pid=52071&amp;refer=application%3Ddubbo-demo-api-consumer%26dubbo%3D2.0.2%26interface%3Dorg.apache.dubbo.demo.DemoService%26methods%3DsayHello%2CsayHelloAsync%26pid%3D52071%26register.ip%3D192.168.199.172%26side%3Dconsumer%26sticky%3Dfalse%26timestamp%3D1622282108905&amp;registry=zookeeper&amp;timestamp=1622282151493 RegistryProtocol#refer方法，会对URL进行重写，然后调用doRefer。 123456789101112131415161718192021public class RegistryProtocol implements Protocol { public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException { // 重写URL，提取出真实的注册中心类型 url = getRegistryUrl(url); // 然后根据URL获取对应类型的Registry，例如url为&quot;zookeeper://&quot;时类型为ZookeeperRegistry Registry registry = registryFactory.getRegistry(url); if (RegistryService.class.equals(type)) { return proxyFactory.getInvoker((T) registry, type, url); } // group=&quot;a,b&quot; or group=&quot;*&quot; Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(REFER_KEY)); String group = qs.get(GROUP_KEY); if (group != null &amp;&amp; group.length() &gt; 0) { if ((COMMA_SPLIT_PATTERN.split(group)).length &gt; 1 || &quot;*&quot;.equals(group)) { return doRefer(getMergeableCluster(), registry, type, url); } } return doRefer(cluster, registry, type, url); }} 重写后的URL为： 1zookeeper://127.0.0.1:2181/org.apache.dubbo.registry.RegistryService?application=dubbo-demo-api-consumer&amp;dubbo=2.0.2&amp;pid=52071&amp;refer=application%3Ddubbo-demo-api-consumer%26dubbo%3D2.0.2%26interface%3Dorg.apache.dubbo.demo.DemoService%26methods%3DsayHello%2CsayHelloAsync%26pid%3D52071%26register.ip%3D192.168.199.172%26side%3Dconsumer%26sticky%3Dfalse%26timestamp%3D1622282108905&amp;timestamp=1622282151493 而根据URL获取的Registry为： 五、RegistryProtocol#doRefer1234567891011121314151617181920public class RegistryProtocol implements Protocol { private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) { RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); // all attributes of REFER_KEY Map&lt;String, String&gt; parameters = new HashMap&lt;String, String&gt;(directory.getUrl().getParameters()); URL subscribeUrl = new URL(CONSUMER_PROTOCOL, parameters.remove(REGISTER_IP_KEY), 0, type.getName(), parameters); if (!ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(REGISTER_KEY, true)) { directory.setRegisteredConsumerUrl(getRegisteredConsumerUrl(subscribeUrl, url)); registry.register(directory.getRegisteredConsumerUrl()); } directory.buildRouterChain(subscribeUrl); directory.subscribe(subscribeUrl.addParameter(CATEGORY_KEY, PROVIDERS_CATEGORY + &quot;,&quot; + CONFIGURATORS_CATEGORY + &quot;,&quot; + ROUTERS_CATEGORY)); Invoker invoker = cluster.join(directory); return invoker; }} 该方法会根据前面获取的注册中心示例Regitry，URL等信息构建RegistryDirectory，然后调用RegistryDirectory#subscribe向注册中心注册Consumer信息，获取并持续监听Provider信息。 此时设置进RegistryDirectory的URL格式为： 1consumer://192.168.199.172/org.apache.dubbo.demo.DemoService?application=dubbo-demo-api-consumer&amp;dubbo=2.0.2&amp;interface=org.apache.dubbo.demo.DemoService&amp;methods=sayHello,sayHelloAsync&amp;pid=52071&amp;side=consumer&amp;sticky=false&amp;timestamp=1622282108905 1.RegistryDirectory#subscribe 该方法内会调用注册中心实例的subscribe方法，并把自己作为Listener传入。自此当前的调用链如上图。 12345678public class RegistryDirectory&lt;T&gt; extends AbstractDirectory&lt;T&gt; implements NotifyListener { public void subscribe(URL url) { setConsumerUrl(url); CONSUMER_CONFIGURATION_LISTENER.addNotifyListener(this); serviceConfigurationListener = new ReferenceConfigurationListener(this, url); registry.subscribe(url, this); }} 2.ZookeeperRegistry#doSubcribe12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class ZookeeperRegistry extends FailbackRegistry { public void doSubscribe(final URL url, final NotifyListener listener) { try { if (ANY_VALUE.equals(url.getServiceInterface())) { String root = toRootPath(); ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners = zkListeners.get(url); if (listeners == null) { zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;&gt;()); listeners = zkListeners.get(url); } ChildListener zkListener = listeners.get(listener); if (zkListener == null) { listeners.putIfAbsent(listener, (parentPath, currentChilds) -&gt; { for (String child : currentChilds) { child = URL.decode(child); if (!anyServices.contains(child)) { anyServices.add(child); subscribe(url.setPath(child).addParameters(INTERFACE_KEY, child, Constants.CHECK_KEY, String.valueOf(false)), listener); } } }); zkListener = listeners.get(listener); } zkClient.create(root, false); List&lt;String&gt; services = zkClient.addChildListener(root, zkListener); if (CollectionUtils.isNotEmpty(services)) { for (String service : services) { service = URL.decode(service); anyServices.add(service); subscribe(url.setPath(service).addParameters(INTERFACE_KEY, service, Constants.CHECK_KEY, String.valueOf(false)), listener); } } } else { List&lt;URL&gt; urls = new ArrayList&lt;&gt;(); // 根据传入的URL“consumer://*”,构建需要监听的PATH for (String path : toCategoriesPath(url)) { ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners = zkListeners.get(url); if (listeners == null) { zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;&gt;()); listeners = zkListeners.get(url); } ChildListener zkListener = listeners.get(listener); if (zkListener == null) { // 把自己作为监听器，监听三个目录 listeners.putIfAbsent(listener, (parentPath, currentChilds) -&gt; ZookeeperRegistry.this.notify(url, listener, toUrlsWithEmpty(url, parentPath, currentChilds))); zkListener = listeners.get(listener); } zkClient.create(path, false); List&lt;String&gt; children = zkClient.addChildListener(path, zkListener); if (children != null) { urls.addAll(toUrlsWithEmpty(url, path, children)); } } // 手动触发notify notify(url, listener, urls); } } catch (Throwable e) { throw new RpcException(&quot;Failed to subscribe &quot; + url + &quot; to zookeeper &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); } }} 其中，toCategoriesPath(url)会构建三个监听的URL，当以下Zookeeper的三个目录发生变化时，会触发ZookeeperRegistry#notify方法。 1230 = &quot;/dubbo/org.apache.dubbo.demo.DemoService/providers&quot;1 = &quot;/dubbo/org.apache.dubbo.demo.DemoService/configurators&quot;2 = &quot;/dubbo/org.apache.dubbo.demo.DemoService/routers&quot; 3.ZookeeperRegistry#notify该方法最终会调用其父类AbstractRegistry的notify方法，该方法中会遍历上面传入的三个Path，调用listener#notify。而listener即是RegistryDirectory。 1234567891011121314151617181920212223242526public abstract class AbstractRegistry implements Registry { protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) { // keep every provider's category. Map&lt;String, List&lt;URL&gt;&gt; result = new HashMap&lt;&gt;(); for (URL u : urls) { if (UrlUtils.isMatch(url, u)) { String category = u.getParameter(CATEGORY_KEY, DEFAULT_CATEGORY); List&lt;URL&gt; categoryList = result.computeIfAbsent(category, k -&gt; new ArrayList&lt;&gt;()); categoryList.add(u); } } if (result.size() == 0) { return; } Map&lt;String, List&lt;URL&gt;&gt; categoryNotified = notified.computeIfAbsent(url, u -&gt; new ConcurrentHashMap&lt;&gt;()); for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) { String category = entry.getKey(); List&lt;URL&gt; categoryList = entry.getValue(); categoryNotified.put(category, categoryList); // 调用RegistryDirectory#notify listener.notify(categoryList); saveProperties(url); } }} 当前调用链为： 4. RegistryDirectory#notify该方法最终会根据Provider目录的URL，调用RegistryDirectory#toInvoker构建Invoker实例的Map，provider的URL示例如下： 1dubbo://192.168.199.172:20880/org.apache.dubbo.demo.DemoService?anyhost=true&amp;application=dubbo-demo-api-consumer&amp;check=false&amp;default=true&amp;deprecated=false&amp;dubbo=2.0.2&amp;dynamic=true&amp;generic=false&amp;interface=org.apache.dubbo.demo.DemoService&amp;methods=sayHello,sayHelloAsync&amp;pid=55345&amp;register.ip=192.168.199.172&amp;release=&amp;remote.application=dubbo-demo-api-provider&amp;side=consumer&amp;sticky=false&amp;timestamp=1622281889692 构建Inovker语句如下： 1invoker = new InvokerDelegate&lt;&gt;(protocol.refer(serviceType, url), url, providerUrl); 调用链为： 5.DubboProtocol#refer1）两个包装类调用DubboProtocol#refer前会调用其两个包装类，对其返回的Invoker进行封装。 12345678910public class ProtocolListenerWrapper implements Protocol { public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException { if (UrlUtils.isRegistry(url)) { return protocol.refer(type, url); } return new ListenerInvokerWrapper&lt;T&gt;(protocol.refer(type, url), Collections.unmodifiableList( ExtensionLoader.getExtensionLoader(InvokerListener.class).getActivateExtension(url, INVOKER_LISTENER_KEY))); }} 12345678public class ProtocolFilterWrapper implements Protocol { public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException { if (UrlUtils.isRegistry(url)) { return protocol.refer(type, url); } return buildInvokerChain(protocol.refer(type, url), REFERENCE_FILTER_KEY, CommonConstants.CONSUMER); }} 2） DubboProtocol#refer1234567891011121314151617public abstract class AbstractProtocol implements Protocol { public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException { return new AsyncToSyncInvoker&lt;&gt;(protocolBindingRefer(type, url)); }}public class DubboProtocol extends AbstractProtocol { public &lt;T&gt; Invoker&lt;T&gt; protocolBindingRefer(Class&lt;T&gt; serviceType, URL url) throws RpcException { optimizeSerialization(url); // create rpc invoker. DubboInvoker&lt;T&gt; invoker = new DubboInvoker&lt;T&gt;(serviceType, url, getClients(url), invokers); invokers.add(invoker); return invoker; }} 根据以上代码可知，最终生成的Invoker结构为： 6. DubboProcotol#getClients该方法最终会调用Exchanges#connect，和服务的Provider建立连接。 1Exchangers.connect(url, requestHandler); 而，Exchanges会调用HeaderExchanger进行connet。 12345public class HeaderExchanger implements Exchanger { public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException { return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))), true); }} 六、RegistryProtocol#doRefer（二）RegistryDirectory#subscribe执行结束后，会调用如下方法，此处cluster是扩展点自动注入的Cluster扩展点的自适应类。 1Invoker invoker = cluster.join(directory); cluster扩展点的包装如下： 123456789101112131415161718192021public class MockClusterWrapper implements Cluster { private Cluster cluster; public MockClusterWrapper(Cluster cluster) { this.cluster = cluster; } @Override public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException { return new MockClusterInvoker&lt;T&gt;(directory, this.cluster.join(directory)); }}public class FailoverCluster extends AbstractCluster { public final static String NAME = &quot;failover&quot;; @Override public &lt;T&gt; AbstractClusterInvoker&lt;T&gt; doJoin(Directory&lt;T&gt; directory) throws RpcException { return new FailoverClusterInvoker&lt;&gt;(directory); }} 经过cluster#join后，Invoker结构如下： 其中，FailoverCluster中包含负载均衡算法，在调用时选择合适的Invoker进行调用。 七、ReferenceConfig#createProxy（二）ReferenceConfig会对REF_PROTOCOL#refer的invoker，调用ProxyFactory扩展点生成引用接口的代理。 1PROXY_FACTORY.getProxy(invoker); 消费者在Zookeeper注册信息如下： 1/dubbo/org.apache.dubbo.demo.DemoService/consumers/consumer%3A%2F%2F192.168.199.172%2Forg.apache.dubbo.demo.DemoService%3Fapplication%3Ddubbo-demo-api-consumer%26category%3Dconsumers%26check%3Dfalse%26dubbo%3D2.0.2%26interface%3Dorg.apache.dubbo.demo.DemoService%26methods%3DsayHello%2CsayHelloAsync%26pid%3D59082%26side%3Dconsumer%26sticky%3Dfalse%26timestamp%3D1622342348716 URL Decode： 1/dubbo/org.apache.dubbo.demo.DemoService/consumers/consumer://192.168.199.172/org.apache.dubbo.demo.DemoService?application=dubbo-demo-api-consumer&amp;category=consumers&amp;check=false&amp;dubbo=2.0.2&amp;interface=org.apache.dubbo.demo.DemoService&amp;methods=sayHello,sayHelloAsync&amp;pid=59082&amp;side=consumer&amp;sticky=false&amp;timestamp=1622342348716","link":"/2021/05/15/Dubbo%E6%9C%8D%E5%8A%A1%E5%BC%95%E5%85%A5%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"ES磁盘不足拒绝写","text":"一、问题描述早间据研发反馈测试环境无最新日志，遂跟踪定位。 二、解决步骤 1）查看运行时日志，提示写入ES成功 2）查看ES监控，写入QPS为0 3）查看ES日志，发现磁盘满载 123456782021-11-29 10:42:50 [INFO ][o.e.c.m.MetaDataCreateIndexService] [node-0] [lop_edi_log_2021.11.30] creating index, cause [api], templates [temp_lop_edi_log], shards [18]/[1], mappings [doc]2021-11-29 10:43:25 [WARN ][o.e.c.r.a.DiskThresholdMonitor] [node-0] high disk watermark [90%] exceeded on [twBRMm_FRmWHk7k38LPg2Q][node-2][/es_home/remote_storage/data/nodes/0] free: 22.7gb[5.6%], shards will be relocated away from this node2021-11-29 10:43:25 [INFO ][o.e.c.r.a.DiskThresholdMonitor] [node-0] low disk watermark [85%] exceeded on [0am0KQmaQDmIAoZ4HdXAjQ][node-0][/es_home/remote_storage/data/nodes/0] free: 41.3gb[10.3%], replicas will not be assigned to this node2021-11-29 10:43:25 [INFO ][o.e.c.r.a.DiskThresholdMonitor] [node-0] low disk watermark [85%] exceeded on [TskuSxM_Tl-_HSgAGslubA][node-1][/es_home/remote_storage/data/nodes/0] free: 41.3gb[10.3%], replicas will not be assigned to this node2021-11-29 10:43:50 [INFO ][o.e.c.r.a.DiskThresholdMonitor] [node-0] low disk watermark [85%] exceeded on [0am0KQmaQDmIAoZ4HdXAjQ][node-0][/es_home/remote_storage/data/nodes/0] free: 41.3gb[10.3%], replicas will not be assigned to this node2021-11-29 10:43:50 [WARN ][o.e.c.r.a.DiskThresholdMonitor] [node-0] high disk watermark [90%] exceeded on [twBRMm_FRmWHk7k38LPg2Q][node-2][/es_home/remote_storage/data/nodes/0] free: 22.7gb[5.6%], shards will be relocated away from this node2021-11-29 10:43:50 [INFO ][o.e.c.r.a.DiskThresholdMonitor] [node-0] low disk watermark [85%] exceeded on [TskuSxM_Tl-_HSgAGslubA][node-1][/es_home/remote_storage/data/nodes/0] free: 41.3gb[10.3%], replicas will not be assigned to this node2021-11-29 10:43:50 [INFO ][o.e.c.r.a.DiskThresholdMonitor] [node-0] rerouting shards: [high disk watermark exceeded on one or more nodes] 4）删除索引，观察磁盘使用情况 5）查看写入QPS仍为0。 6）此时同事通过另一个应用发现了写入ES异常 122021-11-29 10:54:39[ elasticsearch[_client_][listener][T#1]:40318 ] - [ERROR] com.xx.xx.log.collector.es.client.impl.EsTransportClient-afterBulk:198 - 插入ES失 败，ES Index:ClusterBlockException[blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];],错误消息:{} 7）根据异常信息，查询解决方案 https://discuss.elastic.co/t/forbidden-12-index-read-only-allow-delete-api/110282/4 123456789101112131415161718192021222324252627$ PUT .kibana/_settings{ &quot;index&quot;: { &quot;blocks&quot;: { &quot;read_only_allow_delete&quot;: &quot;false&quot; } }}$ PUT _settings{ &quot;index&quot;: { &quot;blocks&quot;: { &quot;read_only_allow_delete&quot;: &quot;false&quot; } }}$ PUT [current_write_index]/_settings{ &quot;index&quot;: { &quot;blocks&quot;: { &quot;read_only_allow_delete&quot;: &quot;false&quot; } }} 8）执行后，ES写入恢复。 三、经验结论1）由于第一个应用的ES是异步批量写入，第一次查看日志返回的成功只是代表提交成功，并不代表写入成功，此处日志有误导性。 2）ES磁盘使用高时，会拒绝写，此时需要根据每日最大写入量来评估索引保存天数","link":"/2021/11/29/ES%E7%A3%81%E7%9B%98%E4%B8%8D%E8%B6%B3%E6%8B%92%E7%BB%9D%E5%86%99/"},{"title":"ES分页","text":"ES分页查询指定页时，需要从头查起，即需要查询出前置页 + 当前页的数据，然后返回当前页的数据。以操作文件举例，例如要取文件的第41行到50行，需要执行head -n 50 file | tail -n 10。所以使用from…size进行深分页查询时必然会消耗性能。 一、from…size的限制1）分页查询语法 1234567GET /_search{ &quot;from&quot; : 0, &quot;size&quot; : 10, &quot;query&quot; : { &quot;term&quot; : { &quot;user&quot; : &quot;kimchy&quot; } }} 2）from…size的限制 Note that from + size can not be more than the index.max_result_window index setting which defaults to 10,000. 官网上说，通过from+size去查询时，页数越深其消耗的堆内存和时间越长。 二、深分页1）Search After 适合实时深分页查询，利用上次结果帮助去索引下一页。 2）Scroll 适合非实时的深分页查询，其会进行指定时间的缓存。 三、深分页是否必须从官网的信息来看，深分页似乎不支持跳页，只能执行下一页。而在大部分深分页的场景下，如日志查询，用户其实并不会去翻页。 所以，有些深分页的需求是伪需求，可以转换为增加条件转换为非深分页。 # 参考 search-request-from-size","link":"/2021/06/06/ES%E5%88%86%E9%A1%B5/"},{"title":"ES分片和副本","text":"一、为什么要设置分片和副本 摘自：动态更新索引 一个 Lucene 索引 我们在 Elasticsearch 称作分片 。一个 Elasticsearch 索引 是分片的集合。 当 Elasticsearch 在索引中搜索的时候， 他发送查询到每一个属于索引的分片(Lucene 索引)，然后像 执行分布式检索 提到的那样，合并每个分片的结果到一个全局的结果集。 ES是含多个数据节点的分布式存储结构，把一个索引分成多个物理分片，把分片分配到不同的节点上，可以充分利用集群的CPU，磁盘等资源，提高存储和检索效率。且分片也使扩容更加方便。 副本是数据容错的常用方式，其和主分片须在不同节点上。这样主分片所在节点故障时，可以把副本分片选为主分片，保证数据不丢失。另外副本分片还可以分摊查询压力，能更好的负载集群的压力。 二、ES的集群结构1. 集群的3类结点ES集群中结点根据其职责划分了多类结点（7.13版本称为role）。我们主要关注以下3类结点，而集群的每个结点根据配置可以具有多个类型： 结点类型 结点职责 配置方式 资源要求 资源规格示例 主结点 负责集群相关操作，如创建，删除索引；跟踪哪些结点是集群的一部分，并决定哪些分片分配给相关结点。 1）ES 6.8中，设置node.master=true，那么该结点就具备主结点资格2）ES 7.13中，设置角色为node.roles: [ master ] CPU，内存，IO要求一般 2核8G 20GB 数据结点 用于存储索引的数据，主要包含对文档的增删改，聚合操作。 1）ES 6.8中，设置node.data=true;2）ES 7.13中，设置角色为node.roles: [ data ] CPU，内存，IO要求较高 16核64G，1600GB 协调结点 当集群搜索压力大时，可以通过协调结点来进行请求路由，及对请求结果归并返回客户端。 默认接收请求的结点都是协调结点，但可以通过配置把让其专司协调工作：1）ES 6.8中，设置node.master=false,node.data=false,node.ingest=false2）ES 7.13中，设置角色为node.roles: [ ] CPU，内存要求较高 2核8G 20GB（由当前查询量较小，故规格较低，正常情况应该与数据结点同等规格） 2. 集群结构假如有含1个专用主结点，1个专用协调结点，3个数据节点的ES集群。当前有个Index有三个分片，副本为1。则其集群结构，及索引分片的分布情况如下图所示。 三、ES的写入过程1）客户端发起文档写入请求，协调结点根据如下路由规则计算应该写入到那个分片。 shard = hash(routing) % number_of_primary_shards。 routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过 hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到 余数 。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。 2）确定好分片位置后，协调结点会把请求转发给含该分片的数据节点； 3）主分片写入后，该数据节点会把请求转发给其副本分片的数据节点； 4）当副本写入成功后（可设置一致性策略-参考），返回给协调节点写入成功； 5）协调结点返回客户端写入成功； 四、ES的查询过程1. 搜索一个文档1）客户端向协调结点请求文档； 2）协调结点根据文档_id确定在哪个分片； 3）协调结点根据某种策略选择其中一个结点的分片，进行请求转发； 4）接受到转发请求的数据结点，检索文档并返回给协调结点； 5）协调结点把结果返回给客户端。 2. 条件搜索文档1）查询阶段 ø 客户端发送请求到协调结点，协调结点创建from + size的空优先队列 ø 协调结点把查询请求转发到索引的每个主分片或副分片中。每个分片在本地执行查询并添加结果到大小为 from + size 的本地有序优先队列中。 ø 每个分片返回各自优先队列中所有文档的 ID 和排序值给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。 2）取回阶段 ø 协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。 ø 每个分片加载并 丰富 文档，如果有需要的话，接着返回文档给协调节点。 ø 一旦所有的文档都被取回了，协调节点返回结果给客户端。 五、ES近实时搜索1）引入buffer和translog（类似Mysql的写入逻辑）； 2）buffer定时1秒刷新缓存为segmentFile，生成segmentFile后Document可被检索； 3）系统缓存每30分钟刷数据到磁盘或者translog达到512mb后刷入磁盘。 图片来源 # 参考 ES 2.x - 近实时搜索 ES 7.13 - 结点类型 ES 6.8 - 结点类型 Elasticsearch学习之ES节点类型以及各种节点的分工 ES 2.x - 路由一个文档到一个分片中 ES 2.x - 新建、索引和删除文档 ElasticSearch （Near Real Time ）NRT 分析","link":"/2021/06/02/ES%E5%88%86%E7%89%87%E5%92%8C%E5%89%AF%E6%9C%AC/"},{"title":"ES的乐观锁","text":"一、ES使用乐观锁进行并发控制ES官方文档-Update API中提到ES6.7.0版本前使用version字段进行并发控制，而6.7.0开始使用if_seq_no，if_primary_term进行并发控制。 二、测试1）创建测试数据，当前version为1。 2）指定版本号更新数据，第一次更新成功 3）指定相同版本号，进行第二次更新失败 参考 ES 7.13——乐观锁并发控制 Elasticsearch系列—并发控制及乐观锁实现原理","link":"/2021/06/01/ES%E7%9A%84%E4%B9%90%E8%A7%82%E9%94%81/"},{"title":"Dubbo服务调用源码分析","text":"一、调用链下图来源于官网。 二、Consumer调用链细化 三、Provider调用链细化","link":"/2021/05/15/Dubbo%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"ES索引分片数设置原则","text":"一、ES索引分片设置原则 存储的数据如果是持续增长的，需要周期建索引进行水平拆分（按小时，按日，按月等），来保证以下的分片原则。 1）副本分片用于保证安全，至少设置为1。副本约多，越影响写入性能。 2）分片总数（主分片 + 副本分片）最好是集群节点数量的倍数，保证可以均匀分配，避免数据倾斜。 3）每个分片大小最好处于10G-65G间。 4）单数据节点上，每GB堆内存不能超过20个分片。 二、线上实战假设我目前有个日志存储的场景如下： ES集群信息： ES有9个数据节点，单数据节点规格为16核64G 7000GB 含协调节点和主节点 1）确认索引创建周期从管理维度上考虑，选择“按日”新建索引，格式类似“my_log_yyyy-MM-dd” 2）确认索引的数据量ø 如果ES中已存在数据，观察ES每日索引的大小，GET _cat/indices。 ø 如果还未有数据，则根据每日的日志条数和平均日志大小，评估索引数据量。 Note：根据观察MQ的日流量和ES的索引值，发现ES是MQ的80%大小（具体比例跟索引mapping中字段类型有关，请就地勘测）。 MQ生产流量 ES索引大小（不含副本） 比例 732.145GB 581.9GB 79.5% 2.964TB 2.25TB 75.9% 3.07TB 2.3TB 74.9% 假设，当前每日索引存储（不含副本）需要800GB。 3）计算索引分片数 根据每GB堆内存不超过20个分片，假设当前堆内存设置为31G 单节点最大支持：31 * 20 = 620分片 按单分片50G，则磁盘相应大小为620 * 50G = 31T，考虑80%负载，磁盘需要38.75T 以上结论可知当，单分片为50G，磁盘空间小于38.75T时，肯定符合每GB堆内存不超过20个分片 按单分片为50GB，则每日索引不含副本共需要800G/50G = 16个分片 索引副本数设置为1，则每日索引含副本共需要16 * 2 = 32个分片 由以上得出的分片数，再考虑分片需要为数据节点数量的整数倍（9的倍数），最终设置日索引分片为18，副本为1 4）推算索引保留时间粗略估算如下： 饱和存储：7000G * 9个数据节点 / (800G * 2) = 39.375天 80%存储：39.375 * 80% = 31.5天 58%存储：39.375 * 58.8% = 23.2天 三、磁盘容量评估 参考阿里云：https://help.aliyun.com/document_detail/72660.html 副本数量：至少1个副本。 索引开销：通常比源数据大10%（_all参数等未计算）。 操作系统预留：默认操作系统会保留5%的文件系统供您处理关键流程、系统恢复以及磁盘碎片等。 Elasticsearch内部开销：段合并、日志等内部操作，预留20%。 安全阈值：通常至少预留15%的安全阈值。 根据以上因素得到：最小磁盘总大小 = 源数据大小 * 3.4。计算方式如下。 磁盘总大小 = 源数据 （1 + 副本数量） 索引开销 /（1 - Linux预留空间）/（1 - Elasticsearch开销）/（1 - 安全阈值） = 源数据 （1 + 副本数量） 1.7 = 源数据 * 3.4 # 参考 https://www.elastic.co/guide/en/elasticsearch/reference/current/size-your-shards.html ES规格容量评估 ES6.5 堆内存设置 ES堆内存该设置多大","link":"/2021/05/19/ES%E7%B4%A2%E5%BC%95%E5%88%86%E7%89%87%E6%95%B0%E8%AE%BE%E7%BD%AE%E5%8E%9F%E5%88%99/"},{"title":"Dubbo扩展点","text":"一、Dubbo扩展点1、Dubbo扩展点来源Dubbo 的扩展点加载从 JDK 标准的 SPI (Service Provider Interface) 扩展点发现机制加强而来。 Dubbo 改进了 JDK 标准的 SPI 的以下问题： 1）ServideLoader获取全集扩展点时会对扩展点进行实例化。 如果有扩展实现初始化很耗时，但如果没用上也加载，会很浪费资源。 2）ServiceLoader扩展点实例化异常时，会吞异常信息。 12345678910private class LazyIterator implements Iterator&lt;S&gt; { private S nextService() { try { c = Class.forName(cn, false, loader); } catch (ClassNotFoundException x) { fail(service, &quot;Provider &quot; + cn + &quot; not found&quot;); } } ...} 3）扩展点内依赖其他扩展点的自动注入问题需要研发自己解决。 Dubbo扩展点增加了对扩展点 IoC 和 AOP 的支持，一个扩展点可以直接 setter 注入其它扩展点。 4）扩展点没有二级分类，无法根据分类指定要获取的实现。 Dubbo扩展点增加了type。 2、Dubbo扩展点的一种声明方式/META-INF/dubbo下声明扩展点，如文件：org.apache.dubbo.common.extension.ExtensionFactory 12adaptive=org.apache.dubbo.common.extension.factory.AdaptiveExtensionFactoryspi=org.apache.dubbo.common.extension.factory.SpiExtensionFactory 文件名是接口，文件内容里一行是一个实现。 每行里，“=”左侧是type（类型），右侧是具体类。 可通过ExtensionLoader.getExtension(type)，获取扩展点的对应类型的实现类。 二、Dubbo扩展点的关键类解析1、ExtensionLoader扩展点加载器，其在实例化时绑定了某个固定扩展点。其主要用来根据指定的type来获取扩展点实例。如果扩展点依赖了其他扩展点，则会通过ExtensionFactory获取需要注入的扩展点并注入。 下图为ExtensionLoader的公共方法列表。 2、ExtensionFactory用于扩展点中依赖的其他扩展点的加载。其主要用来根据某个扩展点的类型来获取扩展点。一般通过AdatptiveExtensionFactory类进行调用，该类是一个composite class，即其包含了本扩展点（ExtensionFactory扩展点）的其他非Adaptive扩展点，参考如下源码。 附：AdaptiveExtensionFactory源码 1234567891011121314151617181920212223242526@Adaptivepublic class AdaptiveExtensionFactory implements ExtensionFactory { private final List&lt;ExtensionFactory&gt; factories; public AdaptiveExtensionFactory() { ExtensionLoader&lt;ExtensionFactory&gt; loader = ExtensionLoader.getExtensionLoader(ExtensionFactory.class); List&lt;ExtensionFactory&gt; list = new ArrayList&lt;ExtensionFactory&gt;(); for (String name : loader.getSupportedExtensions()) { list.add(loader.getExtension(name)); } factories = Collections.unmodifiableList(list); } @Override public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) { for (ExtensionFactory factory : factories) { T extension = factory.getExtension(type, name); if (extension != null) { return extension; } } return null; }} 值得注意的是SpiExtensionFactory会在Dubbo配置的扩展点中寻找。并且其返回的是一个Adaptive（自适应）扩展点实例。该实例同刚才介绍的AdatpiveExtensionFactory一样，是一个composite类。由@Adaptive注解声明或者由ExtensionLoader自动生成。 3、Adaptive扩展点Adaptive扩展点，也成为自适应扩展点。它从成员来看，是本扩展点的一个composite类，包含了其他所有的扩展点。其由@Adaptive注解声明或者由ExtensionLoader自动生成。 附，ExtensionLoader自动生成Adataptive扩展点代码如下。 12345678910111213141516171819package org.apache.dubbo.common.extension.adaptive;import org.apache.dubbo.common.extension.ExtensionLoader;import org.apache.dubbo.common.extension.adaptive.HasAdaptiveExt;import org.apache.dubbo.common.URL;public class HasAdaptiveExt$Adaptive implements HasAdaptiveExt { public String echo(URL arg0, String arg1) { if (arg0 == null) throw new IllegalArgumentException(&quot;url == null&quot;); URL url = arg0; String extName = url.getParameter(&quot;has.adaptive.ext&quot;, &quot;adaptive&quot;); if (extName == null) throw new IllegalStateException(&quot;Failed to get extension (HasAdaptiveExt) name from url (&quot; + url.toString() + &quot;) use keys([has.adaptive.ext])&quot;); HasAdaptiveExt extension = (HasAdaptiveExt) ExtensionLoader.getExtensionLoader(HasAdaptiveExt.class).getExtension(extName); return extension.echo(arg0, arg1); }} 由以上源码可看出，如果一个扩展点需要支持自适应时，则扩展点的方法需要由URL参数（或是参数有URL成员）。 Adaptive类可认为是一个简单工厂，根据方法传入的URL，定位到对应的实例，然后再调用方法。 # 参考 https://dubbo.apache.org/zh/docs/v2.7/dev/spi/","link":"/2021/05/12/Dubbo%E6%89%A9%E5%B1%95%E7%82%B9/"},{"title":"ES脑裂问题","text":"一、ES专用主结点ES的集群规模如果较大时，可以考虑设置专用主结点，设置参数可参考ES分片和副本。配置了参数后的结点被称为*Master-eligible node*，即候选主结点。这些候选主结点之间会通过选举，投票出一个主结点。 二、ES脑裂问题 ES的主结点保存了集群的状态，负责索引的创建等重要工作。一个集群只允许有一个主结点，如果大于一个就会出现不一致的情况。而，如果ES的主结点选举的配置错误的话，就可能会出现多个主结点的情况，这种情况成为脑裂。 脑裂发生后不会自动恢复，需要重启发生脑裂的结点才会恢复。但是，重启的主结点在脑裂期间写入的数据和状态就会丢失。 三、大数选举及场景分析1）参数minimum_master_nodes及配置原则discovery.zen.minimum_master_nodes（默认为1）设置集群的候选主结点数量必须不小于该值，该值配置为quorum可以避免主结点脑裂而出现多个主结点。 quorum = (master_eligible_nodes / 2) + 1 需要注意的是，如果主结点由于网络故障无法发现其他主结点，或者发现的主结点小于quorum，那么他就会由主结点降为候选主结点。这样因网络故障而成为ES集群通讯孤点的主结点降级为候选主结点，也不会再执行主结点职责，避免与此时新选举出来的主结点同时存在而导致脑裂。 2）minimum_master_nodes不符合quorum时，脑裂场景分析假设当前有两个候选主结点，但是没有配置discovery.zen.minimum_master_nodes，即使用默认值1。假如此时发生网络故障，导致两个主结点之间无法通讯，他们各自都会选举自己为主结点1而出现脑裂问题。 3）minimum_master_nodes符合quorum，场景分析假设当前有三个候选主结点，配置discovery.zen.minimum_master_nodes=2，此时如果发生网络故障，则有以下几个场景 从上面四个场景分析，只要三个结点间任意两个结点网络通讯正常（有一条线不中断）就不会发生脑裂。 4）集群的候选结点最少为3个假设，候选结点为两个，quorum = 2/2 + 1 = 2那么一旦两个主结点间网络故障，那么集群中就不会再有主结点了。 # 参考 discovery-settings.html#minimum_master_nodes modules-node.html#split-brain","link":"/2021/06/06/ES%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98/"},{"title":"FTP和sshuttle的故事","text":"0. FTP的两种模式 1. 背景前几日EDI支持时，有研发反馈一个FTP上传超时的问题：1）运行环境： 测试环境（已加至商家网络的白名单）2）EDI结点：FTP上传结点（Passive模式）3）FTP服务器：商家的FTP服务器4）错误信息： 2. 尝试路径 测试环境执行FTP命令 此时发现IP1和IP2不是同一个IP； IP2（类似9.x,x,x）看上去是公网IP，但其实是内网IP 本地FileZilla通过sshuttle连接 1234# 代理控制端口sshuttle -r user@测试服务器IP IP1/32# 代理数据端口sshuttle -r user@测试服务器IP IP2/32 错误同执行命令一致 3. 解决方案猜测出商家侧配置错误，返回的IP2可能是内网地址，于是在我方测试服务器通过iptable开启DNET后解决。 1sudo iptables -t nat -A OUTPUT -p tcp -d IP2 -j DNAT --to-destination IP1","link":"/2019/12/19/FTP%E5%92%8Csshuttle%E7%9A%84%E6%95%85%E4%BA%8B/"},{"title":"Git内部原理","text":"Git是由C语言开发的一套内容寻址文件系统，并在此之上提供了一个VCS用户界面。 一、前言 Git使用比较灵活，达到相同结果有多种方式。 靠记忆不同场景下的命令组合，会停留在“知其然，不知其所以然”的层次。 只有理解Git内部原理和Git命令的底层操作，才能深入浅出的灵活运用Git。 二、Git目录结构使用git init命令初始化当前目录，生成 .git/ 文件夹。 1、工作区、暂存区和Git仓库 工作区是当前目录（除去.git/），所有的编辑操作都在该目录进行。 暂存区对应.git/index文件，它包含了当前暂存区的信息，由它可生成git的tree对象。（git init执行后并没有产生.git/index，而是在首次执行git add命令后才生成，并把由更新文件生成的blob对象放入**.git/objects/**内。） git仓库对应.git/，它存储了项目的所有历史快照，以供需要的时候使用。 2、.git目录.git/包含了以下目录和文件： branches/：新版本不再使用 description：仅供GitWeb程序使用 config：当前项目的配置选项 info/：不同于.gitignore文件，可配置本地的文件忽略模式，不会push到remote库而影响其他人。 hooks/：目录存放钩子脚本 objects/：目录存储所有数据内容 refs/：目录存储指向数据的commit对象的指针 HEAD：文件内容为当前分支 index：文件内容为暂存区的信息 3、index文件 .git/index里存储的是暂存区内容，暂存的内容都会进入仓库，不会丢失（短时间内）。 1）查看index内容 git ls-files --stage 12345678910100644 a65bf3836e0169b1cb49a8c051141652601e80b7 0 .gitignore100644 99cd02507010eff1a8a3f813c16af5b83a32a9fd 0 README.md100644 ba0a399d89da367d5a06fe4a882fddbed1e96ad2 0 pom.xml100644 39138cf9e31fe22fab671a63bee972c29a5c1580 0 src/main/java/com/jd/edi/test/jsf/RpcUtil.java100644 75808965f4c184b2f77966391254c08d3c64f287 0 src/main/resources/log4j2.xml100644 18d6d3f536df2686339624d4ec7ba4c1fa3e73fa 0 src/test/java/com/jd/edi/test/log/DubboTest.java100644 eee242e578dcbc8e0347c06c587a4bc37057dc33 0 src/test/java/com/jd/edi/test/log/JsfTest.java100644 d5117d32b38f39656de1eac6597e648329bcf47d 0 src/test/resources/dubbo/DTC.zip100644 f07cb32715bbe1695c6f5d2e6ae5dcbd04f09e4d 0 src/test/resources/dubbo/dubbo.properties100644 5a4eb082c444ff0be9b7f497fae28e23be49f4e0 0 src/test/resources/edi-ka-1.0.0-SNAPSHOT.zip hexdump -e '16/1 &quot;%02X &quot; &quot; | &quot;' -e '16/1 &quot;%_p&quot; &quot;\\n&quot;' index &gt; out.txt 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858644 49 52 43 00 00 00 02 00 00 00 0B 5D D4 BE 49 | DIRC........]..I22 46 99 3B 5D D4 BE 49 20 21 4A 60 00 00 08 01 | &quot;F.;]..I !J`....00 80 12 32 00 00 81 A4 00 00 03 E8 00 00 03 E8 | ...2............00 00 00 15 A6 5B F3 83 6E 01 69 B1 CB 49 A8 C0 | .....[..n.i..I..51 14 16 52 60 1E 80 B7 00 0A 2E 67 69 74 69 67 | Q..R`......gitig6E 6F 72 65 00 00 00 00 00 00 00 00 5D D2 3C F7 | nore........].&lt;.22 A9 B3 FC 5D D2 3C F7 22 A9 B3 FC 00 00 08 01 | &quot;...].&lt;.&quot;.......00 80 12 25 00 00 81 A4 00 00 03 E8 00 00 03 E8 | ...%............00 00 00 0C 99 CD 02 50 70 10 EF F1 A8 A3 F8 13 | .......Pp.......C1 6A F5 B8 3A 32 A9 FD 00 09 52 45 41 44 4D 45 | .j..:2....README2E 6D 64 00 5F 23 F9 3D 14 62 2F 77 5F 23 F9 3D | .md._#.=.b/w_#.=11 85 C5 BE 00 00 08 01 00 80 11 6F 00 00 81 A4 | ...........o....00 00 03 E8 00 00 03 E8 00 00 11 33 E4 6C 63 C0 | ...........3.lc.55 B9 86 E9 64 87 C5 0F 02 E5 34 11 9B D1 E8 FF | U...d.....4.....00 07 70 6F 6D 2E 78 6D 6C 00 00 00 5F 23 F4 29 | ..pom.xml..._#.)09 38 20 93 5F 23 F4 29 05 A4 9C F2 00 00 08 01 | .8 ._#.)........00 98 0B 4D 00 00 81 A4 00 00 03 E8 00 00 03 E8 | ...M............00 00 05 4A DD B2 E8 32 F1 CF 37 51 02 B9 51 2F | ...J...2..7Q..Q/7E 1C 3D 30 AB D4 D5 E7 00 2B 73 72 63 2F 6D 61 | ~.=0.....+src/ma69 6E 2F 6A 61 76 61 2F 63 6F 6D 2F 6A 64 2F 65 | in/java/com/jd/e64 69 2F 74 65 73 74 2F 6A 73 66 2F 4D 61 69 6E | di/test/jsf/Main2E 6A 61 76 61 00 00 00 00 00 00 00 5E C7 49 0D | .java.......^.I.05 6A B2 B6 5E C7 49 0D 05 6A B2 B6 00 00 08 01 | .j..^.I..j......00 98 07 E4 00 00 81 A4 00 00 03 E8 00 00 03 E8 | ................00 00 03 06 39 13 8C F9 E3 1F E2 2F AB 67 1A 63 | ....9....../.g.cBE E9 72 C2 9A 5C 15 80 00 2E 73 72 63 2F 6D 61 | ..r..\\....src/ma69 6E 2F 6A 61 76 61 2F 63 6F 6D 2F 6A 64 2F 65 | in/java/com/jd/e64 69 2F 74 65 73 74 2F 6A 73 66 2F 52 70 63 55 | di/test/jsf/RpcU74 69 6C 2E 6A 61 76 61 00 00 00 00 5D D4 B4 2E | til.java....]...33 40 3A 5F 5D D4 B4 2E 31 1A EA 8A 00 00 08 01 | 3@:_]...1.......00 98 07 38 00 00 81 A4 00 00 03 E8 00 00 03 E8 | ...8............00 00 06 CB 75 80 89 65 F4 C1 84 B2 F7 79 66 39 | ....u..e.....yf912 54 C0 8D 3C 64 F2 87 00 1D 73 72 63 2F 6D 61 | .T..&lt;d....src/ma69 6E 2F 72 65 73 6F 75 72 63 65 73 2F 6C 6F 67 | in/resources/log34 6A 32 2E 78 6D 6C 00 00 00 00 00 5E C7 49 0D | 4j2.xml.....^.I.05 6A B2 B6 5E C7 49 0D 05 6A B2 B6 00 00 08 01 | .j..^.I..j......00 B6 06 02 00 00 81 A4 00 00 03 E8 00 00 03 E8 | ................00 00 06 2D 18 D6 D3 F5 36 DF 26 86 33 96 24 D4 | ...-....6.&amp;.3.$.EC 7B A4 C1 FA 3E 73 FA 00 30 73 72 63 2F 74 65 | .{...&gt;s..0src/te73 74 2F 6A 61 76 61 2F 63 6F 6D 2F 6A 64 2F 65 | st/java/com/jd/e64 69 2F 74 65 73 74 2F 6C 6F 67 2F 44 75 62 62 | di/test/log/Dubb6F 54 65 73 74 2E 6A 61 76 61 00 00 5F 27 AA 90 | oTest.java.._'..0D 56 22 13 5F 27 AA 90 09 FF A8 76 00 00 08 01 | .V&quot;._'.....v....00 B6 0F B3 00 00 81 A4 00 00 03 E8 00 00 03 E8 | ................00 00 51 50 D0 7D 1E 76 95 F5 EA 98 87 14 69 C9 | ..QP.}.v......i.35 FE E2 D8 70 86 19 1E 00 2E 73 72 63 2F 74 65 | 5...p.....src/te73 74 2F 6A 61 76 61 2F 63 6F 6D 2F 6A 64 2F 65 | st/java/com/jd/e64 69 2F 74 65 73 74 2F 6C 6F 67 2F 4A 73 66 54 | di/test/log/JsfT65 73 74 2E 6A 61 76 61 00 00 00 00 5E C7 49 0D | est.java....^.I.05 6A B2 B6 5E C7 49 0D 05 6A B2 B6 00 00 08 01 | .j..^.I..j......00 C8 0E 96 00 00 81 A4 00 00 03 E8 00 00 03 E8 | ................00 00 0E A2 D5 11 7D 32 B3 8F 39 65 6D E1 EA C6 | ......}2..9em...59 7E 64 83 29 BC F4 7D 00 20 73 72 63 2F 74 65 | Y~d.)..}. src/te73 74 2F 72 65 73 6F 75 72 63 65 73 2F 64 75 62 | st/resources/dub62 6F 2F 44 54 43 2E 7A 69 70 00 00 5E C7 49 0D | bo/DTC.zip..^.I.05 6A B2 B6 5E C7 49 0D 05 6A B2 B6 00 00 08 01 | .j..^.I..j......00 C8 0E 97 00 00 81 A4 00 00 03 E8 00 00 03 E8 | ................00 00 00 FF F0 7C B3 27 15 BB E1 69 5C 6F 5D 2E | .....|.'...i\\o].6A E5 DC BD 04 F0 9E 4D 00 29 73 72 63 2F 74 65 | j......M.)src/te73 74 2F 72 65 73 6F 75 72 63 65 73 2F 64 75 62 | st/resources/dub62 6F 2F 64 75 62 62 6F 2E 70 72 6F 70 65 72 74 | bo/dubbo.propert69 65 73 00 5D D7 A6 44 0F 4A 25 12 5D D7 A5 F6 | ies.]..D.J%.]...20 E6 DA 00 00 00 08 01 00 C8 0B 60 00 00 81 A4 | ..........`....00 00 03 E8 00 00 03 E8 00 29 4F 9C 5A 4E B0 82 | .........)O.ZN..C4 44 FF 0B E9 B7 F4 97 FA E2 8E 23 BE 49 F4 E0 | .D.........#.I..00 2C 73 72 63 2F 74 65 73 74 2F 72 65 73 6F 75 | .,src/test/resou72 63 65 73 2F 65 64 69 2D 6B 61 2D 31 2E 30 2E | rces/edi-ka-1.0.30 2D 53 4E 41 50 53 48 4F 54 2E 7A 69 70 00 00 | 0-SNAPSHOT.zip..00 00 00 00 54 52 45 45 00 00 00 F3 00 2D 31 20 | ....TREE.....-1 31 0A 73 72 63 00 2D 31 20 32 0A 6D 61 69 6E 00 | 1.src.-1 2.main.2D 31 20 32 0A 6A 61 76 61 00 2D 31 20 31 0A 63 | -1 2.java.-1 1.c6F 6D 00 2D 31 20 31 0A 6A 64 00 2D 31 20 31 0A | om.-1 1.jd.-1 1.65 64 69 00 2D 31 20 31 0A 74 65 73 74 00 2D 31 | edi.-1 1.test.-120 31 0A 6A 73 66 00 2D 31 20 30 0A 72 65 73 6F | 1.jsf.-1 0.reso75 72 63 65 73 00 31 20 30 0A C3 B7 95 22 38 01 | urces.1 0....&quot;8.71 55 91 97 79 3D 4A 97 3B 21 B9 57 1E 53 74 65 | qU..y=J.;!.W.Ste73 74 00 2D 31 20 32 0A 6A 61 76 61 00 2D 31 20 | st.-1 2.java.-1 31 0A 63 6F 6D 00 2D 31 20 31 0A 6A 64 00 2D 31 | 1.com.-1 1.jd.-120 31 0A 65 64 69 00 2D 31 20 31 0A 74 65 73 74 | 1.edi.-1 1.test00 2D 31 20 31 0A 6C 6F 67 00 2D 31 20 30 0A 72 | .-1 1.log.-1 0.r65 73 6F 75 72 63 65 73 00 33 20 31 0A DA 51 E1 | esources.3 1..Q.E1 F7 1B E3 6D FF C4 EA 5A 23 05 74 72 EA 7C 76 | ....m...Z#.tr.|v97 64 75 62 62 6F 00 32 20 30 0A ED 23 F0 8E F3 | .dubbo.2 0..#...10 DA 69 79 3B 26 1B 99 E6 81 B8 59 B5 1B 38 09 | ..iy;&amp;.....Y..8.58 52 E9 C5 2C 00 18 95 21 2B 6C 8C 58 FF 6D 16 | XR..,...!+l.X.m.BA 82 A9 | ... 2）index格式 该文件创建的时间，最后修改时间 inode信息，设备号和Innode号 文件权限，例如：777 文件的用户及用户组 文件大小 文件的blobId 文件的相对路径 三、Git命令Git包含底层命令（Plumbing）和高层命令（Procelain）。 1）用户平时使用的Git命令一般为高层命令，如add、commit、checkout等；高层命令对用户友好，便于理解和操作。 2）Git起初被设计为供VCS使用的工具集，这些工具也称为底层命令；底层命令一般不被用户直接使用，而是被shell或脚本调用。 此处列举几个底层命令简要说明： checkout-index：Copy files from the index to the working tree. cat-file：Provide content or type and size information for repository objects. hash-object：Compute object ID and optionally creates a blob from a file. update-index：Register file contents in the working tree to the index. write-tree：Create a tree object from the current index. commit-tree：Create a new commit object. 四、Git对象Git定义了4种对象：blob、tree、commit和tag，它们都位于**.git/objects/**目录下。git对象在原文件的基础上增加了一个头部，即对象内容 = 对象头 + 文件内容。这种格式无法直接通过cat命令读取，需要使用git cat-file这个底层命令才能正确读取。 对象头的格式为：对象头 = 对象类型 + 空格 + 数据内容长度 + null byte，例如一个文件内容为“hello world”，其blob对象头为”blob 11\\000”。 blob：工作区的文件以blob对象的形式进入git仓库，相当于UNIX中的inodes或文件内容。 tree：tree对象包含对blob对象以及其他tree对象的引用，相当于UNIX中的目录。 commit：包含了上一次commit对象的Hash串引用、该时间点项目快照的顶层tree对象的Hash串引用、作者/提交者信息、时间戳、空行，以及提交的注释信息。 tag：包含一个commit的Hash串引用、标签名，以及其他信息（由标签类型决定）。 五、内容寻址1）依赖底层命令git hash-object命令，对文件内容增加头信息后计算hash值并返回，增加-w参数后在git仓库内创建blob对象（blob对象 = 对象头 + 文件内容）。 2）blob对象存储到git仓库目录（.git/objects/）时，依据40位（16进制字符）长度的hash串指定存储目录（hash串前2位）和命名文件（hash串后38位）。 例如某blob对象的hash值为62/0d4582bfbf773ef15f9b52ac434906a3cdf9c3，那么它在git仓库中的路径为.git/objects/62/0d4582bfbf773ef15f9b52ac434906a3cdf9c3。 3）Git内容寻址本质是：Git根据由文件内容（增加文件头）产生的Hash值来标识和索引文件，另外进行命令操作时没有必要写完整的hash串，只要输入的hash串长度是唯一可识别和索引的即可。 4）无需考虑Hash碰撞的情况，在大型项目上也可以放心使用Git。因为在概率上SHA-1产生的哈希值碰撞的机会可以小到忽略。 六、hash碰撞 1）hash碰撞后的原则 当出现冲突时，保留当前仓库已有的对象； 2）冲突场景 已存在 新对象 结果 blob blob commit success, lost fail tree blob commit sucess, push fail commit blob commit sucess, push fail blob commit commit fail, when updating “ref” blob tree commit fail, when create commit tree commit commit fail, when updating “ref” tree tree push success, reference to wrong tree commit commit HEAD always point to old commit tree commit fail, when create commit 七、Git版本机制1）HEAD指向当前分支。若master是当前分支，则HEAD文件内容为ref: refs/heads/master。 2）分支（本地分支、远程分支、远程跟踪分支、跟踪分支）和标签（tag对象）都包含了对commit对象的引用。 3）commit对象包含了上次commit对象的引用（类似单链表）和本次提交的顶级tree对象的引用。 每个顶级tree对象可看做是一个完整的版本。 通过commit对象的链式结构进行串联，形成提交历史和版本历史。 4）总之：git的分支和标签通过引用commit对象来标注当前分支的版本信息。 Note：凡是对Git对象的引用，都指的是Git对象的40位长度的Hash串。 八、引用规格（refspec）引用规格指的是远程仓库分支和本地分支的映射，可表示为&lt;src&gt;:&lt;dst&gt;，这也暗示了数据流向为src → dst。 1）fetch和push命令123# 两命令都包含引用规格（refspec）来指定数据流向。git fetch [remote repository] [remote branch]:[local branch]git push [remote repository] [local branch]:[remote branch] 2）config文件配置refspec当使用缺省的fetch/push命令时，Git会根据.git/config中的refspec配置进行操作。 I、当通过git remote add命令添加一个远程分支的同时，会在.git/config文件中添加一个配置结点。 fetch中的”+“是可选的，它告诉Git在不能fast-forward的情况下，也强制去更新它。此后执行git fetch orgin这个缺省命令时，会拉取origin远程仓库的所有分支。 II、可通过git log origin/master来查看从远程仓库fetch的master分支。 1234# 以下三个命令是等价的，Git会把他们都扩展为refs/remote/origin/mastergit log origin/mastergit log remote/origin/mastergit log refs/remote/origin/master III、refspec指定分支映射 可通过改写fetch行为fetch = +refs/heads/master:refs/remotes/origin/mymaster，指定把远程的master分支映射为本地的origin/mymaster分支。 也可指定多个映射，一次拉取多个指定分支。 12345[remote &quot;origin&quot;] url = git@github.com:kivihub/test.git fetch = +refs/heads/master:refs/remotes/origin/master fetch = +refs/heads/experiment:refs/remotes/origin/experiment fetch = +refs/heads/qa/*:refs/remote/orgin/qa/* 可同时指定push的refspec。若要把本地的master分支push到远程的qa/master分支，可配置如下： 123456[remote &quot;origin&quot;] url = git@github.com:kivihub/test.git fetch = +refs/heads/master:refs/remotes/origin/master fetch = +refs/heads/experiment:refs/remotes/origin/experiment fetch = +refs/heads/qa/*:refs/remote/orgin/qa/* push = refs/heads/master:refs/heads/qa/master IV、删除远程分支通过命令git push origin :master可以删除远程origin库的master分支。因为refspec的格式为:，通过把置空表示把远程分支变为空，也就是删除它。 九、垃圾回收git gc垃圾回收命令用于压缩或删除数据，节省磁盘空间。 将松散对象进行打包存入packfile。 将不被任何commit引用并且已存在一段时间（数月）的对象删除。 参考 GIT科普系列5：index in git 《Pro Git》相关章节内容 Git 内部原理 - 底层命令和高层命令 Git 内部原理 - Git 对象 Git 内部原理 - Git 引用 Git 内部原理 - 包文件 Git 内部原理 - 引用规格 Git 内部原理 - 传输协议 Git 内部原理 - 维护与数据恢复 Git 内部原理 - 环境变量 Git命令列表 .gitignore和exclude Hash碰撞 Linus reply: Starting to think about sha-256? https://stackoverflow.com/questions/9392365/how-would-git-handle-a-sha-1-collision-on-a-blob/34599081#34599081","link":"/2018/01/18/Git%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/"},{"title":"Git基础操作之撤销操作","text":"版本控制的关键是可撤销性，即可以使项目回退到某些操作之前状态。Git作为一款非常优秀的版本控制软件具备了丰富的撤销的命令来应对不同的场景，下面我们来学习一下。 一、修改最后一次提交 命令：git commit --amend 作用：本次提交覆盖上次提交，以此达到修改上次提交的目的。 1、修改直接提交 值得注意的是，两次提交的项目内容和提交人没有变化，但是由于提交的时间不同，导致commit对象的内容不同，因此产生内容的ID也不相同。 2、修改后再提交 二、reset、revert和checkoutGit使用reset、revert和checkout三个命令来回退项目到某一个历史快照。回退有两个影响级别： commit级别：根据指定的commit来恢复项目整体到历史的某一快照。 文件级别：根据指定commit和文件路径来恢复指定文件到某一历史版本。 1、commit级别回退1）回退Git仓库 命令：git reset --soft [commit] 作用：把HEAD引用的当前分支的commit引用移动到指定commit，以此达到回退的目的。 重新根据reset命令撤销刚才的撤销操作（是不是有点绕口） 2）回退Git仓库和暂存区I、命令：git reset [commit]/git reset --mixed [commit] II、作用：本命令会恢复Git仓库到指定commit，并根据指定commit清空覆盖暂存区（不会提示冲突，因为是强行覆盖）。 III、结果： 不在指定commit的文件树中的工作区的目录和文件会变成未跟踪状态； 与指定commit的文件树中的内容不同的文件会变成已修改状态，待加入暂存区。 3）回退Git仓库、暂存区和工作区I、git reset 命令：git reset --hard [commit] 作用：根据指定commit的文件树，覆盖git仓库和暂存区，清空工作区所有已跟踪文件然后以指定commit的内容代替。 结果：1）只有工作区内处于未跟踪状态的目录和文件会维持原来状态；2）其他文件都会与指定commit内容具有相同内容。 II、git revert 命令1：git revert [commit] 作用：打补丁的形式撤销某次历史版本； 命令2：git revert -n [commit]..[commit] 作用：撤销一个commit区间 原理：根据diff操作计算出指定commit与其之前commit的内容差异，针对该差异计算出反补丁，应用反补丁到当前git仓库、暂存区和工作区，并产生一次提交。 条件：1）保持暂存区clean状态；2）工作区不能有和revert补丁冲突的处于已修改状态的文件，例如不能修改同一行等。 4）reset和revert的区别 git reset不会产生新的提交，只通过移动HEAD引用的分支指向的commit来恢复项目快照。 git revert不会影响已有历史，它会产生新的提交来撤销某次或一定范围的修改。 区别列表 命令 git reset git revert 原理 改变分支的commit的引用 对已有commit引用打反补丁 副作用 改变commit历史 不会改变commit历史 适用性 本地分支 公共分支 冲突 无冲突 会有冲突 优点 无冲突的恢复到某次历史快照 可针对中间的某次提交进行撤销操作 本质 覆盖操作 修补操作 2、文件级别回退1）回退暂存区文件 命令：git reset [commit] [file]，若是commit是HEAD可替换为--。 作用：根据指定commit，撤销暂存区指定文件的操作； 结果：若新增，则删除；若删除和修改，则恢复。 2）回退工作区文件 命令1：git checkout file 作用：把暂存区文件检出到工作区； 命令2：git chekcout [commit] [file]，若是commit是HEAD可替换为--。 作用：根据指定commit，从git仓库检出指定文件到暂存区和工作区。 三、提交树Git中每次提交都会存储在Git仓库，只是有些提交经过reset、删除分支、删除储藏等操作后不被分支和标签引用，变成悬挂状态（dangling）。我们可以通过以下命令查看这些提交（Git的提交树和vim的undo树异曲同工）。 1、完整提交树 命令：git log -g或git reflog来查看 作用：显示所有操作，包括撤销的。 2、有效提交树 命令：git log查看 作用：显示当前有效的操作 3、撤销的悬挂提交（dangling commit） 命令：git fsck --lost-found 作用：通过校验Git仓库的完整性（通过引用链），找出悬挂对象。 4、一图以蔽之 四、储藏和恢复由于revert、分支合并等场景下的操作会与工作区和暂存区的内容产生冲突，若不想提交当前工作区和暂存区的修改内容，可以通过储藏命令将其储藏起来，然后在合适的时候恢复工作区和暂存区。 1234git stash # 储藏当前工作区和暂存区git stash list # 查看当前的储藏列表git stash apply # 恢复上一次的储藏内容git stach pop # 恢复上一次的储藏内容，并将其从储藏区删除 五、清除未跟踪文件1）命令1：git clean -f 作用：删除未跟踪文件 2）命令2：git clean -df 作用：删除未跟踪文件和目录 3）一般与git reset --hard命令搭配使用。 123git reset --hard commit # 恢复git仓库、暂存区和工作区（不包含未跟踪内容）到指定commitgit clean -df # 删除当前处于未跟踪状态的文件和目录git status # 当前处于commit，且暂存区和工作区都处于clean状态 六、非本地私有分支恢复至某个版本 1）本地私有分支：本地的分支未跟踪（not track）任何远程仓库的分支，不会push到远程，只有自己可见； 2）非本地私有分支：本地的分支跟踪（track）远程仓库的某分支，该仓库的开发团队都可见； 非本地私有分支要恢复至某个指定版本是大家常常会遇到的一个问题。假如当前提交历史为： 如果我们要恢复到A，有两种方式： 1、通过revert命令 有合并节点或间隔距离较远时不建议使用 1）命令git revert A..HEAD 2）产生多个提交 2、通过reset命令 建议使用 1）命令I、git reset --hard A git的工作区、暂存区变为版本A的内容； HEAD及当前分支dev指向A II、 git reset --soft origin/dev # HEAD及当前分支dev指向origin/dev III、git commit -m 'reset to rivision A' # 产生一个新的提交 2）产生一个提交 参考 代码回滚：git reset、git checkout和git revert区别和联系 在 git 中找回丢失的 commit Git 工具 - 储藏（Stashing） Git的”～”和”^”的区别","link":"/2018/02/04/Git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E4%B9%8B%E6%92%A4%E9%94%80%E6%93%8D%E4%BD%9C/"},{"title":"Git分享","text":"Git原理及应用零、EDI应用 一、 Git原理1. VCS对比1）没有VCS 2）本地版本控制 机制：通过数据库记录文件历次更新的差异，差异以补丁的形式记录对应文件修订前后的内容变化。 不足：不支持多开发者协同工作。 典型软件：rcs 3）集中版本控制 机制：单一的集中管理的服务器保存所有文件的修订版本，协同工作的人们通过客户端连到该服务器，取出最新的文件或提交更新 不足：中央服务器的单点故障可能导致数据丢失。 典型软件：CVS，Subversion，Perforce等。 4）分布式版本控制 机制：每个客户端都拥有独立且完整的版本仓库，且客户端地位相等（类似P2P网络），它们之间可相互获取、推送更新。 优点：1）消除集中版本控制系统的单点故障；2）协作开发时，允许单个客户端在本地版本仓库独立提交更新，并在合适时推送给其他客户端或某个约定为中央仓库的客户端。 典型软件：Git，Mercurial，Bazaar，Darcs等。 2. Git的特性1）保存快照，而非差异 Git关心文件整体内容的变化，而大多数其他系统则关心文件内容的差异（svn基于增量）。 此特性为多分支并行开发提供了支持。 2）几乎所有操作都是本地操作 速度快 客户端离线时也可进行更新操作 3）时刻保持数据完整性 保存到Git之前，所有数据都要经过Hash运算，并将Hash值作为数据的唯一标识和索引，而非文件名。 Git采用SHA-1算法来生成文件或整个目录的杂凑值，并作为唯一标识。该算法输出160bit哈希值，即40个16进制字符（0-9及a-f）。类似24b9da6552252987aa493b52f8696cd6d3b00373。 3. Git目录结构.git/包含了以下目录和文件： branches/：新版本不再使用 description：仅供GitWeb程序使用 config：当前项目的配置选项 12345678910111213[core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true ignorecase = true precomposeunicode = true[remote &quot;origin&quot;] url = git@github.com:kivihub/java-fragment.git fetch = +refs/heads/*:refs/remotes/origin/*[branch &quot;dev&quot;] remote = origin merge = refs/heads/dev info/exclude：不同于.gitignore文件，可配置本地的文件忽略模式，不会push到remote库而影响其他人。 hooks/：目录存放钩子脚本，如校验commit msg，git-lfs objects/：目录存储所有数据内容，可细分为四大对象blob，tree，commit，tag refs/：目录存储指向数据的commit对象的指针 HEAD：文件内容为当前分支 1ref: refs/heads/dev index：文件内容为暂存区的信息 4. 工作区，暂存区和仓库的概念 5. 高级命令和低级命令 用户平时使用的Git命令一般为高层命令，如add、commit、checkout等；高层命令对用户友好，便于理解和操作。 Git起初被设计为供VCS使用的工具集，这些工具也称为底层命令；底层命令一般不被用户直接使用，而是被shell或脚本调用。如cat-file 6. Git的四大对象：blob，tree，commit，tag 1234vim .git/refs/heads/dev// 文件内容b8942bbf8ff41d8670611a7c256e5663d973e28b 7. 基于内容存储和Hash碰撞 依赖底层命令git hash-object命令，对文件内容增加头信息后计算hash值并返回，增加-w参数后在git仓库内创建blob对象（blob对象 = 对象头 + 文件内容）。 blob对象存储到git仓库目录（.git/objects/）时，依据40位（16进制字符）长度的hash串指定存储目录（hash串前2位）和命名文件（hash串后38位）。例如某blob对象的hash值为62/0d4582bfbf773ef15f9b52ac434906a3cdf9c3，那么它在git仓库中的路径为.git/objects/62/0d4582bfbf773ef15f9b52ac434906a3cdf9c3，blob对象采用zlib方式压缩后存储。 Git内容寻址本质是：Git根据由文件内容（增加文件头）产生的Hash值来标识和索引文件。另外进行命令操作时没有必要写完整的hash串，只要输入的hash串长度是唯一可识别和索引的即可。 123456789101112131415161718public class GitBlobSha1Util { public static String digest(File file) throws IOException { return digest((InputStream)(new FileInputStream(file))); } public static String digest(InputStream in) throws IOException { byte[] content = IOUtils.toByteArray(in); return digest(content); } public static String digest(byte[] content) { byte[] header = (&quot;blob &quot; + content.length + &quot;\\u0000&quot;).getBytes(); byte[] sum = new byte[header.length + content.length]; System.arraycopy(header, 0, sum, 0, header.length); System.arraycopy(content, 0, sum, header.length, content.length); return DigestUtils.sha1Hex(sum); }} Hash碰撞 1）当出现冲突时，保留当前仓库已有的对象 2）冲突场景 3）解决方式 commit冲突时，再次提交即可，其中包含时间戳； tree和blob冲突时，修改下文件内容即可，如增加空格，空行等； 8.三路合并（3-way merge） 9. Merge策略概览1）resolve：用于合并两个分支（git merge branchA branchB），合并算法：三方合并。 2）recursive（默认合并策略）：用于合并两个分支（git merge branchA branchB），合并算法：三方合并。 当有多个共同祖先可用于三向合并时，它会创建一个共同祖先的合并树，并将其用作三向合并的参考树。 3）octopus：用于合并多个分支； 4）ours：不限合并分支数量，但遇见冲突时始终使用自己的修改，忽略其他分支的修改； 5）subtree：改进的recursive算法，考虑子树的匹配； 10. Diff算法概览1）MyersDiff（默认算法）：Eugene W. Myers 在他1986年发表于”Algorithmica”的论文”An O(ND) Difference Algorithm and Its Variations”中描述了一种用于处理diff的基础贪婪算法. 论文连接 寻找两个文件的最长公共子序列可转为一个同构问题：有向编辑图 x轴走一步：删除一个字符 y轴走一步：增加一个字符 对角线走一步：无需编辑 初始状态：abcabba x轴2步：cabba 对角线一步：c abba y轴1步：cb abba 对角线2步：cbab ba x轴1步：cbab a 对角线1步：cbaba y轴1步：cbabac 2）HistogramDiff 11. 配置SSH登陆1）减少密码过期带来的困扰 2）多平台认证更方便：git.jd.com,coding.jd.com,github.com 12. 配置sparse checkout1）配置.git/config，core下增加sparsecheckout = true 2）配置.git/info/sparse-checkout 二、 Git命令一览1. 常用命令及参数 123456789101112131415git status // 查看当前Git状态git log // 查看日志git checkout // 可用于1）检出分支；2）创建分支；3）检出文件；4）暂存区覆盖工作区；git stash // 暂存工作区git pull // 拉取远程分支并合并，等效于：git fetch + git mergegit push // 1）push内容到远程，2）删除分支，git push origin :devgit revert // 生成撤销提交git reset // 恢复工作区，暂存区，仓库到指定revisiongit rebase // 变基git cherry-pick // 挑拣git blame // 查看文件中每行的提交信息git diff git show // 查看提交信息等git branch git fiter-branch 2. 特殊符号1）引用符号 2）提交范围 类别 表示 作用 数学概念 两点提交 before..after 隶属于after分支，但不隶属于before的提交 差集 (after-before) 三点提交 before…after 两分支中除去共同拥有的提交外的提交 并集-交集 (before∪after - before∩after) 取非 ^或–not 不包含指定分支的所有提交 差集 3. 使用场景1）恢复到指定版本1234// 事例：dev分支恢复到历史revisiongit reset --hard revisiongit reset --soft origin/devgit commit 2）合并提交/拆分提交1git rebase -i revision 3）删除误提交的大文件1git filter-branch 4）暂存当前工作区12git stash --allgit stash pop/apply --index 5）用其他分支的文件覆盖当前文件1git chekout otherbranch path 三、 Git规范1. 提交流程规范123git commitgit pullgit push 2. 提交信息规范1234&lt;type&gt;: &lt;subject&gt; // 类型及摘要：type由团队内部协定：如feature，refactor，fixbug等&lt;BLANK LINE&gt; // 空行&lt;detail body&gt; // 详细信息&lt;/detail body&gt; 3. 提交粒度粒度：一个工作一个提交 优势：利于code review和回滚 4. pull merge vs pull rebase12git pull = git fetch + git mergegit pull --rebase = git fetch + git rebase 优劣： 1）rebase：提交历史呈线性，较merge整洁，便于代码review； 2）merge：保存原始提交历史； 5. 分支命名规范1234feature/log -- 特性分支refactor/http -- 重构分支hotfix/fastjson -- fixbug分支wangqiwei -- 本地分支/临时分支 6. cherry-pick后小心revert如以下情况会出现非预期结果 四、 Git工作流三大工作流： 1. TBD：Trunk-based development1）特点： TBD的特点是所有团队成员都在单个主干分支上进行开发。 简单易操作，减少分支切换，流行于SVN（svn trunck = git master） 2）流程： 当需要发布时，先考虑使用标签（tag）,即tag某个commit来作为发布的版本。 如果仅仅依靠tag不能满足要求，则从主干分支创建发布分支。 bug修复在主干分支进行，再cherry-pick到发布分支 2. Git Flow 1）适合场景 适合维护多个发布版本 流程较其他工作流复杂 2）分支描述 长期分支 develop：开发分支，稳定后可并入master； master：HEAD总处于可发布态；每个版本对应一个tag； 辅助分支 feature 通常是本地分支，合并回develop后删除； may from develop must merge back to develop (develop)：git merge –no-ff，体现出特性 release 合并回master和develop后删除； may from develop must merge back to develop and master (master)：git merge –no-ff，体现出特性 (devlop)：git merge –no-ff，体现出特性 迁出分支后，首先修改为新版本号； hotfix May from master Must merge back to develop and master (master)：git merge –no-ff，体现出特性 (devlop)：git merge –no-ff，体现出特性（当release分支存在时优先合并进release分支，由release分支合并进develop） 迁出分支后，首先修改为新版本号； 3. GitHub Flow1）特点： 简单实用 2）流程 master分支中也是代表着稳定的代码。该分支已经或即将被部署在生产环境 当需要进行任何修改时，总是从master分支创建新分支。完成之后通过pull request和相关的代码审查来合并回master分支 hotfix, feature分支都遵循上面的准则； 4. 对比","link":"/2020/08/19/Git%E5%88%86%E4%BA%AB/"},{"title":"Git基础操作之正常提交","text":"本人把基础操作分为两个部分：1）正常提交操作；2）撤销操作。主要因为撤销操作有多种场景，且同一命令的不同参数的结果可能大相径庭，故单独把撤销操作做为一节。 一、获取项目的Git仓库 获取项目的Git仓库有两种方式：1）在本地目录初始化Git仓库，通过Git的提交操作新增项目文件至Git仓库，被Git管理；2）通过克隆已有的Git仓库到本地目录，被Git管理。 1、Git初始化本地目录使用git init命令初始化当前目录，操作结束后在本地生成.git仓库。 2、克隆远程仓库到本地若要通过克隆的方式的获取Git仓库，只需要知道远程仓库的Git地址，就可以通过git clone url的方式将其克隆到本地。 1）远程仓库地址选用本人在GitHub上的一个测试项目，仓库地址为https://github.com/kivihub/test.git。 2）通过git clone https://github.com/kivihub/test.git克隆远程仓库。 二、正常的提交流程1、查看状态通过git status命令查看当前状态。 1）未跟踪状态 2）暂存状态 3）已提交状态 4）已修改状态 2、状态变化图 3、暂存文件1）未跟踪文件的暂存操作 新建文件foo.txt（文件处于未跟踪状态）。 git add foo.txt，把文件提交至暂存区（文件处于已暂存状态）。 2）已修改文件的暂存操作 编辑已暂存态和已提交态的文件后，文件新增已修改状态。 git add file，把文件提交至暂存区（文件处于已暂存状态）。 4、提交文件1）提交暂存态文件git commit file 2）提交已修改态（跳过暂存态）和已暂存态文件git commit -a 12341.本命令无视当前路径，它会提交`git status`里除`未跟踪态`以外的所有文件至git仓库。2.相当于执行了两步操作： a. git add 项目的根路径 b. git commit 3）git commit的常用参数 123456git commit -a 提交本项目除未跟踪态以外的所有文件至Git仓库。git commit -m &quot;commit description&quot; -m后空格然后跟着本次提交的描述，可免去进入编辑页面。Note：1.编辑页面也有好处，你可以看到本次修改了文件。2.若想在提交的编辑页面放弃本次提交，则不做输入退出就会放弃提交。 5、修改/删除文件1）通过git命令操作，可根据参数修改文件工作区和暂存区的状态。 12345678910# 示例`git rm file` # 删除工作区和暂存区的指定文件相当于执行了两步操作：1. `rm file` 2. `git add file``git rm --cached file` # 只删除暂存区的指定文件，保留工作区的文件。例如：一个应用场景是误将本该ignore的文件提交至暂存区，可进行如下操作：1.通过此命令删除暂存区文件后，保留工作区文件2.然后通过编辑.gitigore或者exlude文件忽略该文件 2）非git命令操作：按序执行修改→暂存→提交操作。 6、查看历史和差异1）查看历史 git log 123456789`git log`常用参数-g # 查看全部历史，相当于执行 git reflog--oneline # 显示为一行--graph # 图像化显示--all # 显示所有分支--decorate # 标注分支和标签-number # 显示近number次提交信息-p # 按补丁格式显示每次更新的差异（与git diff内容一致）--stat # 显示每次更新的文件修改统计信息 Note：可通过gitk命令运行图形化版本查看工具。Debian系列Linux发行版可通过sudo apt install gitk命令进行安装。 2）查看差异 git diff 1234567891011`git diff` # 比较工作区和暂存区的差异`git diff --cached ` # 比较暂存区和Git仓库的差异`git diff --cached [commit|branch|tag]` # 比较暂存区与指定commit的差异`git diff HEAD` # 比较工作区和Git仓库的差异`git diff [commit|branch|tag]` # 比较工作区和指定commit的差异`git diff [commit|branch|tag] [commit|branch|tag]` # 比较两个commit的差异# Note:以上命令后面都增加文件路径，指定查看具体目录或文件的差异。 附：常用shell操作命令123456789# 在Linux的shell里进行命令操作时难免会输错单词，这时可通过以下几个命令快速修正`ctrl + w` # 删除光标前一个word（等同于Vim编辑态的`ctrl + w`)`ctrl + u` # 清空本行（等同于Vim编辑态的`ctrl + u`）`ctrl + l` # 清屏，相当于执行`clear``ctrl + d` # 退出shell，县挡土相当于执行`exit``cd` # 进入当前用户home`cd -` # 返回刚才目录`ln -s 源目录 目录连接` # 建立目录的软连接，例如：可在用户home建立git仓库的软连接，减少目录的切换操作。`[tab][tab]` # 连续两次tab键，会提示当前的可能命令组合或可选路径","link":"/2018/02/01/Git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E4%B9%8B%E6%AD%A3%E5%B8%B8%E6%8F%90%E4%BA%A4/"},{"title":"Git标签和分支","text":"一、标签 标签是Git的对象，包含了对commit对象的引用；另外每个标签都会有一个标签相同名称的ref文件存储在.git/refs/tags/目录下，文件内容为Git对象的SHA值，此处有两种情况：1）若为轻量级标签，Git不会真正建立tag对象，而由tag的ref文件直接引用commit的SHA值； 2）若为含有附注的标签，则Git会建立tag对象，tag对象包含commit的引用，而tag的ref文件则包含tag对象的引用。 1、查看标签123`git tag` # 查看全部标签，按字母序排列 `git tag -l 'expression'` # 查看符合条件的标签`git show &lt;object&gt;` # 显示Git四种对象的具体信息 2、管理标签1）新建轻量级标签12# 新建轻量级标签，可指定Git对象创建标签，若不指定默认为HEAD。git tag tagname [commit|object] 2）新建含附注的标签12# 新建含附注标签，可指定Git对象创建标签，若不指定默认为HEAD。git tag -a tagname -m ‘tag message’ [commit|object] 3）轻量级标签和含附注标签的区别I、轻量级标签不含打标签人、打标签时间、message等信息 II、轻量级标签并没有真正建立git的tag对象，它只是在.git/refs/tags/目录下创建了一个tag名字的ref文件，文件内容为tag指向的commit引用。 4）分享标签12345git push [remote-branch] tagName # 把标签推送至指定远程分支git push [remote-branch] --tags # 把所有分支推送至指定远程分支git push [remote-branch] :refs/tags/tagName # 删除远程分支指定标签# 默认情况下，git push不会把标签传送到远程服务器 标签除轻量级标签和含附注的标签外，还有签署标签。若持有签署者的公钥则可以通过验证操作来验证。 二、分支 分支不是Git对象，它只是包含git的commit对象引用的常规文件，一般保存在.git/refs/heads/和.git/refs/remotes/两个目录，前者是本地分支，后者是远程分支。 1、分支概念和原理1）首先回顾下Git的四个对象blob、tree、commit和tag。 I、blob对象：对应工作区的文件，按Git定义的格式存储了文件内容，blob索引为其内容的SHA值； II、tree对象：对应工作区的目录，可含有子目录和文件。tree对象的内容为其包含文件名和文件对应的blob的SHA值（或其子目录名称和对应的tree对象的SHA值），tree索引为其内容的SHA值； III、commit对象：包含顶级树（即工作区根目录）的SHA值引用和提交信息，其索引为其内容的SHA值； IV、tag对象：包含了特定commit对象的索引，也称引用，若是含附注的tag还包含打标签的信息，例如标签人、标签时间和message等。 2）分支和轻量级tag类似，只包含了commit对象的索引。 相同点 不同点 分支 含commit对象的索引 分支更新后，分支替换为新的commit索引 标签 含commit对象的索引 创建后内容不再变化 3）分支是包含commit索引的常规文件，存储在.git/refs/heads/目录和.git/refs/remotes/目录下。 4）HEAD是一个具有特殊意义的常规文件，内容为当前分支。例如当前分支为master，那么HEAD文件内容为ref: refs/heads/master。 5）情景例子 I、假设当前有两个分支master和dev，现在HEAD指向master分支（即master是当前分支），如下图所示。 II、当前分支（master分支）进行一次提交后，如下图所示。 III、执行git checkout dev切换分支，结果如图。 2、分支命令 假设当前HEAD指向唯一的分支master，且当前有两个提交，如下图所示。 1）查看分支123456git branch -l # 查看本地分支git branch # 查看本地分支的缺省命令git branch -r # 查看远程分支git branch -a # 查看所有分支其他参数：-v # 显示分支的最后一次提交信息 2）创建并检出分支1234git checkout -b dev # 创建并检出dev分支等同于下面两条命令git branch dev # 创建dev分支git checkout dev # 检出dev分支/切换至dev分支 3）切换分支 git checkout master 4）合并分支经过一系列提交后，git空间状态如下图所示。 I、No FF(非快进)/merge commit(合并提交)当前分支为master分支，dev分支和master分支在47a2提交处发生分离。此时若执行合并操作，则会进行合并提交，也称No FF提交。 git merge dev merge commit的执行步骤如下： a、git首先会对要合并的两个分支的末端的提交和它们的分离处（共同祖先）的提交进行一次简单的三方合并计算。 b、根据计算结果判断是否有合并冲突。当两个分支的操作是互斥时就会发生冲突，例如两个分支都对同一个文件的同一处文本发生了修改操作，则会有合并冲突。 Φ 若无冲突，默认情况下自动执行以下操作： 将工作区的合并结果进行commit操作，产生一个合并提交。该合并提交有两个parent，即两个合并分支的末端的commit对象。 当前分支指向新的commit。 Φ 若有冲突，则需手动解决冲突，然后手动进行提交，产生的合并结果与上面相同。总之，merge commit操作就是根据三个commit对象的快照信息，计算一个新的合并快照，于此同时新建commit对象完成合并操作。 II、Fast forward（快进）a、git checkout dev # 检出dev分支 此时，dev和master两个分支的末端有通路，即有连通的引用链。若在dev分支执行合并master操作，无需创建新的commit对象，可直接将dev的分支指向两个分支中的那个最远末端的commit即可（也就是所谓的快进操作）。 b、git merge master 1234567891011121314151617# 常用参数git merge -m &lt;msg&gt; &lt;commit&gt; ... # -m 后可指定提交信息，否则git自动产生提交信息，类似“merge branch `dev` into master”。git merge --abort# 合并失败后会恢复合并前的状态，类似事务失败的情况。建议执行此操作前保持工作区修改内容已提交，否则可能无法恢复。--commit # 合并成功后自动提交（只针对merge commit）--no-commit # 合并成功后不自动提交，需手动提交（只针对merge commit）--edit,-e 和 --no-edit# 自动合并后，是否编辑提交信息，前者会进入编辑页面对提交信息进行编辑；后者则接受git产生的提交信息。--ff和--no-ff# 针对fast forward合并，指定是否产生新的commit对象。前者不会产生新的commit对象，而后者则会产生新的commit对象指向两个分支的末端commit对象。git默认是--ff操作。--ff-only# 只有当fast forward情况时执行合并，否则不做合并操作。开发中常用此操作，例如master分支和fixbug分支常进行fast forward合并的操作。--squash # 压缩合并，详见下一节《Git补充内容》 5）衍合分支rebase（衍合）是merge之外的另一种分支合并方式，它和merge的方式产生的最终快照内容相同，但和merge有很大区别。 I、优点： rebase会产生一个干净的提交历史。例如为某一开源项目进行贡献时，可把本地的分支代码衍合至远程开源库分支的最新提交，这样管理开源库的人就可以通过fast forward纳入你贡献的代码。 II、原理： 回到两个分支（待衍合分支和被衍合进去的分支）的共同祖先； 提取待衍合分支自共同组先后的每次提交时的差异内容，保存至临时文件； 把这些差异文件按次序应用到被衍合进入的分支（类似打补丁），每次应用差异文件都会生成一个新的commit对象； 衍合完成，得到和merge一样的快照内容；但是rebase丢失了产生这些差异文件的commit引用，这些commit对象会变成悬挂态而在合适的时候被git垃圾回收。 不同点 merge rebase 原理 三个commit的合并 差异文件的在目标分支末端的依次应用 是否重写历史 否 是 适用范围 公有分支 私有分支 III、衍合实例 假设当前状态如下图所示。 git rebase master # 当前分支衍合至master分支 123456# 常用参数git rebase &lt;newbase&gt; &lt;branch&gt;# 把branch分支衍合至newbase分支；若省略branch，则默认为当前分支。git rebase --onto &lt;newbase&gt; &lt;upstream&gt; &lt;branch&gt;# branch分支结合upstream分支，可指定从该两者的共同祖先结点开始产生差异文件。 6）删除分支1234git branch --merged # 查看当前分支和已并入当前分支的其他分支git branch --no-merged # 查看未并入当前分支的其他分支git branch -d branchName # 删除已并入当前分支的其他指定分支git branch -D branchName # 强制删除其他指定分支 3、远程跟踪分支和跟踪分支 Checking out a local branch from a remote-tracking branch automatically creates what is called a “tracking branch” (and the branch it tracks is called an “upstream branch”).——引自《ProGit》 1）远程跟踪分支：本地仓库通过clone、fetch或pull操作把远程仓库的分支内容down到本地git仓库后，远程仓库的.git/refs/heads/下的分支索引文件down到本地仓库的.git/refs/remotes/下，以此可被git检索到，在本地仓库形成远程跟踪分支。一般用（远程仓库名）/（分支名）形式表示远程跟踪分支。 2）跟踪分支：从远程跟踪分支检出的本地分支，称为跟踪分支。值得注意的是：克隆仓库时git会自动建立一个master分支来跟踪远程跟踪分支orgin/master。 跟踪分支会通过本地的远程跟踪分支来间接的对远程仓库的分支进行更新操作。详见Git远程仓库。 123456789# 常用命令及参数git checkout --track [远程名]/[分支名]# 创建跟踪分支并检出git checkout -b [分支名] [远程名]/[分支名]# 创建跟踪分支并检出，可指定跟踪分支名称git push [远程名] :[分支名]# 删除远程分支 附注git help show 参考 git merge的三方合并","link":"/2018/02/27/Git%E6%A0%87%E7%AD%BE%E5%92%8C%E5%88%86%E6%94%AF/"},{"title":"HttpClient未设置connectTimeout导致线程池耗尽","text":"一、背景某商家反馈昨天晚上下单失败，研发查询网关日志后发现是edi集群的线程池耗尽，导致商家失败。 12345678// 异常信息{ &quot;error_response&quot;:{ &quot;en_desc&quot;:&quot;platform connecting service process unknown exception:java.util.concurrent.RejectedExecutionException: [JSF-23003]Biz thread pool of provider has bean exhausted&quot;, &quot;zh_desc&quot;:&quot;平台连接后端服务处理过程中出现未知异常:java.util.concurrent.RejectedExecutionException: [JSF-23003]Biz thread pool of provider has bean exhausted&quot;, &quot;code&quot;:67 }} 二、可能原因分析 业务代码没有问题，但是瞬时流量加大，达到资源瓶颈； 业务代码有问题，使线程阻塞，长期占用线程，无法归还线程池； 三、定位过程 查询网关，定位线程池耗尽的服务器IP； 查询该IP上该时间段的流量，发现流量为0； 以上确定是由于业务代码有问题导致的；此时可通过如下两种方式继续定位问题： 精确定位: 在该机器上执行jstack pid，查看线程堆栈里jsf线程阻塞到哪行代码了； 范围定位: 在该机器上找到当时的日志，查看该线程最后执行的业务逻辑； 由于中间重启过集群，故采取第二种方法定位问题。 日志最终定位到是http请求节点阻塞，然后查看http节点的属性发现没有设置connectTimeout。我们使用的是httpclient-4.5.6，如果不设置connectTimeout则默认无限等待； 四、结论 使用第三方插件时，最好调研下常用配置，并全部配置上去。 避免出现默认值不符合预期时导致程序不健壮。","link":"/2020/08/06/HttpClient%E6%9C%AA%E8%AE%BE%E7%BD%AEconnectTimeout%E5%AF%BC%E8%87%B4%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%80%97%E5%B0%BD/"},{"title":"FutureTask构建高效缓存","text":"例子来源于Java并发编程实战，5.6 构建高效且可伸缩的结果缓存。 12345678910111213141516171819202122232425262728293031323334public class Memoizer&lt;A, V&gt; implements Computable&lt;A, V&gt; { private final ConcurrentMap&lt;A, Future&lt;V&gt;&gt; cache = new ConcurrentHashMap&lt;A, Future&lt;V&gt;&gt;(); private final Computable&lt;A, V&gt; c; public Memoizer(Computable&lt;A, V&gt; c) { this.c = c; } public V compute(final A arg) throws InterruptedException { while (true) { Future&lt;V&gt; f = cache.get(arg); if (f == null) { Callable&lt;V&gt; eval = new Callable&lt;V&gt;() { public V call() throws InterruptedException { return c.compute(arg); } }; FutureTask&lt;V&gt; ft = new FutureTask&lt;V&gt;(eval); f = cache.putIfAbsent(arg, ft); if (f == null) { f = ft; ft.run(); } } try { return f.get(); } catch (CancellationException e) { cache.remove(arg, f); } catch (ExecutionException e) { throw LaunderThrowable.launderThrowable(e.getCause()); } } }}","link":"/2022/05/13/FutureTask%E6%9E%84%E5%BB%BA%E9%AB%98%E6%95%88%E7%BC%93%E5%AD%98/"},{"title":"Gson如何实例化类","text":"一、Gson类图及实例化流程 二、Gson实例化流程 1）获取构造器流程 123456789101112131415161718192021222324252627282930313233343536373839404142434445public final class ConstructorConstructor { public &lt;T&gt; ObjectConstructor&lt;T&gt; get(TypeToken&lt;T&gt; typeToken) { final Type type = typeToken.getType(); final Class&lt;? super T&gt; rawType = typeToken.getRawType(); // first try an instance creator // types must agree final InstanceCreator&lt;T&gt; typeCreator = (InstanceCreator&lt;T&gt;) instanceCreators.get(type); if (typeCreator != null) { return new ObjectConstructor&lt;T&gt;() { @Override public T construct() { return typeCreator.createInstance(type); } }; } // Next try raw type match for instance creators // types must agree final InstanceCreator&lt;T&gt; rawTypeCreator = (InstanceCreator&lt;T&gt;) instanceCreators.get(rawType); if (rawTypeCreator != null) { return new ObjectConstructor&lt;T&gt;() { @Override public T construct() { return rawTypeCreator.createInstance(type); } }; } // 使用默认无参构造函数 ObjectConstructor&lt;T&gt; defaultConstructor = newDefaultConstructor(rawType); if (defaultConstructor != null) { return defaultConstructor; } // 集合类和Map类型指定构造器 ObjectConstructor&lt;T&gt; defaultImplementation = newDefaultImplementationConstructor(type, rawType); if (defaultImplementation != null) { return defaultImplementation; } // finally try unsafe return newUnsafeAllocator(type, rawType); }} 2）Unsafe实例化类当要实例化的类没有无参构造函数时，Gson会使用Unsafe#allocateInstance方法来实例化类。该方法只会在JVM内存区域根据类的定义分配空间，不会调用&lt;init&gt;方法。 123456789101112131415161718192021222324public abstract class UnsafeAllocator { public static UnsafeAllocator create() { // TRY JVM try { Class&lt;?&gt; unsafeClass = Class.forName(&quot;sun.misc.Unsafe&quot;); Field f = unsafeClass.getDeclaredField(&quot;theUnsafe&quot;); f.setAccessible(true); final Object unsafe = f.get(null); final Method allocateInstance = unsafeClass.getMethod(&quot;allocateInstance&quot;, Class.class); return new UnsafeAllocator() { @Override @SuppressWarnings(&quot;unchecked&quot;) public &lt;T&gt; T newInstance(Class&lt;T&gt; c) throws Exception { assertInstantiable(c); return (T) allocateInstance.invoke(unsafe, c); } }; } catch (Exception ignored) { } // TRY dalvikvm ... }}","link":"/2021/09/01/Gson%E5%A6%82%E4%BD%95%E5%AE%9E%E4%BE%8B%E5%8C%96%E7%B1%BB/"},{"title":"Git配置","text":"一、配置gitconfig用户可以通过配置git的config文件定义和保存偏好，config文件有多个对应不用的作用域，且优先级高的会覆盖低的： 1、三个作用域 config路径 作用域 配置命令 优先级 project/.git/config project项目 git config (–local 缺省参数) 高 ~/.gitconfig 当前用户 git config –global 中 /etc/gitconfig 本机所有用户 git config –system 低 2、配置操作1）查看配置文档：git help config 2）查看已有配置 命令 结果 git config -l 显示所有级别的配置内容(按由低到高的优先级排列)，即多个重复项中最后一项生效 git config –local -l 显示本项目的配置内容 git config –global -l 显示当前用户的配置内容 git config –system -l 显示本机所有用户的配置内容 git config –scope key 显示指定作用域的指定key的值，例如:git config –global user.name 3）配置config 配置方式 操作 命令配置 例如：git config –global user.name “kivi” 编辑config文件 例如：vim ~/.gitconfig 3、配置实例要正确使用git，只要简单配置如下即可： git config –global user.name “kivi” git config –global user.email shichengyx@sina.com 二、配置忽略文件git可以配置忽略文件来忽略工作区的指定文件，例如Java项目可通过配置忽略文件来禁止class文件上传到git仓库。 1、两个配置文件git忽略文件有两个：.gitignore和exlude文件，Git根据两个文件的内容忽略相应文件。 1）.gitignore隶属于工作区，是项目的一个文件，被Git版本管理（同其他文件一样以blob对象的形式存储在.git/objects/目录下）。适合配置项目公开的忽略文件，其他开发者可见 2）exclude文件位于.git/info/exclude，不属于项目，不被Git版本管理。适合配置本地的忽略文件，其他开发者不可见 2、语法规则 git help ignore 查看详细规则 1）#起始的行为注释行 2）绝对路径和相对路径 绝对路径：以/起始的路径，例如：/bin/仅忽略根目录下的bin文件下的文件。 相对路径：非/起始的路径，例如：bin/忽略任意层级下的bin文件夹下的文件 3）忽略文件还是目录？ folderA/name：忽略folderA下的name文件和文件夹。 folderA/name/：忽略folderA下的name文件夹。 4）特殊字符：！、?、*、**和[] !：排除 ?：匹配任意一个字符【类似regex的.】 *：匹配任意多个字符（在Linux和Windows平台表现不同，Linux下等同与**，Windows则不等同） **：匹配任意层级目录【类似regex的.*】 []：匹配一个字符组【等同regex的[]】 3、配置gitignorevim .gitignore 12345678# 这是一行注释.[oa] # 忽略以.o、.a结尾的文件或文件夹.html # 忽略以.html结尾的文件或文件夹!foo.html # 但foo.html除外/bin/*.class # 忽略/bin/下以.class结尾的文件，不包括/foo/bin/.classlib/ # 忽略lib下所有文件target/*.jar # 忽略target下以.jar结尾的文件，不包括target/foo/foo.jardoc/**/*.txt # 忽略doc下所有以.txt结尾的文件 4、配置excludevim .git/info/exclude，参考.gitignore配置。 三、配置远程仓库1、远程仓库 Git通过远程仓库的方式进行团队协作开发。远程仓库是指托管到网络上的项目仓库，有权限的项目成员可通过拉取和推送操作来协同开发。 1）管理远程仓库 2）拉取（fetch/pull）和推送（push） 1、命令：git fetch [repository] [remote-branch]:[local-branch] 2、命令：git pull相当于git fetch + git merge。即先把远程分支fetch到本地，然后和当前分支合并（分支合并将在分支章节详细说明）。 3、命令：git push [repository] [local-branch]:[remote-branch]。 若执行：git push origin master:master，结果为： 1）更新远程origin仓库的refs/heads/master分支。 2）更新本地仓库的refs/remotes/origin/master分支。 2、配置远程仓库1）两个相关命令12345// 设置跟踪分支git branch (--set-upstream-to=&lt;upstream&gt; | -u &lt;upstream&gt;) [&lt;branchname&gt;]// 取消跟踪分支git branch --unset-upstream [&lt;branchname&gt;] 2）.gitconfig文件1）git init 12345[core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true 2）git remote add origin git@git.jd.com:wangqiwei7/git-test.git 12345678[core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true[remote &quot;origin&quot;] url = git@git.jd.com:wangqiwei7/git-test.git fetch = +refs/heads/*:refs/remotes/origin/* 3）git branch -u origin/dev dev 1234567891011[core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true[remote &quot;origin&quot;] url = git@git.jd.com:wangqiwei7/git-test.git fetch = +refs/heads/*:refs/remotes/origin/* [branch &quot;dev&quot;] remote = origin merge = refs/heads/dev 4）git branch --unset-upstream dev 12345678[core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true[remote &quot;origin&quot;] url = git@git.jd.com:wangqiwei7/git-test.git fetch = +refs/heads/*:refs/remotes/origin/* 参考 自定义 Git - 配置 Git","link":"/2018/01/29/Git%E9%85%8D%E7%BD%AE/"},{"title":"HttpClient（一）连接池","text":"一、代码示例1）引入httpclient依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.13&lt;/version&gt;&lt;/dependency&gt; 2）测试用例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class HttpClientTest { Logger logger = LoggerFactory.getLogger(HttpClientTest.class); @Before public void startHttpServerOnPort8081() throws IOException, InterruptedException { startHttpServer(8081, &quot;/hello&quot;); } @Before public void startHttpServerOnPort8082() throws IOException, InterruptedException { startHttpServer(8082, &quot;/world&quot;); } private void startHttpServer(int port, String path) throws IOException, InterruptedException { HttpServer httpServer = HttpServer.create(new InetSocketAddress(port), 0); httpServer.setExecutor(Executors.newFixedThreadPool(10)); HttpHandler httpHandler = exchange -&gt; { logger.info(&quot;Server开始处理请求&quot;); try { Thread.sleep(5000); } catch (InterruptedException e) {//ignore } byte[] body = &quot;hello world&quot;.getBytes(StandardCharsets.UTF_8); exchange.getResponseHeaders().add(&quot;Content-Type&quot;, &quot;text/html;charset=UTF-8&quot;); exchange.sendResponseHeaders(200, body.length); exchange.getResponseBody().write(body); exchange.getResponseBody().flush(); exchange.close(); }; httpServer.createContext(path, httpHandler); httpServer.start(); logger.info(&quot;Http Server listening on port &quot; + port); } @Test public void testHttpClient() throws Exception { PoolingHttpClientConnectionManager connManager = new PoolingHttpClientConnectionManager(); // 连接池的最大连接数 connManager.setMaxTotal(20); // 每个路由的最大的连接数 connManager.setDefaultMaxPerRoute(1); // 指定Route，最大连接数 connManager.setMaxPerRoute(new HttpRoute(new HttpHost(&quot;localhost&quot;, 8081)), 2); CloseableHttpClient httpClient = HttpClientBuilder.create() .setConnectionManager(connManager) .build(); List&lt;String&gt; urls = Arrays.asList(&quot;http://localhost:8081/hello&quot;, &quot;http://localhost:8082/world&quot;); for (int i = 0; i &lt; 4; i++) { int j = i; new Thread(() -&gt; { doGet(httpClient, urls.get(j % 2)); }).start(); } new CountDownLatch(1).await(); } private void doGet(CloseableHttpClient httpClient, String url) { logger.info(&quot;客户端开始请求URL: &quot; + url); HttpGet get = new HttpGet(url); RequestConfig config = RequestConfig.custom() // 从HttpClient连接池等待连接超时 .setConnectionRequestTimeout(10000) // TCP建立连接超时时间 .setConnectTimeout(5000) // TCP开始传输数据时，接收到两个packet的最大间隔时间 .setSocketTimeout(8000) .build(); get.setConfig(config); try (CloseableHttpResponse result = httpClient.execute(get)) { String s = EntityUtils.toString(result.getEntity()); logger.info(&quot;Http Response: &quot; + s); } catch (Exception e) { logger.error(&quot;请求失败&quot;, e); } }} 二、线程池设置通过查看org.apache.http.impl.client.HttpClientBuilder#build源码可知，HttpClientBuilder在不设置任何参数的情况下使用的是PoolingHttpClientConnectionManager。 而PoolingHttpClientConnectionManager初始化时默认设置defaultMaxPerRoute=2, maxTotal=20。可以通过以上测试用例验证。 123456789101112public PoolingHttpClientConnectionManager( final HttpClientConnectionOperator httpClientConnectionOperator, final HttpConnectionFactory&lt;HttpRoute, ManagedHttpClientConnection&gt; connFactory, final long timeToLive, final TimeUnit timeUnit) { super(); this.configData = new ConfigData(); // defaultMaxPerRoute=2, maxTotal=20 this.pool = new CPool(new InternalConnectionFactory(this.configData, connFactory), 2, 20, timeToLive, timeUnit); this.pool.setValidateAfterInactivity(2000); this.connectionOperator = Args.notNull(httpClientConnectionOperator, &quot;HttpClientConnectionOperator&quot;); this.isShutDown = new AtomicBoolean(false);} HttpClient的线程池有设置有几个概念： HttpRoute：http请求的主机+port。例如http://localhost:8081/hello的Route为http://localhost:8081 maxPerRoute：一个Route的最大请求数； maxTotal：httpClient实例的最大请求数； 简单比喻，当前总共有maxTotal个苹果，每个人（HttpRoute）最多拿maxPerRoute个，如果不满足则等待ConnectionRequestTimeout时间。 # 参考 Httpclient核心架构设计","link":"/2021/07/04/HttpClient%EF%BC%88%E4%B8%80%EF%BC%89%E8%BF%9E%E6%8E%A5%E6%B1%A0/"},{"title":"HttpClient（二）结构","text":"一、HttpClient结构图 下图来源于对org.apache.httpcomponents:httpclient:4.5.13的源码分析。 二、HttpClient扩展口1）HttpClientBuilder中有对ClientExecChain的装饰方法 12HttpClientBuilder#decorateMainExecHttpClientBuilder#decorateProtocolExec 2）HttpClientBuilder中对ProtocolExec请求和响应拦截器的扩展 12345HttpClientBuilder#addInterceptorFirst(org.apache.http.HttpRequestInterceptor)HttpClientBuilder#addInterceptorLast(org.apache.http.HttpRequestInterceptor)HttpClientBuilder#addInterceptorFirst(org.apache.http.HttpResponseInterceptor)HttpClientBuilder#addInterceptorLast(org.apache.http.HttpResponseInterceptor) 3）HttpClientBuilder中对RetryExec的RetryHandler进行配置 1HttpClientBuilderBack#setRetryHandler(org.apache.http.client.HttpRequestRetryHandler) 三、示例1）HTTP获取服务器证书 - 通过增加ProtocolExec的拦截器实现。代码来源 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class HttpClientGetServerCertificate { public static final String PEER_CERTIFICATES = &quot;PEER_CERTIFICATES&quot;; public static void main(String... args) throws IOException { // create http response certificate interceptor HttpResponseInterceptor certificateInterceptor = (httpResponse, context) -&gt; { ManagedHttpClientConnection routedConnection = (ManagedHttpClientConnection)context.getAttribute(HttpCoreContext.HTTP_CONNECTION); SSLSession sslSession = routedConnection.getSSLSession(); if (sslSession != null) { // get the server certificates from the {@Link SSLSession} Certificate[] certificates = sslSession.getPeerCertificates(); // add the certificates to the context, where we can later grab it from context.setAttribute(PEER_CERTIFICATES, certificates); } }; // create closable http client and assign the certificate interceptor CloseableHttpClient httpClient = HttpClients.custom().addInterceptorLast(certificateInterceptor).build(); try { // make HTTP GET request to resource server HttpGet httpget = new HttpGet(&quot;https://www.baidu.com&quot;); System.out.println(&quot;Executing request &quot; + httpget.getRequestLine()); // create http context where the certificate will be added HttpContext context = new BasicHttpContext(); httpClient.execute(httpget, context); // obtain the server certificates from the context Certificate[] peerCertificates = (Certificate[])context.getAttribute(PEER_CERTIFICATES); // loop over certificates and print meta-data for (Certificate certificate : peerCertificates){ X509Certificate real = (X509Certificate) certificate; System.out.println(&quot;----------------------------------------&quot;); System.out.println(&quot;Type: &quot; + real.getType()); System.out.println(&quot;Signing Algorithm: &quot; + real.getSigAlgName()); System.out.println(&quot;IssuerDN Principal: &quot; + real.getIssuerX500Principal()); System.out.println(&quot;SubjectDN Principal: &quot; + real.getSubjectX500Principal()); System.out.println(&quot;Not After: &quot; + DateUtils.formatDate(real.getNotAfter(), &quot;dd-MM-yyyy&quot;)); System.out.println(&quot;Not Before: &quot; + DateUtils.formatDate(real.getNotBefore(), &quot;dd-MM-yyyy&quot;)); } } finally { // close httpclient httpClient.close(); } }} 2）增加异常监听逻辑 12345HttpRequestRetryHandler retryHandler = (exception, executionCount, context) -&gt; { // 可以在此处增加异常监听逻辑 return DefaultHttpRequestRetryHandler.INSTANCE.retryRequest(exception, executionCount, context);}; clientBuilder.setRetryHandler(retryHandler);","link":"/2021/09/02/HttpClient%EF%BC%88%E4%BA%8C%EF%BC%89%E7%BB%93%E6%9E%84/"},{"title":"Git补充内容","text":"本节作为一个杂烩，介绍Git的一些零散但有用的技能知识。 一、祖先引用（^和～区别） 符号 作用 特殊缩写 ^n 代表当前提交的第n父提交，结果为某一父辈提交 ^是^1的简写 ~n 代表当前提交的n次父提交，结果为某一祖先提交 ～是～1的简写 关于^和～的区别，stackoverflow的What’s the difference between HEAD^ and HEAD~ in Git?下的回答很好，此处引用高票答案的图如下。 二、提交范围通过祖先引用可以指明单次提交，此外通过特定语法我们还可以指定一定范围的提交。这常常是有用的，例如有时我们需要查看“这个分支的哪些提交还没有合并到主分支？”。 类别 表示 作用 数学概念 两点提交 before..after 隶属于after分支，但不隶属于before的提交 差集 (after-before) 三点提交 before…after 两分支中除去共同拥有的提交外的提交 并集-交集 (before∪after - before∩after) 多点提交 ^或–not 不包含指定分支的所有提交 差集 三、git cherry-pick挑拣类似针对某次特定提交的衍合。它首先提取某次提交的补丁，然后试着应用在当前分支上。应用场景： 1）如果某特性分支上有多个commits，你只想引入其中一个，就可使用挑拣。 2）或者个人偏好挑拣胜于衍合。 示例 当前有两个分支，若master分支只想引入e43a6的快照内容，则可进行如下操作。 1git cherry-pick e43a6 # 在当前状态执行挑拣 四、git rebase通过rebase当前分支，可达到修改多个提交的目的。 12345# 重写到指定提交（非Root）之间的所有提交git rebase -i &lt;newbase&gt; # 进入rebase交互模式，从newbase处开始进行多个提交的修改# 重写到Root的所有提交，--root rebase all reachable commits up to the root(s)git rebase -i --root 1、示例 2、命令解释 命令 含义 使用场景 pick 提交 保持原样 reword 先编辑提交信息，然后再提交 可编辑多个历史提交信息 edit 提交后中断，可通过git rebase –continue继续下面操作 1）可编辑多个历史提交信息；2）一个拆分为多个提交（结合命令git reset HEAD~、git add和git commit） squash 把本次提交整合进上一次提交，需编辑的合并的提交信息 把多个提交压缩为一个提交 drop 删除提交 删除提交 五、git filter-branch 作用：遍历所有commit，并对每个提交执行某个指令操作。 场景：1）仓库要开源，遍历所有提交去除掉敏感信息；2）手误提交了一个大文件，需要从仓库里删除。 六、git stash 1、简介1）执行git stash命令，发现只会把已跟踪的文件暂存起来： 2）然后执行git stash pop，发现之前的暂存区的状态会丢失： 2、深入git stash的参数1）暂存所有状态的文件：git stash --all 2）恢复暂存前所有状态：git stash apply|pop --index 七、sparse checkout 假如我本地只想检出edi-rest-launcher，则可进行如下配置： 1、配置.git/config，增加sparsecheckout = true 123456789101112131415[core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true sparsecheckout = true[remote &quot;origin&quot;] url = git@git.jd.com:jdwl_edi/edi-aggregate.git fetch = +refs/heads/*:refs/remotes/origin/*[branch &quot;master&quot;] remote = origin merge = refs/heads/master[branch &quot;dev&quot;] remote = origin merge = refs/heads/dev 2、配置.git/info/sparse-checkout 1edi-rest-launcher 八、子模块 若出现项目引用一个公共库的情况，可把公共库以子模块的方式导入到当前项目。 当前项目库中只保存子模块的url、路径和最新commit的引用。 具体使用可参考：姜家志老师写的文章《使用Git Submodule管理子模块》，本节不在赘述。 九、补丁 多用于公开的大型项目。 当前不做介绍，只需了解可以创建补丁和应用补丁来实现代码更新。 十、Git调试1、文件标注可使用git blame来标注文件，查看文件中某一行是谁在哪一天修改的。其实该命令从名称可以看出来，就是出事后来问责的：）。 12git blame -L &lt;range&gt; filename# 若指定12行到20行，则range可表示为12,20或12,+9，此外还支持正则表达式 2、二分查找git通过二分查找为在大量提交中找出引发系统错误的提交提供了高效的解决方案。 12345678git bisect start &lt;bad&gt; &lt;good&gt;指定问题区间，等同于以下三条命令1. git bisect start2. git bisect bad &lt;bad&gt;3. git bisect good &lt;good&gt;git bisect bad # 标注当前为badgit bisect good # 标注当前为good 十一、git提交规范 1、git提交规范1234&lt;type&gt;: &lt;subject&gt;&lt;BLANK LINE&gt;&lt;detail body&gt;&lt;/detail body&gt; 1）首行 声明提价的类型和摘要，便于通过命令或工具过滤，搜索。 类型主要有：feature，refactor，fixbug等，可团队内协定。 2）首行后的空行 必须存在，是body和首行摘要的分隔符。 3）详情 可详细说明本地提交的内容 粒度要比摘要详细。 2、示例1）新增特性-library相关rest 12345feature: add library rest1) add lib query rest;2) add lib upload rest;3) add lib delete rest; 2）重构已有的library rest 1234refactor: extract BaseController from librarayController 1) extract sso logic to BaseController2) extract file upload logic to BaseController 十二、Git分析工具1、Gource - Git提交可视化 2、gitstats - Git仓库分析，如提交时间分析、提交人分析、趋势，使用说明。","link":"/2018/03/04/Git%E8%A1%A5%E5%85%85%E5%86%85%E5%AE%B9/"},{"title":"Http_Content-Length","text":"Http Content-Length如果请求Header设置里Content-Length，则需要和body体长度匹配。否则会出现非预期结果：1）Content-Length &gt; body length会等待输入完整body体而阻塞，等待超时后关闭链接。 123456789101112# curl -X POST -v -H 'Content-Length:1' baidu.com* Trying 110.242.68.66:80...* Connected to baidu.com (110.242.68.66) port 80 (#0)&gt; POST / HTTP/1.1&gt; Host: baidu.com&gt; User-Agent: curl/7.79.1&gt; Accept: */*&gt; Content-Length:1&gt;* Empty reply from server* Closing connection 0curl: (52) Empty reply from server 2）Content-Length &lt; body length会根据Content-Length截断body体。 参考 understand-http-content-length","link":"/2022/09/08/Http_Content-Length/"},{"title":"HttpClient（三）连接池获取连接","text":"源码：httpcomponents-core-4.4.13，org.apache.http.pool.AbstractConnPool 一、源码+注释123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119public abstract class AbstractConnPool&lt;T, C, E extends PoolEntry&lt;T, C&gt;&gt; implements ConnPool&lt;T, E&gt;, ConnPoolControl&lt;T&gt; { private E getPoolEntryBlocking( final T route, final Object state, final long timeout, final TimeUnit timeUnit, final Future&lt;E&gt; future) throws IOException, InterruptedException, ExecutionException, TimeoutException { // 1. 根据connectionRequestTimeout计算等待终止时间 Date deadline = null; if (timeout &gt; 0) { deadline = new Date (System.currentTimeMillis() + timeUnit.toMillis(timeout)); } this.lock.lock(); try { // 2. 获取该路由的连接池，如果没有则新建 final RouteSpecificPool&lt;T, C, E&gt; pool = getPool(route); E entry; // 3. 循环用来处理等待逻辑 for (;;) { Asserts.check(!this.isShutDown, &quot;Connection pool shut down&quot;); if (future.isCancelled()) { throw new ExecutionException(operationAborted()); } // 4. 尝试从该路由的连接池获取连接 for (;;) { // 若pool.available有可用连接，则移动至pool.leased并返回 entry = pool.getFree(state); if (entry == null) { break; } // entry若过期，设置为close if (entry.isExpired(System.currentTimeMillis())) { entry.close(); } // entry若已close，则从全局可用队列this.available移除 if (entry.isClosed()) { // 全局可用available移除 this.available.remove(entry); // 从pool.leased移动至pool.available pool.free(entry, false); } else { break; } } // 5.1 若从该路由的连接池获取到连接，则从全局可用队列移动到待释放队列，然后返回 // this.available ---&gt; this.leased if (entry != null) { this.available.remove(entry); this.leased.add(entry); onReuse(entry); return entry; } // 5.2 若从该路由的连接池没获取到连接，则开始新建连接逻辑 // 1）获取该路由允许使用连接的最大值 final int maxPerRoute = getMax(route); // 2）计算该路由超出的连接数（由于最少需要释放一个，所以总数+1） final int excess = Math.max(0, pool.getAllocatedCount() + 1 - maxPerRoute); // 3）按LRU淘汰从该路由的pool.available移除空闲连接，同样在全局this.available里删除 if (excess &gt; 0) { for (int i = 0; i &lt; excess; i++) { final E lastUsed = pool.getLastUsed(); if (lastUsed == null) { break; } lastUsed.close(); this.available.remove(lastUsed); pool.remove(lastUsed); } } // 4.1）如果该路由当前已分配的连接小于设置的该路由的最大连接数，并且全局连接数未达到上限，为该路由创建新连接。然后返回。 // 当前全局连接数大于上限时，则根据LRU原则从全局可用连接里淘汰连接（会从其路由里也删除） if (pool.getAllocatedCount() &lt; maxPerRoute) { final int totalUsed = this.leased.size(); final int freeCapacity = Math.max(this.maxTotal - totalUsed, 0); if (freeCapacity &gt; 0) { final int totalAvailable = this.available.size(); if (totalAvailable &gt; freeCapacity - 1) { if (!this.available.isEmpty()) { final E lastUsed = this.available.removeLast(); lastUsed.close(); final RouteSpecificPool&lt;T, C, E&gt; otherpool = getPool(lastUsed.getRoute()); otherpool.remove(lastUsed); } } final C conn = this.connFactory.create(route); entry = pool.add(conn); this.leased.add(entry); return entry; } } // 4.2）加入连接等待队列，当有连接释放时，若等待队列不为空则会唤醒等待的线程，进入下次循环重新尝试获取连接。 // 此处会根据设置的connectionRequestTimeout设置等待超时时间 boolean success = false; try { pool.queue(future); this.pending.add(future); if (deadline != null) { success = this.condition.awaitUntil(deadline); } else { this.condition.await(); success = true; } if (future.isCancelled()) { throw new ExecutionException(operationAborted()); } } finally { pool.unqueue(future); this.pending.remove(future); } if (!success &amp;&amp; (deadline != null &amp;&amp; deadline.getTime() &lt;= System.currentTimeMillis())) { break; } } throw new TimeoutException(&quot;Timeout waiting for connection&quot;); } finally { this.lock.unlock(); } }} 二、获取连接逻辑 根据connectionRequestTimeout计算等待终止时间 获取该路由的连接池，如果没有则新建 循环用来处理等待逻辑 尝试从该路由的连接池获取连接 若从该路由的连接池获取到连接，则从全局可用队列移动到待释放队列，然后返回 若从该路由的连接池没获取到连接，则开始新建连接逻辑 获取该路由允许使用连接的最大值，计算该路由超出的连接数（由于最少需要释放一个，所以总数+1） 按LRU淘汰从该路由的pool.available移除空闲连接，同样在全局this.available里删除 如果该路由当前已分配的连接小于设置的该路由的最大连接数，并且全局连接数未达到上限，为该路由创建新连接，然后返回（当前全局连接数大于上限时，则根据LRU原则从全局可用连接里淘汰连接，会从其对应路由里也删除） 加入连接等待队列，当有连接释放时，若等待队列不为空则会唤醒等待的线程，进入下次循环重新获取连接（此处会根据设置的connectionRequestTimeout设置等待超时时间） 三、结构图","link":"/2022/02/16/HttpClient%EF%BC%88%E4%B8%89%EF%BC%89%E8%BF%9E%E6%8E%A5%E6%B1%A0%E8%8E%B7%E5%8F%96%E8%BF%9E%E6%8E%A5/"},{"title":"Http_trailing_slashes","text":"Trailing slashesUrl尾部的/视情况可能会有不同预期： 位置 例子 是否相同 domain后 github.com/github.com 相同 path后 github.com/kivihubgithub.com/kivihub/ 不同，但可以通过重定向趋同 URL规范里path后的有/，资源视为一个目录，否则视为一个文件，当然你也可以按个人喜好定义。 参考 Should You Have a Trailing Slash at the End of URLs? https://developers.google.com/search/blog/2010/04/to-slash-or-not-to-slash","link":"/2022/09/08/Http_trailing_slashes/"},{"title":"Http上传文件的Content-Type格式","text":"一、问题描述昨天研发反馈使用EDI的HTTP调用结点时，http响应报错如下： Failed to parse multipart servlet request; nested exception is java.io.IOException: org.apache.tomcat.util.http.fileupload.FileUploadException: the request was rejected because no multipart boundary was found。 二、原因EDI在构建http请求头时设置了Content-Type为“multipart/form-data;charset=UTF-8”，缺失了boundary，导致了如上错误。正确的Content-Type格式应该为：“multipart/form-data; boundary=” 三、代码修改设置Camel Body的时候需要一起设置header，最终发送请求的header格式类似： “Content-Type”: “multipart/form-data; boundary=BL6dpsdzxPuead3_GSOFXzNdhK6e85Wth_” 123456/* * 此处必须复写Content-Type，使其格式为：multipart/form-data; boundary=&lt;get after entity has been builded&gt; * 否则，服务端会报错如下：“the request was rejected because no multipart boundary was found” */exchange.getIn().setHeader(Exchange.CONTENT_TYPE, httpEntity.getContentType().getValue());exchange.getIn().setBody(httpEntity); 四、Postman验证上面的Content-Type是postman内置的，下面的是手动加上的。 实验：1）两者都勾选，上传成功 2）只勾选手动添加的Content-Type，上传失败，错误同上 3）只勾选内置的Content-Type，上传成功 参考 Camel send multipart/form-data request https://stackoverflow.com/questions/17415084/multipart-data-post-using-python-requests-no-multipart-boundary-was-found","link":"/2021/01/07/Http%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E7%9A%84Content-Type%E6%A0%BC%E5%BC%8F/"},{"title":"InnoDb死锁分析","text":"mysql8.0增加了performance_schema.data_locks，可以查看Innodb锁状态： 12SELECT ENGINE_TRANSACTION_ID trx_id,INDEX_NAME,LOCK_TYPE,LOCK_DATA,LOCK_MODE,LOCK_STATUS FROM performance_schema.data_locks; 一、死锁案例一假设有两个连接conn1，conn2，且假设d011记录已存在： 1）conn1执行INSERT操作insert employees.departments values('d011', 'qiwei'); # trx_id INDEX_NAME LOCY_TYPE LOCK_DATA LOCK_MODE LOCK_STATUS 1 2360 TABLE IX GRANTED 2 2360 PRIMARY RECORD ‘d011’ S,REC_NOT_GAP GRANTED 2）conn2执行INSERT操作：insert employees.departments values('d011', 'qiwei'); # trx_ix INDEX_NAME LOCY_TYPE LOCK_DATA LOCK_MODE LOCK_STATUS 1 2361 TABLE IX GRANTED 2 2361 PRIMARY RECORD ‘d011’ S,REC_NOT_GAP GRANTED 3 2360 TABLE IX GRANTED 4 2360 PRIMARY RECORD ‘d011’ S,REC_NOT_GAP GRANTED 3）conn1执行UPDATE操作：update employees.departments set dept_name='kivi' where dept_no='d011'; # trx_id INDEX_NAME LOCY_TYPE LOCK_DATA LOCK_MODE LOCK_STATUS 1 2361 TABLE IX GRANTED 2 2361 PRIMARY RECORD ‘d011’ S,REC_NOT_GAP GRANTED 3 2360 TABLE IX GRANTED 4 2360 PRIMARY RECORD ‘d011’ S,REC_NOT_GAP GRANTED 5 2360 PRIMARY RECORD ‘d011’ X,REC_NOT_GAP WAITING 4）conn2执行UPDATE操作：update employees.departments set dept_name='kivi' where dept_no='d011';，发生死锁。 # trx_id INDEX_NAME LOCY_TYPE LOCK_DATA LOCK_MODE LOCK_STATUS 1 2361 TABLE IX GRANTED 2 2361 PRIMARY RECORD ‘d011’ S,REC_NOT_GAP GRANTED 3 2361 PRIMARY RECORD ‘d011’ X,REC_NOT_GAP WAITING 4 2360 TABLE IX GRANTED 5 2360 PRIMARY RECORD ‘d011’ S,REC_NOT_GAP GRANTED 6 2360 PRIMARY RECORD ‘d011’ X,REC_NOT_GAP WAITING 二、死锁案例二假设有两个连接conn1，conn2，且假设d015记录不存在： 1）conn1执行SELECT … FOR UPDATE操作：select * from employees.departments for update where dept_no='d015'; # trx_id INDEX_NAME LOCY_TYPE LOCK_DATA LOCK_MODE LOCK_STATUS 1 2366 TABLE IX GRANTED 2 2366 PRIMARY RECORD supremum pseudo-record X GRANTED 2）conn2执行SELECT … FOR UPDATE操作：conn2&gt; select * from employees.departments for update where dept_no='d015'; # trx_id INDEX_NAME LOCY_TYPE LOCK_DATA LOCK_MODE LOCK_STATUS 1 2367 TABLE IX GRANTED 2 2367 PRIMARY RECORD supremum pseudo-record X GRANTED 3 2366 TABLE IX GRANTED 4 2366 PRIMARY RECORD supremum pseudo-record X GRANTED 3）conn1执行INSERT操作：insert employees.departments values('d015', 'qiwei'); # trx_id INDEX_NAME LOCY_TYPE LOCK_DATA LOCK_MODE LOCK_STATUS 1 2367 TABLE IX GRANTED 2 2367 PRIMARY RECORD supremum pseudo-record X GRANTED 3 2366 TABLE IX GRANTED 4 2366 PRIMARY RECORD supremum pseudo-record X GRANTED 5 2366 PRIMARY RECORD supremum pseudo-record X, INSERT_INTENTION WAITING 4）conn2执行INSERT操作：insert employees.departments values('d015', 'qiwei');，发生死锁。 # trx_id INDEX_NAME LOCY_TYPE LOCK_DATA LOCK_MODE LOCK_STATUS 1 2367 TABLE IX GRANTED 2 2367 PRIMARY RECORD supremum pseudo-record X GRANTED 3 2367 PRIMARY RECORD supremum pseudo-record X, INSERT_INTENTION WAITING 4 2366 TABLE IX GRANTED 5 2366 PRIMARY RECORD supremum pseudo-record X GRANTED 6 2366 PRIMARY RECORD supremum pseudo-record X, INSERT_INTENTION WAITING 三、详解// TODO # 参考 https://dev.mysql.com/doc/mysql-perfschema-excerpt/8.0/en/performance-schema-lock-tables.html https://mysqlserverteam.com/innodb-data-locking-part-1-introduction/ https://mysqlserverteam.com/innodb-data-locking-part-2-locks/ https://mysqlserverteam.com/innodb-data-locking-part-2-5-locks-deeper-dive/ https://mysqlserverteam.com/innodb-data-locking-part-3-deadlocks/","link":"/2021/03/08/InnoDb%E6%AD%BB%E9%94%81%E5%88%86%E6%9E%90/"},{"title":"JDK自带的性能监控工具","text":"一、命令1、jps 查看当前运行的所有java进程 2、jinfo1）查看jvm启动参数 2）修改jvm运行参数（启动参数有部分支持运行时修改） 3、jmap查看内存中类的加载状态，内存的参数，内存的各个区状态，dump内存； 1234jmap -histo pidjmap -histo:alive pid // 手动触发垃圾回收jmap -heap pidjmap -dump 4、jhat网页方式打开分析jmap导出的dump文件； 5、jstack查看线程栈，常用于定位线程死锁，CPU使用率高； NOTE：为什么cpu100%仍能响应jstack？ CPU时分时调度，接收jstack命令的线程会被分配时间片执行。 6、jstat实时监控运行时内存各个区的内存使用状态，常用于JVM内存调优 二、案例1、CPU 100%1）top 找到CPU高的进程，假设为pid 2）top -H -p pid 找到进程中CPU使用高的线程，假设为tid 3）jstack pid 打印线程栈，从中找出tid的线程栈，定位问题代码","link":"/2020/07/16/JDK%E8%87%AA%E5%B8%A6%E7%9A%84%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7/"},{"title":"JDBC的时区调停","text":"一、背景描述 java通过jdbc连接远程数据库插入一条数据，类似如下： insert into tableA (updateTime) values (now());，其中updateTime是timestamp类型。但是jdbc查询的结果确比当前多8个小时。 二、操作1）先查询数据库时区：show variables like '%zone%'; 显示CST，而CST可能有四种可能： 美国中部时间 Central Standard Time (USA) UTC-06:00 澳大利亚中部时间 Central Standard Time (Australia) UTC+09:30 中国标准时 China Standard Time UTC+08:00 古巴标准时 Cuba Standard Time UTC-04:00此时需要进一步查看当前系统的时区。 2）查看数据库所在系统时区：date -R 由此，可知道数据库的时区是东八区。 3）查看JDBC的数据库连接设置的时区，如下： url : jdbc:mysql://192.168.170.151:3358/edi-platform?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=GMT 4）java应用所在时区为东八区 三、原因1）数据库执行now()，获取当前时区（东八区）的时间存储到数据库（真实存储是相对GMT的时间，读取时再转换为数据库时区的时间）； 2）jdbc读取到的时间已经是东八区时间，但是却根据jdbc的url设置把他认为是GMT时间，又对他进行了+8，所以jdbc调停后的时间晚了8个小时； 四、其他如果把jdbc里的时区设置去掉，则自动使用数据库的时区。此时数据库的时区是CST(+8)，但是JDBC却把误认为是CST(-6)，此时读取的最终结果则是差距：8-(-6) = 14小时;","link":"/2020/11/20/JDBC%E7%9A%84%E6%97%B6%E5%8C%BA%E8%B0%83%E5%81%9C/"},{"title":"JMM","text":"一、什么是JMM1、jsr-133-faq http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html 1）处理器内存模型在多处理器系统中，处理器通常会有一层或多层缓存用来提高性能，这加快了数据访问速度，减小共享内存总线上的流量。缓存提高性能同时带来了新的挑战，例如两个处理器同时去读取相同内存位置的值时可能会看到不同的值。 在处理器级别，内存模型定义了共享变量被某处理器修改后对其他处理器可见的充要条件。 有些处理器表现出强大的内存模型，所有处理器在任何时候看到的指定共享变量的值都是相同的。有些处理器表现出较弱的内存模型，通常需要通过内存屏障来实现可见性，例如：1）通过刷新操作使当前处理器读取其他处理器修改的值；2）通过使其他处理器的缓存失效而使其他处理器看到当前处理器修改的值。内存屏障通常在执行lock和unlock时使用，它们对高级语言是不可见的。 有时为强内存模型编写程序更加容易，因为减少了内存屏障的使用。但是即使在强内存模型下，内存屏障也是不可或缺的。处理器的最新趋势鼓励较弱的内存模型，因为他们对缓存一致性的放宽使得跨处理器和大内存有更大的伸缩性。 当一个写操作要对另一个线程可见时，编译器的重排序使问题变得更加复杂。例如，编译器为了优化性能在不改变程序语义的前提下可能把写操作在程序中后移。如果编译器延迟了某个操作，那么另一个线程也会延后看到操作的执行结果。缓存同样有此副作用。反之，如果把写入操作前移，其他线程则可能提前感知操作结果。在内存模型的约束下，允许编译器，运行时和硬件优化执行顺序，我们可以获得更高的性能。 2）Java内存模型java内存模型描述了多线程编程中哪些行为是合法的和线程如何通过内存进行交互。它描述了程序中变量间的关系，及在实际计算机系统中从内存或寄存器中读写变量的低级细节。它通过各种硬件和编译器优化来正确实现。 Java内存模型是一项野心勃勃的事业；这是编程语言首次尝试合并内存模型，该模型为跨多种体系结构的并发提供了一致的语义。大多数其他编程语言，如c,c++都不是直接支持多线程设计的。这些语言针对编译器和体系结构中发生的重排序的保护在很大程度上依赖于其使用的线程库，编译器和代码运行平台。 2、JSR133**给定一个程序和该程序的一串执行轨迹，内存模型描述了该执行轨迹是否是该程序的一次合法执行。**对于 Java，内存模型检查执行轨迹中的每次读操作，然后根据特定规则，检验该读操作观察到的写是否合法。 内存模型描述了某个程序的可能行为。JVM 实现可以自由地生成想要的代码，只 要该程序所有最终执行产生的结果能通过内存模型进行预测。这为大量的代码转换 提供了充分的自由，包括动作(action)的重排序以及非必要的同步移除。 内存模型的一个高级、非正式的概述显示其是一组规则，规定了一个线程的写操作何时会对另一个线程可见。通俗地说，读操作 r 通常能看到任何写操作 w 写入的 值，意味着 w 不是在 r 之后发生，且 w 看起来没有被另一个写操作 w’覆盖掉(从 r 的角度看)。 3、java-memory-modelhttp://tutorials.jenkov.com/java-concurrency/java-memory-model.html Java内存模型规定了如何和何时可以看到由其他线程修改过后的共享变量的值，以及在必须时如何同步的访问共享变量。 4、总结多处理器场景下，同一个变量可能存在多个缓存备份，编译器、解释器、JIT、处理器都可重排指令顺序。并发编程时，程序执行结果预测变得困难。 在此背景下，JMM则是Java在语言层面抽象出多处理器下内存架构和操作，并基于此约定一组顺序规则，使得读操作可预测，从而达到多处理器场景下程序结果可预测的目的。 二、Java对多处理器内存架构的抽象From JSE6 Threads and Locks 主内存和工作内存 八大内存操作：read、load、store、write、use、assign、lock、unlock 三、JSR133中JMM的规则给定一段程序和一段执行轨迹，可以根据JMM判断该执行轨迹是否合法。JMM的存在，约束了JVM在实现时要保证程序的执行轨迹合法，从而使程序员可以推断程序的执行结果。 JVM为保证符合JMM的约束，一般需要考虑以下方面： 1）编译器，JIT和解释器在指令重排时，需要符合JMM； 2）适当的增加内存栅栏，防止CPU级别的指令重排； 1、JMM的正式规则包括两个部分 From JSR133 1）定义良构的执行过程； 每个对变量 x 的读都能看到一个对 x 的写。所有对 volatile 变量的读写都是 volatile 动作 同步顺序与程序顺序以及互斥是一致的 线程的运行遵守线程内(intra-thread)一致性 线程的运行遵守同步顺序一致性 线程的运行遵守 happens-before 一致性 2）执行过程的因果要求（对happens-before内存模型的增强） 2、JMM内置happens-before From JSR133 1）某个线程中的每个动作都happens-before该线程中该动作后面的动作。 2）某个管程上的unlock动作happens-before同一个管程上后续的lock动作。 3）对某个volatile字段的写操作happens-before每个后续对该volatile字段的读 操作。 4）在某个线程对象上调用start()方法happens-before该启动了的线程中的任意 动作。 5）某个线程中的所有动作happens-before任意其它线程成功从该线程对象上的 join()中返回。 6）如果某个动作a happens-before动作b，且b happens-before动作c，则有a happens-before c. 四、JMM为并发编程提供了支持并发编程三大特征：原子性，可见性和有序性；JMM的规则在Java语言层面给予了支持（区别于其他语言需要依赖类库或运行平台）； 1、原子性1）Java的volatile关键字支持double,long的原子读写； 2）JMM中管程的有序性规则对原子性提供了支持； 2、可见性JMM规则的核心就是描述共享变量修改后对其他线程可见的规则； 3、有序性JMM几乎所有规则都围绕有序性展开； # 参考 https://download.oracle.com/otndocs/jcp/memory_model-1.0-pfd-spec-oth-JSpec/ http://tutorials.jenkov.com/java-concurrency/java-memory-model.html http://ifeve.com/java-memory-model-6/ http://www.cs.umd.edu/~pugh/java/memoryModel/index.html#reference http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html https://docs.oracle.com/javase/specs/jvms/se6/html/Threads.doc.html http://gee.cs.oswego.edu/dl/jmm/cookbook.html","link":"/2020/08/08/JMM/"},{"title":"IO","text":"一、IO概念IO是计算机程序和磁盘，网卡等外部资源进行交互的接口。而这些敏感资源都是由操作系统进行统一管理的，所有计算机语言的IO操作最终都是通过操作系统提供的系统调用函数来实现的。 1. IO介质分类文件IO：一般指和本机的磁盘进行交互； 网络IO：通过网卡设备和网络上的其他主机进行通信；在Linux里网络连接也被视为一种文件，但是比文件IO增加了新的处理方法，如accept()。 2. Java包分类Java源码在rt.jar中io分为两个包： java.io.*：传统的IO类，也被成为BIO（Blocking IO/阻塞IO）。 java.nio.*：jdk1.4引入的包，称为new IO。 NOTE：也有人把NIO称为Non-blocking IO/非阻塞IO，但是其中的多路复用是阻塞的，所以如果叫非阻塞IO有点狭义和以偏概全，不利于新人理解。 nio包下关键类： 123456789101112java.nio (since jdk1.4)|__channels| |___Channel| |___SocketChannel| |___ServerSocketChannel| |___Selector| |___SelectionKey||__ByteBuffer|__DirectByteBuffer|__HeapByteBuffer|__MappedByteBuffer BIO和NIO相同点1）【适用文件IO/网络IO】读取数据时，都是阻塞的； BIO和NIO区别1）【适用文件IO/网络IO】BIO是面向流（stream，数据单向传输），NIO基于通道（channel，数据双向传输）面向块（buffer），后者效率更高。 2）【适用网络IO】等待数据阶段，BIO是阻塞的，而NIO是非阻塞的，及其升级版多路复用，基于事件。 3. NIO特性之面向BufferNIO在读写数据时都是通过buffer来和channel交互的。 1. Java示例代码示例一：读文件（来源） 123456789// 1. 获取通道FileInputStream fin = new FileInputStream( &quot;readandshow.txt&quot; );FileChannel fc = fin.getChannel();// 2. 创建缓冲区 ByteBuffer buffer = ByteBuffer.allocate( 1024 );// 3. 读文件内容到缓冲区fc.read( buffer ); 代码示例二：写文件（来源） 12345678910111213// 1. 获取通道FileOutputStream fout = new FileOutputStream( &quot;writesomebytes.txt&quot; );FileChannel fc = fout.getChannel();// 2. 创建缓冲区，并写入内容ByteBuffer buffer = ByteBuffer.allocate( 1024 );for (int i=0; i&lt;message.length; ++i) { buffer.put( message[i] );}buffer.flip();// 3. 写文件fc.write(buffer); 2. 缓冲区类型 1）间接缓冲区 1ByteBuffer buffer = ByteBuffer.allocate( 1024 ); 2）直接缓冲区 定义：给定一个直接字节缓冲区，Java 虚拟机将尽最大努力直接对它执行本机 I/O 操作。也就是说，它会在每一次调用底层操作系统的本机 I/O 操作之前(或之后)，尝试避免将缓冲区的内容拷贝到一个中间缓冲区中(或者从一个中间缓冲区中拷贝数据) 直接缓冲区（参考：com.ibm.developerworks.nio.FastCopyFile） 1ByteBuffer buffer = ByteBuffer.allocateDirect( 1024 ); 内存映射文件（参考：com.ibm.developerworks.nio.UseMappedFile） 使程序可以操作那些无法拷贝到内存的大尺寸文件。 1MappedByteBuffer mbb = fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, 1024 ); 3. 使用ByteBuffer类操作缓冲区1234567891011121314151617181920212223242526272829303132333435363738 /** * Direct vs. non-direct buffers* A byte buffer is either direct or non-direct. Given a direct byte buffer, the Java * virtual machine will make a best effort to perform native I/O operations directly upon * it. That is, it will attempt to avoid copying the buffer's content to (or from) an * intermediate buffer before (or after) each invocation of one of the underlying * operating system's native I/O operations.* A direct byte buffer may be created by invoking the allocateDirect factory method of * this class. The buffers returned by this method typically have somewhat higher * allocation and deallocation costs than non-direct buffers. The contents of direct * buffers may reside outside of the normal garbage-collected heap, and so their impact * upon the memory footprint of an application might not be obvious. It is therefore * recommended that direct buffers be allocated primarily for large, long-lived buffers * that are subject to the underlying system's native I/O operations. In general it is * best to allocate direct buffers only when they yield a measureable gain in program performance.* A direct byte buffer may also be created by mapping a region of a file directly into * memory. An implementation of the Java platform may optionally support the creation of * direct byte buffers from native code via JNI. If an instance of one of these kinds of * buffers refers to an inaccessible region of memory then an attempt to access that * region will not change the buffer's content and will cause an unspecified exception to * be thrown either at the time of the access or at some later time.* Whether a byte buffer is direct or non-direct may be determined by invoking its * isDirect method. This method is provided so that explicit buffer management can be * done in performance-critical code. **/public abstract class ByteBuffer extends Buffer implements Comparable&lt;ByteBuffer&gt; { public static ByteBuffer allocate(int capacity) { if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity); } public static ByteBuffer allocateDirect(int capacity) { return new DirectByteBuffer(capacity); } ...} 从注释中可看出DirectByteBuffer和HeapByteBuffer的区别如下： DirectByteBuffer HeapByteBuffer 分配位置 堆外直接内存，属于直接缓冲区 堆内存，属于间接缓冲区 和内核数据交互时拷贝次数 避免了数据内核态到用户态的内存拷贝（即零拷贝） 需要从内核态拷贝到用户态，即拷贝到JVM堆空间 分配销毁开销 开销较大 开销较小 读写速度 读写较快 读写较慢 使用建议 衡量使用DirectByteBuffer带来的收益，建议程序中池化DirectByteBuffer，减少分配和销毁的开销 4. NIO特性之非阻塞（网络IO等待数据准备阶段）以下通过三种不同的Socket代码来展示其区别，实验时可通过telnet命令发送数据给指定端口。 1. Blocking IO 12345678910111213141516public void testBlocking() throws IOException { ServerSocket serverSocket = new ServerSocket(9000); while (true) { System.out.println(&quot;开始监听&quot;); Socket socket = serverSocket.accept(); System.out.println(&quot;Connection socket: &quot; + socket); BufferedReader in = new BufferedReader(new InputStreamReader(socket.getInputStream())); while (true) { String str = in.readLine(); if (&quot;END&quot;.equals(str)) break; System.out.println(&quot;Accept: &quot; + str); } }} 2. NonBlocking IO 非阻塞是基于channel实现的，serverSocketChannel.configureBlocking(false)。 12345678910111213141516171819202122232425public void testNoBlocking() throws IOException, InterruptedException { ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.socket().bind(new InetSocketAddress(9000)); serverSocketChannel.configureBlocking(false); while (true) { System.out.println(&quot;开始监听&quot;); SocketChannel socketChannel = serverSocketChannel.accept(); if (socketChannel == null) { Thread.sleep(1000); continue; } System.out.println(&quot;Connection socket: &quot; + socketChannel); socketChannel.configureBlocking(false); while (true) { ByteBuffer buffer = ByteBuffer.allocate(1024); int read = socketChannel.read(buffer); if (read != 0) { String content = new String(buffer.array(), 0, read); System.out.print(content); } Thread.sleep(1000); } } 3. 多路复用/事件IO 12345678910111213141516171819202122232425262728293031public void testMultiplexing() throws IOException { Selector selector = Selector.open(); ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.socket().bind(new InetSocketAddress(9000)); serverSocketChannel.configureBlocking(false); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) { selector.select(); Iterator&lt;SelectionKey&gt; iterator = selector.keys().iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); if (key.isAcceptable()) { ServerSocketChannel channel = (ServerSocketChannel) key.channel(); SocketChannel accept = channel.accept(); if (accept != null) { accept.configureBlocking(false); accept.register(selector, SelectionKey.OP_READ); System.out.println(&quot;Connection: &quot; + accept.socket()); } } else if (key.isReadable()) { SocketChannel channel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(1024); int read = channel.read(buffer); if (read != 0) { String content = new String(buffer.array(), 0, read); System.out.print(&quot;accept: &quot; + content); } } } } } 4. 三者对比 二、Linux下IO函数 函数名称 是否阻塞 时间复杂度 说明 recvfrom 同步，阻塞/非阻塞两种模式 - select 同步阻塞，IO多路复用 o(n) 有数据就绪时中断阻塞，轮询所有fd集合； poll 同步阻塞，IO多路复用 o(n) 类似select，区别是没有连接限制 epoll 同步阻塞，IO多路复用 o(1) 类似poll，增加了就绪列表，只遍历它即可 123456789# man selectselect - synchronous I/O multiplexingDESCRIPTION: select() and pselect() allow a program to monitor multiple file de‐ scriptors, waiting until one or more of the file descriptors become &quot;ready&quot; for some class of I/O operation (e.g., input possible). A file descriptor is considered ready if it is possible to perform a corre‐ sponding I/O operation (e.g., read(2), or a sufficiently small write(2)) without blocking. 12345# man pollpoll - wait for some event on a file descriptorDESCRIPTION poll() performs a similar task to select(2): it waits for one of a set of file descriptors to become ready to perform I/O 1234567891011121314151617# man epollepoll - I/O event notification facilityDESCRIPTION The epoll API performs a similar task to poll(2): monitoring multiple file descriptors to see if I/O is possible on any of them. The epoll API can be used either as an edge-triggered or a level-triggered interface and scales well to large numbers of watched file descriptors. The central concept of the epoll API is the epoll instance, an in-kernel data structure which, from a user-space perspective, can be considered as a container for two lists: * The interest list (sometimes also called the epoll set): the set of file descriptors that the process has registered an interest in monitoring. * The ready list: the set of file descriptors that are &quot;ready&quot; for I/O. The ready list is a subset of (or, more precisely, a set of references to) the file descriptors in the interest list that is dynamically populated by the kernel as a result of I/O activity on those file descriptors. The following system calls are provided to create and manage an epoll instance: * epoll_create(2) creates a new epoll instance and returns a file descriptor referring to that instance. (The more recent epoll_create1(2) extends the functionality of epoll_create(2).) * Interest in particular file descriptors is then registered via epoll_ctl(2), which adds items to the interest list of the epoll instance. * epoll_wait(2) waits for I/O events, blocking the calling thread if no events are currently available. (This system call can be thought of as fetching items from the ready list of the epoll instance.) 三、Java调用epoll的时机 Java方法 Linux方法 Selector selector = Selector.open() epoll_create serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT) 把socketChannell加入PollArrayWrapper暂存 selector.select(); 1）取PollArrayWrapper中的句柄执行epoll_ctl2）然后执行epoll_wait # 参考 NIO 入门 - IBM开发者 Linux IO模式及 select、poll、epoll详解","link":"/2021/01/24/IO/"},{"title":"Java运行时内存区域","text":"一、运行时数据区Java虚拟机规范规定的运行时内存主要有以下区域： 1）堆：对象存储区域 2）方法区：类元信息，运行时常量池 3）线程栈和本地方法栈：方法执行时的栈帧信息 4）程序计数器：记录当前线程要执行下一行代码的位置，执行native方法时为空。 Note：栈帧中的动态链接指向当前方法在方法区的地址； 方法区结构（JDK1.6及以下版本） HotSpot虚拟机实现在HotSpot实现时会有些许差别，例如： 1）合并本地方法栈和线程栈 2）方法区的实现 二、内存设置Java常用内存设置参数 例子：如下命令会进行如下设置： 1）设置堆大小为512m 2）设置年轻代中Eden区和Survivor区比例Eden : From Survivor : To Survivor=8:1:1。 java -Xms512m -Xmx512m -XX:SurvivorRatio=8 person/kivi/MainTest Java进程的内存直接内存受限于进程在当前系统下可使用的内存。例如32位系统，应用使用上线为4GB。 三、类装载过程见—类加载机制 四、对象创建过程 五、对象结构Note: 1）MarkWord的长度是一个字，与指针压缩无关。字是CPU一次能并行处理的二进制位数，一般为系统的位数。 2）指针压缩的对象是oop，即对象的引用地址。 地址&lt;=32位，无需启动压缩； 地址在区间(pic/1240-20210115023606994.png) 七、类，类对象，类元信息的关联 八、OutOfMemeory发生位置1、堆区：空间不足，无法创建新对象。 2、方法区：空间不足，无法加载类元数据信息。 3、线程栈：空间不足，无法为线程分配线程栈。 参考 https://docs.oracle.com/javase/specs/ https://zhuanlan.zhihu.com/p/108668874 https://www.breakyizhan.com/javamianshiti/2839.html","link":"/2020/07/11/Java%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/"},{"title":"JVM运行参数","text":"一、JVM参数约定java启动时可以配置运行参数，主要含： JVM通用参数 垃圾回收器参数：可设置JVM运行时各区域内存的大小等 性能调优参数 Debug参数 Note： 1）-X前缀的参数：非标准参数，不保证所有虚拟机实现都支持。删改不会通知； 2）-XX前缀的参数：非稳定参数。删改不会通知； 二、查看JVM参数1）查看jvm各参数默认值 1java -XX:+PrintFlagsInitial 2）查看jvm运行参数值（其中被赋值号为:=的值是被修改过，与初始值不同） 1java -XX:+PrintFlagsFinal 3）查看jvm运行时的参数的命令 12jinfo -flags &lt;pid&gt;jinfo -flag &lt;name&gt; &lt;pid&gt; # 参考 https://www.oracle.com/java/technologies/javase/vmoptions-jsp.html","link":"/2021/11/24/JVM%E8%BF%90%E8%A1%8C%E5%8F%82%E6%95%B0/"},{"title":"Junit源码分析","text":"1. 前置问题 为什么每执行一次被@Test注解的方法都会重新构建实例？ 2. 执行流程执行流程： 执行BlockJUnit4ClassRunner#run方法，由于没有复写该方法，所以调用ParentRunner#run; ParentRunner#run中通过装饰器模式构造执行语句，并执行以下步骤： 执行类级别前置方法； 执行测试方法； 12345// 伪代码foreach methods by @Test instance TestClass build decorator statement by @BeforeTest, @AfterTest run statement 执行类级别后置方法； 3. 关键类注释12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public abstract class ParentRunner&lt;T&gt; extends Runner implements Filterable, Orderable { public void run(final RunNotifier notifier) { EachTestNotifier testNotifier = new EachTestNotifier(notifier, getDescription()); testNotifier.fireTestSuiteStarted(); try { Statement statement = classBlock(notifier); statement.evaluate(); } catch (AssumptionViolatedException e) { testNotifier.addFailedAssumption(e); } catch (StoppedByUserException e) { throw e; } catch (Throwable e) { testNotifier.addFailure(e); } finally { testNotifier.fireTestSuiteFinished(); } } protected Statement classBlock(final RunNotifier notifier) { // 执行所有被@Test标记的方法 Statement statement = childrenInvoker(notifier); if (!areAllChildrenIgnored()) { // 前置处理装饰器，执行@BeforeClass标记的方法 statement = withBeforeClasses(statement); // 后置处理装饰器，执行@AfterClass标记的方法 statement = withAfterClasses(statement); statement = withClassRules(statement); statement = withInterruptIsolation(statement); } return statement; } protected Statement childrenInvoker(final RunNotifier notifier) { return new Statement() { @Override public void evaluate() { runChildren(notifier); } }; } private void runChildren(final RunNotifier notifier) { final RunnerScheduler currentScheduler = scheduler; try { for (final T each : getFilteredChildren()) { currentScheduler.schedule(new Runnable() { public void run() { // 调用BlockJUnit4ClassRunner#methodBlock方法，来执行被@Test标记的方法 ParentRunner.this.runChild(each, notifier); } }); } } finally { currentScheduler.finished(); } } ......} 1234567891011121314151617181920212223242526272829303132333435public class BlockJUnit4ClassRunner extends ParentRunner&lt;FrameworkMethod&gt; { protected Statement methodBlock(final FrameworkMethod method) { Object test; // 每次执行一个被@Test标记的方法时都构建一个新的实例对象 try { test = new ReflectiveCallable() { @Override protected Object runReflectiveCall() throws Throwable { return createTest(method); } }.run(); } catch (Throwable e) { return new Fail(e); } // 根据反射调用被@Test标记的方法 Statement statement = methodInvoker(method, test); statement = possiblyExpectingExceptions(method, test, statement); statement = withPotentialTimeout(method, test, statement); // 前置处理装饰器，执行@Before标记的语句 statement = withBefores(method, test, statement); // 后置处理装饰器，执行@After标记的语句 statement = withAfters(method, test, statement); statement = withRules(method, test, statement); statement = withInterruptIsolation(statement); return statement; } protected Statement withBefores(FrameworkMethod method, Object target, Statement statement) { List&lt;FrameworkMethod&gt; befores = getTestClass().getAnnotatedMethods(Before.class); return befores.isEmpty() ? statement : new RunBefores(statement, befores, target); } ....} 123456789101112131415161718192021222324252627public class RunBefores extends Statement { private final Statement next; private final Object target; private final List&lt;FrameworkMethod&gt; befores; public RunBefores(Statement next, List&lt;FrameworkMethod&gt; befores, Object target) { this.next = next; this.befores = befores; this.target = target; } @Override public void evaluate() throws Throwable { for (FrameworkMethod before : befores) { invokeMethod(before); } next.evaluate(); } /** * @since 4.13 */ protected void invokeMethod(FrameworkMethod method) throws Throwable { method.invokeExplosively(target); } 附：类图","link":"/2020/05/20/Junit%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"LLM与架构治理","text":"一、LLM重塑架构治理项的权重随着cursor、trae等LLM IDE被程序员广泛使用，LLM承担了程序员的编程成本，而架构治理中目标为降低研发成本的治理项可能变得不再重要和必要。例如函数的认知复杂度，LLM能理解远超人类的上下文，可以快速理解函数的含义，甚至可以完成简单的需求开发。这时如果忽略LLM带来的变化，不调整治理项权重，那么必然会导致资源错位，沉没更多的机会成本。 除了对已有的治理项需要调低治理权重。LLM的应用可能会带来新的问题，这类问题可抽象的定义为基于模式生成代码的可用性问题。例如在使用LLM进行已有代码重构时出现的一些列badcase，见下表。这些问题随着LLM的应用，问题出现频次会在数量规模上放大，变成一个棘手的大问题。 LLM重构复杂函数的BadCase 详情 严重等级 语法错误 - 子方法入参类型推断错误 - 删除已有函数，致其他go文件语法异常 - 重复定义已有函数 Fatal 语义不一致 - 控制逻辑不一致 - 丢失打点/日志代码 - 线程组使用有差异，致使并行度有差异 Fatal 引入异常代码 - 新定义map，使用时未初始化 - 新增并发修改变量bug - 修改/清空其他函数 Fatal 子函数风格 - 重构不简约 - 过度抽象 - 常量替换为字符串 - 返回值存在冗余err Warn 那么，架构治理项必然要随着LLM的应用而调整权重。其中一个调整思路为：由降低研发负担转目标变为提高LLM准确性和可用性的目标。 二、LLM重塑架构治理的思路借助LLM强大的模式规律洞察能力可以节省研发一定的认知和操作成本，再辅以相关的tool建设、流程建设则可以进一步提高其在研发活动和生产活动中的使用效能。下面列举几个应用LLM进行架构治理的案例，供参考和发散。 2.1 复杂函数治理2.1.1 相关研究An Empirical Study on the Potential of LLMs in Automated Software Refactoring https://arxiv.org/pdf/2411.04444 原文提到：“在重构解决方案推荐方面，ChatGPT 为 180 个重构案例推荐了 176 个解决方案，其中 63.6% 的推荐方案与人类专家构建的方案相当，甚至更优。然而，ChatGPT 推荐的 176 个方案中有 13 个，Gemini 推荐的 137 个方案中有 9 个是不安全的，这些方案要么改变了源代码的功能，要么引入了语法错误，这表明基于 LLM 的重构存在风险。”具体见下图。 所以该团队提出了“RefactoringMirror”的检测与重新应用策略，来减少不安全的重构。该方案的流程如下，1）先让LLM对函数进行重构；2）通过重构检测工具检测出重构操作；3）使用Jetbrain IDEA工具的refactor tool对原函数相同类型的重构。 Refactoring vs Refuctoring: Advancing the state of AI- automated code improvements https://codescene.com/hubfs/whitepapers/Refactoring-vs-Refuctoring-Advancing-the-state-of-AI-automated-code-improvements.pdf 1）LLM重构函数的正确率较低 2）LLM重构函数的Badcase 3）fact-checking model 提出fact-checking model，验证重构的代码语义一致。（通过坏味道规则来检测） refactoring-tools https://docs.vibe-coding-framework.com/refactoring-tools 提出建设重构工具集来应对重构场景，提高代码的可维护性。 2.1.2 治理思路：LLM plan + LSP action 重构既有函数是研发非预期的工作，需要从研发的日常研发活动中抽取注意力成本。那么减小研发的确认成本和承担风险是驱动大范围重构的必要条件。 基于LLM原理和已有的重构CASE发现如下问题，直接使用LLM重构和校验带来的确认成本和风险太高，难以大范围内推进。 LLM在重构复杂函数时有较大概率会导致语义不一致，准确性不及预期； LLM验证重构结果时，仅有一定概率能发现问题，自我纠错能力较弱； LLM重构结果的badcase种类较多，通过准确规则 or TestCase 覆盖异常情况难度较大； 可行思路：LLM重构 + LLM验证/规则验证 → plan by LLM + action by refactor tools 验证思路： 修复gopls extract tools：kivihub/tools 使用user prompt指定extract tool 1234xxx/path/demo.go#demoFunction认知复杂度很高，通过extract function的方式去重构函数。按如下步骤进行重构：Step1：分析该函数，给出一个最优的需要被抽取为子函数的区间范围，格式为startline-endline。需要保证该范围是完整的ast block。注意，优先选择最大的区间范围。Step2：使用命令抽取子方法。gopls codeaction -w -exec -kind refactor.extract.function flow_control_1.go:{startline}-{endline+1}。注意结束行是endline+1。因为行范围是左闭右开。命令执行结束后，通过git diff查看新增的函数。新增函数应该为newFunction。如果失败请重试命令，重试时不改动参数。因为该操作开销较大，可能被kill，所以失败时需要重试。Step3：对抽取的新方法进行重命名，使其有意义。 2.2 服务耦合治理/强弱依赖/重复调用治理此类治理可以使用LLM定位和下钻分析具体代码，并给出详尽的分析报告。 TODO：待后续有实践时，丰富案例。 三、LLM驱动架构治理的关注点 驱动点 成本要小：架构治理对研发而言是需求之外的任务，是附加给研发的任务。那么治理项减小研发修改成本、修改风险是根本要求。 收益要多：性能、稳定性、合规。 突破点：把一个有驱动力的治理项能力优化到极致，提高平台的认知度。聚焦把一个点做好，做到极致，然后再开放给用户。 治理项不要太泛化，架构治理方面泛化意味不精，很难击中用户痛点。建设有明确目标的，痛点驱动的，极致好用的功能。 尤其是，架构治理属于偏离线性任务，不在研发活动的动线上。只有高价值功能才能吸引用户。 发挥LLM长处：处理大数据分析和洞察的难点 认识到Agent的擅长点，有目的性的节省相应方面的人力 AI与准确性的博弈：使用AI进行治理不能停留在可用阶段，有些治理项需要极高的准确性，否则，就会将确认成本转嫁到研发，从而降低研发的使用意愿。 AI as Architect，AI即架构师。帮助去洞察问题，修复问题。","link":"/2025/09/12/LLM%E4%B8%8E%E6%9E%B6%E6%9E%84%E6%B2%BB%E7%90%86/"},{"title":"Java异常堆栈丢失仅剩一行","text":"一、问题描述今日在测试环境帮研发定位问题时，查看日志，发现异常信息丢失，如下： 12345678910111213141516171819202122232425262728292021-12-16 14:05:27[ http-nio-8082-exec-10:519172801 ] - [WARN ] com.xxx.xxx.XxxFilter-doFilter:107 - 解析Tenant出错， 错误信息:Request processing failed; nested exception is java.lang.NullPointerExceptionorg.springframework.web.util.NestedServletException: Request processing failed; nested exception is java.lang.NullPointerException at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:982) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:687) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)Caused by: java.lang.NullPointerException Caused by: java.lang.NullPointerException之后的异常丢失了。 二、异常信息丢失原因1）Java Doc 123456789101112131415161718192021222324252627282930public class Throwable implements Serializable { /** * Provides programmatic access to the stack trace information printed by * {@link #printStackTrace()}. Returns an array of stack trace elements, * each representing one stack frame. The zeroth element of the array * (assuming the array's length is non-zero) represents the top of the * stack, which is the last method invocation in the sequence. Typically, * this is the point at which this throwable was created and thrown. * The last element of the array (assuming the array's length is non-zero) * represents the bottom of the stack, which is the first method invocation * in the sequence. * * &lt;p&gt;Some virtual machines may, under some circumstances, omit one * or more stack frames from the stack trace. In the extreme case, * a virtual machine that has no stack trace information concerning * this throwable is permitted to return a zero-length array from this * method. Generally speaking, the array returned by this method will * contain one element for every frame that would be printed by * {@code printStackTrace}. Writes to the returned array do not * affect future calls to this method. * * @return an array of stack trace elements representing the stack trace * pertaining to this throwable. * @since 1.4 */ public StackTraceElement[] getStackTrace() { return getOurStackTrace().clone(); }} Throwbable#getStackTrace注释中指出Some virtual machines may, under some circumstances, omit one or more stack frames from the stack trace. In the extreme case, a virtual machine that has no stack trace information concerning this throwable is permitted to return a zero-length array from this method. Generally speaking, the array returned by this method will contain one element for every frame that would be printed by printStackTrace. Writes to the returned array do not affect future calls to this method.。 2）JVM性能优化OmitStackTraceInFastThrow参数 https://forum.cuba-platform.com/t/nullpointerexception-being-seen-but-no-stack-trace/6261/3 Missing stack trace is a JVM optimization for frequently repeated exceptions.You can disable it by adding -XX:-OmitStackTraceInFastThrow to setenv.sh (setenv.bat) file. 也就是说，JDK为了性能会忽略频繁重复出现的异常堆栈，但是可以通过参数-XX:-OmitStackTraceInFastThrow禁用此优化，注意前面有个-。 三、验证查看更广时间范围的日志后，确实发现了完整的NPE堆栈。 # 参考 https://stackoverflow.com/questions/2411487/nullpointerexception-in-java-with-no-stacktrace https://forum.cuba-platform.com/t/nullpointerexception-being-seen-but-no-stack-trace/6261 https://stackoverflow.com/questions/58696093/when-does-jvm-start-to-omit-stack-traces https://yoshihisaonoue.wordpress.com/2021/02/07/jvm-option-xx-omitstacktraceinfastthrow/","link":"/2021/12/16/Java%E5%BC%82%E5%B8%B8%E5%A0%86%E6%A0%88%E4%B8%A2%E5%A4%B1%E4%BB%85%E5%89%A9%E4%B8%80%E8%A1%8C/"},{"title":"MQ消费出现陡增和断崖","text":"一、问题背景今日EDI日请求剧增，日产日志消息也随之倍增，然后就频繁收到MQ积压告警，通过观察消费者积压数量发现存在MQ消息积压陡增的情况。如下图所示： 而，该Topic的另一个消费分组出现了积压断崖情况，如下图所示。 二、问题原因经和MQ的技术支持沟通，可能原因： 1）若消费者消费消息的耗时超过了两次poll的间隔（参数max.poll.interval.ms），被Broker踢除，导致rebalance。 2）rebalance之后，消费者会重新询问消费位点，若没有获取位点，则根据配置的位点重置策略进行位点重置。 3）消费者的位点重置策略参数为auto.offset.reset： 如果auto.offset.reset=earliest，则重新消费，导致积压都增高； 如果auto.offset.reset=lastest，则就近消费，导致积压断崖。 三、修改方案把max.poll.interval.ms的值由10000改为30000后，观察发现问题修复。 四、其他位点获取失败长期看来是不可避免的，配置重置策略时可以评估以下因素： 1）如果可以接受重复消费，不接受消息丢失，选择earliest； 2）如果可以接受部分丢失，不想去重复消费，选择lasteat；","link":"/2021/05/22/MQ%E6%B6%88%E8%B4%B9%E5%87%BA%E7%8E%B0%E9%99%A1%E5%A2%9E%E5%92%8C%E6%96%AD%E5%B4%96/"},{"title":"MQ积压2亿了","text":"一、问题背景5月17日，下午4点由于EDI集群上某商家请求剧增，MQ的生产流量也变成平时两倍，而日志消费应用消费能力不足，导致日志积压到MQ，24小时后积压到2亿。 二、解决步骤1）登陆MQ监控页面，查看其他消费者是否有积压 发现有其他应用无积压，说明MQ没有达到消费瓶颈。 评估应该是日志消费应用处理逻辑较多或者写入ES有瓶颈。 2）登陆日志消费应用，执行jstack，分析调用栈 jstack里发现涉及到ES写入逻辑时，大部分线程处于等待ES响应态。 评估可能是ES有瓶颈。 3）登陆ES监控页面，查看ES的写入QPS和资源使用率 ES的写入QPS为4K左右，CPU使用率为10%-30%间。 评估ES写入远没有到瓶颈，可能是日志消费应用没有并发写入ES导致。 4）修改日志消费应用，改为并发写ES 旧逻辑是同步的非并发写： 12BulkRequestBuilder bulkRequest = transportClient.prepareBulk();BulkResponse responses = bulkRequest.execute().actionGet(awaitTime); 新逻辑改为使用BulkProcessor并发写： 12345678910111213141516BulkProcessor bulkProcessor = BulkProcessor.builder(transportClient, new BulkProcessor.Listener() { @Override public void beforeBulk(long l, BulkRequest bulkRequest) { } @Override public void afterBulk(long l, BulkRequest bulkRequest, BulkResponse } @Override public void afterBulk(long l, BulkRequest bulkRequest, Throwable throwable) { } }).setBulkActions(10000) .setBulkSize(new ByteSizeValue(20, ByteSizeUnit.MB)) .setFlushInterval(TimeValue.timeValueSeconds(5)) .setConcurrentRequests(4) .setBackoffPolicy(BackoffPolicy.exponentialBackoff(TimeValue.timeValueMillis(100), 1)) .build(); 5）修改代码后，重新观察ES监控 写入QPS峰值达到1.8W，CPU使用率达到60%。此是MQ的积压数几乎稳定，不再增长也不减少。 经和ES技术沟通，当前ES负载较合适不适合再增加并发度。于是考虑申请新ES来分摊压力。 6）新建Topic，新申请ES，解决问题 ø MQ上新建Topic，大流量的商家的日志写到新Topic上； ø 新申请几台日志消费应用，消费新Topic，写入新ES。 经观察新ES集群的写入QPS均值约1.7W。 执行以上操作后，积压问题解决。 三、问题结论积压问题需要开源节流两方面考虑。后面考虑可以不保存查询类日志，减小流量压力。","link":"/2021/05/20/MQ%E7%A7%AF%E5%8E%8B2%E4%BA%BF%E4%BA%86/"},{"title":"Maven仓库更新策略","text":"maven仓库的更新策略指的是更新maven-metadata-[repository].xml，即何时触发从远程仓库读取最西的’maven-metadata-[repository].xml’的策略。 一、Maven下载仓库配置 updatePolicy: 该标签用于指定更新尝试发生的频率。Maven会比较远程和本地pom的时间戳（时间戳在maven-metadata文件）。可选项有：1）always；2）daily（默认）；3）interval:X(X为整数，单位为分钟)；4）never。 12345678910111213141516171819202122232425262728&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; ... &lt;repositories&gt; &lt;repository&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;never&lt;/updatePolicy&gt; &lt;checksumPolicy&gt;fail&lt;/checksumPolicy&gt; &lt;/snapshots&gt; &lt;name&gt;Nexus Snapshots&lt;/name&gt; &lt;id&gt;snapshots-repo&lt;/id&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; ... &lt;/pluginRepositories&gt; ...&lt;/project&gt; 二、Maven更新逻辑 参考maven3.6.3源码：org.apache.maven.artifact.repository.metadata.DefaultRepositoryMetadataManager#resolve方法 如果-U强制更新，update=true 如果maven-metadata-local.xml存在，且该文件的lastModified不符合更新策略，update=false 如果maven-metadata-snapshot.xml不存在，update=true 如果maven-metadata-snapshot.xml存在，则检查resolver-status.properties中的时间戳是否符合更新策略1）如果符合，update=true2）否则，update=false 123#NOTE: This is a Maven Resolver internal implementation file, its format can be changed without prior notice.#Tue Aug 11 16:46:54 CST 2020maven-metadata-snapshots.xml.lastUpdated=1597135614187 三、Maven更新策略源码 参考maven3.6.3源码：org.apache.maven.artifact.repository.ArtifactRepositoryPolicy#checkOutOfDate 1234567891011121314151617181920212223242526272829public boolean checkOutOfDate(Date lastModified) { boolean checkForUpdates = false; if (UPDATE_POLICY_ALWAYS.equals(updatePolicy)) { checkForUpdates = true; } else if (UPDATE_POLICY_DAILY.equals(updatePolicy)) { // Get local midnight boundary Calendar cal = Calendar.getInstance(); cal.set(Calendar.HOUR_OF_DAY, 0); cal.set(Calendar.MINUTE, 0); cal.set(Calendar.SECOND, 0); cal.set(Calendar.MILLISECOND, 0); if (cal.getTime().after(lastModified)) { checkForUpdates = true; } } else if (updatePolicy.startsWith(UPDATE_POLICY_INTERVAL)) { String s = updatePolicy.substring(UPDATE_POLICY_INTERVAL.length() + 1); int minutes = Integer.valueOf(s); Calendar cal = Calendar.getInstance(); cal.add(Calendar.MINUTE, -minutes); if (cal.getTime().after(lastModified)) { checkForUpdates = true; } } // else assume &quot;never&quot; return checkForUpdates; } 四、Maven build时使用哪个Jar 读取groupId/artifactId/version/maven-metadata-local.xml中versioning -&gt; snapshotVersions -&gt; snapshotVersion -&gt; updated（只看jar包的，忽略pom） 读取groupId/artifactId/version/maven-metadata-snapshot.xml中versioning -&gt; lastUpdated 选择最近的时间戳的依赖版本；若是远程版本，且版本不存在时会触发远程jar下载逻辑。 NOTE:如果远程比本地的新，则远程下载的包会复制一份覆盖本地的artifactId-version.jar和pom文件; 参考 http://maven.apache.org/pom.html#Repositories","link":"/2020/08/11/Maven%E4%BB%93%E5%BA%93%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5/"},{"title":"MVCC的InnoDB实现","text":"MVCC是为了保证事务的非阻塞读，提高并发性的一种机制。目前有两种主流实现； 前置问题 mysql的事务是一开始就生成事务ID吗？ read view是什么？ read view生成的时机？ read view如何实现隔离级别？ read view生成的时机？ read view和版本链的关系？ DML操作会生成事务快照吗？ 一、通过undo log实现1. 版本链事务针对记录的修改都会通过复制产生新的记录放到库表里，老的记录则放入undo log，并通过回滚指针关联。 2. read view和隔离级别read view是事务实现隔离性时，用于判断记录可见性的事务集合。其格式为[tx_min, tx_id, ...], tx_max， 括号内为数据库当前所有未提交事务的集合，tx_min是未提交事务中ID最小的事务； 括号外的tx_max是数据库当前已创建的最大事务ID； 假设记录的事务ID为tx_id，则可见性规则如下：1）若tx_id &lt; tx_min，则当前记录时可见；2）若tx_id &gt; tx_max，则当前记录时不见；3）若tx_id不在readview中，则当前记录可见；4）若tx_id在readview中 * 若tx_id是当前事务ID，则记录可见； * 若tx_id是当前事务ID，则记录不可见； Note：1.当前事务ID会在事务执行DML操作时才会生成，查询操作不会生成；2.读未提交只需读版本链里最新的记录即可，无需readview;3.读已提交和可重复读会依赖readview来保证不同程度的一致性读，但他们生成readview的时机不同；4.生成的readview是数据库级别的当前活跃事务的快照;5.readview会在事务执行读取操作时生成，DML操作不会生成； 读未提交 读已提交 可重复读 是否使用readview 否 是 是 生成readview时机 每次读取都生成 事务第一次读取时生成 3. mvcc操作步骤假设有read view=[tx_min, tx_id, …], tx_max。1）如果记录的事务ID小于tx_min，则当前记录可见，返回当前记录；2）如果记录的事务ID大于tx_max，则当前记录不可见；回滚指针回溯上一条记录，执行1）；3）如果记录不在readview括号内，则记录可见，返回当前记录；4）如果记录在readview括号内，有两种情况： 若事务ID是当前事务ID，则当前记录可见，返回当前记录； 若事务ID不是当前事务ID，则当前记录不可见；回滚指针回溯上一条记录，执行1）操作；","link":"/2020/05/20/MVCC%E7%9A%84InnoDB%E5%AE%9E%E7%8E%B0/"},{"title":"Maven3.x兼容笔记","text":"一、依赖解析 The core of Maven 3 uses Aether for dependency resolution. Aether employs a different approach to calculate the transitive dependencies and is meant to fix some of the trickier (conflict) resolution issues within Maven 2.x. In practice, this change can result in different class paths especially for projects with big/complex dependency graphs. For instance, projects that erroneously have conflicting dependencies on their classpath might encounter build issues depending on the classpath order. See JETTY-1257 for a concrete example of this issue. Furthermore, not all parts of the Maven 2.x resolution API could be bridged onto Aether. Most notably the maven-dependency-tree shared component which is used for mvn dependency:tree still uses the legacy resolution code. As such, the output from mvn dependency:tree can differ from the actual dependency tree used by Maven itself to derive the classpaths of a project (see MSHARED-167 for an example of such a discrepancy). For now, the actual dependency trees can be inspected when running Maven with debug logging enabled. Last but not least, Maven 3 inspects the POMs of all matching versions when processing version ranges to enable sophisticated conflict resolution. Maven3.x的core使用Aether进行依赖解析，其于Maven2.x表现不一致。也就是说使用maven2和maven3对一个项目构建时结果可能不一致。 有些插件仍在使用老的解析API，如mvn dependency:tree使用的maven-depdency-tree共享组件。这就导致通过mvn dependency:tree的结果与Maven core计算的依赖树不同。 二、插件仓库 Maven 3 aims at supporting a stricter separation between the compile/runtime/test dependencies of a project and the plugins used to build the project. For this reason, build extensions, plugins and plugin dependencies are no longer resolved from the of a project but only from its. Maven3开始插件的依赖只会从plugin仓库获取，目的是为了隔离插件和项目构件，简化运维工作。 #、参考 https://cwiki.apache.org/confluence/display/MAVEN/Maven+3.x+Compatibility+Notes","link":"/2022/02/10/Maven3.x%E5%85%BC%E5%AE%B9%E7%AC%94%E8%AE%B0/"},{"title":"Map","text":"一、存储结构 二、HashMap.put流程 1）遍历Tree时根据Hash值进行查询。Tree是根据Hash构建的红黑树。 2）new HashMap不设置初始容量时table为null，put第一个元素时会创建长度为16的table。 3）放入元素后，判定size超过负载后会扩容，负载 = tablesize * 负载因子默认0.75。 I、不扩容条件：预期元素数量 &lt; tableSize * 0.75，那么tableSize &gt; 预期元素数量 / 0.75 = 预期元素个数 * 4 / 3。 II、如预期放一个元素，那么初始容量设置最小为2。 4）初始size会经过计算转换为大于它的最小2的幂值。便于计算下标：keyHash &amp; (table.size - 1) 5）扩容：JDK7并发时可能出现环线链表，导致死循环。JDK8通过高低位扩容方式避免了死锁发生。 三、ConcurrentHashMap1）JDK8通过syncronized锁定bucket，也就是bucket的第一个Node。 2）JDK7通过分段锁来锁定，分段锁依赖ReentrantLock。内置多个分段锁，访问时通过key模除获取要使用的分段锁。 四、Table长度为什么是2的幂1、HashMap中table的size1）table的size为power of two,即2^n。 2）若不指定大小，table的默认size为2^4 3）若通过构造函数传入initialCapacity，则根据**tableSizeFor(int cap)**计算table的size。 2、HashMap的table的初始化时机 table在初次使用时才会初始化。 3、为什么table的大小是2的幂？HashMap根据**(table.length-1) &amp; hash来把对象值映射到table的某个坐标。此处，table.length-1起到了一个mask的作用。此处的hash是经过spread后的，参见static final int hash(Object key)**。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172 /** * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) */ transient Node&lt;K,V&gt;[] table; public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } /** * Returns a power of two size for the given target capacity. */ static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; }/** * Implements Map.get and related methods. * * @param hash hash for key * @param key the key * @return the node, or null if none */ final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; }/** * Computes key.hashCode() and spreads (XORs) higher bits of hash * to lower. Because the table uses power-of-two masking, sets of * hashes that vary only in bits above the current mask will * always collide. (Among known examples are sets of Float keys * holding consecutive whole numbers in small tables.) So we * apply a transform that spreads the impact of higher bits * downward. There is a tradeoff between speed, utility, and * quality of bit-spreading. Because many common sets of hashes * are already reasonably distributed (so don't benefit from * spreading), and because we use trees to handle large sets of * collisions in bins, we just XOR some shifted bits in the * cheapest possible way to reduce systematic lossage, as well as * to incorporate impact of the highest bits that would otherwise * never be used in index calculations because of table bounds. */ static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); }","link":"/2019/10/30/Map/"},{"title":"Maven仓库类型","text":"一、JFrog的仓库类型1. 本地仓库 本地仓库是本地管理的物理仓库，可以deploy构件。 2. 远程仓库远程管理的仓库，本地仓库有可能是其他的仓库的远程仓库。 3. 虚拟仓库虚拟仓库又称仓库组，可以聚合多个仓库为一个相同的URL。 二、maven的仓库类型狭义上：maven仓库 = 中央仓库 + 远程仓库 + 本机仓库 广义上：maven仓库 = 远程仓库（含中央仓库）+ 本机仓库 以下定义按狭义来说明： 1. 中央仓库Maven中央存储库是由Maven社区提供的资源库，它包含了大量的常用程序库。地址为：http://repo1.maven.org/maven2/。可通过在settings.xml文件中声明仓库id为central覆盖。 2. 远程仓库远程仓库是对中央仓库的补充，有些构建并没有发布到中央仓库维护，而是由其他组织，公司或个人维护。此时需要手动在settings.xml或pom.xml中声明所需的远程仓库。 三、maven构建时查找构建顺序 本机仓库：~/.m2/repository 中央仓库：默认的maven社区提供的仓库，或本地settings.xml配置的覆盖的仓库； 远程仓库：settings.xml，pom.xml中指定的仓库； 四、settings.xml中配置仓库认证 标签路径：settings -&gt; servers -&gt; server 针对仓库id，配置认证方式；当下载或发布的仓库需要认证时，会从中获取认证信息； 五、配置下载仓库5.1 settings.xml中配置下载仓库 标签路径：settings -&gt; profiles -&gt; profile -&gt; repositories -&gt; repository 此仓库是maven构建时用于下载构建的仓库； 此仓库一般配置为虚拟仓库，因为一个虚拟仓库可以聚合多个仓库，好管理； 其ID和发布仓库ID不在一个命名空间，可以同名； 5.2 pom.xml中配置下载仓库 project -&gt; repositories -&gt; repository 其他属性同5.1 六、pom.xml中配置部署仓库 此处仓库是maven用于发布上传构建的目标仓库； 此仓库为JFrog中的本地仓库，因为上传必须有个准确的目的库； 其ID和远程仓库ID不在一个命名空间，可以同名； 参考 https://www.jfrog.com/confluence/display/RTF6X/Configuring+Repositories https://www.yiibai.com/maven/maven_repositories.html http://maven.apache.org/xsd/settings-1.1.0.xsd","link":"/2020/08/07/Maven%E4%BB%93%E5%BA%93%E7%B1%BB%E5%9E%8B/"},{"title":"Maven依赖协调原则及依赖顺序的影响","text":"一、Maven依赖协调原则1）POM的直接依赖，后声明的依赖有效 12345678910111213141516171819202122232425&lt;?xml version=&quot;1.0&quot;?&gt;&lt;project xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;person.kivihub&lt;/groupId&gt; &lt;artifactId&gt;maven-demo&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;!-- 被覆盖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.thoughtworks.xstream&lt;/groupId&gt; &lt;artifactId&gt;xstream&lt;/artifactId&gt; &lt;version&gt;1.4.17&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 有效 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.thoughtworks.xstream&lt;/groupId&gt; &lt;artifactId&gt;xstream&lt;/artifactId&gt; &lt;version&gt;1.4.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2）POM的间接依赖 DependencyManagement存在？ 条件 优先原则 存在约束且约束中版本冲突 当前pom和父pom约束冲突 使用当前pom声明的约束版本 同一pom层级约束冲突 递归解析后，使用先声明的约束版本 不存在约束且间接依赖冲突 路径深度不同 使用路径最短的依赖 路径深度相同 使用先声明依赖 二、POM中依赖顺序的影响1）冲突场景1、无DependencyManagement a、POM内的GA相同（relocation后）的直接依赖，顺序变化时影响解析结果 b、POM的GA相同（relocation后）间接依赖路径深度相同时，首个出现的顺序变化时影响解析结果 2、有DependencyManagement 同一pom内（同一层级）多个import的依赖约束（递归解析后）中包含对同一GA的约束冲突，先声明的有效。 2）影响结果1、一定影响相冲突的依赖的版本 2、可能影响相冲突依赖的子依赖版本，冲突的依赖可能exclude内容不同。 三、结论1）非必要，不要调整依赖的顺序。 2）推荐通过DependencyManagement声明依赖版本。 2）需要调整时，比较调整前后依赖解析结果是否一致。辅助命令mvn dependency:list。 # 参考 DependencyManagment作用 Maven源码-依赖解析","link":"/2022/01/22/Maven%E4%BE%9D%E8%B5%96%E5%8D%8F%E8%B0%83%E5%8E%9F%E5%88%99%E5%8F%8A%E4%BE%9D%E8%B5%96%E9%A1%BA%E5%BA%8F%E7%9A%84%E5%BD%B1%E5%93%8D/"},{"title":"Maven如何处理循环依赖","text":"一、Reactor对Project中model循环依赖检测 发生阶段：开始构建时，解析project的model解析顺序 检测到循环依赖时动作：抛出异常，终止解析 冲突时解决办法：单独构建子模块或者避免循环依赖（如项目重构，版本错位等） 二、Aether构建依赖树时对循环依赖的处理 参考：https://wiki.eclipse.org/Aether/Dependency_Graph 发生阶段：依赖图解析为依赖树时 检测到循环依赖时动作：按Maven依赖调停原则执行，不会报错","link":"/2022/02/09/Maven%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/"},{"title":"Maven属性替换","text":"一、替换规则参考：https://maven.apache.org/ref/3.8.4/maven-model-builder/ 1）替换时间 属性替换发生在ModelBuilder构建effective pom时，主要流程包括：profile激活、合并重复依赖、profile注入、父pom解析直至super pom、父子pom模型继承合并、模型的属性替换（也称属性翻译，属性解释）。 也就是说属性替换发生在父子pom继承合并之后，含依赖继承合并、配置继承合并等。使用合并后的配置、内置配置、环境配置，进行pom中的变量替换。 2）优先级 pom中的变量${xxx}在替换时可能多个配置Context都含有，此时会依据以下顺序来获取。从下面的图可知，pom.xml中定义属性优先级比内置变量project.*低，无法覆盖它们。也就是说父pom中使用${project.version}声明的版本会依据子pom的版本来替换。 value evaluation result common examples project.* - 内置属性 POM content (see POM reference) ${project.version} ${project.build.finalName} ${project.artifactId} ${project.build.directory} project.basedir the directory containing the pom.xml file ${project.basedir} project.baseUri the directory containing the pom.xml file as URI ${project.baseUri} build.timestamp maven.build.timestamp the UTC timestamp of build start, in yyyy-MM-dd'T'HH:mm:ss'Z' default format, which can be overridden with maven.build.timestamp.format POM property ${maven.build.timestamp} * - 命令行中-D属性 user properties, set from CLI with -Dproperty=value ${skipTests} * - pom.xml中属性 model properties, such as project properties set in the pom ${any.key} maven.home The path to the current Maven home. ${maven.home} maven.version The version number of the current Maven execution (since 3.0.4). For example, “3.0.5“. ${maven.version} maven.build.version The full build version of the current Maven execution (since 3.0.4). For example, “Apache Maven 3.2.2 (r01de14724cdef164cd33c7c8c2fe155faf9602da; 2013-02-19T14:51:28+01:00)“. ${maven.build.version} maven.repo.local The repository on the local machine Maven shall use to store installed and downloaded artifacts (POMs, JARs, etc). ${user.home}/.m2/repository * Java system properties (see JDK reference) ${user.home} ${java.home} env.* * environment variables ${env.PATH} settings.* Local user settings (see settings reference) ${settings.localRepository} 二、示例1）父Pom.xml 12345678910111213141516171819202122&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;person&lt;/groupId&gt; &lt;artifactId&gt;parent&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;prop-1&gt;parent&lt;/prop-1&gt; &lt;prop-2&gt;parent&lt;/prop-2&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 和子pom.xml保留一个进行测试，效果一样--&gt; &lt;dependency&gt; &lt;groupId&gt;${prop-1}&lt;/groupId&gt; &lt;artifactId&gt;${prop-2}&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2）当前pom.xml 123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;artifactId&gt;person&lt;/artifactId&gt; &lt;groupId&gt;parent&lt;/groupId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;son&lt;/artifactId&gt; &lt;version&gt;1.1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;prop-1&gt;son&lt;/prop-1&gt; &lt;project.version&gt;1.2.0-SNAPSHOT&lt;/project.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;${prop-1}&lt;/groupId&gt; &lt;!-- 当前pom覆盖父pom属性，prop-1 --&gt; &lt;artifactId&gt;${prop-2}&lt;/artifactId&gt; &lt;!-- 当前pom未定义，直接继承父pom属性，prop-2 --&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;!-- 当前pom尝试覆盖内置属性，但是失败 --&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 3）在当前Pom所在工程执行mvn clean compile报错如下： 1Could not find artifact son:parent:jar:1.1.0-SNAPSHOT 由此可看出最终生效的属性如下： prop-1：当前pom属性，当前pom覆盖了父pom prop-2：父pom属性，当前pom未定义该属性，继承自父pom project.version：当前pom尝试覆盖优先级更高的内置属性，但是失败 # 参考 为什么我不能覆盖DependencyManagement导入的pom的版本","link":"/2022/01/24/Maven%E5%B1%9E%E6%80%A7%E6%9B%BF%E6%8D%A2/"},{"title":"Maven常用命令","text":"常用命令1）只处理当前Pom，不递归处理子module -N –non-recursive Do not recurse into sub-projects 12# 只发布父pommvn clean deploy -N some_parent.xml 2）查看依赖树 https://maven.apache.org/plugins/maven-dependency-plugin/ 1234567891011# list格式展示有效依赖$ mvn dependency:list -Dsort=true -U -f pom.xml# tree格式展示有效依赖$ mvn dependency:tree -U -f pom.xml# tree格式显示指定依赖$ mvn dependency:tree -U -Dincludes=[groupId]:[artifactId]:[type]:[version] -f pom.xml# tree格式展示所有依赖，含已被maven依赖调停的忽略依赖$ mvn dependency:tree -U -Dverbose -f pom.xml 3）设置版本号 1$ mvn versions:set -DnewVersion=1.0.1-SNAPSHOT 4）清除本地仓库缓存 https://maven.apache.org/plugins/maven-dependency-plugin/usage.html#dependency:purge-local-repository 1234# By default, deleted artifacts can be re-resolved afterwards; # you can disable this by specifying -DreResolve=false$ mvn dependency:purge-local-repository$ mvn dependency:purge-local-repository -DreResolve=false -DactTransitively=false 5）查看effective pom 1$ mvn help:effective-pom","link":"/2021/09/06/Maven%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"title":"Maven并行参数加快编译","text":"一、引自stackoverflow https://stackoverflow.com/a/54514457 mvn clean install [INFO] Total time: 01:05 h mvn clean install -DskipTests [INFO] Total time: 18:35 min mvn clean install -Dmaven.test.skip -DskipTests [INFO] Total time: 10:58 min mvn -T 1C clean install -Dmaven.test.skip -DskipTests [INFO] Total time: 04:00 min We can also skip the javadoc to be generated as Archmed commented by adding -Dmaven.javadoc.skip=true mvn -T 1C clean install -Dmaven.test.skip -DskipTests -Dmaven.javadoc.skip=true Dont use imports, on IntelliJ, choose &gt; Analyze &gt; Run inspection by name &gt; imports , to find all imports and correct it. Remove all unused imports in your project &gt; on Intellij &gt; Analyze &gt; Run inspection by name &gt; unused imports Remove all unused code (classes, variable, field, parameter, etc..), on Intellij : Analyze &gt; run inspection by name &gt; unused declaration. Upgrade to last JAVA VERSION I have found that the task mvn clean, is taking 2 minutes to clean the TARGET folder before building. I did create a new task called quickclean, and i am using it instead of clean, this way mvn -T 1C quickclean install -Dmaven.test.skip -DskipTests . This new task quickclean is only renaming the build folder from TARGET to TARGET-yyyy-MM-dd-HH-mm(what is VERY FAST). So now, every time you make a new mvn quickclean install..., you have a folder with the time of the build. The inconvient, it’s that this may take a lot of space on the hard disk, so you have to clean all this directories sometimes. So for that i have created another task called: trashclean, to put all this folder to trash. I am running this tasks maybe on time per week. or month, depending on my work mvn trashclean. 二、引自Wiki Maven 3.x has the capability to perform parallel builds. The command is as follows: 1）mvn -T 4 clean install Builds with 4 threads 2）mvn -T 1C clean install 1 thread per cpu core 3）mvn -T 1.5C clean install 1.5 thread per cpu core # 参考 https://stackoverflow.com/questions/32368976/ways-to-make-maven-build-faster https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3","link":"/2022/01/27/Maven%E5%B9%B6%E8%A1%8C%E5%8F%82%E6%95%B0%E5%8A%A0%E5%BF%AB%E7%BC%96%E8%AF%91/"},{"title":"Maven源码-主流程","text":"一、MavenCli#mainmaven使用Plexus容器（一种IOC容器）进行MOJO等管理，apache-maven/src/bin/m2.conf里声明了其主类org.apache.maven.cli.MavenCli： 12345678main is org.apache.maven.cli.MavenCli from plexus.coreset maven.conf default ${maven.home}/conf[plexus.core]load ${maven.conf}/loggingoptionally ${maven.home}/lib/ext/*.jarload ${maven.home}/lib/*.jar 123456789101112131415161718192021222324252627public int doMain( CliRequest cliRequest ) initialize( cliRequest ); // 解析输入的命令 cli( cliRequest ); // 获取系统配置 properties( cliRequest ); logging( cliRequest ); version( cliRequest ); // 初始化Plexus容器，查找Maven相关实现 // lookup(Maven、ModelProcessor、ConfigurationProcessor、ToolchainsBuilder...) PlexusContainer localContainer = container( cliRequest ); commands( cliRequest ); // 解析全局和用户级别的settings.xml，并填充至cliRequest.request configure( cliRequest ); // 解析工具链，支持插件使用指定版本JDK toolchains( cliRequest ); // 根据环境配置配置、命令行参数等填充cliRequest populateRequest( cliRequest ); encryption( cliRequest ); repository( cliRequest ); // 执行 return execute( cliRequest ); } 二、DefaultMaven#execute 步骤参考类注释：org.apache.maven.DefaultMaven#doExecute(org.apache.maven.execution.MavenExecutionRequest) 1. Setup initial properties设置开始时间 2. Validate local repository directory is accessible验证本地仓库目录可访问。 3. Create RepositorySystemSession调用org.apache.maven.repository.internal.MavenRepositorySystemUtils#newSession生成Session。Session内主要包含了用来解析依赖图的相关配置，如下源码所示： 123456789101112131415161718DefaultRepositorySystemSession session = new DefaultRepositorySystemSession();// 依赖遍历器DependencyTraverser depTraverser = new FatArtifactTraverser();session.setDependencyTraverser(depTraverser);// 设置依赖版本约束DependencyManager depManager = new ClassicDependencyManager();session.setDependencyManager(depManager);// 设置依赖过滤器，如过滤test,provided范围，可选的和排除的依赖。DependencySelector depFilter = new AndDependencySelector(new ScopeDependencySelector(&quot;test&quot;, &quot;provided&quot;), new OptionalDependencySelector(), new ExclusionDependencySelector());session.setDependencySelector( depFilter );// 设置依赖冲突调节器，如路径最短选择器DependencyGraphTransformer transformer = new ConflictResolver(new NearestVersionSelector(), new JavaScopeSelector(), new SimpleOptionalitySelector(), new JavaScopeDeriver());transformer = new ChainedDependencyGraphTransformer( transformer, new JavaDependencyContextRefiner() );session.setDependencyGraphTransformer(transformer); 另外，session里还包含了仓库，proxy，认证等信息。 4. Create MavenSessionMavenSession内引用了PlexusContainer、RepositorySystemSession，cliRequest.request（类型为：MavenExecutionRequest）。 5. Execute AbstractLifecycleParticipant.afterSessionStart(session)Sesstion开始后的扩展点，当前无默认实现。 6. Get reactor projects looking for general POM errors7. Create ProjectDependencyGraph Create ProjectDependencyGraph using trimming which takes into account –projects and reactor mode. This ensures that the projects passed into the ReactorReader are only those specified. 1）DefaultProjectBuider -&gt; DefaultModelBuilder对当前pom进行Model构建，也就是生成effective pom。 具体细节可参考下一节。 2）DefaultProjectBuider中对Model注入生命周期的插件Mojo、递归解析import的DependencyManagement。 3）DefaultProjectBuider -&gt; DefaultModelBuilder对parent pom进行Model，也就是生成effective pom。 4）DefaultProjectBuider设置当前Model、父Model、要执行的插件等信息到Project对象。 5）设置Project对象至MavenSession。 8. Create ReactorReader with the getProjectMap(projects) NOTE that getProjectMap(projects) is the code that checks for duplicate projects definitions in the build. Ideally this type of duplicate checking should be part of getting the reactor projects in 6). The duplicate checking is conflated with getProjectMap(projects). 9. Execute AbstractLifecycleParticipant.afterProjectsRead(session)Project读取后的扩展点，当前无默认实现。 10. Create ProjectDependencyGraph without trimming Create ProjectDependencyGraph without trimming(as trimming was done in 7). A new topological sort is required after the execution of 9) as the AbstractLifecycleParticipants are free to mutate the MavenProject instances, which may change dependencies which can, in turn, affect the build order. 11. Execute LifecycleStarter.start()12345678// 构建执行计划MavenExecutionPlan executionPlan = builderCommon.resolveBuildPlan( session, currentProject, taskSegment, new HashSet&lt;Artifact&gt;() );// 获取执行计划中要执行的MOJOList&lt;MojoExecution&gt; mojoExecutions = executionPlan.getMojoExecutions();// 执行MOJOmojoExecutor.execute( session, mojoExecutions, reactorContext.getProjectIndex()); 1）DefaultLifecycleExecutionP lanCalculator -&gt; DefaultMavenPluginManager根据命令行指定的插件或生命周期，从Maven插件管理器中获取要执行的Mojo。 构建执行计划时会根据输入的maven命令和Maven的phase集，计算出本次命令需要执行的所有phase及phase绑定的MOJO（关键方法：DefaultLifecycleExecutionPlanCalculator#calculateMojoExecutions）。 2）根据要执行的Mojo列表生成MavenExecutionPlan，调用MojoExecutor.execute。 3）MojoExecutor#ensureDependenciesAreResolved对依赖进行深度递归解析。 具体细节可参考下一节。 4）调用DefaultBuildePluginManager#executeMojo执行Mojo，执行相应逻辑。 图 - MojoExecutor接收到的mojoExecutions 附录、整体调用栈","link":"/2022/01/22/Maven%E6%BA%90%E7%A0%81-%E4%B8%BB%E6%B5%81%E7%A8%8B/"},{"title":"Maven源码-模块说明","text":"一、Maven源码结构 https://maven.apache.org/ref/3.8.4/index.html 箭头表示模块的依赖关系，箭尾模块依赖箭头模块。 二、主要模块说明 模块 说明 所在仓库 目录 model Maven的POM模型类 https://github.com/apache/maven maven-model artifact Maven构件接口和实现 https://github.com/apache/maven maven-artifact repository-metadata Maven仓库模型 https://github.com/apache/maven maven-repository-metadata builder-support model/setting/toolchains构造器描述 https://github.com/apache/maven maven-builder-support module-builder Maven effective model构造器 https://github.com/apache/maven maven-model-builder resolver 根据给定仓库进行依赖解析，原eclipse/aether项目，maven 3.x集成进来 https://github.com/apache/maven-resolver maven-resolver-1.7.3 resolver-provider resolver扩展，绑定local和远程仓库 https://github.com/apache/maven maven-resolver-provider plugin-api 插件API，由MOJO实现的goal组成 https://github.com/apache/maven maven-plugin-api core maven核心，管理整个构建过程 https://github.com/apache/maven maven-core 附录、官网的模块信息第一幅图点击对应模块热点区域后，会跳转至响应文档，如点击model-builder后跳转至https://maven.apache.org/ref/3.8.4/maven-model-builder/。 如下图，可以从Source Code Management中找到其所在GitHub仓库地址：https://github.com/apache/maven/tree/maven-3.8.4/maven-model-builder，然后就可以进行源码下载和调试了。","link":"/2022/01/22/Maven%E6%BA%90%E7%A0%81-%E6%A8%A1%E5%9D%97%E8%AF%B4%E6%98%8E/"},{"title":"Maven分类classifier使用","text":"classifier一、官网描述 https://maven.apache.org/pom.html The classifier distinguishes artifacts that were built from the same POM but differ in content. It is some optional and arbitrary string that - if present - is appended to the artifact name just after the version number. As a motivation for this element, consider for example a project that offers an artifact targeting Java 11 but at the same time also an artifact that still supports Java 1.8. The first artifact could be equipped with the classifier jdk11 and the second one with jdk8 such that clients can choose which one to use. Another common use case for classifiers is to attach secondary artifacts to the project’s main artifact. If you browse the Maven central repository, you will notice that the classifiers sources and javadoc are used to deploy the project source code and API docs along with the packaged class files. 二、使用场景**用于GAV相同，但内容不同的构件。**例如： 1. 编译等级分类1）发布方 pom中指定classfier，然后mvn clean install or mvn clean deploy。 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;maven-test&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-jar&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;classifier&gt;jdk8&lt;/classifier&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;distributionManagement&gt; &lt;snapshotRepository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;name&gt;maven2 repository-snapshots&lt;/name&gt; &lt;url&gt;http://artifactory.xxx.com/libs-snapshots-local&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt;&lt;/project&gt; 2）使用方 使用带分类的jar时，需要指定分类。 123456&lt;dependency&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;maven-test&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;classifier&gt;jdk8&lt;/classifier&gt;&lt;/dependency&gt; 3）查看私服的jar包信息 maven-test/1.0-SNAPSHOT/maven-metadata.xml 中，jar包上加了&lt;classifier&gt;jdk8&lt;/classifier&gt;限定。 1234567891011121314151617181920212223242526&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;metadata modelVersion=&quot;1.1.0&quot;&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;maven-test&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;versioning&gt; &lt;snapshot&gt; &lt;timestamp&gt;20211123.114128&lt;/timestamp&gt; &lt;buildNumber&gt;1&lt;/buildNumber&gt; &lt;/snapshot&gt; &lt;lastUpdated&gt;20211123114129&lt;/lastUpdated&gt; &lt;snapshotVersions&gt; &lt;snapshotVersion&gt; &lt;extension&gt;pom&lt;/extension&gt; &lt;value&gt;1.0-20211123.114128-1&lt;/value&gt; &lt;updated&gt;20211123114128&lt;/updated&gt; &lt;/snapshotVersion&gt; &lt;snapshotVersion&gt; &lt;classifier&gt;jdk8&lt;/classifier&gt; &lt;extension&gt;jar&lt;/extension&gt; &lt;value&gt;1.0-20211123.114128-1&lt;/value&gt; &lt;updated&gt;20211123114128&lt;/updated&gt; &lt;/snapshotVersion&gt; &lt;/snapshotVersions&gt; &lt;/versioning&gt;&lt;/metadata&gt; 2. 类型分类文档、源码、Jar # 参考 https://stackoverflow.com/questions/13061193/maven-generating-two-jar-files-when-used-with-classifier-tag https://stackoverflow.com/questions/4725668/how-to-deploy-snapshot-with-sources-and-javadoc","link":"/2021/11/23/Maven%E5%88%86%E7%B1%BBclassifier%E4%BD%BF%E7%94%A8/"},{"title":"Maven源码-调试方法","text":"MAVEN源码调试 1. 查看本机Maven版本 1234567$ mvn -vApache Maven 3.6.3Maven home: /usr/share/mavenJava version: 1.8.0_292, vendor: Private Build, runtime: /usr/lib/jvm/java-8-openjdk-amd64/jreDefault locale: en_US, platform encoding: UTF-8OS name: &quot;linux&quot;, version: &quot;5.4.0-84-generic&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot; 2. 准备maven源码12345678# 克隆Maven源码到本地$ git clone git@github.com:apache/maven.git# 迁出对应版本代码$ git checkout maven-3.6.3# 编译源码$ mvn clean install -Dmaven.test.skip=true -Drat.ignoreErrors=true 3. 用mvnDebug执行，其会阻塞等待链接1234$ mvnDebug clean install -f pom.xmlPreparing to execute Maven in debug modeListening for transport dt_socket at address: 8000 4. Maven源码中通过Remote JVM Debug进行调试 # 附录 - 常用源码仓库地址123git@github.com:apache/maven.gitgit@github.com:apache/maven-resolver.gitgit@github.com:apache/maven-dependency-plugin.git","link":"/2022/01/22/Maven%E6%BA%90%E7%A0%81-%E8%B0%83%E8%AF%95%E6%96%B9%E6%B3%95/"},{"title":"Maven生命周期和插件MOJO","text":"一、插件命名 You will typically name your plugin &lt;yourplugin&gt;-maven-plugin. Calling it maven-&lt;yourplugin&gt;-plugin (note “Maven” is at the beginning of the plugin name) is strongly discouraged since it’s a reserved naming pattern for official Apache Maven plugins maintained by the Apache Maven team with groupId org.apache.maven.plugins. Using this naming pattern is an infringement of the Apache Maven Trademark. 其中yourplugin是你的插件名，可以通过mvn yourplugin:goal调用指定MOJO。 二、Maven生命周期和MOJO1）Maven三个独立生命周期参考：官网-maven生命周期 2）Maven生命周期和插件绑定关系参考：官网-Maven常用插件的默认绑定 三、MOJO执行的两个方式1）执行Maven生命周期1$ mvn phase 2）直接调用插件语法格式： 1234# 完全限定名:goal$ mvn [groupId]:[artifactId]:[version]:[goal]# 插件名:goal$ mvn [pluginName]:[goal] 示例： 12$ mvn org.apache.maven.plugins:maven-dependency-plugin:2.8:tree$ mvn dependency:tree 附录：MAVEN所有phase 文件：maven-core/src/main/resources/META-INF/plexus/components.xml。 类：DefaultLifecycleExecutionPlanCalculator.defaultLifeCycles属性 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!--Licensed to the Apache Software Foundation (ASF) under oneor more contributor license agreements. See the NOTICE filedistributed with this work for additional informationregarding copyright ownership. The ASF licenses this fileto you under the Apache License, Version 2.0 (the&quot;License&quot;); you may not use this file except in compliancewith the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0Unless required by applicable law or agreed to in writing,software distributed under the License is distributed on an&quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANYKIND, either express or implied. See the License for thespecific language governing permissions and limitationsunder the License.--&gt;&lt;!-- There is currently only one component descriptor that cannot be generated from annotations because of the accompanying configuration. Our options are to embed this information programatically or use a configuration source to pull in the lifecycle information.--&gt;&lt;component-set&gt; &lt;components&gt; &lt;!-- 'default' lifecycle, without any binding since it is dependent on packaging --&gt; &lt;component&gt; &lt;role&gt;org.apache.maven.lifecycle.Lifecycle&lt;/role&gt; &lt;implementation&gt;org.apache.maven.lifecycle.Lifecycle&lt;/implementation&gt; &lt;role-hint&gt;default&lt;/role-hint&gt; &lt;configuration&gt; &lt;id&gt;default&lt;/id&gt; &lt;!-- START SNIPPET: lifecycle --&gt; &lt;phases&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;phase&gt;initialize&lt;/phase&gt; &lt;phase&gt;generate-sources&lt;/phase&gt; &lt;phase&gt;process-sources&lt;/phase&gt; &lt;phase&gt;generate-resources&lt;/phase&gt; &lt;phase&gt;process-resources&lt;/phase&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;phase&gt;generate-test-sources&lt;/phase&gt; &lt;phase&gt;process-test-sources&lt;/phase&gt; &lt;phase&gt;generate-test-resources&lt;/phase&gt; &lt;phase&gt;process-test-resources&lt;/phase&gt; &lt;phase&gt;test-compile&lt;/phase&gt; &lt;phase&gt;process-test-classes&lt;/phase&gt; &lt;phase&gt;test&lt;/phase&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;phase&gt;pre-integration-test&lt;/phase&gt; &lt;phase&gt;integration-test&lt;/phase&gt; &lt;phase&gt;post-integration-test&lt;/phase&gt; &lt;phase&gt;verify&lt;/phase&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;phase&gt;deploy&lt;/phase&gt; &lt;/phases&gt; &lt;!-- END SNIPPET: lifecycle --&gt; &lt;/configuration&gt; &lt;/component&gt; &lt;!-- 'clean' lifecycle, with default binding --&gt; &lt;component&gt; &lt;role&gt;org.apache.maven.lifecycle.Lifecycle&lt;/role&gt; &lt;implementation&gt;org.apache.maven.lifecycle.Lifecycle&lt;/implementation&gt; &lt;role-hint&gt;clean&lt;/role-hint&gt; &lt;configuration&gt; &lt;id&gt;clean&lt;/id&gt; &lt;!-- START SNIPPET: clean --&gt; &lt;phases&gt; &lt;phase&gt;pre-clean&lt;/phase&gt; &lt;phase&gt;clean&lt;/phase&gt; &lt;phase&gt;post-clean&lt;/phase&gt; &lt;/phases&gt; &lt;default-phases&gt; &lt;clean&gt; org.apache.maven.plugins:maven-clean-plugin:2.5:clean &lt;/clean&gt; &lt;/default-phases&gt; &lt;!-- END SNIPPET: clean --&gt; &lt;/configuration&gt; &lt;/component&gt; &lt;!-- 'site' lifecycle, with default bindings --&gt; &lt;component&gt; &lt;role&gt;org.apache.maven.lifecycle.Lifecycle&lt;/role&gt; &lt;implementation&gt;org.apache.maven.lifecycle.Lifecycle&lt;/implementation&gt; &lt;role-hint&gt;site&lt;/role-hint&gt; &lt;configuration&gt; &lt;id&gt;site&lt;/id&gt; &lt;!-- START SNIPPET: site --&gt; &lt;phases&gt; &lt;phase&gt;pre-site&lt;/phase&gt; &lt;phase&gt;site&lt;/phase&gt; &lt;phase&gt;post-site&lt;/phase&gt; &lt;phase&gt;site-deploy&lt;/phase&gt; &lt;/phases&gt; &lt;default-phases&gt; &lt;site&gt; org.apache.maven.plugins:maven-site-plugin:3.3:site &lt;/site&gt; &lt;site-deploy&gt; org.apache.maven.plugins:maven-site-plugin:3.3:deploy &lt;/site-deploy&gt; &lt;/default-phases&gt; &lt;!-- END SNIPPET: site --&gt; &lt;/configuration&gt; &lt;/component&gt; &lt;component&gt; &lt;role&gt;org.sonatype.plexus.components.sec.dispatcher.SecDispatcher&lt;/role&gt; &lt;role-hint&gt;maven&lt;/role-hint&gt; &lt;implementation&gt;org.sonatype.plexus.components.sec.dispatcher.DefaultSecDispatcher&lt;/implementation&gt; &lt;description&gt;Maven Security dispatcher&lt;/description&gt; &lt;requirements&gt; &lt;requirement&gt; &lt;role&gt;org.sonatype.plexus.components.cipher.PlexusCipher&lt;/role&gt; &lt;field-name&gt;_cipher&lt;/field-name&gt; &lt;/requirement&gt; &lt;requirement&gt; &lt;role&gt;org.sonatype.plexus.components.sec.dispatcher.PasswordDecryptor&lt;/role&gt; &lt;field-name&gt;_decryptors&lt;/field-name&gt; &lt;/requirement&gt; &lt;/requirements&gt; &lt;configuration&gt; &lt;_configuration-file&gt;~/.m2/settings-security.xml&lt;/_configuration-file&gt; &lt;/configuration&gt; &lt;/component&gt; &lt;/components&gt;&lt;/component-set&gt; # 参考 Maven插件命名规范 Maven生命周期和构建原理","link":"/2021/09/18/Maven%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E5%92%8C%E6%8F%92%E4%BB%B6MOJO/"},{"title":"Maven间接依赖未下载","text":"一、问题描述昨日收到一个告警，内容如下： 123452021-11-09 15:01:04 警告，应用：xxx，自定义监控：exception.write.kafka，告警内容：&quot;消费本地失败消息写入Kafka失败java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory&quot;，报警主机：xxx.xxx.xxx.xxx 二、解决路径1）依赖不存在or依赖错版本1.1 定位net/jpountz/lz4/LZ4Factory所在Jar的Maven坐标 12345&lt;dependency&gt; &lt;groupId&gt;net.jpountz.lz4&lt;/groupId&gt; &lt;artifactId&gt;lz4&lt;/artifactId&gt; &lt;version&gt;xxx&lt;/version&gt;&lt;/dependency&gt; 1.2 从问题主机应用的*libs/*中未发现该依赖，定位问题是包缺失。 2）定位依赖缺失原因2.1 本地查看应用依赖树，发现lz4-xxx.jar由kafka-clients引入 123456$ mvn dependency:tree -Dverbose -X -U -f pom.xml | tee tree.txt+- org.apache.kafka:kafka-clients:jar:0.11.0.1:compile +- net.jpountz.lz4:lz4:jar:1.3.0:compile +- org.xerial.snappy:snappy-java:jar:1.1.2.6:compile \\- (org.slf4j:slf4j-api:jar:1.7.25:compile - omitted for conflict with 1.7.22) 2.2 清空本地Maven缓存，再次查看依赖树 123456# 清空pom中依赖树中的本地缓存$ mvn dependency:purge-local-repository -DreResolve=false -DactTransitively=false# 查看依赖树$ mvn dependency:tree -Dverbose -X -U -f pom.xml | tee tree.txt+- org.apache.kafka:kafka-clients:jar:0.11.0.1:compile 2.3 判定私服仓库kafka-clients-0.11.0.1.pom发生变化 私服仓库中存在两个kafka-clients-0.11.0.1.pom，而libs-release-local仓库的pom内容为空，如下图。 3）解决问题联系上传人和私服管理员进行删除，打包恢复正常。 三、原因总结1）研发把kafka-clients-0.11.0.1.jar上传到仓库libs-release-local，且pom.xml未正确设置。 2）私服仓库里lib-release-local比remote-repos优先级高，导致maven解析了错误依赖。","link":"/2021/11/10/Maven%E9%97%B4%E6%8E%A5%E4%BE%9D%E8%B5%96%E6%9C%AA%E4%B8%8B%E8%BD%BD/"},{"title":"Maven源码-依赖解析","text":"一、依赖解析流程说明1）通过DefaultModelBuilder#build生成当前pom的Model，也就是effective pom。 2）递归解析（深度遍历）effective pom的child dependency，生成effective pom。 二、生成effective pom 参考：https://maven.apache.org/ref/3.8.4/maven-model-builder/ 源码：org.apache.maven.model.building.DefaultModelBuilder#build 阶段11、profile activation从命令行指定激活的profile 2、raw model validation当前pom的Raw model校验 3、model normalization当前pom的model规范化，合并重复声明的依赖 4、profile injection把激活态profile（命令行指定激活的或者POM中默认激活的）内容合并注入到model中，如配置、依赖等。 5、parent resolution until super-pom解析当前pom的父POM的model直到SuperPOM。解析完后，lineage内的对象如下。 源码如下： 123456789101112131415161718192021222324252627282930313233343536Collection&lt;String&gt; parentIds = new LinkedHashSet&lt;&gt;(); // 用来判断循环解析List&lt;ModelData&gt; lineage = new ArrayList&lt;&gt;(); // 用来保存当前pom到super-pom mode的列表for (ModelData currentData = resultData; currentData != null;) { lineage.add(currentData); Model rawModel = currentData.getModel(); currentData.setRawModel(rawModel); Model tmpModel = rawModel.clone(); currentData.setModel(tmpModel); // model normalization, 去重 modelNormalizer.mergeDuplicates( tmpModel, request, problems ); // 当前POM是超级POM时Break if (currentData == superData) { break; } configureResolver( request.getModelResolver(), tmpModel, problems ); ModelData parentData = readParent(tmpModel, currentData.getSource(), request, problems); // 使迭代依次向上找父POM，把他们放入lineage集合内 if ( parentData == null ) { currentData = superData; } else if ( currentData == resultData ) { // 首次迭代，设置pom的继承属性 currentData.setGroupId(currentData.getRawModel().getGroupId() == null ? parentData.getGroupId() : currentData.getRawModel().getGroupId()); currentData.setVersion(currentData.getRawModel().getVersion() == null ? parentData.getVersion() : currentData.getRawModel().getVersion()); currentData.setArtifactId(currentData.getRawModel().getArtifactId()); parentIds.add(currentData.getId()); // 入口POM加入parentIds currentData = parentData; } else if (!parentIds.add( parentData.getId())) { // 判断父POM循环 throw new RuntimeException(&quot;The parents form a cycle&quot;); } else { currentData = parentData; }} 6、inheritance assembly当前pom的model继承合并父POM的配置和依赖等内容。遍历lineage对model进行聚合，从后往前聚合，如下图： 参考源码：org.apache.maven.model.merge.ModelMerger#mergeModel 12345678910111213141516171819202122232425262728293031323334353637protected void mergeModel( Model target, Model source, boolean sourceDominant, Map&lt;Object, Object&gt; context ) { mergeModelBase( target, source, sourceDominant, context ); mergeModel_ChildProjectUrlInheritAppendPath( target, source, sourceDominant, context ); mergeModel_ModelVersion( target, source, sourceDominant, context ); mergeModel_Parent( target, source, sourceDominant, context ); mergeModel_GroupId( target, source, sourceDominant, context ); mergeModel_ArtifactId( target, source, sourceDominant, context ); mergeModel_Version( target, source, sourceDominant, context ); mergeModel_Packaging( target, source, sourceDominant, context ); mergeModel_Name( target, source, sourceDominant, context ); mergeModel_Description( target, source, sourceDominant, context ); mergeModel_Url( target, source, sourceDominant, context ); mergeModel_InceptionYear( target, source, sourceDominant, context ); mergeModel_Organization( target, source, sourceDominant, context ); mergeModel_Licenses( target, source, sourceDominant, context ); mergeModel_MailingLists( target, source, sourceDominant, context ); mergeModel_Developers( target, source, sourceDominant, context ); mergeModel_Contributors( target, source, sourceDominant, context ); mergeModel_IssueManagement( target, source, sourceDominant, context ); mergeModel_Scm( target, source, sourceDominant, context ); mergeModel_CiManagement( target, source, sourceDominant, context ); mergeModel_Prerequisites( target, source, sourceDominant, context ); mergeModel_Build( target, source, sourceDominant, context ); mergeModel_Profiles( target, source, sourceDominant, context );}protected void mergeModelBase( ModelBase target, ModelBase source, boolean sourceDominant, Map&lt;Object, Object&gt; context ) { mergeModelBase_DistributionManagement( target, source, sourceDominant, context ); mergeModelBase_Modules( target, source, sourceDominant, context ); mergeModelBase_Repositories( target, source, sourceDominant, context ); mergeModelBase_PluginRepositories( target, source, sourceDominant, context ); mergeModelBase_Dependencies( target, source, sourceDominant, context ); mergeModelBase_Reporting( target, source, sourceDominant, context ); mergeModelBase_DependencyManagement( target, source, sourceDominant, context ); mergeModelBase_Properties( target, source, sourceDominant, context );} 7、model interpolation当前pom的model进行变量解释。变量替换时遵循一定顺序（valueSources内的ValurSource顺序）从配置上下文里找。可参考：Maven属性替换 参考：org.apache.maven.model.interpolation.StringVisitorModelInterpolator#interpolateModel 8、url normallizationUrl规范化，如一些相对目录的替换。 阶段2：可选的插件处理1、model path translation模型中路径（如main路径、target路径等）解析，替换为当前操作系统的文件分隔符、路径分割。 2、plugin management injection插件约束注入。 3、(optional) lifecyle bindings injection生命周期绑定注入。合并默认插件至model，默认插件通过*lifecycle.getPluginsBoundByDefaultToAllLifecycles( packaging )*获取。 4、dependency management import解析model中dependencyManagment中的import依赖，并注入model。会触发import依赖的effective pom解析。 如下所示： 123456789101112&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 第三方依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;person.kivihub&lt;/groupId&gt; &lt;artifactId&gt;my-bom&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependencies&gt;&lt;dependencyManagement&gt; 从org.apache.maven.model.composition.DefaultDependencyManagementImporter源码可看出是先声明的有效。 顺序：当前pom的dependencyManagment &gt; 当前pom的dependency的import &gt; 父pom中的dependencyManagement &gt; 父pom中的dependencyManagement的import。 5、dependency management injection根据上一步解析出的依赖版本约束，修改model中依赖的版本。 源码：org.apache.maven.model.management.DefaultDependencyManagementInjector#injectManagement 6、model normalization - inject default values给model中的dependency和plugin设置默认的scope — compile。 7、(optional) report configuration8、(optional) report convesion to decoupled site plugin9、(optional) plugins configuration10、effective model validation模型校验，如进行model的groupId，artifactId，version非空校验。 三、递归解析子依赖 MojoExecutor执行Mojo前会调用org.apache.maven.lifecycle.internal.MojoExecutor#ensureDependenciesAreResolved进行依赖的递归解析。 Model是一个多叉数模型，递归解析的过程也是多叉树遍历的过程，Maven再进行解析时通过深度遍历来解析。 观察上面堆栈，发现递归解析发生时逻辑主要在以下两个方法内： 1）org.eclipse.aether.internal.impl.collect.DefaultDependencyCollector#processDependency 2）org.eclipse.aether.internal.impl.collect.DefaultDependencyCollector#doRecurse 递归时需要的参数主要有以下内容： 123456789101112131415/*** org.eclipse.aether.internal.impl.collect.DefaultDependencyCollector#process*/private void process(final Args args, // 入参，含session（含冲突协调器dependencyGraphTransformer）、trace、 Results results, List&lt;Dependency&gt; dependencies, // 本次要遍历的直接依赖 List&lt;RemoteRepository&gt; repositories, // 远程仓库 DependencySelector depSelector, // 依赖选择器，如scop选择器、optional选择器、exclude选择器。递归时会向下合并 DependencyManager depManager, // 依赖版本管理 DependencyTraverser depTraverser, // 依赖访问者 VersionFilter verFilter) { for (Dependency dependency : dependencies) { processDependency(args, results, repositories, depSelector, depManager, depTraverser, verFilter, dependency); }} 1、DefaultDependencyCollector#doRecurse1）对depSelector、depManager、depTraverser、verFilter进行下钻式的合并，即子从父继承合并属性。 2）把当前处理的依赖放入栈：Args.nodes，该依赖解析完后弹出。可通过此栈观察当前遍历的路径和深度。 2、DefaultDependencyCollector#processDependency1）根据depSelector对依赖进行判断是否忽略，如ScopeDependencySelector、OptionalDependencySelector、ExclusionDependencySelector。 2）根据depManager对依赖进行约束，也就是dependencyManagement标签里的内容。 3）根据depTraverser判断是否需要递归解析。 4）使用成员属性descriptorReader解析当前依赖的effective pom。其会调用ModelBuilder#build生成effective pom，执行两个phase。 5）判断是否是relocation，如果是，则进行重定向解析；如果不是，则进行下一步。 6）根据depTraverser结果，判断是否进行递归处理。如果需要递归处理则遍历effective pom的依赖，调用DefaultDependencyCollector#doRecurse方法 3、递归解析图示 四、依赖调停 递归解析完子依赖后，会获取一个依赖全集。下一步会调用ChainedDependencyGraphTransformer#transformGraph对依赖进行调停。 123456789101112131415161718/*** org.eclipse.aether.internal.impl.collect.DefaultDependencyCollector*/public CollectResult collectDependencies(RepositorySystemSession session, CollectRequest request) { // ...递归解析部分... DependencyGraphTransformer transformer = session.getDependencyGraphTransformer(); if (transformer != null) { try { DefaultDependencyGraphTransformationContext context = new DefaultDependencyGraphTransformationContext(session); context.put(TransformationContextKeys.STATS, stats); result.setRoot(transformer.transformGraph(node, context)); } catch (RepositoryException e) { result.addException(e); } }} ConflictResolver 参考：org.eclipse.aether.util.graph.transformer.ConflictResolver#transformGraph 1）ConflictIdSorter#transformGraph计算冲突的依赖，并设置到context内。 org.eclipse.aether.util.graph.transformer.ConflictMarker#analyze 深度遍历依赖树，把依赖按gourp:artifact:classifier:extension进行分组。 2）遍历依赖全集，根据上面的分组判断是否冲突；冲突的加入conflictIds。 3）遍历conflictIds，针对每个冲突都深度遍历依赖全集，获取所有冲突的依赖。 4）对冲突的依赖进行调停，依次调用：VersionSelector（默认实现NearestVersionSelector）、ScopeSelector、OptionalitySelector进行依赖调停。 五、Maven和Aether https://maven.apache.org/aether.html https://wiki.eclipse.org/Aether/What_Is_Aether 以上分析是基于Maven3.X，其依赖解析内容使用了Aether。该项目来自eclipse社区，后引入为maven-resolver项目，edi-core内也有部门实现类。 Aether依赖解析说明参考文章，内容为以上流程的概要说明。","link":"/2022/01/25/Maven%E6%BA%90%E7%A0%81-%E4%BE%9D%E8%B5%96%E8%A7%A3%E6%9E%90/"},{"title":"MySQL_Workbench常用操作","text":"1. 一个连接内的多个查询共用一个事务 2.开启或关闭事务自动提交3.显示Mysql内置数据库","link":"/2020/08/03/MySQL_Workbench%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"title":"MySql和B+树","text":"一、前置问题 什么是索引？ 为什么数据库要建索引？不建索引可以吗？索引是不是越多越好？ Mysql是通过索引从硬盘里找到对应的行记录吗？ 有序树，平衡树，红黑树，B树和B+树的关系？ mysql为什么使用B+树实现索引结构？HashMap为什么使用红黑树？ mysql存储引擎索引的分裂方式是传统的中间分裂吗？ 聚集索引和非聚集索引的区别？聚集索引的叶子节点一定包含了完整数据吗？ 聚集索引是严格按照物理顺利存储的吗？ 主键，联合主键的概念？主键可以有多个吗？主键和索引的关系？ 联合索引和联合主键的关系？ 为什么主键建议使用整形自增？ 如果删除了所有索引，还能进行查询和删除操作吗，速度怎么样？ 覆盖索引是什么？它解决了什么问题？ 联合索引为什么遵循最左前缀原则？查询条件中的两个联合索引字段可以颠倒吗？ 如何分析SQL语句是否使用了索引？什么是执行计划？ 二、数据库管理海量数据带来的挑战数据库作为一个管理数据的一个软件，管理海量数据是必须满足的一个特性。海量的数据必然是持久化到主机磁盘上，数据库需要通过IO操作访问磁盘来实现数据的读写功能。此时面临的挑战是如何高性能的读取数据，其中的一个关键指标是减少IO次数。 为了减少IO和提高数据访问效率，需要依赖某种数据结构来对海量的数据建立一个地址表，这种数据结构被称为索引（index）。 目前主要有两个方案：1）Hash索引；2）B+树索引。本文讨论B+树索引。 三、海量的数据迫使数据库使用B+树索引 数据库为了应对海量数据的索引需要解决几个痛点： 1）通过索引快速查找数据； 2）数据更新时易于索引维护； 3）海量数据时IO次数较少； 4）支持Range操作； 树的类型 解决痛点 缺陷 二叉查找树 1）数据量小时可快速查找 极端情况下可能成为一条链，导致查询的时间复杂度为O(n) 平衡二叉树 1）数据量小时可快速查找2）完全平衡的特性使其查询的时间复杂度可以稳定到O(logn) 维护平衡的开销太大 红黑树 1）数据量小时可快速查找；2）非完全平衡的特性使查询时间复杂度接近O(log2n)；3）维护平衡的开销较小 海量数据时，二叉树的高度太高，会增加IO次数 B树（平衡多叉树，B指balance） 1）海量数据时可快速查找；2）平衡特性使其查询的时间复杂度为O(logxn)； 3）维护平衡的开销较小；4）高扇出使其树的高度不高，一般在2-4层。 非叶子节点包含完整数据，导致索引过大，内存每次IO加载的索引数量减少，从而引发多次IO B+树 几乎解决了数据库的所有痛点，且支持range操作 从上图可知HashMap使用红黑树的原因主要有三点： 1）其存储的数据量较小； 2）需要符合快速查找； 3）减小维护平衡的开销； 4）不需要range操作； 延伸一点： 索引并不是越多越好，应该有个平衡，过多的索引必然会增大维护索引的开销，同时会导致磁盘IO的增加。 为了增加IO的效率，索引并不是定位到磁盘里的具体某一行，而是读取该行所在的页（页是mysql管理磁盘的最小单位）到内存，然后在内存里通过二分查找定位具体的记录（虽然记录间通过双向链表连接，但是PageDirectory里的Slot是按顺序排）。 四、聚集索引和非聚集索引 聚集或非聚集指的是索引和数据是否聚集 索引 特性 优点 缺点 聚集索引 1）和数据聚集在一起的索引，其叶子节点保存的是完整数据。2）所以叶子节点的顺序是按照聚集索引来组织和排序的，但物理存储时不是严格按照物理顺序存储的（页之间，页内记录之间通过双向链表来连接）； 1）查询效率比非聚集索引高； 1）重建索引开销较大； 非聚集索引 1）索引的叶子节点不包含完整数据，代替的聚集索引的id；2）数据的物理存储与非聚集索引不相关；3）是对非聚集索引的补充，以应对其他查询需求； 1）非聚集索引占用空间较小；2）重建索引开销较小； 1）不考虑覆盖索引的情况时，查询效率较低（因为非聚集索引查询后，需再去查询聚集索引，即查找两棵树） 五、主键和索引的关系 主键：指的是一个列或多列的组合，其值能唯一地标识表中的每一行，通过它可强制表的实体完整性。其中多列组合的主键称为联合主键； **简单来说，主键是数据库的表来标识每行记录的唯一性和完整性的一个或多个列的组合；**每张表最多只有一个主键。 1）主键和索引在概念是没有任何关系由以上概念得知主键是数据库管理和组织表数据的一种逻辑上的概念；而索引是查找表数据的一种数据结构概念；两者在概念上没有关系； 2）InnoDB的聚集索引的三种来源a. 主键存在由于主键具有唯一性，所以InnoDb会在主键存在时优先使用主键创建索引，即主键索引，此时的主键索引也就是聚集索引。 b. 主键不存在，但存在非空的唯一索引c. 生成隐藏主键（整形递增）数据库如果没有指定主键和非空唯一索引，那么会生成一个隐藏列来作为索引列；所以即便没有声明主键和索引也可以进行查询和DML操作； 六、自增主键是一种InnoDb索引规范DBA们千万次叮咛我们使用整型自增主键主要基于以下事实： 1）整型的比较比字符串要高效，提高查找索引树的速度； 2）InnoDb的索引页的分裂会判断插入是否是随机的，如果是随机的会通过中间分裂；如果是有序的则为了保证页的满载（否则数据页中的数据始终为半页的负载），则会以插入记录作为分裂点； 3）自增是使新增的记录都放到末尾，且以他作为分裂点，使得每页处于满载态；否则会频繁出现分裂，必然引起磁盘碎片和增大维护索引的开销； 七、联合索引和聚集索引关系 联合索引是指该索引由多个字段组合而成，重点在多个字段组成索引； 聚集索引指的是索引和数据聚合在一起，重点在数据和索引聚合； 两个概念是不同维度的，相互正交；所以有些情况下他们是有重叠的。例如以下情况时联合索引就是聚集索引：1）联合主键存在时，此时生成联合索引，也是聚集索引； 2）主键不存在时，若有联合索引满足非空的条件，有可能被选择为聚集索引； 八、索引覆盖 查找的数据就是索引字段，在非叶子节点就包含了要查询的列。 例如有联合索引idx_name_age，那么SQL语句select name from persion where name就是一次索引覆盖的查询。 九、联合索引的最左前缀原则该原则基于一个事实是：联合索引是根据构成索引的列的先后顺序来排序的。 例如：联合索引idx_name_age_salary，可类比为一个三位数字的排序：百位，十位，个位。 十、执行计划通过增加explain前缀可以查看mysql的执行计划，其中包含以下关键信息：1）本次SQL的位置，是子查询还是主查询； 2）复合查询的执行顺序； 3）每次查询的访问类型或访问范围，全表，索引等； 4）每个查询是是否使用了索引，使用的索引名称，及其判断条件； 5）是否使用了fileSort； 参考资料： MYSQL技术内幕 InnoDb存储引擎 第五章 https://www.cnblogs.com/lice-blog/p/11569443.html","link":"/2020/05/14/MySql%E5%92%8CB+%E6%A0%91/"},{"title":"Maven查看模块依赖图","text":"当进行模块重构和重组时，需要查看当前模块间的依赖关系。以下说明了两个常用的方式。 一、IDEA旗舰版-模块依赖图 https://www.jetbrains.com/help/idea/project-module-dependencies-diagram.html From the main menu, select View | Tool Windows | Project (Alt+1), select an item (project/module) for which you want to view a diagram. Right-click the selected item and from the context menu, select Diagram | Show Diagram (or press Ctrl+Alt+Shift+U). From the list that opens, select a type of the diagram you want to create. 二、maven-graph-plugin 源码：https://github.com/fusesource/mvnplugins/tree/master/maven-graph-plugin 命令：mvn org.fusesource.mvnplugins:maven-graph-plugin:1.45:reactor -Dhide-external=true -Dgraph.direction=BT 配置项：参考源码ProjectMojo.java 示例：git@github.com:apache/maven.git根目录执行命令后得到下图： 参考： http://site.kuali.org/maven/plugins/graph-maven-plugin/1.0.14/ https://github.com/fusesource/mvnplugins/tree/master/maven-graph-plugin https://mvnrepository.com/artifact/org.fusesource.mvnplugins/maven-graph-plugin/1.45 https://stackoverflow.com/questions/4084669/how-to-generate-a-graph-of-the-dependency-between-all-modules-of-a-maven-project","link":"/2022/02/09/Maven%E6%9F%A5%E7%9C%8B%E6%A8%A1%E5%9D%97%E4%BE%9D%E8%B5%96%E5%9B%BE/"},{"title":"Mysql_InnoDB锁","text":"Mysql有多种存储引擎，他们的锁机制也不尽相同。例如MyISAM不支持行锁只有表琐，所以本文主要讨论InnoDB引擎的锁机制。 一、前置问题 为什么要有锁？锁对性能影响大吗？ 锁有几种逻辑分类？ Innodb的锁是公平锁吗？ 如何检测和避免死锁？Innodb会对死锁自动处理吗？ 行锁是锁的什么？表琐是在哪一层实现的，服务器层还是存储引擎层？ 表琐有几种？意向锁是什么？ mysql有锁升级吗？什么是锁升级？ 二、锁是维护数据一致性的必要条件数据库在处理并发访问共享资源时，需要锁来保护资源数据的一致性。 三、锁分类3.1 锁在层级上分为：1）服务器级别锁；2）存储引擎级别锁；服务器锁：在mysql服务器层实现并发控制，会忽略存储引擎的锁；存储引擎锁：在存储引擎层实现，锁的粒度一般比服务器层要更细； 3.2 锁从粒度上可分为：1）行锁；2）表琐；两者都可以表现为共享性或排他性； 行锁在存储引擎层实现;一般通过锁索引来实现； 表琐1）Mysql服务器层； 12LOCK TABLE t READ;LOCK TABLE t WRITE; 2）InnoDB存储引擎也实现了一种表琐，意向锁（意向共享锁，意向排它锁）； 1234select * from t where id &lt; 3 lock in share mode; // 表上加意向共享锁select * from t where id &lt; 3 lock for update; // 表上加意向排它锁update t set name = 'test' where id = 3; // 表上加意向排它锁delete from t where id = 3; // 表上加意向排它锁 意向锁是InnoDB在增加行锁时，同时在表上标记的一个信息。用于多个事务对表资源进行竞争获取锁时，避免去查看表中记录的行锁信息，提高了性能。例如：事务A，执行语句update t set name = 'test' where id = 3;时会加两把锁：a. 在id=3的索引上加行锁；b. 在t表上增加意向排他锁：IX LOCK此时，事务B要执行LOCK TABLE t READ;，需要在表上增加X锁。此时由于X,IX锁的不兼容，该事务被阻塞； 意向锁间兼容性由于意向锁实际上是行锁的一种表级别的提示，他们都是要操作行，所以意向锁之间不会导致事务（在表级别）相互阻塞。如果是操作的相同行时通过行锁阻塞来实现并发控制。 IX IS IX 兼容 兼容 IS 兼容 兼容 读写表琐兼容性 X S X 不兼容 不兼容 S 不兼容 兼容 意向锁和读写锁的兼容性 X S IX 不兼容 不兼容 IS 不兼容 兼容 3.3 锁在访问性上可分为：1）共享锁；2）排它锁共享锁：也称为读锁，多个用户可以获取某资源的共享锁，互不阻塞；排它锁：也称为写锁，多个用户尝试去获取排他锁时，只有一个会成功，其他的被阻塞； 四、死锁在InnoDb中两个或多个事务并发访问多个资源时，双发都请求对方占用的资源时，会发生死锁。 死锁原因多个事务以不同的顺序去锁定资源时，就可能会发生死锁。 如何避免死锁以相同的顺序去请求资源，并且可以设置等待超时时间避免一直等待下去； 如何解决死锁InnoDB引擎检测到死锁时，强制回滚其中的一方事务，解锁争抢资源； 五、锁升级一般数据库把锁作为一种稀缺资源，当多个小粒度的锁开销较大时，会升级为一个粗粒度的锁来减小开销。类似java中的锁粗化； 举个栗子1）Mysql中多个行锁升级为页锁，或页锁升级为表琐。2）拿Java的锁粗化来举例： 123456789public void doSomethingMethod(){ synchronized(lock){ //do some thing } //这是还有一些代码，做其它不需要同步的工作，但能很快执行完毕 synchronized(lock){ //do other thing }} 会被优化为以下形式； 12345678public void doSomethingMethod(){ //进行锁粗化：整合成一次锁请求、同步、释放 synchronized(lock){ //do some thing //做其它不需要同步但能很快执行完的工作 //do other thing }} InnoDB没有锁升级在InnoDB中锁通过位图实现，开销是一致的，无需升级。","link":"/2020/05/17/Mysql_InnoDB%E9%94%81/"},{"title":"Mysql事务及其隔离级别","text":"1.前置问题 什么是事务？事务的特性？ 隔离级别有几种？为什么要有不同的隔离级别？ 隔离级别是会话级的吗？ mvcc是什么？为什么要有mvcc？ mvcc和隔离级别的关系？ mvcc的两种同构模型？ redo log和undo log的区别？ 2. 事务应用系统在操作数据库时，往往需要进行组合操作，事务的存在是把这种组合操作视为一个原子操作，要么全部执行成功，要么全不执行。事务通过原子性来保证数据库状态的一致性。 事务四个特性1）原子性：在事务中的数据库操作视为一个整体，要么全部执行，要么全不执行，避免只执行了部分操作，导致数据不一致； 2）一致性：在事务操作前和操作后，数据库的数据始终处于一致性状态。例如，转账操作，需要保证转账前后，转账双方的总额不变； 3）隔离性：也称并发控制；多个事务并发访问数据库时，不同事务的操作在执行时要相互隔离，在提交前对其他事务不可见； 4）持久性：事务一旦提交，就是永久的。即便数据库宕机也能恢复。 3. 事务隔离性考虑到并发的性能，MySql等数据库在实现隔离性性的时候并没有完全真正的隔离。目前有四种事务隔离级别标准： insert into t (id, name) values(1, “wang”) // 初始化语句 1）读未提交一个事务读到了另一个事务未提交的修改，这种现象被称为脏读； 时间顺序 事务一 事务二 1 BEGIN 2 select name from t where id = 1 // 结果为“wang” BEGIN 3 update t set name=”王” where id = 1 4 select name from t where id = 1 // 结果为“王” 5 COMMIT COMMIT 2）读已提交一个事务读到了另一个事务已提交的修改，这种现象被称为不可重复读； 时间顺序 事务一 事务二 1 BEGIN 2 select name from t where id = 1 // 结果为“wang” BEGIN 3 update t set name=”wang” where id = 1 4 select name from t where id = 1 // 结果为“wang” 5 COMMIT 6 select name from t where id = 1 // 结果为“王” 7 COMMIT 3）可重复读一个事务读取的结果不会受另一个事务（无论是否提交）影响。 时间顺序 事务一 事务二 1 BEGIN 2 select name from t where id = 1 // 结果为“wang” BEGIN 3 update t set name=”wang” where id = 1 4 select name from t where id = 1 // 结果为“wang” 5 COMMIT 6 select name from t where id = 1 // 结果为“wang” 7 COMMIT 但是可重复读无法解决幻读问题，即当事务A读取某个范围的记录时，事务B在该范围内插入了新的记录，那么事务A再次读取该范围记录时，就会发现新增了记录。 4）串行化数据库强制事务串行执行来避免并发问题。 附：隔离级别表 隔离级别 脏读 不可重复读 幻读 读未提交 Y Y Y 读已提交 N Y Y 可重复读 N N Y 串行化 N N N 4. InnoDb事务隔离性的实现InnoDB通过MVCC+间隙锁支持可重复读。 1）MVCC支持修改、删除记录的可重复读。 MVCC的ReadView可支持实现读已提交、可重复读的非阻塞快照读，MVCC的InnoDB实现。 2）间隙锁支持新增记录的可重复读，使可RR避免大部分幻读问题。 特别场景下仍会幻读，如事务A增加了一行记录，事务B update此条记录（尽管其看不到，仍可根据ID进行更新）则会导致update前后看到的记录数不同。 5. redo log和undo log redo log undo log 作用 保证事务的持久性 帮助事务回滚和支持mvcc功能 记录内容 物理日志，记录的是页的物理修改操作 逻辑日志，根据每行记录进行记录 参考 MySql技术内幕 InnoDB存储引擎 第七章","link":"/2020/05/19/Mysql%E4%BA%8B%E5%8A%A1%E5%8F%8A%E5%85%B6%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"},{"title":"Mysql优化","text":"一、filesort filesort用于order by或group by语句，要求返回的结果集有序或分组。如果结果集不大则完全可以在内存中排序，否则需要借助磁盘来完成排序。 1、filesort与索引1）如果explain的Extra中不含using filesort，说明使用索引，且不执行filesort操作； 2）如果explain的Extra中包含using filesort，说明不使用索引，且执行filesort操作； 若执行了filesort，则trace中显示如下信息： 1234567&quot;filesort_summary&quot;: { &quot;rows&quot;: 100, &quot;examined_rows&quot;: 100, &quot;number_of_tmp_files&quot;: 0, &quot;sort_buffer_size&quot;: 25192, &quot;sort_mode&quot;: &quot;&lt;sort_key, packed_additional_fields&gt;&quot;} 2、关键参数1）max_length_for_sort_data 用于决定使用哪种排序算法的值，如果需要排序的列的总大小加上order by列的大小超过了 max_length_for_sort_data定义的字节使用双路排序，否则使用单路排序。如果增大该值，同时应该适当增加sort_buffer_size的值。 NOTE：如果该值设置的过大，将导致磁盘IO增多，cpu使用下降。 2）max_sort_lenght 一般用于对text，blob列排序，通过该值指定需要排序的前缀长度并忽略剩余的值，以减少内存使用。 3）sort_buffer_size 排序的内存缓冲区大小，该值应该尽可能的大，以便排序的结果集能尽量被容纳进去。可在会话级别进行控制。 3、单路排序和双路排序1）单路排序 一次性取出所有查询的字段，进行排序，无需回表。 2）双路排序 取出排序字段和改行指针值进行排序，排序结束后再根据指针回表查询所有查询的字段。归并排序 二、NLJ和BNL MySQL使用嵌套循环算法或其变种来实现表之间的关联。 假设有三张表如下； 1234Table Join Typet1 ranget2 reft3 ALL 1、NLJ（Nested-Loop Join Algorithm）NLJ可以理解为关联多表时，执行循环遍历和嵌套操作来筛选结果集。假如t1,t2,t3的行数分别为x,y,z，那么扫描行数n=xyz。 12345678// 官网伪代码for each row in t1 matching range { for each row in t2 matching reference key { for each row in t3 { if row satisfies join conditions, send to client } }} 2、BNL（Block Nested-Loop Join Algorithm）BNL可以理解为在NLJ的基础上的变种，通过引入join buffer来缓存一批外层的行，减少遍历的次数。假如t1,t2,t3的行数分别为x,y,z，joinbuffer一次可容纳j条记录，那么扫描行数n=xyz/j。 12345678910111213141516171819202122// 官方伪代码for each row in t1 matching range { for each row in t2 matching reference key { store used columns from t1, t2 in join buffer if buffer is full { for each row in t3 { for each t1, t2 combination in join buffer { if row satisfies join conditions, send to client } } empty join buffer } }}if buffer is not empty { for each row in t3 { for each t1, t2 combination in join buffer { if row satisfies join conditions, send to client } }} 三、ICP索引条件下推ICP(Index Condition Pushdown)，索引条件下推是Mysql针对使用索引检索时的一种优化手段。索引下推中下推的是where中有关索引的条件，由服务层下推到存储引擎层，使之返回更小的数据行到服务层。 1、不使用ICP场景1）存储引擎遍历table t的索引，对每一个索引执行后续操作； 2）根据索引从table t中取出行（如果是二级索引需要回表），返回服务器； 3）服务器通过where条件中针对table t的条件来过滤行； 2、使用ICP场景1）存储引擎遍历table t的索引，对每一个索引执行后续操作； 2）存储引擎根据where中针对table t条件中当前索引列的查询条件，对索引进行检查， 如果满足，则根据索引从table t中取出行并将其返回至mysql服务器层，继续执行后续操作 否则，返回第1）步获取下一个索引； 3）服务器根据剩余的条件过滤引擎返回的数据行； 3、优点1）减少存储引擎访问表的次数； 2）减少mysql服务器访问存储引擎的次数； 4、参考图片 # 参考 https://dev.mysql.com/doc/refman/5.7/en/order-by-optimization.html https://dev.mysql.com/doc/internals/en/optimizer-tracing.html https://dev.mysql.com/doc/refman/8.0/en/nested-loop-joins.html#nested-loop-join-algorithm https://dev.mysql.com/doc/refman/8.0/en/index-condition-pushdown-optimization.html","link":"/2020/08/03/Mysql%E4%BC%98%E5%8C%96/"},{"title":"Mysql如何保证数据不丢失","text":"一、前置问题 binlog, redolog区别 二、InnoDB实现原子级的持久性1. 直接把buffer中的修改页写到磁盘的挑战1）如何保证Mysql底层数据页的完整性 首先写磁盘操作的非原子性，事务提交后，直接把buffer中的修改页写入磁盘，如果此过程中数据库宕机，则可能导致事务写入不完整，且重启后无法恢复； 2）如何避免频繁写Mysql数据页导致性能下降 随机写盘的IO效率低和响应时间长。因为数据库数据按B+数的结构存储，其数据必然是不连续的；持久化操作必然是非顺序写，IO的操作必然导致客户端响应时间变大； 2. Innodb的解决方案——redo log1）double write来避免partial page write，保证页完整性。 双写的原则是任何时候不破坏页的完整性。BufferPoll中的脏页会先把他保存到其他地方，保存成功后再去覆盖原有位置的页。这样无论何时都有一个完整的数据页。 2）通过AOF日志记录避免频繁刷盘 redo log是Innodb存储引擎引入的，用来解决事务级别的持久化和原子性；redo log的使用是建立在页完整的基础上的。 I、redo log存储了本次的事务的操作，其最后的行end trx_num来标识事务是否已完成；通过该行来原子性标识是否事务是否完成； II、redo log顺序写的特性保证其IO效率高，响应快； 通过同步写redo log，异步刷新修改页到磁盘实现高响应；如果写磁盘发生宕机则通过重放redo log实现crash recovery，实现数据不丢失； 三、bin logbin log是mysql server层的日志，主要用来实现主从同步； 四、redo log的二段式提交innoDB为了使redo log和bin log保持同步，即保证主库和从库的同步，在收到事务的commit操作后，采用二段式提交实现； 1）第一步：pepare redo log，第一次提交 1234start tx_num;write operate_1;write operate_n;pepare tx_num; 2）第二步：write bin log 1write binlog; 3）第三步：end tx_num，第二次提交 1end tx_num; 此时，有三种场景： 1）第一步失败（redo log中无prepare tx_num行）- mysql认为事务提交失败，忽略事务； 2）第二步失败（redo log中存在prepare tx_num行）- mysql通过redo log恢复bin log，继续执行第三步，事务提交成功； 3）第三步失败（redo log中存在prepare tx_num行）- 重启后继续执行第三步，事务提交成功； 参考 https://www.cnblogs.com/biao/p/11820310.html https://dev.mysql.com/doc/refman/8.0/en/innodb-doublewrite-buffer.html https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_checksum_algorithm https://blog.csdn.net/jolly10/article/details/79791574","link":"/2020/08/03/Mysql%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E5%A4%B1/"},{"title":"Mysql对Null的判断","text":"Mysql数据库中的Null是一个特殊的存在，表示该记录没有值，不同于空（’’）和0；1）应该使用IS NULL或者IS NOT NULL来判断2）禁止使用&lt;&gt;, &lt;, &gt;, =去检测NULL，因为其结果集永远是空; NOTE：任何数和NULL运算结果都为NULL。3）NULL不同于’’, 0。它表示’not having a value’。 参考 https://dev.mysql.com/doc/refman/8.0/en/working-with-null.html https://dev.mysql.com/doc/refman/8.0/en/problems-with-null.html","link":"/2020/09/30/Mysql%E5%AF%B9Null%E7%9A%84%E5%88%A4%E6%96%AD/"},{"title":"Mysql索引优化","text":"一、索引设计原则1、减少大基数范围查询 1）少用!=,&lt;&gt;; 2）少用is null, is not null; 2、等值查询时，避免转换操作1）避免在等号左侧的索引列上做计算操作，如函数，类型转换； 2）避免等号右侧的类型与索引类不同而引起类型转换； 3、聚合索引查询时的最左前缀法则1）范围条件的索引会中断左前缀匹配； 4、尽量应用覆盖索引，查询必要的列而非所有列5、少用范围查询1）少用or，in 2）Like查询时尽量采用后模糊“xxx%”，而非前模糊“%xxx”; 6、使用orderby或group by时尽量对索引列操作，避免出现filesort7、in, exist1）select * from A where id in (select id from B) 以B为驱动表去遍历A；适合于B数据量 &lt; A数据量 2）select * from A where exists (select 1 from B where B.id = A.id) 以A为驱动表去遍历B；适合于B数据量 &gt; A数据量 8、countcount(*) ，count(1)会统计字段为null的行； count(col)不会统计该列为null的行； 二、索引选择123456enum idx_type { CLUSTERED_PK, UNIQUE, NOT_UNIQUE, FULLTEXT}; 1、索引选择顺序 聚集索引 &gt; 唯一索引 &gt; 普通索引 &gt; 全文索引 2、索引基数：Cardinality select index from multiple indexes To eliminate rows from consideration. If there is a choice between multiple indexes, MySQL normally uses the index that finds the smallest number of rows (the most selective index). selectivity A property of data distribution, the number of distinct values in a column (its cardinality) divided by the number of records in the table. High selectivity means that the column values are relatively unique, and can retrieved efficiently through an index. If you (or the query optimizer) can predict that a test in a WHERE clause only matches a small number (or proportion) of rows in a table, the overall query tends to be efficient if it evaluates that test first, using an index. 通过命令show index from table可查看索引基数。 123456+-----------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |+-----------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| edi_cache | 0 | PRIMARY | 1 | id | A | 965 | NULL | NULL | | BTREE | | || edi_cache | 0 | uniq_key | 1 | cache_key | A | 966 | NULL | NULL | YES | BTREE | | |+-----------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ # 参考 https://zhuanlan.zhihu.com/p/110649783 https://dev.mysql.com/doc/refman/8.0/en/mysql-indexes.html https://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos_selectivity","link":"/2020/08/03/Mysql%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96/"},{"title":"Nginx架构翻译","text":"Inside NGINX: How We Designed for Performance &amp; ScaleNGINX在web性能方面处于领先地位，这完全归功于软件的设计方式。许多web服务器和应用程序服务器使用简单的线程或基于进程的体系结构，而NGINX则以复杂的事件驱动体系结构脱颖而出，使其能够在现代硬件上扩展到数十万个并发连接。 内部NGINX信息图从高级流程架构向下展开，以说明NGINX如何在单个流程中处理多个连接。本博客将进一步详细介绍这一切的工作原理。 设置场景–NGINX流程模型 为了更好地理解这种设计，您需要了解NGINX是如何运行的。NGINX有一个主进程（它执行特权操作，如读取配置和绑定到端口）以及许多Worker进程和辅助进程。 在这个四核服务器上，NGINX主进程创建了四个Worker进程和两个缓存辅助进程（用于管理磁盘内容缓存）。 为什么架构很重要？任何Unix应用程序的基本基础都是线程或进程。（从Linux操作系统的角度来看，线程和进程基本相同；主要区别在于它们共享内存的程度。）线程或进程是一组自包含的指令，这些指令可以被操作系统在CPU内核上调度执行。大多数复杂的应用程序并行运行多个线程或进程，原因有两个： 他们可以同时使用更多的计算核。 线程和进程使并行操作变得非常容易（例如，同时处理多个连接）。 进程和线程消耗资源。它们各自使用内存和其他操作系统资源，需要在内核进行交换（一种称为上下文切换的操作）。大多数现代服务器可以同时处理数百个小型活动线程或进程，但一旦内存耗尽或高I/O负载导致大量上下文切换，性能就会严重下降。 设计网络应用程序的常用方法是为每个连接分配一个线程或进程。此体系结构简单且易于实现，但当应用程序需要处理数千个同时连接时，它无法扩展。 NGINX是如何工作的？NGINX使用如下进程模型，该模型根据可用的硬件资源进行调整： 主进程执行特权操作，如读取配置和绑定到端口，然后创建少量子进程（下三种类型）。 缓存加载程序进程在启动时运行，将基于磁盘的缓存加载到内存中，然后退出。它的日程安排比较保守，因此其资源需求较低。 缓存管理器进程定期运行，并从磁盘缓存中删除条目，使其保持在配置的大小内。 工作进程完成了所有工作！它们处理网络连接，将内容读写到磁盘，并与上游服务器通信。 在大多数情况下推荐的NGINX配置（每个CPU核运行一个工作进程）可以最有效地利用硬件资源。您可以通过在worker_processs指令上设置auto参数来配置它： 1worker_processes auto; 当NGINX服务器处于活动状态时，只有Worker进程繁忙。每个Worker进程以非阻塞方式处理多个连接，减少了上下文切换的数量。 每个Worker进程都是单线程的，独立运行，可以获取新的连接并进行处理。这些进程可以使用共享内存进行通信，以获取共享缓存数据、会话持久性数据和其他共享资源。 在NGINX Worker进程内部 每个NGINX Worker进程都使用NGINX配置进行初始化，并由主进程提供一组侦听套接字。 NGINX Worker进程首先等待侦听套接字上的事件（accept_mutex和kernel socket sharding）。事件由新的 incoming connections启动。这些连接被分配给状态机–HTTP状态机是最常用的，但NGINX还为stream（原始TCP）traffic和许多邮件协议（SMTP、IMAP和POP3）实现状态机。 状态机本质上是告诉NGINX如何处理请求的一组指令。大多数执行与NGINX相同功能的web服务器使用类似的状态机——区别在于实现。 调度状态机把状态机想象成国际象棋的规则。每个HTTP事务都是一局象棋游戏。棋盘的一边是web服务器——一个可以快速做出决策的大师。另一边是远程客户端，即通过相对较慢的网络访问站点或应用程序的web浏览器。 然而，游戏规则可能非常复杂。例如，web服务器可能需要与其他方通信（代理到上游应用程序）或与身份验证服务器通信。web服务器中的第三方模块甚至可以扩展游戏规则。 阻塞状态机回想一下，我们将进程或线程描述为操作系统可以调度他在CPU内核上运行的一组自包含指令。大多数web服务器和web应用程序使用process‑per‑connection或者thread‑per‑connection来下棋。每个进程或线程都包含从一个游戏玩到最后的指令。在服务器运行该进程的过程中，它将大部分时间用于“阻塞”——等待客户端完成下一步操作。 web服务器进程侦听listen sockets的新连接（由客户端启动的新游戏）。 当它得到一个新的游戏时，它会玩这个游戏，在每次移动后阻塞，等待客户的响应。 游戏完成后，web服务器进程可能会等待客户端是否希望启动新游戏（这对应于keepalive连接）。如果连接关闭（客户端关闭或出现超时），web服务器进程将返回侦听新游戏。 需要记住的重要一点是，每个活动HTTP连接（每局国际象棋游戏）都需要一个专用的进程或线程（一个特级大师）。该体系结构简单，易于使用第三方模块进行扩展（“新规则”）。然而，存在一个巨大的不平衡：相当轻量级的HTTP连接（由文件描述符和少量内存表示）映射到一个单独的线程或进程，一个非常重的操作系统对象。这是一种编程的便利，但却是极大的浪费。 NGINX是一位象棋大师也许你听说过同步展示赛，一位国际象棋大师同时与数十名对手对弈？ 这就是NGINX Worker进程下“国际象棋”的方式。每个Woker（记住，通常一个Woker分配一个CPU核）都是一个象棋大师，可以同时玩数百（事实上，数十万）个游戏。 Woker进程等待listern和connection套接字上的事件。 套接字上发生事件时，Woker进程会处理这些事件： listen套接字上的事件表示客户端已开始新的国际象棋游戏。Woker进程创建一个新的connection套接字。 connection套接字上的事件表示客户端进行了新的移动。Woker迅速作出反应。 工作者从不阻塞在network traffic上等待其“对手”（客户端）响应。当它移动后，Worker立即进入其他游戏，来处理等待中的移动命令，或者欢迎新玩家进入。 为什么这比阻塞、多进程体系结构更快？NGINX可以很好地扩展，以支持每个Woker进程处理十万级连接。每个新连接都会创建另一个文件描述符，并在工作进程中消耗少量额外内存。每个连接的额外开销很少。NGINX进程可以固定在cpu上。上下文切换相对较少，只在没有工作要做时发生切换。 在阻塞、connection‑per‑process的方法中，每个连接都需要大量额外的资源和开销，并且上下文切换（从一个进程切换到另一个进程）非常频繁。 要获得更详细的解释，请查看这篇关于NGINX架构的文章，作者是NGINX，Inc.公司的企业发展副总裁兼联合创始人安德鲁·阿列克谢夫。 通过适当的系统调优，NGINX可以扩展到每个工作进程处理数十万个并发HTTP连接，并且可以处理流量峰值（新游戏的涌入），而不会打乱节奏。 更新配置和升级NGINXNGINX的进程体系结构具有少量Woker进程，可以非常高效地更新配置，甚至NGINX二进制文件本身。 更新NGINX配置是一个非常简单、轻量级和可靠的操作。它通常只意味着运行nginx -s reload命令，该命令检查磁盘上的配置并向主进程发送SIGHUP信号。 当主进程收到SIGHUP时，它会执行两项操作： 重新加载配置并派生一组新的Worker进程。这些新的Worker进程立即开始接受连接和处理流量（使用新的配置设置）。 指示旧Worker进程正常退出。Woker进程停止接受新连接。只要当前的每个HTTP请求完成，Woker进程就会干净地关闭连接（也就是说，没有延迟的keepalives）。关闭所有连接后，Worker进程将退出。 这个重新加载过程可能会导致CPU和内存使用量的小幅增加，但与活动连接的资源负载相比，这通常是难以察觉的。您可以每秒多次重新加载配置（许多NGINX用户正是这样做的）。当有多代NGINX工作进程等待连接关闭时，很少会出现问题，但即使是这些问题也会很快得到解决。 NGINX的二进制升级过程实现了高可用性的圣杯——您可以动态升级软件，而无需任何连接中断、停机或服务中断。 二进制升级过程类似于优雅地重新加载配置。新的NGINX主进程与原始主进程并行运行，它们共享侦听套接字。这两个进程都是活动的，它们各自的worker进程处理流量。然后，您可以向老主人及其工作人员发出信号，让他们优雅地退出。 在控制NGINX中对整个过程进行了更详细的描述。 结论NGINX的内部信息图提供了NGINX如何运行的高级概述，但在这个简单的解释背后是十多年的创新和优化，使NGINX能够在各种硬件上提供尽可能最佳的性能，同时保持现代web应用程序所需的安全性和可靠性。 如果您想阅读更多关于NGINX中优化的信息，请查看以下伟大的参考资料： Installing and Tuning NGINX for Performance (webinar; slides at Speaker Deck) Tuning NGINX for Performance The Architecture of Open Source Applications – NGINX Socket Sharding in NGINX Release 1.9.1 (using the SO_REUSEPORT socket option) # 参考 https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/ https://www.nginx.com/resources/library/infographic-inside-nginx/ https://www.aosabook.org/en/nginx.html","link":"/2021/12/15/Nginx%E6%9E%B6%E6%9E%84%E7%BF%BB%E8%AF%91/"},{"title":"Netty高性能分析","text":"一、Netty高性能分析1）使用NIO多路复用技术，使其能高效的支持大量的客户端连接 2）使用主从Reactor模型，BossGroup和WorkerGroup分工明确，BossGroup只负责接收Channel，加快了客户端建立连接的速度。 3）使用多线程Reactor模型，WorkerGroup分配多个NioEventLoop，使CPU和IO达到一个更好的平衡，提升了CPU利用率，加快了客户端的响应效率 4）采用单线程处理客户端请求，避免同步带来的开销（无锁串行化思想） 5）支持高性能序列化协议，也体现了Netty的扩展性 6）采用零拷贝技术，减少内存拷贝开销（参考：零拷贝） 7）ByteBuf内存池化设计，减少了分配和销毁Direct Buffer带来的开销 8）灵活的TCP配置 二、io.netty.buffer.ByteBuf对DirectByteBuffer的池化1. PooledDirectByteBuf继承结构 2. PooledDirectByteBuf分配的工具类1）PooledByteBufAllocator 2）ByteBufUtil（配置io.netty.allocator.type=pooled） 12345678910111213141516public final class ByteBufUtil { static { String allocType = SystemPropertyUtil.get(&quot;io.netty.allocator.type&quot;, &quot;unpooled&quot;).toLowerCase(Locale.US).trim(); ByteBufAllocator alloc; if (&quot;unpooled&quot;.equals(allocType)) { alloc = UnpooledByteBufAllocator.DEFAULT; logger.debug(&quot;-Dio.netty.allocator.type: {}&quot;, allocType); } else if (&quot;pooled&quot;.equals(allocType)) { alloc = PooledByteBufAllocator.DEFAULT; logger.debug(&quot;-Dio.netty.allocator.type: {}&quot;, allocType); } else { alloc = UnpooledByteBufAllocator.DEFAULT; logger.debug(&quot;-Dio.netty.allocator.type: unpooled (unknown: {})&quot;, allocType); } }} # Netty对Select空循环Bug的修复参考代码：io.netty.channel.nio.NioEventLoop#select，该方法内部会对空轮训进行计数，默认达到512次后会调用rebuildSelector()方法重新构建一个新的Selector。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364private void select() throws IOException { Selector selector = this.selector; try { int selectCnt = 0; long currentTimeNanos = System.nanoTime(); long selectDeadLineNanos = currentTimeNanos + delayNanos(currentTimeNanos); for (;;) { long timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L; if (timeoutMillis &lt;= 0) { if (selectCnt == 0) { selector.selectNow(); selectCnt = 1; } break; } int selectedKeys = selector.select(timeoutMillis); selectCnt ++; // 有事件发生，被唤醒或者任务队列非空时跳出循环 if (selectedKeys != 0 || oldWakenUp || wakenUp.get() || hasTasks()) { break; } if (selectedKeys == 0 &amp;&amp; Thread.interrupted()) { // Thread was interrupted so reset selected keys and break so we not run into a busy loop. // As this is most likely a bug in the handler of the user or it's client library we will // also log it. See https://github.com/netty/netty/issues/2426 if (logger.isDebugEnabled()) { logger.debug(&quot;Selector.select() returned prematurely because &quot; + &quot;Thread.currentThread().interrupt() was called. Use &quot; + &quot;NioEventLoop.shutdownGracefully() to shutdown the NioEventLoop.&quot;); } selectCnt = 1; break; } if (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; 0 &amp;&amp; selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) { // The selector returned prematurely many times in a row. Rebuild the selector to work around the problem. logger.warn(&quot;Selector.select() returned prematurely {} times in a row; rebuilding selector.&quot;, selectCnt); rebuildSelector(); selector = this.selector; // Select again to populate selectedKeys. selector.selectNow(); selectCnt = 1; break; } currentTimeNanos = System.nanoTime(); } if (selectCnt &gt; MIN_PREMATURE_SELECTOR_RETURNS) { if (logger.isDebugEnabled()) { logger.debug(&quot;Selector.select() returned prematurely {} times in a row.&quot;, selectCnt - 1); } } } catch (CancelledKeyException e) { if (logger.isDebugEnabled()) { logger.debug(CancelledKeyException.class.getSimpleName() + &quot; raised by a Selector - JDK bug?&quot;, e); } // Harmless exception - log anyway }}","link":"/2021/02/06/Netty%E9%AB%98%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"title":"RPC服务线程池大小及集群规模评估","text":"写在前面的话一个RPC服务在发布时不可避免的要设置其线程池大小，而我们往往却只根据经验来设置，需知不同场景不同业务下其需要配置不同的值方能使系统更稳定。以下内容是我认为应该去考虑的因素和具体的一些步骤，留待慢慢验证。 一、评估单机最佳线程数 根据该RPC服务提供的具体业务场景，设置不同线程池数量，进行单机压测。观察在不同的压力梯度下，单机系统资源的运行情况，包括CPU使用率，内存使用率，GC频率，网络流量，IO繁忙度等。 需要注意的是抛开具体场景去压测是毫无意义的，不同的业务场景下CPU，IO的开销比例是不同的（即下面公式的W/C）。只有限定业务场景，进行压测，才能找到适合该CPU，IO比例的线程池设置。 图、一种线程池计算公式。 二、评估单机最佳TPS根据上面得出的线程池，测试在不同的TPS下，单机系统状态。找到如下区间的TPS： 1）CPU使用率：40% ～ 70% 2）内存使用率：40% ～ 60% 3）网络TCP重传数较低 4）磁盘使用率稳定 三、评估集群规模假设上一步单机下得出的最佳单机NodeTPS，接下来考虑集群的规模。一般遵循以下步骤： 1）通过历史监控数据，找到RPC服务每秒接收的峰值请求数，记为ClusterTPS。 2）初步估算集群规模为：ClusterNum = ClusterTPS / NodeTPS 3）考虑集群滚动更新比例，记为P，则 ClusterNum = ClusterNum / (1 - P) 4）增加安全系数Secure(值大于1)，ClusterNum = ClusterNum * Secure 5）大促时流量成倍增加，要保证SLA的话，则集群数量也需要相应倍增。 四、评估示例假设有RPC服务经过压测，历史数据采集和整理，得出以下信息 1）单机线程池最优为500，最佳TPS为200 2）集群TPS为：3000 3）初步估算集群规模：3000/200 = 15 4）集群滚动更新比例为20%，则集群规模为：15 / (1 - 0.2) = 18.75 5）安全系数为1.2，则集群规模为：18.75 * 1.2 = 22.5 6）若大促是平时4倍流量，则大促时集群规模应为：22.5 * 4 = 90 写在后面的话此评估模型不一定精准，但是可提供一种思路去科学的设置线程池参数和选择集群规模。至于精准性，本着先有而后优，非一蹴而就。需要在实践中不断迭代总结，优化思路和方法。","link":"/2021/05/22/RPC%E6%9C%8D%E5%8A%A1%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%A4%A7%E5%B0%8F%E5%8F%8A%E9%9B%86%E7%BE%A4%E8%A7%84%E6%A8%A1%E8%AF%84%E4%BC%B0/"},{"title":"Netty核心组件源码分析","text":"以下结构图和流程图通过阅读netty-all-4.0.19.Final.jar源码分析而来。本文主要是以Server端执行过程进行分析。 零、Netty使用示例代码1234567891011121314151617181920212223class ChatServer { public static void main(String[] args) throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) { ch.pipeline().addLast(new DelimiterBasedFrameDecoder(MAX_FRAME_LENGTH, DELIMITER)); ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new StringEncoder()); ch.pipeline().addLast(new ChatServerHandler()); } }); ChannelFuture channelFuture = serverBootstrap.bind(LISTEN_PORT).sync(); System.out.println(&quot;ChatServer started.&quot;); channelFuture.channel().closeFuture().await(); }} 一、NioServerSocketChannel和NioSocketChannel1. 类继承结构 2. 简化版 二、NioEventLoopGroup和NioEventLoop1. 类继承结构 2. 简化版 三、整体结构图 四、对比ScalableIOInJava的多反应器模型1. ScalableIOInJava的多反应器模型 2. Netty的多反应器模型","link":"/2021/02/05/Netty%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"RSA与Padding模式","text":"一、RSA公钥加密同一明文，每次密文不一致根据PKCS#1加密块格式定义，RSA每次使用公钥进行加密时，原文需要进行伪随机填充。这就相当于是增加了噪声，达到同一原文的加密结果每次都不一样，使攻击者无法通过密文知晓原文是否一致。 二、PKCS#1 Encryption-block formatting摘要 123456789101112131415A block type BT, a padding string PS, and the data D shall be formatted into an octet string EB, the encryption block. EB = 00 || BT || PS || 00 || D . (1)The block type BT shall be a single octet indicating the structure ofthe encryption block. For this version of the document it shall havevalue 00, 01, or 02. For a private- key operation, the block typeshall be 00 or 01. For a public-key operation, it shall be 02.The padding string PS shall consist of k-3-||D|| octets. For blocktype 00, the octets shall have value 00; for block type 01, theyshall have value FF; and for block type 02, they shall bepseudorandomly generated and nonzero. This makes the length of theencryption block EB equal to k. # 参考 百度百科 PKCS PKCS#1 RSA Encryption PKCS#1 Encryption-block formatting CSDN-为什么RSA公钥每次加密得到的结果都不一样？ why-are-rsa-ciphertexts-different-for-the-same-plaintext","link":"/2021/03/22/RSA%E4%B8%8EPadding%E6%A8%A1%E5%BC%8F/"},{"title":"OOM_Killer","text":"OOM Killer一、什么是OOM Killer程序运行的空间局部性决定一段时间内执行的代码段比较集中，任何时候并不需要加载所有数据到物理内存。 操作系统把进程所需的内存空间按页进行管理/加载，通过虚拟页和物理页的映射可以实现： 同时运行多个程序，他们各自拥有独立的虚拟内存地址。 单个程序可以只加载当前用到的数据到物理内存。 二、什么时候触发当所有运行程序所需的虚拟内存超过物理内存阈值时，linux内核会通过oom killer会选择oom_score大的进程杀掉，并且不会产生warn。通过cat /proc/{pid}/oom_score查看进程oom_score。 三、相关日志 grep kill /var/log/messages dmsg -T | grep kill 参考 Linux 的 OOM Killer 机制分析 how-to-diagnose-oom-errors-on-linux-systems man-page/dmesg","link":"/2022/09/08/OOM_Killer/"},{"title":"Netty聊天室Demo","text":"一、概述本文使用Netty实现了简单的聊天逻辑，旨在理解Netty的API使用，粘包拆包，编解码，处理器链的内容。 应用层需要对接收到的TCP数据包的粘包拆包情况进行必要处理，粘包拆包如下图： 参考： servlet是如何处理粘包问题的? 怎样判断已经接收完HTTP客户端的请求数据？ tomcat NIO处理报文 是否需要拆包 粘包 二、Server端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * @author wangqiwei * @date 2021/01/25 9:38 PM */public class NettyServer { private static final int LISTEN_PORT = 9000; private static final ByteBuf DELIMITER = Unpooled.copiedBuffer(&quot;_&quot;.getBytes()); private static final int MAX_FRAME_LENGTH = 1024; public static void main(String[] args) throws InterruptedException { // bossGroup,workGroup对应了ScalableIoInJava里的反应器多线程模式 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) { // 分隔符解码器 - 用于解决粘包拆包问题 ch.pipeline().addLast(new DelimiterBasedFrameDecoder(MAX_FRAME_LENGTH, DELIMITER)); // 字符串解码器（字节转为字符）- ChannelInboundHandler ch.pipeline().addLast(new StringDecoder()); // 字符串编码器（字符转为字节） - ChannelOutboundHandler ch.pipeline().addLast(new StringEncoder()); // 业务逻辑处理器 ch.pipeline().addLast(new ChatServerHandler()); } }); // 监听端口 ChannelFuture channelFuture = serverBootstrap.bind(LISTEN_PORT).sync(); System.out.println(&quot;ChatServer started.&quot;); // 阻塞等待channel关闭 channelFuture.channel().closeFuture().await(); } static class ChatServerHandler extends SimpleChannelInboundHandler { // Netty提供的存放Channel的工具类，此处需声明为静态。因为每个channel对应不同的Handler实例 private static ChannelGroup onlineClients = new DefaultChannelGroup(GlobalEventExecutor.INSTANCE); @Override public void channelActive(ChannelHandlerContext ctx) { Channel channel = ctx.channel(); String msg = String.format(&quot;Client[%s] online&quot;, channel.remoteAddress()); onlineClients.add(channel); System.out.println(msg); onlineClients.writeAndFlush(msg + &quot;_&quot;, itemChannel -&gt; !itemChannel.equals(channel)); } @Override public void channelInactive(ChannelHandlerContext ctx) { Channel channel = ctx.channel(); String msg = String.format(&quot;Client[%s] offline&quot;, channel.remoteAddress()); onlineClients.remove(channel); System.out.println(msg + &quot;_&quot;); onlineClients.writeAndFlush(msg + &quot;_&quot;, itemChannel -&gt; !itemChannel.equals(channel)); } @Override protected void channelRead0(ChannelHandlerContext ctx, Object msg) { Channel channel = ctx.channel(); msg = String.format(&quot;Client[%s] says: %s&quot;, channel.remoteAddress(), msg); System.out.println(msg); // 转发客户端消息给其他客户端 onlineClients.writeAndFlush(msg + &quot;_&quot;, itemChannel -&gt; !itemChannel.equals(channel)); } }} 三、Client端1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/** * @author wangqiwei * @date 2021/01/28 9:59 PM */public class NettyClient { private static final int LISTEN_PORT = 9000; private static final ByteBuf DELIMITER = Unpooled.copiedBuffer(&quot;_&quot;.getBytes()); private static final int MAX_FRAME_LENGTH = 1024; public static void main(String[] args) throws InterruptedException { EventLoopGroup eventExecutors = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); bootstrap.group(eventExecutors) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) { // 分隔符解码器 - 用于解决粘包拆包问题 ch.pipeline().addLast(new DelimiterBasedFrameDecoder(MAX_FRAME_LENGTH, DELIMITER)); // 字符串解码器（字节转为字符）- ChannelInboundHandler ch.pipeline().addLast(new StringDecoder()); // 字符串编码器（字符转为字节） - ChannelOutboundHandler ch.pipeline().addLast(new StringEncoder()); // 业务逻辑处理器 ch.pipeline().addLast(new ChatClientHandler()); } }); ChannelFuture channelFuture = bootstrap.connect(&quot;localhost&quot;, LISTEN_PORT); channelFuture.await(); System.out.println(&quot;Client connected server.&quot;); sendMsgWithConsole(channelFuture.channel());// sendBatchMsg(channelFuture.channel()); // 阻塞等待channel关闭 channelFuture.channel().closeFuture().await(); } /** * 批量发送消息，测试粘包拆包问题 */ private static void sendBatchMsg(Channel channel) { int i = 20; while (i-- &gt; 0) { ByteBuf byteBuf = Unpooled.copiedBuffer(&quot;I am here._&quot;.getBytes()); channel.writeAndFlush(byteBuf); } } /** * 通过终端发送消息，模拟交互 */ private static void sendMsgWithConsole(Channel channel) { Scanner scanner = new Scanner(System.in); while (scanner.hasNextLine()) { String s = scanner.nextLine(); System.out.println(&quot;Console input:&quot; + s); channel.writeAndFlush(s + &quot;_&quot;); } } static class ChatClientHandler extends ChannelInboundHandlerAdapter { @Override public void channelActive(ChannelHandlerContext ctx) { System.out.println(&quot;Client online&quot;); } @Override public void channelInactive(ChannelHandlerContext ctx) { System.out.println(&quot;Client offline&quot;); } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { System.out.println(msg); } }} # 反应器多线程模式参考：Scalable_IO_in_Java","link":"/2021/01/30/Netty%E8%81%8A%E5%A4%A9%E5%AE%A4Demo/"},{"title":"Redis总结","text":"一、Redis数据结构1、String1）常用使用场景 计数器，分布式自增ID 2、Hash谨慎出现大Key，导致性能下降和负载不均衡 1）使用场景 分布式锁 3、List1）实现常见数据结构 I、实现栈：LPUSH + LPOP II、实现队列：LPUSH + RPOP III、实现阻塞队列：LPUSH + BRPOP 2）LRange LRange可使用负坐标，-1代表最后一个元素。 3）常见使用场景 实现发布订阅，如微博等，pull + push 4、Set1）常见使用场景 I、随机取值。如随机抽奖，srandemember key count, spop key count II、去重后统计数量。如统计uniq元素 III、检查元素是否包含。如实现朋友圈我是否点赞，我关注的人也关注他 IV、方便的集合操作，并集，交集，差集。如实现好友共同关注（交集），我可能认识的人（差集） 5、ZSet1）常用使用场景 有序集合，可实现排名场景，延迟队列 2）skipList TODO 补充底层存储结构二、Redis是单线程吗？1、是单线程吗？ Redis接收网络请求，执行是单线程。 Redis持久化，异步删除，同步是其他线程。 2、为什么选择单线程？ It’s not very frequent that CPU becomes your bottleneck with Redis, as usually Redis is either memory or network bound. For instance, using pipelining Redis running on an average Linux system can deliver even 1 million requests per second, so if your application mainly uses O(N) or O(log(N)) commands, it is hardly going to use too much CPU. 无论是否纯内存的DB，性能的瓶颈往往在IO，而非CPU。 三、Redis高性能原因Redis单机能达到100W/S的原因： 1）C语言实现 2）采用IO多路复用技术接收和响应请求，减少网络开销 3）采用单线程处理请求，减少线程切换开销，减少线程并发开销 4）采用内存为运行时存储，无磁盘IO的限制 5）支持水平扩容，分布式均衡请求压力 四、Redis持久化https://redis.io/topics/persistence 1、RDB-快照1）快照机制 将数据库的内存的快照（snapshot）以二进制的方式保存到磁盘中，文件名dump.rdb 2）快照时机 I、自动触发：配置文件 123# 可以配置多个save条件，当有一个符合条件即可触发执行bgsave。save 60 1000 # 每60秒内至少1000个key发生变化时（增删改），则重写rdbsave 300 50 II、手动处罚：执行命令-save/bgsave save：会阻塞主线程，直到快照生成完毕。生成快照期间，Redis无法处理客户端请求 bgsave：会fork出一个子进程，共享主进程的内存空间，由子进程负责执行快照生成，与此同时Redis可正常处理客户端请求。采用copy-on-write方式，主线程有修改时，对复制的副本做修改，子进程会负责把副本内容写入快照。 III、主从全量复制时生成快照 IV、执行shutdown命令生成快照 3）RDB优点 I、格式紧凑，适合于备份和恢复、进行灾备 II、性能好，把IO操作交给子进程，父进程无需介入 III、快速恢复，比AOF文件更快速的恢复 4）RDB缺点 I、数据损失多，时间点式备份策略可能会导致写操作结果丢失 II、需要经常fork子进程，如果数据集过大fork时间也会变长，影响客户端命令执行和响应。 2、AOF-Append only File1）AOF机制 将写命令追加记录在appendonly.aof文件中（先写入os cache，然后根据配置的刷盘策略进行sync刷盘）。系统启动时会根据它恢复数据。当文件过大时redis会执行重写操作缩小体积。 2）配置文件开启AOF 12# 开启AOFappendonly yes 3）AOF落盘机制 AOF日志会先写入操作系统系统的内存缓冲区，当缓冲区满、超过指定时间、执行fsync命令时会进行落盘。 1234# 落盘策略appendfsync always # 每条命令都刷盘appendfsync everysec # 每秒刷盘一次，默认选择，兼顾安全和速度appendfsync no # 交给操作系统 4）AOF重写配置 12auto‐aof‐rewrite‐min‐size auto‐aof‐rewrite‐percentage 5）AOF优点 I、更灵活的持久化策略，可按需选择一致性和速度 II、追加方式，磁盘写入快，断电时不易产生写故障。可通过redis-check-aof命令进行检查和修复 III、格式容易解析和理解 6）AOF缺点 I、格式非紧凑，相同数据集备份比RDB大 II、根据具体策略，AOF可能比RDB更慢。RDB在处理大量写入时也能有不错的性能。 3、混合持久化1）混合持久化机制 AOF在重写时，把重写时刻的当前数据内存做快照，然后把重写时刻之后的命令以AOF格式追加到快照上，重写完成后修改名称为appendonly.aof覆盖原有文件。 恢复时就可以先通过RDB进行快速恢复到某个时间点，然后重放AOF的命令日志。 2）配置文件开启混合持久化 1aof‐use‐rdb‐preamble yes 五、Redis集群结构参考常见分布式中间件的共识协议 六、pipeline1）客户端可批量发送请求，最后再读取服务端的响应。 2）客户端有buffer，buffer满时发送一次请求到服务端 3）服务端依次处理客户端发来的批量请求，然后把结果返回给客户端。 4）客户端发送完命令前不会读取缓冲区，缓冲区满后服务端不能再发送响应。 所以要避免发送大批量的命令集。 七、Lua脚本和事务https://redis.io/topics/transactions A Redis script is transactional by definition, so everything you can do with a Redis transaction, you can also do with a script, and usually the script will be both simpler and faster. 1、Lua脚本特性 1）减小网络开销 2）原子操作：Redis会将整个脚本作为一个整体执行，中间不会被其他进程或者进程的命令插入 3）脚本复用：客户端的脚本可上传至Server，其他客户端亦可使用。 4）替代Redis事务功能：原生事务不支持事务回滚，Lua脚本则支持报错回滚操作 2、脚本死循环 1）使用命令：script kill 2）原理：lua脚本引擎内置钩子函数，如脚本运行超时后会调用钩子函数检查kill标志位。 八、部分故障时是否提供服务12cluster-require-full-coverage yes # 部分master故障后，不再提供服务cluster-require-full-coverage no # 部分master故障后，其他master仍能提供服务 九、Redis集群模式下命令限制Redis集群模式下只有一个数据库（db0），其他模式有16个（db0-db15，不支持自主命名）可以通过select number来选择数据库。 1、集群模式下只有一个db0数据库，select命令无法使用。 2、Multi-Key操作受限，多Key需要在一个slot内。 3、Lua脚本同样只能操作一个slot内的数据。 使用hashTag，取Key内{}中内容进行散列，使需要操作的多个key落入同一个slot。不支持嵌套，使用时注意避免数据倾斜。 # 参考 https://help.aliyun.com/document_detail/145968.html https://www.cxymm.net/article/chushoufengli/110879106","link":"/2022/03/14/Redis%E6%80%BB%E7%BB%93/"},{"title":"SLF4J日志框架","text":"一、SLF4j和其他框架适配1、日志框架图 Note1: 重点理解SLF4J可以和其他框架双向桥接就可以了。 NOTE2：slf4j-simple可以在测试用例里作为实现使用，不用配置任何实现的配置文件，简单方便。 2、slf4j和logback由相同的人开发 https://github.com/qos-ch 3、slf4j工程结构 4、实战操作 以下是我们项目中pom.xml的一段日志配置。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;!--=========== log相关配置 begin ============--&gt;&lt;!-- slf4j api--&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt;&lt;/dependency&gt;&lt;!-- jcl桥接至slf4j --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt;&lt;/dependency&gt;&lt;!-- slf4j桥接至Log4j2 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- log4j桥接至Log4j2 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-1.2-api&lt;/artifactId&gt; &lt;version&gt;${log4j2.version}&lt;/version&gt;&lt;/dependency&gt;&lt;!-- log4j2 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-api&lt;/artifactId&gt; &lt;version&gt;${log4j2.version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt; &lt;version&gt;${log4j2.version}&lt;/version&gt;&lt;/dependency&gt;&lt;!-- web工程需要包含log4j-web，非web工程不需要 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-web&lt;/artifactId&gt; &lt;version&gt;${log4j2.version}&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 使用log4j2的AsyncLogger需要包含disruptor --&gt;&lt;dependency&gt; &lt;groupId&gt;com.lmax&lt;/groupId&gt; &lt;artifactId&gt;disruptor&lt;/artifactId&gt; &lt;version&gt;${disruptor.version}&lt;/version&gt;&lt;/dependency&gt;&lt;!--============ log相关配置 end ==============--&gt; 解析图： 本项目中也可以将lo4j API桥接至SFL4J API，如下图所示： 二、Slf4j占位符1、SLF4j打印日志方法1）静态分派12345678910111213141516/*** 静态分派至：void warn(String var1, Throwable var2);*/logger.warn(&quot;error msg: &quot;, ex)logger.warn(&quot;error msg: {}&quot;, ex)/*** 静态分派至：void warn(String var1, Object var2, Object var3);*/logger.warn(&quot;error msg: {} {}&quot;, &quot;anything&quot;, ex);/*** 静态分派至：void warn(String var1, Object... var2);*/logger.warn(&quot;error msg: {} {}&quot;, &quot;anything&quot;, &quot;anything&quot;, ex);logger.warn(&quot;error msg: {} {} {}&quot;, &quot;anything&quot;, &quot;anything&quot;, ex); 2）结论I、logger的占位参数小于等于1时，会打印异常堆栈； II、logger的占位参数大于等于2时： 如果参数和占位符相等，每个参数调用toString方法输出； 如果参数=占位符+1， 且最后一个为异常，则打印异常堆栈； Note：异常类的toString方法输出内容是“类名+errorMessage”。如果是NPE，那么errorMessage为null； 1234567public class Throwable implements Serializable { public String toString() { String s = getClass().getName(); String message = getLocalizedMessage(); return (message != null) ? (s + &quot;: &quot; + message) : s; }} 2、Demo类12345678910111213141516171819202122public class NPETest { static Logger logger = LoggerFactory.getLogger(NPETest.class); public static void main(String[] args) { try { try { long l = (Long) null; } catch (Throwable e) { // NPE的getMessage返回null throw new MyException(&quot;内部异常信息&quot; + e.getMessage(), e); } } catch (Throwable throwable) { logger.warn(&quot;外部异常信息&quot;, throwable); // print error stack logger.warn(&quot;外部异常信息{}&quot;, throwable); // print error stack logger.warn(&quot;外部异常信息{}{}&quot;, &quot;占位&quot;, throwable, throwable); // print error stack logger.warn(&quot;外部异常信息{}{}&quot;, &quot;占位&quot;, throwable); // Not print error stack logger.warn(&quot;外部异常信息{}{}{}&quot;, &quot;占位&quot;, &quot;占位&quot;, throwable, throwable); // print error stack logger.warn(&quot;外部异常信息{}{}{}&quot;, &quot;占位&quot;, &quot;占位&quot;, throwable); // Not print error stack } }} 3、最后重要的事情说三遍使用SLF4j打印日志时一定保证“参数个数 = 占位符个数 + 1（异常）”，确保打印日志堆栈使用SLF4j打印日志时一定保证“参数个数 = 占位符个数 + 1（异常）”，确保打印日志堆栈使用SLF4j打印日志时一定保证“参数个数 = 占位符个数 + 1（异常）”，确保打印日志堆栈 三、System.err重定向到slf4j1、背景第三方源码质量参差不齐，许多异常并没有正确输出。代码会出现如下： 12345try { doSomething();} catch(Throwable throwable) { throwable.printStackTrace();} 异常信息没有通过日志框架输出。 2、重定向System.err/out到slf4j123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.PrintStream;/*** 工具类*/public class SystemOutErrToSlf4j { private static Logger logger = LoggerFactory.getLogger(SystemOutErrToSlf4j.class); /** * 可重定向{@link java.lang.System#err}，{@link java.lang.Throwable#printStackTrace()}输出至SLF4J */ public static void redirectSysErrToSlf4j() { PrintStream stderrStream = System.err; PrintStream newStderrStream = new PrintStream(stderrStream) { @Override public void println(Object x) { super.println(x); if (x instanceof Throwable) { logger.error(&quot;&quot;, (Throwable) x); } } }; System.setErr(newStderrStream); } /** * 可重定向{@link java.lang.System#out}输出至SLF4J */ public static void redirectSysOutToSlf4j() { PrintStream stderrStream = System.out; PrintStream newStderrStream = new PrintStream(stderrStream) { @Override public void print(boolean b) { super.print(b); logger.info(String.valueOf(b)); } @Override public void print(char c) { super.print(c); logger.info(String.valueOf(c)); } @Override public void print(int i) { super.print(i); logger.info(String.valueOf(i)); } @Override public void print(long l) { super.print(l); logger.info(String.valueOf(l)); } @Override public void print(float f) { super.print(f); logger.info(String.valueOf(f)); } @Override public void print(double d) { super.print(d); logger.info(String.valueOf(d)); } @Override public void print(String s) { super.print(s); logger.info(s); } @Override public void print(Object obj) { super.print(obj); logger.info(obj.toString()); } }; System.setOut(newStderrStream); }} 123456789101112131415161718/*** 测试类*/public class TestSystemOutErrorToSlf4j { public static void main(String[] args) { try { int a = 1 / 0; } catch (Throwable throwable) { throwable.printStackTrace(); } SystemOutErrToSlf4j.redirectSysErrToSlf4j(); try { int a = 1 / 0; } catch (Throwable throwable) { throwable.printStackTrace(); } }} # 参考 http://www.slf4j.org/manual.html http://www.slf4j.org/legacy.html https://edivad.wordpress.com/2007/02/26/systemout-and-systemerr-over-log4j/ https://stackoverflow.com/questions/2559095/configuration-log4j-consoleappender-to-system-err","link":"/2020/07/07/SLF4J%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/"},{"title":"Scalable_IO_in_Java","text":"本文是Scalable IO in Java的翻译，旨在了解java中IO的React模式。为了更清晰的理解，我调整了文章的部分顺序。 大纲 可扩展的网络服务 事件驱动处理 反应器模式 基础版本 多线程版本 其他变种 java nio包非阻塞IO api一览 一、网络服务Web服务，分布式对象等，大都有相同的结构： 读请求 解码请求 服务处理 编码响应 返回响应 但每一步的性质和成本不同，如Xml解析，文件传输，页面渲染，服务处理，等等。 1. 典型的服务设计 1）每个handler由单独的线程调用执行。 2）典型的ServerSocketLoop程序： 123456789101112131415161718192021222324252627class Server implements Runnable { public void run() { try { ServerSocket ss = new ServerSocket(PORT); while (!Thread.interrupted()) new Thread(new Handler(ss.accept())).start(); // or, single-threaded, or a thread pool } catch (IOException ex) { /* ... */ } } static class Handler implements Runnable { final Socket socket; Handler(Socket s) { socket = s; } public void run() { try { byte[] input = new byte[MAX_INPUT]; socket.getInputStream().read(input); byte[] output = process(input); socket.getOutputStream().write(output); } catch (IOException ex) { /* ... */ } } private byte[] process(byte[] cmd) { /* ... */ } }} NOTE：代码示例中忽略了异常处理。 2. 可扩展性的目标 负载增加时的优雅降级（更多客户端） 随着资源（CPU、内存、磁盘、带宽）的增加而不断改进（即，可水平扩容） 满足可用性和性能目标 低延迟 满足峰值需求 可调服务质量 分而治之通常是实现任何可伸缩性目标的最佳方法 将处理划分为小任务，每个任务执行一个动作而不阻塞 任务条件满足时开始执行，通常IO事件作为触发器 二、事件驱动设计 java.nio提供了基础机制的支持来实现可扩展性的目标： 1）非阻塞的读和写 2）分派与监听到的IO事件给关联的任务 他们有一系列的事件驱动设计的变种实现，事件驱动IO的思路大致相同，但是实现各有不同。 1. 背景：AWT的事件 2. 事件驱动的优劣 通常比其他方法更有效 更少的资源 通常不需要每个客户端都有一个线程来处理 更小的负载 更少的上下文切换，且更少的锁定场景 但是分发可能会慢一点 必须手动绑定动作到事件上 通常增加了编程的难度 必须切分为简单的非阻塞任务 类似GUI的事件驱动 无法消除所有的阻塞：GC，页面失效，等 必须跟踪服务的逻辑状态 三、反应器模式（Reactor Pattern）1. 反应器三部曲 **反应器（Reactor）**对IO事件做出响应，把他们分发给合适的处理器。 类似AWT thread。 **处理器（Handler）**执行非阻塞操作。 把反应器和处理器进行关联。类似AWT addActionListener。 2. java.nio支持 Channels 连接文件，socket等，支持非阻塞读取 Buffers 类似数组的对象，可供Channel读写 Selectors 分辨哪些Channel有IO事件发生 SelctionKeys 维护IO事件状态和绑定 3. 基础反应器设计 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Reactor implements Runnable { final Selector selector; final ServerSocketChannel serverSocket; //1. Setup Reactor(int port) throws IOException { selector = Selector.open(); serverSocket = ServerSocketChannel.open(); serverSocket.socket().bind(new InetSocketAddress(port)); serverSocket.configureBlocking(false); SelectionKey sk = serverSocket.register(selector, SelectionKey.OP_ACCEPT); sk.attach(new Acceptor());}/* Alternatively, use explicit SPI provider: SelectorProvider p = SelectorProvider.provider(); selector = p.openSelector(); serverSocket = p.openServerSocketChannel(); */ // 2. Dispatch Loop public void run() { // normally in a new Thread try { while (!Thread.interrupted()) { selector.select(); Set selected = selector.selectedKeys(); Iterator it = selected.iterator(); while (it.hasNext()) dispatch((SelectionKey)(it.next()); selected.clear(); } } catch (IOException ex) { /* ... */ } } void dispatch(SelectionKey k) { Runnable r = (Runnable)(k.attachment()); if (r != null) r.run(); } // 3. Acceptor class Acceptor implements Runnable { // inner public void run() { try { SocketChannel c = serverSocket.accept(); if (c != null) new Handler(selector, c); } catch(IOException ex) { /* ... */ } } }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647final class Handler implements Runnable { final SocketChannel socket; final SelectionKey sk; ByteBuffer input = ByteBuffer.allocate(MAXIN); ByteBuffer output = ByteBuffer.allocate(MAXOUT); static final int READING = 0, SENDING = 1; int state = READING; // 4. Handler Setup Handler(Selector sel, SocketChannel c) throws IOException { socket = c; c.configureBlocking(false); // Optionally try first read now sk = socket.register(sel, 0); sk.attach(this); sk.interestOps(SelectionKey.OP_READ); sel.wakeup(); } boolean inputIsComplete() { /* ... */ } boolean outputIsComplete() { /* ... */ } void process() { /* ... */ } // 5. Request handling public void run() { try { if (state == READING) read(); else if (state == SENDING) send(); } catch (IOException ex) { /* ... */ } } void read() throws IOException { socket.read(input); if (inputIsComplete()) { process(); state = SENDING; // Normally also do first write now sk.interestOps(SelectionKey.OP_WRITE); } } void send() throws IOException { socket.write(output); if (outputIsComplete()) sk.cancel(); } } 4. 变种 - 状态关联对应处理器Gof状态模式简单使用，把Handler作为附件绑定给SelectionKey。 1234567891011121314151617181920class Handler { // ... public void run() { // initial state is reader socket.read(input); if (inputIsComplete()) { process(); sk.attach(new Sender()); sk.interest(SelectionKey.OP_WRITE); sk.selector().wakeup(); } } class Sender implements Runnable { public void run(){ // ... socket.write(output); if (outputIsComplete()) sk.cancel(); } }} 5. 变种 - 多线程设计1）多线程设计思路 按策略添加线程以实现可扩展性 主要适用于多处理器 工作线程 反应器应该快速触发处理器（然后返回） 处理器执行过程会减慢反应器速度 将非IO处理逻辑转移到其他线程（反应器线程） 多反应器线程 单反应器线程处理IO时，可能会饱和 将负荷分配给其他反应堆 负载平衡以匹配CPU和IO速率 2）多线程 - 工作线程 避免非IO处理以加速反应器线程，类似POSA2 Proactor designs 比将计算绑定处理重写为事件驱动形式更简单 应该保持纯粹的非阻塞计算 足够的处理量以超过开销 但很难对IO进行重复处理 最好在第一次读取时，把所有输入写入缓冲区 使用线程池以便可以调整和控制 通常需要比客户端少很多的线程 1234567891011121314151617181920212223class Handler implements Runnable { // uses util.concurrent thread pool static PooledExecutor pool = new PooledExecutor(...); static final int PROCESSING = 3; // ... synchronized void read() { // ... socket.read(input); if (inputIsComplete()) { state = PROCESSING; pool.execute(new Processer()); } } synchronized void processAndHandOff() { process(); state = SENDING; // or rebind attachment sk.interest(SelectionKey.OP_WRITE); } class Processer implements Runnable { public void run() { processAndHandOff(); } }} 3）多线程 - 反应器线程 反应器使用线程池 匹配CPU，IO速率 静态或动态构造 每个反应器有单独的Selector, Thread, dispatch loop 通过Acceptor分发给其他反应器 1234567891011Selector[] selectors; // also create threads int next = 0;class Acceptor { // ... public synchronized void run() { ... Socket connection = serverSocket.accept(); if (connection != null) new Handler(selectors[next], connection); if (++next == selectors.length) next = 0; } } 4）任务间协调 传递 每个任务启用、触发或调用下一个任务；这通常最快，但可能很脆弱 回调 - 每个处理器的分发器 设置状态，附件等 Gof调停模式的变种 队列 例如，跨阶段传递缓冲区 Futures 当每个任务产生一个结果时，在join或wait/notify之上分层协调 附：线程池参数 可调节工作线程池 Main method execute(Runnable r) 可设置的参数 任务队列的类型 最大线程数 最小线程数 初始线程 空闲线程的最大存活时间 必要时会被新的线程代替 饱和策略/拒绝策略 阻塞，丢弃，producer-run等 6. 使用java.nio的其他特性 每个反应器使用多个Selector 不同的IO事件绑定不同的处理器 需要小心进行同步协调处理 文件传输 自动文件到网络或网络到文件复制 内存映射文件（Memory-mapped file） 通过缓冲区访问文件 直接缓冲区 有时可实现零拷贝 但是设置和完成开销很大 最适合长连接的应用程序 7. 基于连接的扩展 替代单次请求 客户端连接 客户端发送批量请求数据 客户端断开连接 示例 数据库和事务监视器 多人游戏，聊天等 可扩展的基础网络模式 处理许多相对长寿命的客户 记录客户端和会话状态 分发服务给多个主机 # 参考 nio.pdf ——doug lea 本仓库副本","link":"/2021/01/26/Scalable_IO_in_Java/"},{"title":"SFTP和FTPS，HTTPS","text":"一、HTTPS&amp;FTPS using SSL1. SSL SSL证书就是遵守SSL协议，由受信任的CA机构颁发的数字证书。 通过证书链来进行认证双方的身份和加解密信息。 2. HTTPS HTTPS是HTTP的安全版本，它可以通过SSL / TLS连接保护在线传输的任何通信 3. FTPS二、SFTP using ssh1. ssh 通过非对称密钥来实现加密通讯 2. SFTP 使用jsch包来实现连接SFTP 12345&lt;dependency&gt; &lt;groupId&gt;com.jcraft&lt;/groupId&gt; &lt;artifactId&gt;jsch&lt;/artifactId&gt; &lt;version&gt;0.1.54&lt;/version&gt;&lt;/dependency&gt; 使用FTPClient来连接FTP 12345&lt;dependency&gt; &lt;groupId&gt;commons-net&lt;/groupId&gt; &lt;artifactId&gt;commons-net&lt;/artifactId&gt; &lt;version&gt;3.6&lt;/version&gt;&lt;/dependency&gt; 参考资料 http://www1.se.cuhk.edu.hk/~seem3490/project/group5-present-small https://www.ftptoday.com/blog/secure-ftp 什么是SSL和HTTPS？ FTPS（基于 SSL 的FTP）与 SFTP（SSH 文件传输协议）对比","link":"/2020/03/31/SFTP%E5%92%8CFTPS%EF%BC%8CHTTPS/"},{"title":"ServiceLoader","text":"一、Java SPI使用123456ServiceLoader&lt;MySpiInterface&gt; load = ServiceLoader.load(MySpiInterface.class);Iterator&lt;MySpiInterface&gt; iterator = load.iterator();while (iterator.hasNext()) { MySpiInterface obj = iterator.next(); obj.doSomethind();} 二、Java 惰性加载java.util.ServiceLoader里使用了惰性迭代器：java.util.ServiceLoader.LazyIterator。 其会在首次调用LazyIterator#hasNext时，读取所有的META-INF下指定接口的文件名称，然后赋值给Enumeration&lt;URL&gt;类型变量。 其内部还有一个迭代器pending，用以迭代单个SPI文件下定义的多个实现类。 其会在调用LazyIterator#next时，取出迭代器pending指向的SPI类，并进行初始化操作。 下面为其源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192private class LazyIterator implements Iterator&lt;S&gt; { Class&lt;S&gt; service; ClassLoader loader; Enumeration&lt;URL&gt; configs = null; Iterator&lt;String&gt; pending = null; String nextName = null; private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) { this.service = service; this.loader = loader; } private boolean hasNextService() { if (nextName != null) { return true; } if (configs == null) { try { String fullName = PREFIX + service.getName(); if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); } catch (IOException x) { fail(service, &quot;Error locating configuration files&quot;, x); } } while ((pending == null) || !pending.hasNext()) { if (!configs.hasMoreElements()) { return false; } pending = parse(service, configs.nextElement()); } nextName = pending.next(); return true; } private S nextService() { if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try { c = Class.forName(cn, false, loader); } catch (ClassNotFoundException x) { fail(service, &quot;Provider &quot; + cn + &quot; not found&quot;); } if (!service.isAssignableFrom(c)) { fail(service, &quot;Provider &quot; + cn + &quot; not a subtype&quot;); } try { S p = service.cast(c.newInstance()); providers.put(cn, p); return p; } catch (Throwable x) { fail(service, &quot;Provider &quot; + cn + &quot; could not be instantiated&quot;, x); } throw new Error(); // This cannot happen } public boolean hasNext() { if (acc == null) { return hasNextService(); } else { PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() { public Boolean run() { return hasNextService(); } }; return AccessController.doPrivileged(action, acc); } } public S next() { if (acc == null) { return nextService(); } else { PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() { public S run() { return nextService(); } }; return AccessController.doPrivileged(action, acc); } } public void remove() { throw new UnsupportedOperationException(); }}","link":"/2021/06/30/ServiceLoader/"},{"title":"SpingAop","text":"一、Spring AOP1、动态代理实现 1）如果使用接口，则使用JDK动态代理 2）如果没使用接口，则使用CGLib动态代理 2、AspectJ关系使用AspectJ的切点表达式和解析逻辑 3、三种渐进实现方式1）通过ProxyFactoryBean生成 设置target和拦截器，生成target接口的代理类。拦截逻辑被放入AdvisedSupport构成拦截链，在JdkDynamicAopProxy#invoke执行时会选择合适的拦截器执行。 虽然是构成了拦截链，但仍是栈式调用。 缺点：每个需要代理类都需要手动装配，无法方便的声明针对细粒度对方法进行拦截。 2）通过ProxyFactoryBean + xxxAdvisor 可针对方法进行细粒度声明增强。 缺点：每个代理类都需要手动装配 3）通过BeanNameAutoProxyCreator + xxxAdvisor 可针对指定类表达式 4）AspectJ 注解式声明。第一个BeanPostProcessor来解析含AspectJ注解的所有BeanDefinition生成Advisor，最后一个BeanPostProcessor生成动态代理。 入口类EnableAspectJAutoProxy。 二、图示 三、AOP执行顺序先执行order小的AOP。","link":"/2021/01/14/SpingAop/"},{"title":"STFP报错Connection_reset","text":"1. 背景EDI的测试环境最近经常有开发返回SFTP报错，堆栈如下： 12345678910111213141516171819Caused by: org.apache.camel.component.file.GenericFileOperationFailedException: Cannot connect to edisftp://xxxx@116.196.***.*** 22 at org.apache.camel.component.file.remote.SftpOperations.connect(SftpOperations.java:149) at com.jd.lsb.edi.component.sftp.EdiSftpOperations.connect(EdiSftpOperations.java:39) at com.jd.lsb.edi.component.sftp.CustomerRemoteFileProducer.connectIfNecessary(CustomerRemoteFileProducer.java:218) at com.jd.lsb.edi.component.sftp.CustomerRemoteFileProducer.recoverableConnectIfNecessary(CustomerRemoteFileProducer.java:210) at com.jd.lsb.edi.component.sftp.CustomerRemoteFileProducer.preWriteCheck(CustomerRemoteFileProducer.java:137) at org.apache.camel.component.file.GenericFileProducer.processExchange(GenericFileProducer.java:114) at com.jd.lsb.edi.component.sftp.CustomerRemoteFileProducer.process(CustomerRemoteFileProducer.java:62) at com.jd.lsb.edi.component.sftp.EdiSftpEndpoint$1.process(EdiSftpEndpoint.java:73) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.SendProcessor$2.doInAsyncProducer(SendProcessor.java:178) at org.apache.camel.impl.ProducerCache.doInAsyncProducer(ProducerCache.java:445) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:173) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ... 56 moreCaused by: com.jcraft.jsch.JSchException: Session.connect: java.net.SocketException: Connection reset at com.jcraft.jsch.Session.connect(Session.java:504) at org.apache.camel.component.file.remote.SftpOperations.connect(SftpOperations.java:121) ... 68 more 2. 解决方案执行命令telnet ip port。1）若连接正常 会输出SSH-2.0-OpenSSH_6.6.1类似的SSH信息 1234Trying 192.168.xxx.xxx...Connected to 192.168.xxx.xxx.Escape character is '^]'.SSH-2.0-OpenSSH_6.6.1 Note:j-one平台工具中的telnet，即使连接成功后也会自动断开（通过堡垒机可保持连接），类似如下： 12345Trying 192.168.xxx.xxx...Connected to 192.168.xxx.xxx.Escape character is '^]'.SSH-2.0-OpenSSH_6.6.1Connection closed by foreign host. 2）若连接异常： 12Trying 192.168.xxx.xxx...telnet: connect to address 192.168.xxx.xxx: Connection refused 或 1234Trying 192.168.xxx.xxx...Connected to 192.168.xxx.xxx.Escape character is '^]'.Connection closed by foreign host.","link":"/2020/06/22/STFP%E6%8A%A5%E9%94%99Connection_reset/"},{"title":"SpringIOC","text":"一、IOC容器启动 二、扩展点 1、BeanDefinition后置处理器 1）两个扩展点I、BeanFactoryPostProcessor II、BeanDefinitionRegistryPostProcessor 扩展了上面接口，增加了bean定义注册方法。AnnotationConfigApplicationContext构造函数注册的ConfigurationClassPostProcessor。 2）两者执行顺序I、BeanDefinitionRegistryPostProcessor#postProcessBeanDefinitionRegistry II、BeanFactoryPostProcessor#postProcessBeanFactory 3）ConfigurationClassPostProcessorI、ConfigurationClassPostProcessor#postProcessBeanDefinitionRegistry，解析配置类，含注解Configuration，Component，ComponentScan，Import，ImportResource，Bean。 解析逻辑在ConfigurationClassParser，解析配置类注解顺序： PropertySource ComponentScan ComponentScanAnnotationParser进行解析bean定义，使用ClassPathBeanDefinitionScanner进行扫描。当发现解析出的为配置类时，递归调用ConfigurationClassParser#parse进行递归解析。 Import ImportResource Bean II、ConfigurationClassPostProcessor#postProcessBeanFactory，为配置类生成CGLib动态代理 2、Bean创建扩展点BeanPostProcessor，如实现AOP。 3、Bean初始化扩展点Aware接口","link":"/2022/03/21/SpringIOC/"},{"title":"SpingAopProxy","text":"一、Spring抽象出了AopProxy接口用处： 1）用来抽象JDK和Cglib； 2）暗示统一了他们的自调用行为：调用Target的方法。 Note： CGlib可以实现自调用时走代理对象，但是Spring统一了动态代理的规则，使其和jdk的动态代理保持一致，致使程序在使用不同的代理时能表现一致。（非不能也，实不为也） 这就是事务方法嵌套调用时，第二个注解不生效原因。可通过exposeTarget，通过代理类显示调用另一个方法。 二、CglibAopProxy源码从以下代码的路径中可以发现，Cglib使用methodProxy.invoke(target, argsToUse)而非methodProxy.invoke(proxy, argsToUse)，来保持和jdk动态代理同样的逻辑。 1、位置：DynamicAdvisedInterceptor#intercept12345678910111213141516171819202122232425262728293031323334353637383940414243444546public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { Object oldProxy = null; boolean setProxyContext = false; Class&lt;?&gt; targetClass = null; Object target = null; try { if (this.advised.exposeProxy) { // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; } // May be null. Get as late as possible to minimize the time we // &quot;own&quot; the target, in case it comes from a pool... target = getTarget(); if (target != null) { targetClass = target.getClass(); } List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); Object retVal; // Check whether we only have one InvokerInterceptor: that is, // no real advice, but just reflective invocation of the target. if (chain.isEmpty() &amp;&amp; Modifier.isPublic(method.getModifiers())) { // We can skip creating a MethodInvocation: just invoke the target directly. // Note that the final invoker must be an InvokerInterceptor, so we know // it does nothing but a reflective operation on the target, and no hot // swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = methodProxy.invoke(target, argsToUse); } else { // We need to create a method invocation... retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed(); } retVal = processReturnType(proxy, target, method, retVal); return retVal; } finally { if (target != null) { releaseTarget(target); } if (setProxyContext) { // Restore old proxy. AopContext.setCurrentProxy(oldProxy); } }} 2、位置：CglibMethodInvocation12345678910111213141516171819202122232425private static class CglibMethodInvocation extends ReflectiveMethodInvocation { private final MethodProxy methodProxy; private final boolean publicMethod; public CglibMethodInvocation(Object proxy, Object target, Method method, Object[] arguments, Class&lt;?&gt; targetClass, List&lt;Object&gt; interceptorsAndDynamicMethodMatchers, MethodProxy methodProxy) { super(proxy, target, method, arguments, targetClass, interceptorsAndDynamicMethodMatchers); this.methodProxy = methodProxy; this.publicMethod = Modifier.isPublic(method.getModifiers()); } /** * Gives a marginal performance improvement versus using reflection to * invoke the target when invoking public methods. */ @Override protected Object invokeJoinpoint() throws Throwable { if (this.publicMethod) { return this.methodProxy.invoke(this.target, this.arguments); } else { return super.invokeJoinpoint(); } } } 位置：org.springframework.aop.support.AopUtils#invokeJoinpointUsingReflection 123456789101112131415161718192021public static Object invokeJoinpointUsingReflection(Object target, Method method, Object[] args) throws Throwable { // Use reflection to invoke the method. try { ReflectionUtils.makeAccessible(method); return method.invoke(target, args); } catch (InvocationTargetException ex) { // Invoked method threw a checked exception. // We must rethrow it. The client won't see the interceptor. throw ex.getTargetException(); } catch (IllegalArgumentException ex) { throw new AopInvocationException(&quot;AOP configuration seems to be invalid: tried calling method [&quot; + method + &quot;] on target [&quot; + target + &quot;]&quot;, ex); } catch (IllegalAccessException ex) { throw new AopInvocationException(&quot;Could not access method [&quot; + method + &quot;]&quot;, ex); } }","link":"/2021/01/14/SpingAopProxy/"},{"title":"Springboot配置文件读取顺序","text":"一、配置读取时机1）SpringApplication#run 1234567891011121314151617181920212223242526272829303132333435363738394041public ConfigurableApplicationContext run(String... args) { StopWatch stopWatch = new StopWatch(); stopWatch.start(); DefaultBootstrapContext bootstrapContext = createBootstrapContext(); ConfigurableApplicationContext context = null; configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(bootstrapContext, this.mainApplicationClass); try { ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 此处加载配置，准备配置环境 ConfigurableEnvironment environment = prepareEnvironment(listeners, bootstrapContext, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); context = createApplicationContext(); context.setApplicationStartup(this.applicationStartup); prepareContext(bootstrapContext, context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); } listeners.started(context); callRunners(context, applicationArguments); } catch (Throwable ex) { handleRunFailure(context, ex, listeners); throw new IllegalStateException(ex); } try { listeners.running(context); } catch (Throwable ex) { handleRunFailure(context, ex, null); throw new IllegalStateException(ex); } return context;} 2）SpringApplication#prepareEnvironment 1234567891011121314151617181920private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, DefaultBootstrapContext bootstrapContext, ApplicationArguments applicationArguments) { // Create and configure the environment ConfigurableEnvironment environment = getOrCreateEnvironment(); configureEnvironment(environment, applicationArguments.getSourceArgs()); ConfigurationPropertySources.attach(environment); // 此处调用监听器进行配置环境准备 listeners.environmentPrepared(bootstrapContext, environment); DefaultPropertiesPropertySource.moveToEnd(environment); Assert.state(!environment.containsProperty(&quot;spring.main.environment-prefix&quot;), &quot;Environment prefix cannot be set via properties.&quot;); bindToSpringApplication(environment); if (!this.isCustomEnvironment) { environment = new EnvironmentConverter(getClassLoader()).convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); } ConfigurationPropertySources.attach(environment); return environment;} 3）SpringApplicationRunListeners#environmentPrepared 1234void environmentPrepared(ConfigurableBootstrapContext bootstrapContext, ConfigurableEnvironment environment) { doWithListeners(&quot;spring.boot.application.environment-prepared&quot;, (listener) -&gt; listener.environmentPrepared(bootstrapContext, environment));} 4）EventPublishingRunListener#environmentPrepared 12345public void environmentPrepared(ConfigurableBootstrapContext bootstrapContext, ConfigurableEnvironment environment) { this.initialMulticaster.multicastEvent( new ApplicationEnvironmentPreparedEvent(bootstrapContext, this.application, this.args, environment));} 5）ConfigFileApplicationListener#onApplicationEvent 123456789101112131415161718192021222324252627282930313233343536package org.springframework.boot.context.config;/** * {@link EnvironmentPostProcessor} that configures the context environment by loading * properties from well known file locations. By default properties will be loaded from * 'application.properties' and/or 'application.yml' files in the following locations: * &lt;ul&gt; * &lt;li&gt;file:./config/&lt;/li&gt; * &lt;li&gt;file:./config/{@literal *}/&lt;/li&gt; * &lt;li&gt;file:./&lt;/li&gt; * &lt;li&gt;classpath:config/&lt;/li&gt; * &lt;li&gt;classpath:&lt;/li&gt; * &lt;/ul&gt; * The list is ordered by precedence (properties defined in locations higher in the list * override those defined in lower locations). * &lt;p&gt; * Alternative search locations and names can be specified using * {@link #setSearchLocations(String)} and {@link #setSearchNames(String)}. * &lt;p&gt; * Additional files will also be loaded based on active profiles. For example if a 'web' * profile is active 'application-web.properties' and 'application-web.yml' will be * considered. * &lt;p&gt; * The 'spring.config.name' property can be used to specify an alternative name to load * and the 'spring.config.location' property can be used to specify alternative search * locations or specific files. */public class ConfigFileApplicationListener implements EnvironmentPostProcessor, SmartApplicationListener, Ordered { @Override public boolean supportsEventType(Class&lt;? extends ApplicationEvent&gt; eventType) { return ApplicationEnvironmentPreparedEvent.class.isAssignableFrom(eventType) || ApplicationPreparedEvent.class.isAssignableFrom(eventType); } ...} 二、配置读取顺序application.properties和application.yml配置的加载顺序，就如ConfigFileApplicationListener的注释所写： 12345file:./config/file:./config/*/file:./classpath:/config/classpath:/","link":"/2021/07/01/Springboot%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E9%A1%BA%E5%BA%8F/"},{"title":"Spring集成第三方组件-JSF","text":"一、JSF介绍jsf是京东内部自研使用的RPC框架，同dubbo，目前已开源至github—joyrpc。本文从spring的角度去看是如何集成jsf的。 二、Spring在配置文件支持自定义namespace 通过阅读源码画出如下流程图，从中可看出在解析XML时会调用BeanDefinitionParserDelegate来解析自定义的namespace，并根据其指定的NamespaceHandler实例，调用parse方法完成beanDefinition注册。 123456789101112131415161718192021public class BeanDefinitionParserDelegate { /** * Parse a custom element (outside of the default namespace). * @param ele the element to parse * @param containingBd the containing bean definition (if any) * @return the resulting bean definition */ @Nullable public BeanDefinition parseCustomElement(Element ele, @Nullable BeanDefinition containingBd) { String namespaceUri = getNamespaceURI(ele); if (namespaceUri == null) { return null; } NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) { error(&quot;Unable to locate Spring NamespaceHandler for XML schema namespace [&quot; + namespaceUri + &quot;]&quot;, ele); return null; } return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd)); }} 三、JSF通过自定义namespace注册bean1. jsf-comsumer.xml常规配置在Sping的bean配置文件中增加jsf的schema信息后，声明两个jsf的bean：注册中心和一个示例消费者。 12345678910111213&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:jsf=&quot;http://jsf.jd.com/schema/jsf&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://jsf.jd.com/schema/jsf http://jsf.jd.com/schema/jsf/jsf.xsd&quot;&gt; &lt;!-- 注册中心 --&gt; &lt;jsf:registry id=&quot;jsfRegistry&quot; protocol=&quot;jsfRegistry&quot; index=&quot;i.jsf.jd.com&quot; /&gt; &lt;!-- 服务调用者配置--&gt; &lt;jsf:consumer id=&quot;demoConsumer&quot; interface=&quot;pers.jsf.demo.IDemoConsumer&quot; protocol=&quot;jsf&quot; alias=&quot;demo&quot; /&gt;&lt;/beans&gt; 2. 找到jsf的schema对应的handler 在jsf-1.6.9的依赖中找到jsf集成spring的两个文件：spring.schemas和spring.handlers（可类比参考joyrpc/joyrpc-spring/src/main/resources/META-INF目录，只是schema有些差异） 1）spring.schemas 声明xml中jsf相关配置的语法，可用于让IDE自动提示和校验语法。 1http\\://jsf.jd.com/schema/jsf/jsf.xsd=META-INF/jsf.xsd 2）spring.handlers 声明xml中jsf命名空间对应的NamespaceHandler实例。 1http\\://jsf.jd.com/schema/jsf=com.jd.jsf.gd.config.spring.JSFNamespaceHandler 3. JSFNamespaceHandlerJSFNamespaceHandler是spring的NamespaceHanlder的子类，用来处理命名空间下声明的各个标签。在pase方法里调用了init方法中注册的针对不同标签的BeanDefinitionParser（目的是把bean定义解析注册逻辑分离到JSFBeanDefinitionParser，单一职责）。 12345678910111213141516171819202122232425262728293031323334public class JSFNamespaceHandler extends NamespaceHandlerSupport { private final Map&lt;String, BeanDefinitionParser&gt; parsers = new HashMap&lt;String, BeanDefinitionParser&gt;(); public void init() { this.registerBeanDefinitionParser(&quot;provider&quot;, new JSFBeanDefinitionParser(ProviderBean.class, true)); this.registerBeanDefinitionParser(&quot;consumer&quot;, new JSFBeanDefinitionParser(ConsumerBean.class, true)); this.registerBeanDefinitionParser(&quot;consumerGroup&quot;, new JSFBeanDefinitionParser(ConsumerGroupBean.class, true)); this.registerBeanDefinitionParser(&quot;server&quot;, new JSFBeanDefinitionParser(ServerBean.class, true)); this.registerBeanDefinitionParser(&quot;registry&quot;, new JSFBeanDefinitionParser(RegistryConfig.class, true)); this.registerBeanDefinitionParser(&quot;annotation&quot;, new JSFBeanDefinitionParser(AnnotationBean.class, true)); this.registerBeanDefinitionParser(&quot;parameter&quot;, new JSFParameterDefinitionParser(ParameterConfig.class)); this.registerBeanDefinitionParser(&quot;filter&quot;, new JSFBeanDefinitionParser(FilterBean.class, true)); this.registerBeanDefinitionParser(&quot;connStrategy&quot;, new JSFBeanDefinitionParser(ConnStrategyBean.class, true)); } @Override public BeanDefinition parse(Element element, ParserContext parserContext) { return findParserForElement(element, parserContext).parse(element, parserContext); } private BeanDefinitionParser findParserForElement(Element element, ParserContext parserContext) { String localName = parserContext.getDelegate().getLocalName(element); BeanDefinitionParser parser = this.parsers.get(localName); if (parser == null) { parserContext.getReaderContext().fatal( &quot;Cannot locate BeanDefinitionParser for element [&quot; + localName + &quot;]&quot;, element); } return parser; } protected final void registerBeanDefinitionParser(String elementName, BeanDefinitionParser parser) { this.parsers.put(elementName, parser); }} 4. JSFBeanDefinitionParserJSFBeanDefinitionParser是spring的BeanDefinitionParser的子类，用来根据xml中配置的参数，把某个jsf标签解析为一个spring bean。由于类代码较长，取其中关键代码，可参考joyrpc-AbstractBeanDefinitionParser.java 123456789101112131415161718192021222324252627282930 public class JSFBeanDefinitionParser implements BeanDefinitionParser { private static final Logger logger = LoggerFactory.getLogger(JSFBeanDefinitionParser.class); private final Class&lt;?&gt; beanClass; private final boolean required; public JSFBeanDefinitionParser(Class&lt;?&gt; beanClass, boolean required) { this.beanClass = beanClass; this.required = required; } public BeanDefinition parse(Element element, ParserContext parserContext) { return this.parse(element, parserContext, this.beanClass, this.required); } private BeanDefinition parse(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean requireId) { RootBeanDefinition beanDefinition = new RootBeanDefinition(); beanDefinition.setBeanClass(beanClass); beanDefinition.setLazyInit(false); /** * 从element取属性填充到beanDefinition中，调用方法： * beanDefinition.getPropertyValues().addPropertyValue(property, value); * 忽略此处逻辑 */ String id = element.getAttribute(&quot;id&quot;); parserContext.getRegistry().registerBeanDefinition(id, beanDefinition); return beanDefinition; }} 由源码可见在创建RootBeanDefinition时设置的类是JSFNamespaceHandler中传入的，此处我们取ConsumerBean进行观察。 5. ConsumerBean 从类图可看出ConsumerBean是一个FactoryBean，在其getObject方法里，调用了JSF的获取Consumer实例的API，并返回实例。 123456789101112131415161718public class ConsumerBean&lt;T&gt; extends ConsumerConfig&lt;T&gt; implements InitializingBean, FactoryBean, ApplicationContextAware, DisposableBean, BeanNameAware { private static final long serialVersionUID = 6835324481364430812L; private static final Logger LOGGER = LoggerFactory.getLogger(ConsumerBean.class); private ApplicationContext applicationContext; private transient String beanName; private transient T object; private transient Class objectType; protected ConsumerBean() { } public T getObject() throws Exception { this.object = CommonUtils.isUnitTestMode() ? null : this.refer(); return this.object; } ...} 6. 小结Jsf通过声明自定义namespace对应的NamespaceHandler子类，来处理xml中jsf标签的解析和注册逻辑。且最终注册的beanDefinition是一个FactoryBean，在其getObject里进行具体bean实例的生成。 四、总结第三方组件要集成进入spring，把类交给spring容器进行声明周期管理，一般都会采取FactoryBean实现。通过FactoryBean可以获取足够的灵活性，第三方组件可以用一个公共的逻辑对组件内的类完成注入Spring的过程。","link":"/2021/01/17/Spring%E9%9B%86%E6%88%90%E7%AC%AC%E4%B8%89%E6%96%B9%E7%BB%84%E4%BB%B6-JSF/"},{"title":"Spring循环依赖","text":"一、前置问题 Bean创建流程？ 什么是循环依赖？ 三级缓存可以解决哪些循环依赖场景？ 二级缓存可以解决循环依赖吗？如果可以，为什么不使用？ Bean创建的场景？二维：循环依赖和代理 二、循环依赖Spring循环依赖相关的代码现在比较繁琐，如果阅读时不考虑版本的变迁，很难理解解决循环依赖的流程。 我把Spring依赖的解决方案认为是三个迭代版本的最终版，这样理解起来会更清晰。 版本 目的 版本一 解决普通bean的创建，不涉及AOP和循环引用 版本二 版本一 + AOP支持 版本三 版本二 + 循环依赖支持 分析1）Spring的Bean创建的正常逻辑是初始化后在生成潜在代理对象。 2）若不需要生成代理，则二级缓存即可，也不会破坏正常创建流程。 3）若需要生成代理对象 I、若只使用二级缓存，无论是否存在循环依赖，都会破坏正常初始化逻辑。需要在Bean实例化后-注入属性前，生成代理对象放入缓存。 II、若使用三级缓存， 无循环依赖时，会执行正常的初始化逻辑； 有循环依赖时，则会在注入属性时生成代理逻辑； 结论 如果只是解决循环依赖问题，使用二级缓存即可，在实例化时提前创建代理对象仿佛缓存。 但是为了最大限度保证Bean创建的正常逻辑，使用了三级缓存。即非必要不破坏正常逻辑。 三、源码解析AbstractBeanFactory#doGetBean 1）getSingleton(beanName) 尝试从一级缓存singletonObjects、二级缓存earlySingletonObjects、三级缓存singletonFactories中获取Bean对象。 如果找到则返回Bean对象：在三级缓存中获取到时，调用ObjectFactory（调用SmartInstantiationAwareBeanPostProcessor#getEarlyBeanReference可提前生成代理），则把原始对象或代理对象移入二级缓存。 否则执行下一步 =》getSingleton(beanName, ObjectFactory) 2）getSingleton(beanName, ObjectFactory) 设置bean为创建中，singletonsCurrentlyInCreation#add(beanName) 调用objectFacotry#getObject =》 AbstractAutowireCapableBeanFactory#createBean 设置bean创建完毕，singletonsCurrentlyInCreation#remove(beanName) 清空二、三级缓存，把Bean对象加入一级缓存 3）AbstractAutowireCapableBeanFactory#createBean 调用InstantiationAwareBeanPostProcessor，可潜在生成代理对象，若生成则返回。 调用doCreateBean，进行Bean创建 =》AbstractAutowireCapableBeanFactory#doCreateBean 4）AbstractAutowireCapableBeanFactory#doCreateBean 调用createBeanInstance，创建Bean对象 调用addSingletonFactory，把Bean对象封装为ObjectFactory加入三级缓存singletonFactories 调用singletonFactories，初始化Bean对象，如属性注入 调用initializeBean，执行Bean对象的初始化方法，并在其前后调用BeanPostProcessor，可潜在生成动态代理（若之前执行过getEarlyBeanReference则不再执行，避免生成不同代理对象） 调用getSingleton，把Bean对象由三级缓存移到二级缓存earlySingletonObjects，并返回","link":"/2020/11/13/Spring%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/"},{"title":"Springboot自动配置","text":"一、SpringBoot自动配置原理简单的SpingBoot启动示例： 123456@SpringBootApplicationpublic class SpringBootdemoApplication { public static void main(String[] args) { SpringApplication.run(SpringBootdemoApplication.class, args); }} 1）注解*@SpringBootApplication*除去元注解外，我们只需关注*@EnableAutoConfiguration*即可 12345678910111213141516171819202122@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })public @interface SpringBootApplication { @AliasFor(annotation = EnableAutoConfiguration.class, attribute = &quot;exclude&quot;) Class&lt;?&gt;[] exclude() default {}; @AliasFor(annotation = EnableAutoConfiguration.class, attribute = &quot;excludeName&quot;) String[] excludeName() default {}; @AliasFor(annotation = ComponentScan.class, attribute = &quot;basePackages&quot;) String[] scanBasePackages() default {}; @AliasFor(annotation = ComponentScan.class, attribute = &quot;basePackageClasses&quot;) Class&lt;?&gt;[] scanBasePackageClasses() default {};} 2）注解*@EnableAutoConfiguration*123456789101112@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration { String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;; Class&lt;?&gt;[] exclude() default {}; String[] excludeName() default {}; 其中，@AutoConfigurationPackage是把当前类所在的包通过org.springframework.boot.autoconfigure.AutoConfigurationPackages.Registrar注册进Spring的内置bean（org.springframework.boot.autoconfigure.AutoConfigurationPackages），以供本身（JPA框架）或其他第三方集成（mybatis扫描entity）调用。 3）EnableAutoConfigurationImportSelector12345678910111213public class EnableAutoConfigurationImportSelector extends AutoConfigurationImportSelector { @Override protected boolean isEnabled(AnnotationMetadata metadata) { if (getClass().equals(EnableAutoConfigurationImportSelector.class)) { return getEnvironment().getProperty( EnableAutoConfiguration.ENABLED_OVERRIDE_PROPERTY, Boolean.class, true); } return true; }} 本类没有关键信息，向上查看其父类逻辑AutoConfigurationImportSelector。 4）AutoConfigurationImportSelector而AutoConfigurationImportSelector实现了DeferredImportSelector接口，实现延迟加载，用来处理条件性Bean。以下为spring doc的说明。 public interface DeferredImportSelector extends ImportSelector A variation of ImportSelector that runs after all @Configuration beans have been processed. This type of selector can be particularly useful when the selected imports are @Conditional. Implementations can also extend the Ordered interface or use the Order annotation to indicate a precedence against other DeferredImportSelectors. 在此类主要加载了META-INF/spring.facotries文件中的自动配置类属性，然后从方法selectImports返回，完成自动注册配置类beanDefition。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered { // 通过BeanFactoryAware注入 private ConfigurableListableBeanFactory beanFactory; @Override public String[] selectImports(AnnotationMetadata annotationMetadata) { if (!isEnabled(annotationMetadata)) { return NO_IMPORTS; } try { /* * 加载META-INF/spring-autoconfigure-metadata.properties文件， * 内部声明了配置类的Order，Condition等信息 */ AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader.loadMetadata(this.beanClassLoader); /* * 读取META-INF/spring.facotries文件中自动配置属性。 * key=org.springframework.boot.autoconfigure.EnableAutoConfiguration */ AnnotationAttributes attributes = getAttributes(annotationMetadata); List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); /* * 忽略非关键逻辑（对配置类进行去重，排除规则，排序等） */ fireAutoConfigurationImportEvents(configurations, exclusions); return configurations.toArray(new String[configurations.size()]); } catch (IOException ex) { throw new IllegalStateException(ex); } } protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) { List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames( getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, &quot;No auto configuration classes found in META-INF/spring.factories. If you are using a custom packaging, make sure that file is correct.&quot;); return configurations; }} 5）总结 二、案例1 - Interceptor加载1. 注册Interceptor代码示例1234567891011121314151617181920212223242526@Configurationpublic class MyWebMvcConfig extends WebMvcConfigurationSupport { /* * 拦截器配置 */ @Override public void addInterceptors(InterceptorRegistry registry) { // 注册自定义拦截器，添加拦截路径和排除拦截路径 registry.addInterceptor(new Test1Interceptor()) // 添加拦截器1 .addPathPatterns(&quot;/**&quot;) // 添加拦截路径 .excludePathPatterns(// 添加排除拦截路径 &quot;/hello&quot;) .order(0); registry.addInterceptor(new Test2Interceptor()) // 添加拦截器2 .addPathPatterns(&quot;/**&quot;) // 添加拦截路径 .excludePathPatterns(// 添加排除拦截路径 &quot;/test1&quot;) .order(1); super.addInterceptors(registry); }}作者：朝雾轻寒链接：https://juejin.cn/post/6844903975469203469来源：掘金 2. Interceptor实现自动配置流程1）spring.factories文件的自动配置key中含有：org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration 2）该配置类解析时会解析其内部静态类org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration.EnableWebMvcConfiguration 12345678910111213141516171819202122232425262728@Configuration@ConditionalOnWebApplication@ConditionalOnClass({ Servlet.class, DispatcherServlet.class, WebMvcConfigurerAdapter.class })@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter({ DispatcherServletAutoConfiguration.class, ValidationAutoConfiguration.class })public class WebMvcAutoConfiguration { @Configuration @Import(EnableWebMvcConfiguration.class) @EnableConfigurationProperties({ WebMvcProperties.class, ResourceProperties.class }) public static class WebMvcAutoConfigurationAdapter extends WebMvcConfigurerAdapter { ... } @Configuration public static class EnableWebMvcConfiguration extends DelegatingWebMvcConfiguration{ @Bean @Override public RequestMappingHandlerAdapter requestMappingHandlerAdapter() { RequestMappingHandlerAdapter adapter = super.requestMappingHandlerAdapter(); adapter.setIgnoreDefaultModelOnRedirect(this.mvcProperties == null ? true : this.mvcProperties.isIgnoreDefaultModelOnRedirect()); return adapter; } ... }} 3）EnableWebMvcConfiguration的父类DelegatingWebMvcConfiguration，调用被@Aut1owiried声明的setConfigurers方法，注册WebMvcConfigurer的子类（MyWebMvcConfig）。 12345678910111213@Configurationpublic class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport { @Autowired(required = false) public void setConfigurers(List&lt;WebMvcConfigurer&gt; configurers) { if (!CollectionUtils.isEmpty(configurers)) { this.configurers.addWebMvcConfigurers(configurers); } } protected void addInterceptors(InterceptorRegistry registry) { this.configurers.addInterceptors(registry); }} 4）调用工厂方法WebMvcAutoConfiguration$EnableWebMvcConfiguration#requestMappingHandlerMapping()时会调用到DelegatingWebMvcConfiguration#addInterceptors完成注册。 1234567@Bean@Primary@Overridepublic RequestMappingHandlerMapping requestMappingHandlerMapping() { // Must be @Primary for MvcUriComponentsBuilder to work return super.requestMappingHandlerMapping();} 三、案例2 - mybatis自动加载1）mybatis有个mybatis-spring-boot-autoconfigure工程，用来mybatis相关bean的自动加载。 1234&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-autoconfigure&lt;/artifactId&gt;&lt;/dependency&gt; 2）该工程增加以下两个配置文件用于被Spring自动扫描并实现注入。 META-INF/spring-autoconfigure-metadata.properties 1234567#Thu Jan 16 22:08:16 CST 2020com.baomidou.mybatisplus.autoconfigure.MybatisPlusAutoConfiguration.AutoConfigureAfter=org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,com.baomidou.mybatisplus.autoconfigure.MybatisPlusLanguageDriverAutoConfigurationcom.baomidou.mybatisplus.autoconfigure.MybatisPlusAutoConfiguration.ConditionalOnClass=org.apache.ibatis.session.SqlSessionFactory,org.mybatis.spring.SqlSessionFactoryBeancom.baomidou.mybatisplus.autoconfigure.MybatisPlusAutoConfiguration=com.baomidou.mybatisplus.autoconfigure.MybatisPlusLanguageDriverAutoConfiguration=com.baomidou.mybatisplus.autoconfigure.MybatisPlusLanguageDriverAutoConfiguration.ConditionalOnClass=org.apache.ibatis.scripting.LanguageDrivercom.baomidou.mybatisplus.autoconfigure.MybatisPlusAutoConfiguration.ConditionalOnSingleCandidate=javax.sql.DataSource META-INF/spring.facotries 1234# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.baomidou.mybatisplus.autoconfigure.MybatisPlusLanguageDriverAutoConfiguration,\\ com.baomidou.mybatisplus.autoconfigure.MybatisPlusAutoConfiguration 3）总结 如果我们的工程时依赖于springboot，那么也可以通过声明spring.facotries的方式来无侵入的注入另一个模块的bean。否则就得在代码里写大量的*@Import或者@ComponentScan*。 # 参考 本仓库副本：spring.facotries spring-autoconfigure-metadata.properties 使用Interceptor - 廖雪峰 Spring MVC - 拦截器（Interceptor）","link":"/2021/01/27/Springboot%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE/"},{"title":"Spring注解Import","text":"一、注解源码123456789101112@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Import { /** * {@link Configuration}, {@link ImportSelector}, {@link ImportBeanDefinitionRegistrar} * or regular component classes to import. */ Class&lt;?&gt;[] value();} 二、注解说明1、import注解可以导入ImportSelector、ImportBeanDefinitionRegistrar、配置类、普通Component。 123456// Mybatis@Import(MapperScannerRegistrar.class)// Springboot@Import(EnableAutoConfigurationImportSelector.class)// springmvc@Import(EnableWebMvcConfiguration.class) 2、ImportSelector和ImportBeanDefinitionRegistrar区别 1）ImportSelector返回Bean的类名，由ConfigurationClassPostProcessor的ConfigurationClassParser进行解析注册。 2）ImportBeanDefinitionRegistrar无返回值，一般由自身实例化bean，然后注册到BeanFactory。 所以第三方框架要通过接口生成Bean的场景，一般使用ImportBeanDefinitionRegistrar。","link":"/2022/03/21/Spring%E6%B3%A8%E8%A7%A3Import/"},{"title":"Spring集成示例组件实战","text":"一、背景描述我构想了一个类似于mybatis的简化场景如下： 假设当前我有一个组件，名字是Mine。其功能是读取XML文件封装为内存对象，并提供一些操作，如读写等。现在我想通过Spring集成该组件。达到通过自定义注解的属性指定其绑定的XML文件，然后通过FactoryBean解析生成真正的目标对象，然后被纳入Spring的Bean管理中。使其可以通过Spring的注解（如Autowire等）注入到其他Bean里。 二、实践1. 流程如下图比较简单，不做解释 2. 具体代码Ø EnableMineScan.java123456789101112131415161718192021222324252627282930@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(MineBeanDefinitionRegistrar.class)public @interface EnableMineScan { /** * Alias for the {@link #basePackages()} attribute. Allows for more concise * annotation declarations e.g.: * {@code @EnableMyBatisMapperScanner(&quot;org.my.pkg&quot;)} instead of {@code * * @EnableMyBatisMapperScanner(basePackages= &quot;org.my.pkg&quot;})}. */ String[] value() default {}; /** * Base packages to scan for MyBatis interfaces. Note that only interfaces * with at least one method will be registered; concrete classes will be * ignored. */ String[] basePackages() default {}; /** * Type-safe alternative to {@link #basePackages()} for specifying the packages * to scan for annotated components. The package of each class specified will be scanned. * &lt;p&gt;Consider creating a special no-op marker class or interface in each package * that serves no purpose other than being referenced by this attribute. */ Class&lt;?&gt;[] basePackageClasses() default {};} Ø MineBeanDefinitionRegistrar.java12345678910111213141516171819202122232425262728293031323334353637public class MineBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware { private ResourceLoader resourceLoader; @Override public void setResourceLoader(ResourceLoader resourceLoader) { this.resourceLoader = resourceLoader; } @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { MineBeanDefinitionScanner scanner = new MineBeanDefinitionScanner(registry); // this check is needed in Spring 3.1 if (resourceLoader != null) { scanner.setResourceLoader(resourceLoader); } AnnotationAttributes annoAttrs = AnnotationAttributes.fromMap( importingClassMetadata.getAnnotationAttributes(EnableMineScan.class.getName())); List&lt;String&gt; basePackages = new ArrayList&lt;&gt;(); for (String pkg : annoAttrs.getStringArray(&quot;value&quot;)) { if (StringUtils.hasText(pkg)) { basePackages.add(pkg); } } for (String pkg : annoAttrs.getStringArray(&quot;basePackages&quot;)) { if (StringUtils.hasText(pkg)) { basePackages.add(pkg); } } for (Class&lt;?&gt; clazz : annoAttrs.getClassArray(&quot;basePackageClasses&quot;)) { basePackages.add(ClassUtils.getPackageName(clazz)); } scanner.doScan(StringUtils.toStringArray(basePackages)); }} Ø MineBeanDefinitionScanner.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class MineBeanDefinitionScanner extends ClassPathBeanDefinitionScanner { public MineBeanDefinitionScanner(BeanDefinitionRegistry registry) { super(registry, false); } @Override public Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) { Set&lt;BeanDefinitionHolder&gt; beanDefinitions = super.doScan(basePackages); if (beanDefinitions.isEmpty()) { logger.warn(&quot;No MineService was found in '&quot; + Arrays.toString(basePackages) + &quot;' package. Please check your configuration.&quot;); } else { processBeanDefinitions(beanDefinitions); } return beanDefinitions; } private void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) { for (BeanDefinitionHolder holder : beanDefinitions) { ScannedGenericBeanDefinition definition = (ScannedGenericBeanDefinition) holder.getBeanDefinition(); Map&lt;String, Object&gt; annotationAttributes = definition.getMetadata() .getAnnotationAttributes(MineBean.class.getName()); definition.getConstructorArgumentValues().addGenericArgumentValue(definition.getBeanClassName()); definition.setBeanClass(MineFactoryBean.class); definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); definition.getPropertyValues().add(&quot;xmlFile&quot;, annotationAttributes.get(&quot;xmlFile&quot;)); } } @Override protected boolean isCandidateComponent(AnnotatedBeanDefinition beanDefinition) { return isCandidateComponent(beanDefinition.getMetadata()); } @Override protected boolean isCandidateComponent(MetadataReader metadataReader) { return isCandidateComponent(metadataReader.getClassMetadata()); } private boolean isCandidateComponent(ClassMetadata classMetadata) { return classMetadata.isInterface() &amp;&amp; classMetadata.isIndependent() &amp;&amp; ArrayUtils.contains(classMetadata.getInterfaceNames(), AbstractMineService.class.getName()); } @Override protected boolean checkCandidate(String beanName, BeanDefinition beanDefinition) { if (super.checkCandidate(beanName, beanDefinition)) { return true; } else { logger.warn(&quot;Skipping MineFactoryBean with name '&quot; + beanName + &quot;' and '&quot; + beanDefinition.getBeanClassName() + &quot;. Bean already defined with the same name!&quot;); return false; } }} Ø MineBean.java12345public @interface MineBean { String value() default &quot;&quot;; String xmlFile() default &quot;&quot;;} Ø AbstractMineService.java1234public interface AbstractMineService { Object read(String xpath); void write(String xpath, Object obj);} Ø MineFactoryBean.java123456789101112131415161718192021222324252627282930313233343536373839404142public class MineFactoryBean&lt;T extends AbstractMineService&gt; implements FactoryBean&lt;T&gt; { private Class&lt;? extends AbstractMineService&gt; mapperInterface; private String xmlFile; public MineFactoryBean() { } public MineFactoryBean(Class&lt;? extends AbstractMineService&gt; mapperInterface) { this.mapperInterface = mapperInterface; } @Override public T getObject() throws Exception { ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader(); return (T) Proxy.newProxyInstance(contextClassLoader, new Class[]{mapperInterface}, new MineBeanInvoker()); } @Override public Class&lt;?&gt; getObjectType() { return mapperInterface; } @Override public boolean isSingleton() { return true; } public String getXmlFile() { return xmlFile; } public void setXmlFile(String xmlFile) { this.xmlFile = xmlFile; } class MineBeanInvoker implements InvocationHandler { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 调用Mine组件进行解析和执行，忽略具体逻辑 } }} 3. 使用示例1234@EnableMineScan(basePackageClasses = SpringConfiguration.class)@Configurationpublic class SpringConfiguration {} 123@MineFactoryBean(xmlFile = &quot;any.xml&quot;)public interface MineDemoRunner extends AbstractMineService {} 1234567891011@RunWith(value = SpringJUnit4ClassRunner.class)@ContextConfiguration(classes = SpringConfiguration.class)public class SpringMain { @Autowired private MineDemoRunner mineService; @Test public void test() { mineService.read(&quot;/root/sub&quot;) }}","link":"/2021/05/09/Spring%E9%9B%86%E6%88%90%E7%A4%BA%E4%BE%8B%E7%BB%84%E4%BB%B6%E5%AE%9E%E6%88%98/"},{"title":"Spring事务","text":"一、关键类1、EnableTransactionManagement 123456@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(TransactionManagementConfigurationSelector.class)public @interface EnableTransactionManagement {} 2、TransactionManagementConfigurationSelector123456789101112131415public class TransactionManagementConfigurationSelector extends AdviceModeImportSelector&lt;EnableTransactionManagement&gt; { @Override protected String[] selectImports(AdviceMode adviceMode) { switch (adviceMode) { case PROXY: return new String[] {AutoProxyRegistrar.class.getName(), ProxyTransactionManagementConfiguration.class.getName()}; case ASPECTJ: return new String[] {TransactionManagementConfigUtils.TRANSACTION_ASPECT_CONFIGURATION_CLASS_NAME}; default: return null; } }} 3、AutoProxyRegistrar会注册生成动态代理的BeanPostProcessorAutoProxyRegistrar#registerBeanDefinitions调用AopConfigUtils#registerAutoProxyCreatorIfNecessary把InfrastructureAdvisorAutoProxyCreator注册进入BeanFactory。 4、ProxyTransactionManagementConfiguration注册事务的Advisor(TransactionInterceptor)org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration 12345678910111213141516171819202122232425262728293031@Configurationpublic class ProxyTransactionManagementConfiguration extends AbstractTransactionManagementConfiguration { @Bean(name = TransactionManagementConfigUtils.TRANSACTION_ADVISOR_BEAN_NAME) @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public BeanFactoryTransactionAttributeSourceAdvisor transactionAdvisor() { BeanFactoryTransactionAttributeSourceAdvisor advisor = new BeanFactoryTransactionAttributeSourceAdvisor(); // 解析Transaction注解，确定Bean是否需要进行过事务Advisor注入 advisor.setTransactionAttributeSource(transactionAttributeSource()); advisor.setAdvice(transactionInterceptor()); advisor.setOrder(this.enableTx.&lt;Integer&gt;getNumber(&quot;order&quot;)); return advisor; } @Bean @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public TransactionAttributeSource transactionAttributeSource() { return new AnnotationTransactionAttributeSource(); } @Bean @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public TransactionInterceptor transactionInterceptor() { TransactionInterceptor interceptor = new TransactionInterceptor(); interceptor.setTransactionAttributeSource(transactionAttributeSource()); if (this.txManager != null) { interceptor.setTransactionManager(this.txManager); } return interceptor; }} 二、AOP和事务的BeanPostProcessor谁生效两者的beanName相同，有多个代理生成的后置处理器时，根据APC_PRIORITY_LIST顺序进行选择，大的生效，即同时开启时AOP的Bean后置处理器生效。 1234567891011121314151617public abstract class AopConfigUtils { /** * Stores the auto proxy creator classes in escalation order. */ private static final List&lt;Class&lt;?&gt;&gt; APC_PRIORITY_LIST = new ArrayList&lt;Class&lt;?&gt;&gt;(); /** * Setup the escalation list. */ static { // 事务BeanPostProcessor APC_PRIORITY_LIST.add(InfrastructureAdvisorAutoProxyCreator.class); APC_PRIORITY_LIST.add(AspectJAwareAdvisorAutoProxyCreator.class); // AOPBeanPostProcessor APC_PRIORITY_LIST.add(AnnotationAwareAspectJAutoProxyCreator.class); }} 三、自定义Advisor和事务Advisor执行顺序显示指定Order来声明顺序 四、事务异常回滚1234567891011121314151617181920212223242526272829public class TransactionInterceptor extends TransactionAspectSupport implements MethodInterceptor, Serializable { protected Object invokeWithinTransaction(Method method, Class&lt;?&gt; targetClass, final InvocationCallback invocation) throws Throwable { if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) { // Standard transaction demarcation with getTransaction and commit/rollback calls. TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification); Object retVal = null; try { // This is an around advice: Invoke the next interceptor in the chain. // This will normally result in a target object being invoked. retVal = invocation.proceedWithInvocation(); } catch (Throwable ex) { // target invocation exception // 事务异常处理 completeTransactionAfterThrowing(txInfo, ex); throw ex; } finally { cleanupTransactionInfo(txInfo); } commitTransactionAfterReturning(txInfo); return retVal; } ... }} 1234567public class DefaultTransactionAttribute extends DefaultTransactionDefinition implements TransactionAttribute { // 默认只回滚Error和RuntimeException public boolean rollbackOn(Throwable ex) { return (ex instanceof RuntimeException || ex instanceof Error); } ... } 所以尽量在方法上声明@Transactional(rollbackFor = Exception.class)来对检查异常进行回滚。 五、事务嵌套参考：org.springframework.transaction.support.AbstractPlatformTransactionManager#suspend 生成SuspendedResourcesHolder的单链表结构保存事务信息。","link":"/2021/01/15/Spring%E4%BA%8B%E5%8A%A1/"},{"title":"StringEscapeUtils","text":"一、类的限定名org.apache.commons.lang3.StringEscapeUtils 二、类的使用可用来转义和反转义字符串。 三、使用场景1）前端可通过输入字符串’\\n,\\r,\\b,\\f,\\t’或unicode码点字符串，后台通过该类简单解析为反转义后的字符。","link":"/2020/11/15/StringEscapeUtils/"},{"title":"System.currentTimeMillis()与GMT","text":"一、System.currentTimeMillis()函数注释12345678910111213141516171819public final class System { /** * Returns the current time in milliseconds. Note that * while the unit of time of the return value is a millisecond, * the granularity of the value depends on the underlying * operating system and may be larger. For example, many * operating systems measure time in units of tens of * milliseconds. * * &lt;p&gt; See the description of the class &lt;code&gt;Date&lt;/code&gt; for * a discussion of slight discrepancies that may arise between * &quot;computer time&quot; and coordinated universal time (UTC). * * @return the difference, measured in milliseconds, between * the current time and midnight, January 1, 1970 UTC. * @see java.util.Date */ public static native long currentTimeMillis();} 二、说明System.currentTimeMillis()函数获取的是格林威治（GMT）自1970-1-1起始的毫秒数，也称为epoch。 例如：我在东八区的2020-11-24 13:00调用该函数获取的毫秒数为1606194000；而该毫秒数相对于1970-1-1的时间为2020-11-24 5:00，即GMT时间； 三、结论 在时间准确的前提下，某一时刻在全球各个时区调用System.currentTimeMillis()的结果是一样的。","link":"/2020/11/24/System.currentTimeMillis()%E4%B8%8EGMT/"},{"title":"ThreadLocal内存泄漏","text":"一、ThreadLocal内存和引用结构 二、内存泄漏原因 1）ThreadLocalMap中Entry的Key对ThreadLocal变量的引用是弱引用，ThreadLocal变量可随着实例回收而回收。 2）ThreadLocalMap中Entry的Value对ThreadLocal创建的值是强引用，GC Root是线程对象Thread，跟随线程的生命周期。而现在很多框架如Tomat等使用的是线程池，线程可能在JVM运行期间都不会被销毁。 3）如果ThreadLocal变量在回收前没有调用remove方法，删除Entry，则会导致内存泄漏。 三、解决方案在ThreadLocal回收前及时调用Remove方法，否则会在线程销毁时才回收。","link":"/2022/03/16/ThreadLocal%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F/"},{"title":"String","text":"一、String.compareTo1、源码 1234567891011121314151617181920public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence { public int compareTo(String anotherString) { int len1 = value.length; int len2 = anotherString.value.length; int lim = Math.min(len1, len2); char v1[] = value; char v2[] = anotherString.value; int k = 0; while (k &lt; lim) { char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) { return c1 - c2; } k++; } return len1 - len2; }} 2、流程解析 1）从0到minLength比较字符大小。如果存在字符不相等，返回字符差。 2）返回两者length差。 二、String.getBytes的编码1、字节数组和字符串间转换时指定编码1）第一种方式，通过字符串指定编码，需要catch或throw检查异常UnsupportedEncodingException。 123byte[] bytes = &quot;你好，世界&quot;.getBytes(&quot;utf-8&quot;);String str = new String(bytes, &quot;utf-8&quot;); 2）第二种方式，使用StandardCharsets的编码常量 123byte[] bytes = &quot;你好，世界&quot;.getBytes(StandardCharsets.UTF_8);String str = new String(bytes, StandardCharsets.UTF_8); 2、编码类","link":"/2020/04/19/String/"},{"title":"Spring集成第三方组件-Mybatis","text":"一、mybatis简介Mybaits是java语言一个ORM框架。官网介绍如下： MyBatis 是一款优秀的持久层框架，它支持自定义 SQL、存储过程以及高级映射。MyBatis 免除了几乎所有的 JDBC 代码以及设置参数和获取结果集的工作。MyBatis 可以通过简单的 XML 或注解来配置和映射原始类型、接口和 Java POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。 mybatis把SQL抽离到了xml中（此处不考虑使用注解声明SQL方式，因为违背了SQL可配置的原则，不推崇），如下所示： 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;org.mybatis.example.BlogMapper&quot;&gt; &lt;select id=&quot;selectBlog&quot; resultType=&quot;Blog&quot;&gt; select * from Blog where id = #{id} &lt;/select&gt;&lt;/mapper&gt; 使用时，有几种不同的方式： 1）直接通过XML中的命名空间直接通过 12SqlSession session = sqlSessionFactory.openSession()Blog blog = (Blog) session.selectOne(&quot;org.mybatis.example.BlogMapper.selectBlog&quot;, 101); 2）定义一个与之相对应的java接口作为DAO层使用。 1234package org.mybatis.example;public interface BlogMapper { Blog selectBlog(int id);} 使用时通过接口执行操作： 123SqlSession session = sqlSessionFactory.openSession()BlogMapper mapper = session.getMapper(BlogMapper.class);Blog blog = mapper.selectBlog(101); 目前第二种方式比较常用，更符合ORM的使用习惯。 二、Spring通过MapperScan注解集成Mybatis spring使用可以通过配置文件和注解来集成mybatis，此处只探究注解方式的实现机制。 1. MapperScan注解，设置扫描包MapperScan使用如下，只需要在某个Bean上加伤@MapperScan即可： 1234567@SpringBootApplication @MapperScan(&quot;pers.kivi.demo.mapper&quot;) public class App { public static void main(String[] args) { SpringApplication.run(App.class, args); } } 观察MapperScan注解发现其通过Import注解引入了MapperScannerRegistrar： 1234567@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(MapperScannerRegistrar.class)public @interface MapperScan { ...} 2.@Import的解析时机在org.springframework.context.support.AbstractApplicationContext#invokeBeanFactoryPostProcessors调用时，会调用ConfigurationClassPostProcessor这个内置的BeanFactoryPostProcessor对传入的配置类进行级联的解析，把符合条件的类解析为BeanDefinition注册到beanDefinitionMap中。 其中就包含对*@Import注解的解析，ConfigurationClassPostProcessor会调用其registerBeanDefinitions*方法注册bean定义。 3. MapperScannerRegistrar该接口是ImportBeanDefinitionRegistrar的子类，职责是负责注册BeanDefinition到BeanFactory。 123456789101112131415161718192021222324252627282930public class MapperScannerRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware { private ResourceLoader resourceLoader; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { AnnotationAttributes annoAttrs = AnnotationAttributes.fromMap(importingClassMetadata.getAnnotationAttributes(MapperScan.class.getName())); ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); /** * 设置属性至scanner，忽略此处逻辑 */ List&lt;String&gt; basePackages = new ArrayList&lt;String&gt;(); for (String pkg : annoAttrs.getStringArray(&quot;value&quot;)) { if (StringUtils.hasText(pkg)) { basePackages.add(pkg); } } for (String pkg : annoAttrs.getStringArray(&quot;basePackages&quot;)) { if (StringUtils.hasText(pkg)) { basePackages.add(pkg); } } for (Class&lt;?&gt; clazz : annoAttrs.getClassArray(&quot;basePackageClasses&quot;)) { basePackages.add(ClassUtils.getPackageName(clazz)); } scanner.doScan(StringUtils.toStringArray(basePackages)); }} 从源码可以发现，MapperScannerRegistrar使用ClassPathMapperScanner来扫描传入的package，解析并注册BeanDefinition。 4.ClassPathMapperScannerClassPathMapperScanner继承了ClassPathBeanDefinitionScanner来扫描BeanDefinition，但是为了把Mybatis声明的Mapper接口扫描为BeanDefinition，其重写了isCandidateComponent方法。 然后把扫描到的Bean定义的class通过processBeanDefinitions方法设置为MapperFactoryBeans。 123456789101112131415161718192021222324252627282930313233343536373839404142package org.mybatis.spring.mapper;public class ClassPathMapperScanner extends ClassPathBeanDefinitionScanner { /** * Calls the parent search that will search and register all the candidates. * Then the registered objects are post processed to set them as * MapperFactoryBeans */ @Override public Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) { /** * 调用父类doScan方法进行扫描并注册BeanDefinition */ Set&lt;BeanDefinitionHolder&gt; beanDefinitions = super.doScan(basePackages); /** * 把已经注册的Mybatis的Mapper接口的BeanDefinition的class修改为MapperFactoryBeans */ processBeanDefinitions(beanDefinitions); return beanDefinitions; } private void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) { GenericBeanDefinition definition; for (BeanDefinitionHolder holder : beanDefinitions) { definition = (GenericBeanDefinition) holder.getBeanDefinition(); // the mapper interface is the original class of the bean // but, the actual class of the bean is MapperFactoryBean definition.getConstructorArgumentValues().addGenericArgumentValue(definition.getBeanClassName()); definition.setBeanClass(this.mapperFactoryBean.getClass()); /** *设置其他BeanDefinition属性 */ } } @Override protected boolean isCandidateComponent(AnnotatedBeanDefinition beanDefinition) { return beanDefinition.getMetadata().isInterface() &amp;&amp; beanDefinition.getMetadata().isIndependent(); } } 5. MapperFactoryBeans不出意外MapperFactoryBean肯定是一个FactoryBean，负责对接口生成对应的代理实例。 12345678910public class MapperFactoryBean&lt;T&gt; extends SqlSessionDaoSupport implements FactoryBean&lt;T&gt; { ... @Override public T getObject() throws Exception { return getSqlSession().getMapper(this.mapperInterface); } ...} 三、Spring创建Bean时机Spring会在org.springframework.context.support.AbstractApplicationContext#finishBeanFactoryInitialization方法中对非BeanFactoryPostProcessor，ApplicationListener类型等的普通Bean进行初始化。如果发现某BeanDefinitino的类型是FactoryBean，则会继续调用getObject方法创建具体实例。 至此完成Mybatis的Mapper集成进Spring的Context管理。 四、总结Spring内部提供了太多的扩展点供增强使用，例如: 1）BeanFactoryPostProcessor可以用来增强BeanDefinition的加载； 2）BeanPostProcessor可以用来增强Bean创建过程； 3）Aware可以使Bean织入Spring的一些Bean； 4）EventListener/ApplicationEventMulticaster可以用来实现广播自己的事件； 5）Xml配置文件直至自定义schema的NameSpaceHandler，来进行BeanDefinition注册； 等等。 我们实际开发的时候多了解里面的机制，就可以做到更低耦合，更优雅的功能扩展和实现。","link":"/2021/01/17/Spring%E9%9B%86%E6%88%90%E7%AC%AC%E4%B8%89%E6%96%B9%E7%BB%84%E4%BB%B6-Mybatis/"},{"title":"Tomcat类加载器","text":"springboot实现定义了一个符合双亲委派的类TomcatEmbeddedWebappClassLoader extends WebappClassLoader，因为springboot只针对一个应用运行的场景，所以无需打破双亲委派。 使用IDEA调试Tomcat代码时，在Project Settings - Libraries里把tomcat/lib加进来就可以了。 一、前置问题 tomcat的类加载破坏了双亲委派吗？ 为什么要破坏双亲委派？ tomcat的类加载器的继承关系？ tomcat的类加载层级和机制？ 二、Tomcat的类加载器类图 说明：1）WebappClassLoaderBase及其子类是Tomcat自己实现的类加载器；2）其默认打破了双亲委派机制，用来实现Tomcat多应用间的隔离； 三、Tomcat类加载层级 说明：1）Bootstrap类加载器：JDK的启动类加载器和扩展类加载器2）System类加载器：JDK的应用类加载器3）Common,Catalina,Shared类加载器：是三个URLClassLoader实例，分别指定了不同的path；4）Webapp类加载器：Tomcat定义的类加载器WebappClassLoaderBase及其自类； 四、Tomcat类加载器创建1. 执行tomcat启动脚本catalina.sh，运行主类org.apache.catalina.startup.Bootstrap#main；2. Bootstrap#main会执行以下操作2.1 实例化Bootstrap并调用其init方法（此处暂不考虑以service运行）；1234567891011121314151617181920212223242526/** * Main method and entry point when starting Tomcat via the provided * scripts. * * @param args Command line arguments to be processed */ public static void main(String args[]) { if (daemon == null) { // Don't set daemon until init() has completed Bootstrap bootstrap = new Bootstrap(); try { bootstrap.init(); } catch (Throwable t) { handleThrowable(t); t.printStackTrace(); return; } daemon = bootstrap; } else { // When running as a service the call to stop will be on a new // thread so make sure the correct class loader is used to prevent // a range of class not found exceptions. Thread.currentThread().setContextClassLoader(daemon.catalinaLoader); } ... } Bootstrap#init方法会执行以下操作： 123456789101112131415161718192021222324public void init() throws Exception { initClassLoaders(); Thread.currentThread().setContextClassLoader(catalinaLoader); SecurityClassLoad.securityClassLoad(catalinaLoader); // Load our startup class and call its process() method if (log.isDebugEnabled()) log.debug(&quot;Loading startup class&quot;); Class&lt;?&gt; startupClass = catalinaLoader.loadClass(&quot;org.apache.catalina.startup.Catalina&quot;); Object startupInstance = startupClass.newInstance(); // Set the shared extensions class loader if (log.isDebugEnabled()) log.debug(&quot;Setting startup class properties&quot;); String methodName = &quot;setParentClassLoader&quot;; Class&lt;?&gt; paramTypes[] = new Class[1]; paramTypes[0] = Class.forName(&quot;java.lang.ClassLoader&quot;); Object paramValues[] = new Object[1]; paramValues[0] = sharedLoader; Method method = startupInstance.getClass().getMethod(methodName, paramTypes); method.invoke(startupInstance, paramValues); catalinaDaemon = startupInstance;} 2.1.1 初始化类加载器：common,server,shared。1）类型为URLClassLoader，未打破双亲委派；2）其path从catalina.properties中读取common.loader，server.loader，shared.loader的键值；3）指定parent关系 1234567891011121314private void initClassLoaders() { try { commonLoader = createClassLoader(&quot;common&quot;, null); if( commonLoader == null ) { // no config file, default to this loader - we might be in a 'single' env. commonLoader=this.getClass().getClassLoader(); } catalinaLoader = createClassLoader(&quot;server&quot;, commonLoader); sharedLoader = createClassLoader(&quot;shared&quot;, commonLoader); } catch (Throwable t) { handleThrowable(t); log.error(&quot;Class loader creation threw exception&quot;, t); System.exit(1); } Note: tomcat-8.5.56里把common, server, shared合成了一个。 12345678private ClassLoader createClassLoader(String name, ClassLoader parent) throws Exception { // 因为catalina.properties的server.loader和shared.loader的值都为空，所以catalinaLoader,sharedLoader都指向commonLoader。 String value = CatalinaProperties.getProperty(name + &quot;.loader&quot;); if (value != null &amp;&amp; !value.equals(&quot;&quot;)) { } else{ return parent; }} 2.1.2 设置server类加载器为当前线程的ContextClassLoader2.1.3 实例化org.apache.catalina.startup.Catalina，并把shared类加载器设为其父类加载器2.2 Bootstrap#main接收到startd命令时会调用bootstrap#load，bootstrap#start12345if (command.equals(&quot;startd&quot;)) { args[args.length - 1] = &quot;start&quot;; daemon.load(args); daemon.start();} 2.2.1 load方法1）通过Digester读取server.xml来初始化Catalina#server； 1234digester.addRuleSet(new HostRuleSet(&quot;Server/Service/Engine/&quot;));digester.addRuleSet(new ContextRuleSet(&quot;Server/Service/Engine/Host/&quot;));// 设置HOST的parentClassLoader为catalina的parentClassLoader，即shared类加载器digester.addRule(&quot;Server/Service/Engine&quot;,new SetParentClassLoaderRule(parentClassLoader)); 2）HostRuleSet里设置 1234567// prefix = &quot;Server/Service/Engine/&quot;digester.addObjectCreate(prefix + &quot;Host&quot;, &quot;org.apache.catalina.core.StandardHost&quot;, &quot;className&quot;);digester.addSetNext(prefix + &quot;Host&quot;, &quot;addChild&quot;, &quot;org.apache.catalina.Container&quot;); 3）ContextRuleSet里设置设置Host的Context为StarndardContext，然后设置StandardContext的loader为WebappLoader 123456// prefix =&quot;Server/Service/Engine/Host/&quot;digester.addObjectCreate(prefix + &quot;Context&quot;, &quot;org.apache.catalina.core.StandardContext&quot;, &quot;className&quot;);digester.addObjectCreate(prefix + &quot;Context/Loader&quot;, &quot;org.apache.catalina.loader.WebappLoader&quot;, &quot;className&quot;); 4）StandardContext把WebappLoader的context设为自身 1loader.setContext(this); 5）WebappLoader里把StandardContext的parentClassLoader设为应用类加载器的parent。而StandardContext的parentClassLoader为空，继续找其parent（StandardHOST）的paretClassLoader，即shared类加载器。 1234567891011121314151617private String loaderClass = ParallelWebappClassLoader.class.getName();private WebappClassLoaderBase createClassLoader() throws Exception { Class&lt;?&gt; clazz = Class.forName(loaderClass); WebappClassLoaderBase classLoader = null; if (parentClassLoader == null) { parentClassLoader = context.getParentClassLoader(); } Class&lt;?&gt;[] argTypes = { ClassLoader.class }; Object[] args = { parentClassLoader }; Constructor&lt;?&gt; constr = clazz.getConstructor(argTypes); classLoader = (WebappClassLoaderBase) constr.newInstance(args); return classLoader; } 五、应用类加载器加载机制 不开启委托（默认情况，delegate=false），破坏了双亲委派1）检查类是否被加载；有则返回，没有则继续执行；2）使用JavaSE类加载器加载类；若成功则返回，否则继续执行；3）应用类加载器尝试加载类；若成功则返回，否则继续执行；4）应用类加载器委托给父加载器（shared类加载器）加载；若成功则返回，否则抛出ClassNotFoundException; 开启委托（delegate=true）， 符合双亲委派1）检查类是否被加载；有则返回，没有则继续执行；2）使用JavaSE类加载器加载类；若成功则返回，否则继续执行；3）应用类加载器委托给父加载器（shared类加载器）加载；若成功则返回，否则继续执行；4）应用类加载器尝试加载类；若成功则返回，否则抛出ClassNotFoundException; Note: JavaSE类加载器默认为启动类加载器。（应用类加载器的构造器里指定了其指向String.class.getClassLoader();） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { Class&lt;?&gt; clazz = null; // 检查类是否被加载过 clazz = findLoadedClass0(name); if (clazz != null) { if (resolve) resolveClass(clazz); return (clazz); } clazz = findLoadedClass(name); if (clazz != null) { if (resolve) resolveClass(clazz); return (clazz); } // 优先使用JavaSE类加载器加载类 String resourceName = binaryNameToPath(name, false); ClassLoader javaseLoader = getJavaseClassLoader(); boolean tryLoadingFromJavaseLoader; try { tryLoadingFromJavaseLoader = (javaseLoader.getResource(resourceName) != null); } catch (Throwable t) { tryLoadingFromJavaseLoader = true; } if (tryLoadingFromJavaseLoader) { try { clazz = javaseLoader.loadClass(name); if (clazz != null) { if (resolve) resolveClass(clazz); return (clazz); } } catch (ClassNotFoundException e) { // Ignore } } boolean delegateLoad = delegate || filter(name, true); // 委托开启的话，使用委托给parent类加载器（在自身尝试加载前） if (delegateLoad) { try { clazz = Class.forName(name, false, parent); if (clazz != null) { if (resolve) resolveClass(clazz); return (clazz); } } catch (ClassNotFoundException e) { // Ignore } } // 自身去加载类 try { clazz = findClass(name); if (clazz != null) { if (resolve) resolveClass(clazz); return (clazz); } } catch (ClassNotFoundException e) { // Ignore } // 如果委托没有开启的话，委托给parent去加载（在自身尝试加载后） if (!delegateLoad) { try { clazz = Class.forName(name, false, parent); if (clazz != null) { if (resolve) resolveClass(clazz); return (clazz); } } catch (ClassNotFoundException e) { // Ignore } } throw new ClassNotFoundException(name); } 参考 https://tomcat.apache.org/tomcat-8.5-doc/class-loader-howto.html https://pt.slideshare.net/wptree/class-loader-incloud/5","link":"/2020/07/09/Tomcat%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8/"},{"title":"TroubleShooting方法论","text":"程序员的编程时间分布也符合二八原则,20%时间Conding, 80%时间调Debugging. 相比编码水平, TroubleShooting的能力可能更影响效率. 本文旨在把工作中的定位错误的思路整理为文字, 便于后期不断的优化和规范. 0. 写在前面一般而言，当我们发现程序的运行不符合我们的预期时，我们就会认为有不好的事情在发生。“不符合预期”可严谨的描述为我的程序及其依赖的第三方程序在运行中产生了不是我所预期的结果。此处有三个主体：1）我本人；2）我写的程序；3）依赖的第三方程序。 由此得出三种产生非预期结果的原因： 1）程序运行正确，但是我本人对其运行机制不清楚导致对其结果误判； 2）我自己写的程序逻辑有问题； 3）我依赖的第三方程序有问题； 1. 思维定势 问题提问者的说辞不一定是对错误的正确描述, 需要自己去判断 问题发生的时间和发现的时间可能差距很大。当前发现的错误有可能新引入的，也有可能是触发了之前粗心留下的彩蛋。 在解决问题时，要大胆想象问题空间和小心的求证。 任何错误的认定，都会使后面的探索徒劳。如同走迷宫，错误的路径只会让你困在死胡同，最终回到原点。 之前类似问题的原因，不一定是本次问题的原因。 2. 通用策略1234567891011121314151617181920212223242526271. 重现问题 1.1 写测试用例，快速复现问题。这也为以后定位减少工作量。2. 定位问题 2.1 看 2.1.1 观察错误堆栈 2.1.2 输出更详细的日志信息 2.1.3 内存Dump &amp; CPU Jstack 2.1.4 JMX等监测工具 2.2 DEBUG 2.2.1 本地调试(Debug Tool &amp; Print &amp; Log) 2.2.2 远程调试 2.3 找变化 2.3.1 找出与上一次正确版本的差异和变化 2.4 梳理调用链 2.4.1 梳理流程，通过二分法定位错误点 2.4.2 梳理流程，优先排查容易定位的点(和2.4.1酌情选择) 2.5 搜和问 2.5.1 查看出问题组件的文档，优先看常见问题QA 2.5.2 Google &amp; Stackoverflow 2.5.3 询问软件的开发和支持人员3. 解决问题4. 沉淀为文档 3. 场景策略 日常开发场景 123定义: 开发场景为研发人员在着手解决自己书写或他人遗留的代码的情景.优势: 该场景下可优先借助IDE进行Debug.手段: IDE Debug工具(断点, 条件断点, 打印过程变量) 线上运维场景 12345678910定义: 开发场景为研发人员要定位正在线上环境运行的代码的情景.劣势: 1) 线上日志级别高, 日志不精细, 不容易定位问题和知晓问题代码上下文;2) 线上Bug不容易复现, bug可能是执行频度较低的代码路径, 只有特殊的请求才会触发;3) 安全起见, 线上服务器一般不允许执行远程调试手段: 1) 若是重大Bug, 则先回滚版本减少损失2) 增加或通过log4j抽取详细的线上日志3) 本地运行线上版本包进行调试4) Dump内存和CPU信息 测试运维场景 1234567定义: 开发场景为研发人员要定位正在测试环境运行的代码的情景.优势: bug不会影响生产, 且测试服务器允许远程调试 手段: 1) 远程调试2) 增加日志3) 本地运行测试版本包进行调试4) Dump内存和CPU信息 4. 优先定位路径中耗时较短的片段 在日常的定位问题时，二分法有时候不是首选，有时候通过粗略的评估整个调用路径中各个片段定位的耗时，优先挑拣容易定位的片段可能会起到事半功倍的作用。例如：有些片段只需要通过一个简单的命令，例如ping，telnet就可以定位问题出现在上游还是下游。 5. 如何提升 规范自己 帮助他人","link":"/2019/05/17/TroubleShooting%E6%96%B9%E6%B3%95%E8%AE%BA/"},{"title":"User_vs_Kernel","text":"Java编程的环境里涉及的两个有关User和Kernel有两个场景：1）JVM与操作系统交互时，用户线程（User Level Thread）和内核线程（Kernel Level Thread）的映射关系；此处的用户线程就是JVM通过线程库产生的线程。2）Java程序执行过程中，权限在用户态（User Mode）和内核态（Kernel Mode）切换。 1. User Level Thread与Kernel Level Thread 用户线程由应用来管理线程的创建、销毁，而内核线程由操作系统来管理； 用户线程处于应用内部，由应用自己来管理。例如，JVM的GreenThread，NoneGreenThread。 内核线程由操作系统管理，是直接访问CPU、执行指令的线程。 用户的线程需要映射到操作系统的内核线程上，即把操作委托给操作系统线程来执行指令。 用户线程和内核线程的映射模式有：多对多模式，多对一模式，一对一模式。 2. User Mode与Kernel Mode 操作系统为了进行资源保护，才划分了用户态和内核态。关键资源只能由内核态的权限才能访问，这样可以保护系统的关键数据不被破坏，使系统可以正常运行。 JVM在运行时可以通过系统调用等方式转为内核态。 3. 概念聚合场景JVM运行时的某个线程（用户态线程）映射到操作系统的内核线程。该线程在执行程序中的一个系统调用指令时，触发了用户态到内核态的权限切换，以此来访问系统的关键资源。 参考资料： stackoverflow: 用户态和内核态 用户线程和内核线程 Multithreading Models 用户态和内核态的区别 wiki: Green_threads","link":"/2019/11/07/User_vs_Kernel/"},{"title":"URI格式","text":"一、一个URI异常示例代码 123public static void main(String[] args) throws URISyntaxException { new URI(&quot;http://test.jd.com /index.html&quot;);} 报错信息1234567Exception in thread &quot;main&quot; java.net.URISyntaxException: Illegal character in authority at index 7: http://test.jd.com /index.html at java.net.URI$Parser.fail(URI.java:2848) at java.net.URI$Parser.parseAuthority(URI.java:3186) at java.net.URI$Parser.parseHierarchical(URI.java:3097) at java.net.URI$Parser.parse(URI.java:3053) at java.net.URI.&lt;init&gt;(URI.java:588) at TmpTest.main(TmpTest.java:17) 异常分析 JAVA中根据格式解析认证模块时，如果出错，其报错非法字符的位置为认证模块的首位，而不是真正出错的位置。如http://test.jd.com /index.html解析认证组件 test.jd.com 时出错（多了一个空格），报错的非法字符位置为7，即http://后面的位置。 二、URI格式介绍 URI的通用格式定义：URI = scheme:[//authority]path[?query][#fragment]其中：authority = [userinfo@]host[:port] URI中的authority组件：1）认证组件被互联网Server或特定协议的命名机关注册登记；2）认证组件跟在//后面；遇到符号?，/结束。3）认证模块是非必须的； URI示例 参考 https://tools.ietf.org/html/rfc2396#section-3.1 https://en.wikipedia.org/wiki/Uniform_Resource_Identifier","link":"/2020/07/21/URI%E6%A0%BC%E5%BC%8F/"},{"title":"URLClassPath源码分析","text":"一、前置问题 URLClassLoader和URLClassPath的关系？ URLClassPath的用处？ 如何处理不同类型的资源，如zip,jar和普通文件夹？ 二、URLClassLoaderURLClassLoader的作用是依赖URLClassPath来定位读取资源，可参考文章类加载机制 关键代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class URLClassLoader extends SecureClassLoader implements Closeable { /* The search path for classes and resources */ private final URLClassPath ucp; public URL findResource(final String name) { /* * The same restriction to finding classes applies to resources */ URL url = AccessController.doPrivileged( new PrivilegedAction&lt;URL&gt;() { public URL run() { return ucp.findResource(name, true); } }, acc); return url != null ? ucp.checkURL(url) : null; } protected Class&lt;?&gt; findClass(final String name) throws ClassNotFoundException { final Class&lt;?&gt; result; try { result = AccessController.doPrivileged( new PrivilegedExceptionAction&lt;Class&lt;?&gt;&gt;() { public Class&lt;?&gt; run() throws ClassNotFoundException { String path = name.replace('.', '/').concat(&quot;.class&quot;); Resource res = ucp.getResource(path, false); if (res != null) { try { return defineClass(name, res); } catch (IOException e) { throw new ClassNotFoundException(name, e); } } else { return null; } } }, acc); } catch (java.security.PrivilegedActionException pae) { throw (ClassNotFoundException) pae.getException(); } if (result == null) { throw new ClassNotFoundException(name); } return result; }} 三、URLClassPathURLClassPath根据URL的协议类型创建不同的Loader来解析不同的资源类型。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120/** * This class is used to maintain a search path of URLs for loading classes * and resources from both JAR files and directories. * * @author David Connelly */public class URLClassPath { public URL findResource(String name, boolean check) { Loader loader; int[] cache = getLookupCache(name); for (int i = 0; (loader = getNextLoader(cache, i)) != null; i++) { URL url = loader.findResource(name, check); if (url != null) { return url; } } return null; } private synchronized Loader getNextLoader(int[] cache, int index) { if (closed) { return null; } if (cache != null) { if (index &lt; cache.length) { Loader loader = loaders.get(cache[index]); if (DEBUG_LOOKUP_CACHE) { System.out.println(&quot;HASCACHE: Loading from : &quot; + cache[index] + &quot; = &quot; + loader.getBaseURL()); } return loader; } else { return null; // finished iterating over cache[] } } else { return getLoader(index); } } private synchronized Loader getLoader(int index) { if (closed) { return null; } // Expand URL search path until the request can be satisfied // or the URL stack is empty. while (loaders.size() &lt; index + 1) { // Pop the next URL from the URL stack URL url; synchronized (urls) { if (urls.empty()) { return null; } else { url = urls.pop(); } } // Skip this URL if it already has a Loader. (Loader // may be null in the case where URL has not been opened // but is referenced by a JAR index.) String urlNoFragString = URLUtil.urlNoFragString(url); if (lmap.containsKey(urlNoFragString)) { continue; } // Otherwise, create a new Loader for the URL. Loader loader; try { loader = getLoader(url); // If the loader defines a local class path then add the // URLs to the list of URLs to be opened. URL[] urls = loader.getClassPath(); if (urls != null) { push(urls); } } catch (IOException e) { // Silently ignore for now... continue; } catch (SecurityException se) { // Always silently ignore. The context, if there is one, that // this URLClassPath was given during construction will never // have permission to access the URL. if (DEBUG) { System.err.println(&quot;Failed to access &quot; + url + &quot;, &quot; + se ); } continue; } // Finally, add the Loader to the search path. validateLookupCache(loaders.size(), urlNoFragString); loaders.add(loader); lmap.put(urlNoFragString, loader); } if (DEBUG_LOOKUP_CACHE) { System.out.println(&quot;NOCACHE: Loading from : &quot; + index ); } return loaders.get(index); } /* * Returns the Loader for the specified base URL. */ private Loader getLoader(final URL url) throws IOException { try { return java.security.AccessController.doPrivileged( new java.security.PrivilegedExceptionAction&lt;Loader&gt;() { public Loader run() throws IOException { String file = url.getFile(); if (file != null &amp;&amp; file.endsWith(&quot;/&quot;)) { if (&quot;file&quot;.equals(url.getProtocol())) { return new FileLoader(url); } else { return new Loader(url); } } else { return new JarLoader(url, jarHandler, lmap, acc); } } }, acc); } catch (java.security.PrivilegedActionException pae) { throw (IOException)pae.getException(); } }}","link":"/2020/06/11/URLClassPath%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Vim笔记","text":"参考资料：《Vim 7.4 中文手册》，《Vim实用技巧》 1、查找某个单词时，可以用/，？；也可在普通模式下，光标定位在该单词下，输入*，#。 2、关于标记 123456// '为单引号'' 跳转回刚才的位置ma 设置标记 【小写是文件内的，大写是全局的】'a 跳转到a的标记处&lt;Ctrl-i&gt; 跳转到相对新的位置&lt;Ctrl-o&gt; 跳转到相对旧的位置 3、一些特殊标记 1234' 跳转前的光标位置&quot; 最后编辑的光标位置[ 最后修改的开始位置] 最后修改的结束位置 4、Redo/Undo 123456789u undo&lt;Ctrl-r&gt; redo// 撤销树:undolist 查看撤销树:g- 时间点后退:g+ 时间点前进:undo num 跳转到某一个节点上:earlier 10s 回到10秒前 m:代表分钟，h:代表小时，d:代表天 5、点命令 . 重复最后一次的修改操作，重复任何除&quot;u&quot;（撤销），&lt;C-R&gt;和冒号命令外的修改 6、可视模式 12v 逐光标选择，可视模式下可用：o,O移动到对角上或另一边上。V 按行选择 7、文本对象有 123456w word s sentence p passage(or) ()内容 [or] []中内容{or} {}中内 8、大小写 1234567~ 交换大小写U 转换成大写 u 转换成小写guw 把这个单词变成小写gUw 把这个单词变成大写g~~ 把本行转换大写// 可视模式下，可直接用U,u来转换。 9、文件操作 12345678gf（光标移动到文件下）:find 文件名 可以添加路径： :set path+=path:args *.txt 可以打开多个文件 // 使用next,previous等来移动:argo command 所有文件执行命令:saveas newname 文件另存为newname:read {filename} 将某个文件读入某行:.,$write tempo 将部分本文件写入tempo文件 :.write &gt;&gt;tempo 将当前行追加入tempo文件 10、使用寄存器 12345678910111213141516171）特殊寄存器： &quot;寄存器 默认存储器。内容是最近删除或者复制内容。 0寄存器 存储复制内容2）拷贝/粘贴：拷贝 &quot;fyas 拷贝一个句子到寄存器f &quot;fYas 拷贝一个句子增加到寄存器f 粘贴 插入模式时 &lt;Ctrl-R&gt; {register} 将寄存器内容插入到光标位置； 普通模式时 &quot;fp 将寄存器f内容粘贴出来3）记录和回放命令：记录q{register} q // 普通模式下，q大写寄存器 q 追加内容执行宏@{register} 第二次开始就可以用@@ 11、分割窗口：split vsplit 12&lt;Ctrl-W&gt; w h j k l t b变换窗口(top bottom)&lt;Ctrl-W&gt; H J K L 移动窗口(top bottom) 12、折叠 12345678910111213zf 创建一个折叠zo 打开一个折叠zc 关闭一个折叠zr 减少折叠zm 折叠更多如果你有一个嵌套了好几层深的折叠，可以用如下两个命令操作：zR 这几个嵌套全部打开zM 这几个嵌套全部关闭还可以用如下命令快速禁止和恢复折叠功能：zn 快速禁止折叠功能zN 快速恢复折叠功能 13、替换 123456789101112131415:%substitute/from/to/gc主要参数： %：表示所有行 g：表示global全局 c:confirm,确认行范围参数： . ：表示当行 0：表示首行 $：表示末行 Num：表示某一行行范围示例： :1,5s/this/that/g 1到5行上执行替换命令。 :54s/President/Fool/ 指定第54行进行替换 14、global命令： 1:[range]global/{pattern}/{command} //其中pattern，会让你找到符合该模式的某一行 15、反转行顺序 1:g/^/m 0 //其中m是move的意思 16、单词统计 1g&lt;Ctrl-g&gt; 17、命令行窗口 1q: 可以编辑其中的命令，并执行。 18、缓冲区列表： 123456789101112131415查看命令:buffers或者:ls打开一个缓冲区： :buffer 2(缓冲区号):buffer name(缓冲区文件名)变换缓冲区： :bnext :bprevious :bfist :blast删除一个缓冲区： :bdelete 3 19、加密 123vim -x exam.txt 启用加密set key=启用/关闭加密:X 已经打开文件后实施加密 20、插入模式时更正 12&lt;Ctrl-W&gt; 删除该词&lt;Ctrl-U&gt; 删除本行 21、自动补全 1234567891011&lt;C-P&gt;或者&lt;C-N&gt;补全特定文本： &lt;C-X&gt;&lt;C-F&gt; 文件名 &lt;C-X&gt;&lt;C-L&gt; 整行 &lt;C-X&gt;&lt;C-D&gt; 宏定义 &lt;C-X&gt;&lt;C-I&gt; 当前文件以及所包含的的文件 &lt;C-X&gt;&lt;C-K&gt; 字典文件内的单词 &lt;C-X&gt;&lt;C-T&gt; 同义词词典文件内的单词 &lt;C-X&gt;&lt;C-]&gt; 标签 &lt;C-X&gt;&lt;C-V&gt; Vim命令行 22、从另一行拷贝 123yy/p yy复制，p粘贴&lt;C-Y&gt; 该命令插入光标上方的字符&lt;C-E&gt; 该命令插入光标下方的字符 23、数字加减 1234普通模式下，光标移动到数字下： &lt;C-A&gt; 增加13&lt;C-A&gt; 增加3&lt;C-X&gt; 减去1 24、单个模式里匹配大小写敏感 12\\c 在模式前添加\\c，忽略本次大小写敏感\\C 在模式前添加\\C，本次匹配大小写敏感","link":"/2022/05/20/Vim%E7%AC%94%E8%AE%B0/"},{"title":"Webmethod的IS加入Cluster异常","text":"一、问题描述前天晚上建华重启Webmethod IS后发现IS无法正常加入Cluster。管理端报错如下， 二、解决路径1）通过堡垒机登陆该机器查看IS启动日志server.log，发现有如下异常信息： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677782021-03-02 00:07:55 CST [ISS.0017.0001E] An error was encountered parsing SoftwareAG-IS-Core.xml: net.sf.ehcache.CacheException: Unable to load class net.sf.ehcache.terracotta.ExpressEnterpriseTerracottaClusteredInstanceFactory. Initial cause was org.terracotta.toolkit.ToolkitInstantiationException: java.lang.RuntimeException: Unable to create toolkit. at net.sf.ehcache.util.ClassLoaderUtil.createNewInstance(ClassLoaderUtil.java:90) at net.sf.ehcache.terracotta.TerracottaClusteredInstanceHelper.newClusteredInstanceFactory(TerracottaClusteredInstanceHelper.java:157) at net.sf.ehcache.terracotta.TerracottaClient.createNewClusteredInstanceFactory(TerracottaClient.java:180) at net.sf.ehcache.terracotta.TerracottaClient.createClusteredInstanceFactory(TerracottaClient.java:129) at net.sf.ehcache.CacheManager.doInit(CacheManager.java:463) at net.sf.ehcache.CacheManager.init(CacheManager.java:395) at net.sf.ehcache.CacheManager.&lt;init&gt;(CacheManager.java:270) at net.sf.ehcache.CacheManager.newInstance(CacheManager.java:1116) at net.sf.ehcache.CacheManager.newInstance(CacheManager.java:1092) at com.wm.app.b2b.server.cache.config.CacheManagerConfig.readConfiguration(CacheManagerConfig.java:311) at com.wm.app.b2b.server.cache.config.CacheManagerConfig.readConfiguration(CacheManagerConfig.java:365) at com.wm.app.b2b.server.cache.config.CacheManagerReader.call(CacheManagerReader.java:33) at com.wm.app.b2b.server.cache.config.CacheManagerReader.call(CacheManagerReader.java:13) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.terracotta.toolkit.ToolkitInstantiationException: java.lang.RuntimeException: Unable to create toolkit. at org.terracotta.modules.ehcache.TerracottaToolkitBuilder.createToolkit(TerracottaToolkitBuilder.java:65) at org.terracotta.modules.ehcache.TerracottaToolkitBuilder.buildToolkit(TerracottaToolkitBuilder.java:58) at org.terracotta.modules.ehcache.ToolkitInstanceFactoryImpl.createTerracottaToolkit(ToolkitInstanceFactoryImpl.java:183) at org.terracotta.modules.ehcache.ToolkitInstanceFactoryImpl.&lt;init&gt;(ToolkitInstanceFactoryImpl.java:119) at org.terracotta.modules.ehcache.ToolkitInstanceFactoryImpl.&lt;init&gt;(ToolkitInstanceFactoryImpl.java:129) at org.terracotta.modules.ehcache.EnterpriseToolkitInstanceFactory.&lt;init&gt;(EnterpriseToolkitInstanceFactory.java:23) at org.terracotta.modules.ehcache.store.EnterpriseTerracottaClusteredInstanceFactory.createToolkitInstanceFactory(EnterpriseTerracottaClusteredInstanceFactory.java:21) at org.terracotta.modules.ehcache.store.TerracottaClusteredInstanceFactory.&lt;init&gt;(TerracottaClusteredInstanceFactory.java:65) at org.terracotta.modules.ehcache.store.EnterpriseTerracottaClusteredInstanceFactory.&lt;init&gt;(EnterpriseTerracottaClusteredInstanceFactory.java:15) at net.sf.ehcache.terracotta.ExpressEnterpriseTerracottaClusteredInstanceFactory.&lt;init&gt;(ExpressEnterpriseTerracottaClusteredInstanceFactory.java:11) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at net.sf.ehcache.util.ClassLoaderUtil.createNewInstance(ClassLoaderUtil.java:73) ... 16 moreCaused by: org.terracotta.toolkit.ToolkitInstantiationException: java.lang.RuntimeException: Unable to create toolkit. at com.terracotta.toolkit.api.TerracottaToolkitFactoryService.createToolkit(TerracottaToolkitFactoryService.java:63) at org.terracotta.toolkit.ToolkitFactory.create(ToolkitFactory.java:100) at org.terracotta.toolkit.ToolkitFactory.createToolkit(ToolkitFactory.java:84) at org.terracotta.modules.ehcache.TerracottaToolkitBuilder.createToolkit(TerracottaToolkitBuilder.java:63) ... 30 moreCaused by: java.lang.RuntimeException: Unable to create toolkit. at com.terracotta.toolkit.client.TerracottaToolkitCreator.createToolkit(TerracottaToolkitCreator.java:95) at com.terracotta.toolkit.api.EnterpriseTerracottaToolkitFactoryService.createToolkit(EnterpriseTerracottaToolkitFactoryService.java:17) at com.terracotta.toolkit.api.TerracottaToolkitFactoryService.createToolkit(TerracottaToolkitFactoryService.java:58) ... 33 moreCaused by: java.lang.RuntimeException: java.lang.RuntimeException: java.lang.IllegalStateException: Your product key only allows maximum 20 clients to connect. at com.terracotta.toolkit.express.TerracottaInternalClientImpl.init(TerracottaInternalClientImpl.java:101) at com.terracotta.toolkit.client.TerracottaToolkitCreator.createInternalToolkit(TerracottaToolkitCreator.java:154) at com.terracotta.toolkit.client.TerracottaToolkitCreator.createInternalToolkitSynchronously(TerracottaToolkitCreator.java:111) at com.terracotta.toolkit.client.TerracottaToolkitCreator.createToolkit(TerracottaToolkitCreator.java:78) ... 35 moreCaused by: java.lang.RuntimeException: java.lang.IllegalStateException: Your product key only allows maximum 20 clients to connect. at com.tc.lang.StartupHelper.startUp(StartupHelper.java:53) at com.tc.object.DistributedObjectClientFactory.create(DistributedObjectClientFactory.java:157) at com.terracotta.toolkit.express.CreateClient$ClientCreatorCallableImpl.call(CreateClient.java:123) at com.terracotta.toolkit.express.TerracottaInternalClientImpl.init(TerracottaInternalClientImpl.java:93) ... 38 moreCaused by: java.lang.IllegalStateException: Your product key only allows maximum 20 clients to connect. at com.tc.object.DistributedObjectClient.openChannel(DistributedObjectClient.java:838) at com.tc.object.DistributedObjectClient.start(DistributedObjectClient.java:798) at com.tc.object.DistributedObjectClientFactory$2.execute(DistributedObjectClientFactory.java:138) at com.tc.lang.StartupHelper.startUp(StartupHelper.java:50) ... 41 moreCaused by: com.tc.net.MaxConnectionsExceededException: Your product key only allows maximum 20 clients to connect. at com.tc.net.protocol.transport.ClientMessageTransport.handleHandshakeError(ClientMessageTransport.java:139) at com.tc.net.protocol.transport.ClientMessageTransport.handshakeConnection(ClientMessageTransport.java:361) at com.tc.net.protocol.transport.ClientMessageTransport.openConnection(ClientMessageTransport.java:326) at com.tc.net.protocol.transport.ClientConnectionEstablisher.connectTryAllOnce(ClientConnectionEstablisher.java:156) at com.tc.net.protocol.transport.ClientConnectionEstablisher.open(ClientConnectionEstablisher.java:143) at com.tc.net.protocol.transport.ClientMessageTransport.open(ClientMessageTransport.java:113) at com.tc.net.protocol.delivery.OnceAndOnlyOnceProtocolNetworkLayerImpl.open(OnceAndOnlyOnceProtocolNetworkLayerImpl.java:294) at com.tc.net.protocol.tcm.ClientMessageChannelImpl.open(ClientMessageChannelImpl.java:108) at com.tc.object.DSOClientMessageChannelImpl.open(DSOClientMessageChannelImpl.java:96) at com.tc.object.DistributedObjectClient.openChannel(DistributedObjectClient.java:825) ... 44 more. See the Integration Server error log for the full stack trace. 2）根据Webmethod官网的帖子，验证license是否一致。由于没有账号看不到帖子上的日志信息，先验证license三是否一致。经验证发现一致，排除license过期可能。 3）考虑是由于连接数达到上限导致的，于是登陆TC集群的所有机器查看TC的连接数，执行命令： 12ps -ef | grep terracotta # 找到对应进程号netstat -anp | grep terracotta_pid # 查看连接数 通过该命令发现TC是主备模式，只有一台处于激活态（通过命令查看连接数，有连接的即是激活的TC），如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657[wm99@A01-R14-I148-67 ~]$ netstat -anp | grep 45409(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)tcp6 0 0 :::9530 :::* LISTEN 45409/javatcp6 0 0 :::9540 :::* LISTEN 45409/javatcp6 0 0 :::9510 :::* LISTEN 45409/javatcp6 0 0 :::44527 :::* LISTEN 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.99:44369 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9530 172.20.97.177:60588 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.20.97.177:43834 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.20.97.177:44208 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.85:44472 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.99:44490 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:45409 10.176.86.248:21600 ESTABLISHED -tcp6 0 0 172.28.148.67:9510 172.28.148.66:38103 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.99:44455 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.67:43806 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.99:44420 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.85:44129 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.67:43854 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.20.97.177:44138 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.20.97.177:44068 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.20.97.177:43904 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.85:44308 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.66:38157 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.67:43840 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.66:38695 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.66:38731 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.99:44010 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.20.97.177:44103 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.20.97.177:43869 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.20.97.177:43939 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.67:43862 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.67:43871 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.66:38651 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9530 172.28.148.66:41151 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.66:38068 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.85:44254 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.67:43842 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.20.97.177:43616 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.85:44393 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.66:38313 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.67:43867 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.85:44773 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.99:44197 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.85:44572 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.85:44810 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.99:44652 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.66:38266 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.99:44120 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.67:43853 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.85:44650 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.66:38495 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.178.99:44595 ESTABLISHED 45409/javatcp6 0 0 172.28.148.67:9510 172.28.148.67:43857 ESTABLISHED 45409/javaunix 2 [ ] STREAM CONNECTED 483755797 45409/javaunix 2 [ ] STREAM CONNECTED 483975815 45409/java 然后重启该TC，IS成功加入cluster。 三、总结可通过命令netstat -anp | grep pid查看连接数，排查一些连接数量受限的问题。 # 参考 https://tech.forums.softwareag.com/t/clustering-of-is-9-10-with-terracotta-server-array/193340","link":"/2021/03/03/Webmethod%E7%9A%84IS%E5%8A%A0%E5%85%A5Cluster%E5%BC%82%E5%B8%B8/"},{"title":"Zookeeper概念","text":"一、Zookeeper协调框架1、Zookeeper是一个基于内存的分布式协调框架。其暴漏一些简单元语，基于此可以synchronization、configuration maintenance、group and naming。 2、关键特性 文件系统式结构+监听通知 3、Zookeeper设计目标 1）简单易用。提供类文件系统的内存存储结构，方便理解和使用。Java可使用Curator与ZK交互。 2）支持副本。一台Server故障时，客户端会自动连接到其他Server。 3）有序。Zookeeper为事务和更新提供数字标识。 4）性能好。Zookeeper在读多写少的场景下表现优异。 4、常用场景 1）分布式锁：公平锁、非公平锁、读写锁 2）注册中心：如jsf 3）Leader选举 二、一致性保证 Sequential Consistency - Updates from a client will be applied in the order that they were sent. Atomicity - Updates either succeed or fail. No partial results. Single System Image - A client will see the same view of the service regardless of the server that it connects to. i.e., a client will never see an older view of the system even if the client fails over to a different server with the same session. Reliability - Once an update has been applied, it will persist from that time forward until a client overwrites the update. Timeliness - The clients view of the system is guaranteed to be up-to-date within a certain time bound. 三、Zookeeper持久化1、快照类似Redis RDB 2、事务日志类似Redis AOF 落盘配置： 12// 默认强制落盘zookeeper.forceSync=true 四、ZAB 1、原子广播/崩溃恢复 参考：常见分布式中间件的共识协议 2、多级队列 五、ZK集群1、三个角色 1）leader：处理读请求，写请求 2）follower：处理读请求，可参与选举变为leader 3）observer：处理读请求 六、实现分布式锁1、非公平锁 利用对同一个临时节点的创建和监听机制实现。容易引起羊群效应，也就是解锁时会signalAll，可使用公平锁实现方式。 2、公平锁 利用临时有序节点实现，创建临时顺序节点后，若是最小节点，获取锁；若不是最小的节点，则监听前一个节点。 3、读写锁 在公平锁基础上，对临时节点进行读写分类。读节点监听前面的写节点，写节点监听前一个写节点或者前一个写节点后的读节点。 # 参考 https://zookeeper.apache.org/doc/r3.8.0/zookeeperOver.html https://blog.51cto.com/stefanxfy/4722107","link":"/2022/03/14/Zookeeper%E6%A6%82%E5%BF%B5/"},{"title":"cacert证书查看和导入","text":"一、使用keytool命令KeyTool命令一览1）KeyTool命令 1234567891011121314151617181920212223$ keytool -helpKey and Certificate Management ToolCommands: -certreq Generates a certificate request -changealias Changes an entry's alias -delete Deletes an entry -exportcert Exports certificate -genkeypair Generates a key pair -genseckey Generates a secret key -gencert Generates certificate from a certificate request -importcert Imports a certificate or a certificate chain -importpass Imports a password -importkeystore Imports one or all entries from another keystore -keypasswd Changes the key password of an entry -list Lists entries in a keystore -printcert Prints the content of a certificate -printcertreq Prints the content of a certificate request -printcrl Prints the content of a CRL file -storepasswd Changes the store password of a keystoreUse &quot;keytool -command_name -help&quot; for usage of command_name 2）证书查看命令1234567891011121314151617181920$ keytool -list -helpkeytool -list [OPTION]...Lists entries in a keystoreOptions: -rfc output in RFC style -alias &lt;alias&gt; alias name of the entry to process -keystore &lt;keystore&gt; keystore name -storepass &lt;arg&gt; keystore password -storetype &lt;storetype&gt; keystore type -providername &lt;providername&gt; provider name -providerclass &lt;providerclass&gt; provider class name -providerarg &lt;arg&gt; provider argument -providerpath &lt;pathlist&gt; provider classpath -v verbose output -protected password through protected mechanismUse &quot;keytool -help&quot; for all available commands 3）证书导入命令1234567891011121314151617181920212223$ keytool -importcert -helpkeytool -importcert [OPTION]...Imports a certificate or a certificate chainOptions: -noprompt do not prompt -trustcacerts trust certificates from cacerts -protected password through protected mechanism -alias &lt;alias&gt; alias name of the entry to process -file &lt;filename&gt; input file name -keypass &lt;arg&gt; key password -keystore &lt;keystore&gt; keystore name -storepass &lt;arg&gt; keystore password -storetype &lt;storetype&gt; keystore type -providername &lt;providername&gt; provider name -providerclass &lt;providerclass&gt; provider class name -providerarg &lt;arg&gt; provider argument -providerpath &lt;pathlist&gt; provider classpath -v verbose outputUse &quot;keytool -help&quot; for all available commands 证书查看1）查看所有证书12345678910111213141516171819202122232425262728$ keytool -list -keystore cacerts -storepass changeit -vKeystore type: jksKeystore provider: SUNYour keystore contains 154 entriesAlias name: debian:go_daddy_class_2_ca.pemCreation date: Jan 11, 2018Entry type: trustedCertEntryOwner: OU=Go Daddy Class 2 Certification Authority, O=&quot;The Go Daddy Group, Inc.&quot;, C=USIssuer: OU=Go Daddy Class 2 Certification Authority, O=&quot;The Go Daddy Group, Inc.&quot;, C=USSerial number: 0Valid from: Wed Jun 30 01:06:20 CST 2004 until: Fri Jun 30 01:06:20 CST 2034Certificate fingerprints: SHA1: 27:96:BA:E6:3F:18:01:E2:77:26:1B:A0:D7:77:70:02:8F:20:EE:E4 SHA256: C3:84:6B:F2:4B:9E:93:CA:64:27:4C:0E:C6:7C:1E:CC:5E:02:4F:FC:AC:D2:D7:40:19:35:0E:81:FE:54:6A:E4Signature algorithm name: SHA1withRSASubject Public Key Algorithm: 2048-bit RSA key (3)Version: {10}Extensions: ...**************************************************************************************其他153个证书 2）查看指定证书12345678910111213141516171819$ keytool -list -keystore cacerts -storepass changeit -v -alias debian:go_daddy_class_2_ca.pemAlias name: debian:go_daddy_class_2_ca.pemCreation date: Jan 11, 2018Entry type: trustedCertEntryOwner: OU=Go Daddy Class 2 Certification Authority, O=&quot;The Go Daddy Group, Inc.&quot;, C=USIssuer: OU=Go Daddy Class 2 Certification Authority, O=&quot;The Go Daddy Group, Inc.&quot;, C=USSerial number: 0Valid from: Wed Jun 30 01:06:20 CST 2004 until: Fri Jun 30 01:06:20 CST 2034Certificate fingerprints: SHA1: 27:96:BA:E6:3F:18:01:E2:77:26:1B:A0:D7:77:70:02:8F:20:EE:E4 SHA256: C3:84:6B:F2:4B:9E:93:CA:64:27:4C:0E:C6:7C:1E:CC:5E:02:4F:FC:AC:D2:D7:40:19:35:0E:81:FE:54:6A:E4Signature algorithm name: SHA1withRSASubject Public Key Algorithm: 2048-bit RSA key (3)Version: {10}Extensions: ... 3）查看证书RFC格式123456789101112131415161718192021222324252627282930$ keytool -list -keystore cacerts -storepass changeit -rfc -alias debian:go_daddy_class_2_ca.pemAlias name: debian:go_daddy_class_2_ca.pemCreation date: Jan 11, 2018Entry type: trustedCertEntry-----BEGIN CERTIFICATE-----MIIEADCCAuigAwIBAgIBADANBgkqhkiG9w0BAQUFADBjMQswCQYDVQQGEwJVUzEhMB8GA1UEChMYVGhlIEdvIERhZGR5IEdyb3VwLCBJbmMuMTEwLwYDVQQLEyhHbyBEYWRkeSBDbGFzcyAyIENlcnRpZmljYXRpb24gQXV0aG9yaXR5MB4XDTA0MDYyOTE3MDYyMFoXDTM0MDYyOTE3MDYyMFowYzELMAkGA1UEBhMCVVMxITAfBgNVBAoTGFRoZSBHbyBEYWRkeSBHcm91cCwgSW5jLjExMC8GA1UECxMoR28gRGFkZHkgQ2xhc3MgMiBDZXJ0aWZpY2F0aW9uIEF1dGhvcml0eTCCASAwDQYJKoZIhvcNAQEBBQADggENADCCAQgCggEBAN6d1+pXGEmhW+vXX0iG6r7d/+TvZxz0ZWizV3GgXne77ZtJ6XCAPVYYYwhv2vLM0D9/AlQiVBDYsoHUwHU9S3/Hd8M+eKsaA7Ugay9qK7HFiH7Eux6wwdhFJ2+qN1j3hybX2C32qRe3H3I2TqYXP2WYktsqbl2i/ojgC95/5Y0V4evLOtXiEqITLdiOr18SPaAIBQi2XKVlOARFmR6jYGB0xUGlcmIbYsUfb18aQr4CUWWoriMYavx4A6lNf4DD+qta/KFApMoZFv6yyO9ecw3ud72a9nmYvLEHZ6IVDd2gWMZEewo+YihfukEHU1jPEX44dMX4/7VpkI+EdOqXG68CAQOjgcAwgb0wHQYDVR0OBBYEFNLEsNKR1EwRcbNhyz2h/t2oatTjMIGNBgNVHSMEgYUwgYKAFNLEsNKR1EwRcbNhyz2h/t2oatTjoWekZTBjMQswCQYDVQQGEwJVUzEhMB8GA1UEChMYVGhlIEdvIERhZGR5IEdyb3VwLCBJbmMuMTEwLwYDVQQLEyhHbyBEYWRkeSBDbGFzcyAyIENlcnRpZmljYXRpb24gQXV0aG9yaXR5ggEAMAwGA1UdEwQFMAMBAf8wDQYJKoZIhvcNAQEFBQADggEBADJL87LKPpH8EsahB4yOd6AzBhRckB4Y9wimPQoZ+YeAEW5p5JYXMP80kWNyOO7MHAGjHZQopDH2esRU1/blMVgDoszOYtuURXO1v0XJJLXVggKtI3lpjbi2Tc7PTMozI+gciKqdi0FuFskg5YmezTvacPd+mSYgFFQlq25zheabIZ0KbIIOqPjCDPoQHmyW74cNxA9hi63ugyuV+I6ShHI56yDqg+2DzZduCLzrTia2cyvk0/ZM/iZx4mERdEr/VxqHD3VILs9RaRegAhJhldXRQLIQTO7ErBBDpqWeCtWVYpoNz4iCxTIM5CufReYNnyicsbkqWletNw+vHX/bvZ8=-----END CERTIFICATE----- 证书导入123456789101112131415161718$ keytool -importcert -keystore cacerts -storepass changeit \\ -file jianshu.com.cert -alias jianshu -trustcacerts -vOwner: CN=*.jianshu.com, O=&quot;Shanghai Bai Ji Information Technology Co,. Ltd&quot;, L=Shanghai, ST=Shanghai, C=CNIssuer: CN=DigiCert TLS RSA SHA256 2020 CA1, O=DigiCert Inc, C=USSerial number: 50396147162fd8a9d02f112b1c9df1cValid from: Fri Oct 08 08:00:00 CST 2021 until: Wed Nov 09 07:59:59 CST 2022Certificate fingerprints: SHA1: 96:99:E0:31:22:25:FA:E5:DD:72:E9:E5:C4:1D:1E:AF:BE:E9:DB:4D SHA256: DE:E0:96:F1:6A:3E:ED:7C:8C:4E:60:A6:63:37:80:50:AE:63:EA:57:C0:20:2C:1A:B3:FD:49:31:1D:37:89:69Signature algorithm name: SHA256withRSASubject Public Key Algorithm: 2048-bit RSA key (3)Version: {10}...Trust this certificate? [no]: yCertificate was added to keystore[Storing cacerts] 二、GUI工具-KeyStore Explorer 开源，简洁，跨平台。 地址：https://keystore-explorer.org/index.html 1）安装后启动应用： 2）软件界面： # 参考 https://keystore-explorer.org/index.html","link":"/2021/12/15/cacert%E8%AF%81%E4%B9%A6%E6%9F%A5%E7%9C%8B%E5%92%8C%E5%AF%BC%E5%85%A5/"},{"title":"commons-io依赖冲突","text":"一、问题描述昨日夜间接到研发反馈，EDI商家新上线后启动异常，需要协助排查，异常信息为：java.lang.NoSuchMethodError: org.apache.commons.io.IOUtils.toString(Ljava/io/InputStream;Ljava/nio/charset/Charset;)Ljava/lang/String; 二、问题排查 由异常原因可知，肯定是commons-io包发生了冲突。 1）查看打包的commons-io版本发现打的Package中有两个包： commons-io-2.5.jar commons-io-1.3.2.jar 由上判断两个包的groupId应该不同，导致maven没有依赖调停。 2）确认两者的groupId是否相同 jar name GroupId in jar GroupId in pom.xml commons-io-2.5.jar commons-io commons-io commons-io-1.3.2.jar commons-io org.apache.commons 依赖树解析时根据pom.xml判断，故此处两者的groupId是不同的。 根据maven编译时的下载地址获取两个pom.xml如下： commons-io-2.5.jar 123456789101112131415&lt;?xml version=&quot;1.0&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;parent&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-parent&lt;/artifactId&gt; &lt;version&gt;39&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;name&gt;Apache Commons IO&lt;/name&gt; ...&lt;/project&gt; commons-io-1.3.2.jar 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;description&gt;POM was created by Sonatype Nexus&lt;/description&gt;&lt;/project&gt; 以上发现两者的groupId不同，印证了第一步猜测。 3）对比与之前编译日志，找到处理commons-io时是否有差异 已知公司内部私服在白天下午发生故障，执行了恢复操作。而冲突在此之后，期间工程的pom.xml未发生变化。 无commons-io冲突日志 123456789101112Downloaded from central: http://artifactory.jd.com/libs-releases/org/apache/apache/16/apache-16.pom (16 kB at 574 kB/s)Downloading from central: http://artifactory.jd.com/libs-releases/org/apache/commons/commons-io/1.3.2/commons-io-1.3.2.pomProgress (1): 640 BDownloaded from central: http://artifactory.jd.com/libs-releases/org/apache/commons/commons-io/1.3.2/commons-io-1.3.2.pom (640 B at 28 kB/s)Downloading from central: http://artifactory.jd.com/libs-releases/commons-io/commons-io/1.3.2/commons-io-1.3.2.pomProgress (1): 2.2/11 kBProgress (1): 6.3/11 kBProgress (1): 10/11 kB Progress (1): 11 kB Downloaded from central: http://artifactory.jd.com/libs-releases/commons-io/commons-io/1.3.2/commons-io-1.3.2.pom (11 kB at 450 kB/s) 有commons-io冲突日志 1234Downloading from central: http://artifactory.jd.com/libs-releases/org/apache/commons/commons-io/1.3.2/commons-io-1.3.2.pomProgress (1): 464 BDownloaded from central: http://artifactory.jd.com/libs-releases/org/apache/commons/commons-io/1.3.2/commons-io-1.3.2.pom (464 B at 18 kB/s) 从日志里看，两者在下载commons-io-1.3.2.pom时有差异。 无冲突的进行了重定向操作，这就可以解释之前为何没有commons-io冲突了。 http://artifactory.jd.com/libs-releases/org/apache/commons/commons-io/1.3.2/commons-io-1.3.2.pom 重定向为： http://artifactory.jd.com/libs-releases/commons-io/commons-io/1.3.2/commons-io-1.3.2.pom 4）查看本地缓存的旧pom路径*.m2/org/apache/commons/common-io/1.3.2/commons-io-1.3.2.pom* 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;distributionManagement&gt; &lt;relocation&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;message&gt;https://issues.sonatype.org/browse/MVNCENTRAL-244&lt;/message&gt; &lt;/relocation&gt; &lt;/distributionManagement&gt;&lt;/project&gt; 发现本地缓存的pom有relocation标签，进行了重定向操作。也解释了之前无冲突时，commons-io重定向下载。 5）查看公司内部私服发现有两个仓库内都有这个commons-io-1.3.2.pom。 其中中心仓库的pom是带relocation标签的，而yhd_sumclub_release仓库则是不带relocation标签的。 由此猜测下载时使用了yhd_sumclub_release的pom，导致了本次冲突。 三、问题原因经排查应该是公司内新增yhd_sumclub_release仓库中的错误pom文件导致了冲突。需要及时反馈给相关团队。 四、后续次日发现线上打包恢复正常了。我于是在本机尝试再次请求该地址： 1）浏览器请求： 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;description&gt;POM was created by Sonatype Nexus&lt;/description&gt;&lt;/project&gt; 2）命令请求： 12345678910111213141516$ curl http://artifactory.jd.com/libs-releases/org/apache/commons/commons-io/1.3.2/commons-io-1.3.2.pom&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;distributionManagement&gt; &lt;relocation&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;message&gt;https://issues.sonatype.org/browse/MVNCENTRAL-244&lt;/message&gt; &lt;/relocation&gt; &lt;/distributionManagement&gt;&lt;/project&gt; 以上两个结果发现，浏览器请求结果还是错误的。于是观察请求详情发现其使用了本地磁盘缓存，清空缓存后也恢复正常。 以上，本次commons-io冲突告一段落。 # 参考 浏览器是根据什么决定「from disk cache」与「from memory cache」？","link":"/2021/09/15/commons-io%E4%BE%9D%E8%B5%96%E5%86%B2%E7%AA%81/"},{"title":"XSRF和XSS","text":"一、XSRF XSRF（Cross-site request forgery），即跨站请求伪造攻击。 XSRF发生过程： 1）首先用户登陆正常网站A站后，服务端会把认证相关信息写入浏览器Cookie； 2）然后用户访问恶意网站B站，B站会构造访问A站的请求，该请求会携带A站写在浏览器中的Cookie； 3）A站服务器在收到B站发出的伪造请求时，A站只根据之前写入的Cookie验证操作的合法性，误执行了跨站的伪造请求。图片来源 二、XSS XSS（Cross-Site Scripting），即跨站脚本攻击。 本质是网站被恶意脚本注入攻击，恶意脚本通过持久化或非持久化的方式从正常可信的网站返回后，完美绕开浏览器同源策略的限制，其可在脚本中读取用户的Cookie信息，以便利用其身份做一些危险操作。 以下图片来源：https://www.myrasecurity.com/en/what-is-cross-site-scripting/ 1）非持久化XSS攻击者构造包含恶意脚本的URL，发送给被害用户让其在浏览器中访问。 2）持久化XSS攻击者把包含恶意脚本的内容上传至目标网站，可被其他用户浏览。 三、XSRF vs XSS 引自：https://portswigger.net/web-security/csrf/xss-vs-csrf CSRF通常只适用于用户能够执行的操作的子集。许多应用程序通常实现CSRF防御，但忽略了一个或两个暴露的操作。相反，成功的XSS攻击通常可以诱导用户执行用户能够执行的任何操作，而不管漏洞出现的功能如何。 CSRF可以描述为一种“单向”漏洞，即攻击者可以诱导受害者发出HTTP请求，但他们无法从该请求中检索响应（所以查询类服务往往不受影响）。相反，XSS是“双向的”，因为攻击者注入的脚本可以发出任意请求、读取响应并将数据导出到攻击者选择的外部域。 1）XSRF：允许攻击者诱导被害者执行一些无法感知的请求到目标网站 目标网站信任用户 攻击者诱导用户的浏览器去发送其伪造的请求到目标网站 目标网站执行了攻击者的请求 2）XSS：允许攻击者执行在受害者的浏览器上执行任意脚本 用户信任目标网站 攻击者把恶意脚本注入到用户信任的网站 用户的浏览器执行了攻击者注入的脚本 # 参考 WIKI: Cross-site_request_forgery WIKI: XSS https://www.myrasecurity.com/en/what-is-cross-site-scripting/ https://portswigger.net/web-security/csrf/xss-vs-csrf","link":"/2021/03/04/XSRF%E5%92%8CXSS/"},{"title":"echo无法清空日志","text":"一、问题描述前段时间webmethod应用所在物理机磁盘满了，于是清理其日志。但是有个通过Log4j2记录的日志文件在执行cat /dev/null | tee *.log后大小又瞬间恢复到原来尺寸。当时感觉应该应该是使用Appender导致的，但时苦于没有找到log4j2.xml配置也就搁置了。 二、问题探究 近期因为log4j2漏洞问题，需要梳理log4j2的配置。在webmethod研发的帮助下，返回查找最终在一个jar包内发现了log4j2.xml，如下所示。 12345678910111213141516171819202122232425262728&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;error&quot; monitorInterval=&quot;3600&quot;&gt; &lt;properties&gt; &lt;property name=&quot;patternLayout&quot;&gt;%X%-5p - %d{yyyy-MM-dd HH:mm:ss} [%t] %l -- %m%n&lt;/property&gt; &lt;/properties&gt; &lt;Appenders&gt; &lt;Console name=&quot;Console&quot; follow=&quot;true&quot;&gt; &lt;PatternLayout pattern=&quot;${patternLayout}&quot;/&gt; &lt;/Console&gt; &lt;RollingRandomAccessFile name=&quot;rollingFile&quot; fileName=&quot;xxxxx.log&quot; filePattern=&quot;xxxx.%d{yyyy-MM-dd}.log.gz&quot;&gt; &lt;PatternLayout charset=&quot;UTF-8&quot; pattern=&quot;${patternLayout}&quot;/&gt; &lt;Policies&gt; &lt;TimeBasedTriggeringPolicy modulate=&quot;true&quot; interval=&quot;1&quot;/&gt; &lt;/Policies&gt; &lt;/RollingRandomAccessFile&gt; &lt;Async name=&quot;async&quot;&gt; &lt;AppenderRef ref=&quot;rollingFile&quot;/&gt; &lt;AppenderRef ref=&quot;Console&quot;/&gt; &lt;/Async&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level=&quot;info&quot; includeLocation=&quot;true&quot;&gt; &lt;AppenderRef ref=&quot;async&quot;/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 三、文档和源码1）文档 https://logging.apache.org/log4j/log4j-2.2/manual/appenders.html#RollingRandomAccessFileAppender The RollingRandomAccessFileAppender is similar to the standard RollingFileAppender except it is always buffered (this cannot be switched off) and internally it uses a ByteBuffer + RandomAccessFile instead of a BufferedOutputStream. 2）源码 a）org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender.Builder构造函数声明org.apache.logging.log4j.core.appender.rolling.RollingRandomAccessFileManager作为文件管理器 b）RollingRandomAccessFileManager使用java.io.RandomAccessFile进行文件访问，如下： 123456789101112private void createFileAfterRollover(final String fileName) throws IOException { this.randomAccessFile = new RandomAccessFile(fileName, &quot;rw&quot;); if (this.isAttributeViewEnabled()) { this.defineAttributeView(Paths.get(fileName)); } if (this.isAppend()) { this.randomAccessFile.seek(this.randomAccessFile.length()); } this.writeHeader();} 四、测试1）运行测试用例 12345678910public class RandomAccessFileTest { @Test public void testWrite() throws IOException, InterruptedException { RandomAccessFile randomAccessFile = new RandomAccessFile(&quot;./test.log&quot;, &quot;rw&quot;); for (int i = 0; i &lt; Integer.MAX_VALUE; i++) { randomAccessFile.writeBytes(String.valueOf(i)); Thread.sleep(1000); } }} 2）bash中执行 1$ cat /dev/null &gt; test.log 3）可观察到文件大小归零后又重新恢复 4）查看文件内容，文件确实被清空了 五、RandomAccessFile https://docs.oracle.com/javase/8/docs/api/java/io/RandomAccessFile.html Instances of this class support both reading and writing to a random access file. A random access file behaves like a large array of bytes stored in the file system. There is a kind of cursor, or index into the implied array, called the file pointer; input operations read bytes starting at the file pointer and advance the file pointer past the bytes read. If the random access file is created in read/write mode, then output operations are also available; output operations write bytes starting at the file pointer and advance the file pointer past the bytes written. Output operations that write past the current end of the implied array cause the array to be extended. The file pointer can be read by the getFilePointer method and set by the seek method. 也就是说RandomAccessFile持有文件描述符，并记录了文件起始位置和读写位置。写入的时候会记录上次读写的位置。 上面测试用例的图解过程如下： 1）RandomAccessFile持有指向文件test.log的文件描述符号，持有文件起始位置和当前写入位置，写入位置随写入递增，指向文件末尾。 2）当RandomAccessFile写完内容”7”后，此时执行cat /dev/null &gt; test.log后，文件内容为空。 3）之后RandomAccessFile接着其之前持有的写入位置进行写入，写入后如下：","link":"/2021/12/20/echo%E6%97%A0%E6%B3%95%E6%B8%85%E7%A9%BA%E6%97%A5%E5%BF%97/"},{"title":"el表达式与BigDecimal","text":"一、问题描述上周四研发使用EDI的数据转换时发现el表达式计算结果不正确，即使用el表达式进行除法的时候结果不对。例如：${numVar/1000}，其中通过日志里观察numVar的变量值为2，但是结果确实0. 二、定位 在数据转换模块增加测试用例，发现结果正常为0.002。 推测numVar类型不对，通过观察流程发现该值是从数据库里读出来的。 通过远程断点发现该值类型为BigDecimal类型，经测试发现如果numVar是Decimal类型，其运算结果就是0. 三、源码分析1234567891011public class NumberOperations { public static final Number div(TypeConverter converter, Object o1, Object o2) { if (o1 == null &amp;&amp; o2 == null) { return LONG_ZERO; } if (isBigDecimalOrBigInteger(o1) || isBigDecimalOrBigInteger(o2)) { return converter.convert(o1, BigDecimal.class).divide(converter.convert(o2, BigDecimal.class), BigDecimal.ROUND_HALF_UP); } return converter.convert(o1, Double.class) / converter.convert(o2, Double.class); }} el计算时如果发现除数和被除数有一个BigDecimal时，就会执行converter.convert(o1, BigDecimal.class).divide(converter.convert(o2, BigDecimal.class), BigDecimal.ROUND_HALF_UP)。即执行除法后四舍五入取整。 四、解决方案${numVar / 1000} 改为${numVar.doubleValue() / 1000}","link":"/2020/11/15/el%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%B8%8EBigDecimal/"},{"title":"explain","text":"mysql5.7以上版本在查看explain时需关闭衍生表优化：set session optimizer_switch='derived_merge=off'，否则会隐藏衍生表的信息； 一、explain概述explain可以显示SQL执行的相关信息，如使用哪个索引，执行顺序等。具体如下： 列名 含义 解释 id select的标识 id大的先执行，id相等由上到下执行 select type 查询类型 table 查询的表名 partitios 匹配的分区名 分库时使用 type 联表类型 描述表之间是如何关联（join）的 ref 与实际索引进行比较的列或常量 possible_keys 可选的索引 key 实际选择的索引 key_len 实际选择的索引的长度 一般用于判断联合索引 rows 待检查行的预估值 filtered 根据条件筛选的行数在表中的百分比 Extra 附加信息 二、select type 值 含义 SIMPLE 简单查询，没使用联表或子查询 PRIMARY 最外层查询 SUBQUERY 子查询 DRIVDE 衍生表 三、type12345678910// 假设有如下表定义：CREATE TABLE `employees` ( `id` int(11) NOT NULL, `first_name` varchar(14) NOT NULL, `last_name` varchar(16) NOT NULL, `gender` enum('M','F') NOT NULL, `hire_date` date NOT NULL, PRIMARY KEY (`emp_no`), KEY `idx_name` (`first_name`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 效率：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all 值 含义 解释 简化理解 举例 system 表中只有一行数据，是const的特例 表中只有一行数据，一般指衍生表 表只有一行记录 const 表中最多只有一行数据符合匹配条件 将主键或唯一索引的所有部分与常量值进行比较时为const，结果集最多有一条 查询条件为主键或唯一索引全部，ref为const select * from employees where id=1 eq_ref 根据前表的每行数据在当前表只能关联一行数据 一般为两个表的链接字段为主键列或唯一索引的所有部分，使得两张表的记录一一对应 联表场景，主键或唯一索引全部，ref为联表字段 select * from employees as a left join dept_emp as b on a.id = b.emp_id ref 对于前一个表中的每个行组合，将从该表中读取具有匹配索引值的所有行 联表时使用键的左边前缀，或者键不是主键或唯一索引全部，使得两张表的记录会出现一对多的情况 查询条件非主键或唯一索引的全部，ref为联表字段 select * from employees where first_name=’wang’ range 使用索引检索给定范围内的行 如使用&lt;&gt;,&gt;,&gt;=,&lt;,&lt;=,in,like,between 走索引，范围查询 index 扫描索引数 常见于不加查询条件的覆盖索引查询 走索引，全表扫描 all 扫描全表 常见于不加查询条件，或查询条件没有加索引 不走索引，全表扫描 四、Extra 值 含义 Using index 只查询索引数即可获得结果集，无需回表 Using index condition 使用索引下推，延迟回表；且减少了需要回表的结果集 Using temporary 解析结果集时需要用到临时表 Using filesort 使用文件排序，数量小时使用内存排序，数量大时使用磁盘排序 参考 https://dev.mysql.com/doc/refman/5.7/en/explain-output.html","link":"/2020/07/28/explain/"},{"title":"VCS简介","text":"一、三类版本控制系统1、本地版本控制系统 1）机制：通过数据库记录文件历次更新的差异，差异以补丁的形式记录对应文件修订前后的内容变化。 2）不足：不支持多开发者协同工作。 3）典型软件：rcs。 2、集中化版本控制系统1）机制：单一的集中管理的服务器保存所有文件的修订版本，协同工作的人们通过客户端连到该服务器，取出最新的文件或提交更新。 2）不足：中央服务器的单点故障可能导致数据丢失。 3）典型软件：CVS，Subversion，Perforce等。 3、分布式版本控制系统1）机制：每个客户端都拥有独立且完整的版本仓库，且客户端地位相等（类似P2P网络），它们之间可相互获取、推送更新。 2）优点： 消除集中版本控制系统的单点故障； 协作开发时，允许单个客户端在本地版本仓库独立提交更新，并在合适时推送给其他客户端或某个约定为中央仓库的客户端。 3）典型软件：Git，Mercurial，Bazaar，Darcs等。 二、Git基础1、Git优势 速度 简单的设计 对非线性开发模式的强力支持（允许上千个并行开发分支） 完全分布式 有能力高效管理类似Linux内核一样的超大规模项目（速度和数据量） 2、Git特性1）保存快照，而非差异 Git关心文件整体内容的变化，而大多数其他系统则关心文件内容的差异。 此特性为多分支并行开发提供了支持。 2）几乎所有操作都是本地操作 速度快 客户端离线时也可进行更新操作 3）时刻保持数据完整性 保存到Git之前，所有数据都要经过Hash运算，并将Hash值作为数据的唯一标识和索引，而非文件名。 Git采用SHA-1算法来生成文件或整个目录的杂凑值，并作为唯一标识。该算法输出160bit哈希值，即40个16进制字符（0-9及a-f）。类似24b9da6552252987aa493b52f8696cd6d3b00373。 4）多数操作仅添加数据 保证历史版本的可回溯 5）三种状态（git status命令当前状态） 原理：通过比较相同文件名所对应的SHA-1值是否相同，来判断文件是否更新。 I、已修改（modified） 状态：工作区的文件已修改，还未暂存。 系统通过比较工作区和暂存区（对应.git/index）内相同文件名的文件的SHA-1值，来判定文件是否更新。 用户可通过git diff命令查看工作区和暂存区内容的具体差异。 II、已暂存（staged） 状态：工作区修改的文件已保存至暂存区，但还未提交。 系统通过比较暂存区（对应.git/index）和Git仓库（对应.git/HEAD）内相同文件名的文件的SHA-1值，来判定文件是否更新。 用户可通过git diff --cached命令查看暂存区和Git仓库的具体内容差异。 III、已提交（committed） 状态：暂存区的文件已提交至版本库。 系统通过比较暂存区和Git仓库内相同文件名的文件的SHA-1值，来判定文件是否更新。（同上） 6）单向性I、当差异发生时提示已修改，已暂存，已提交三种状态，这暗示了Git中更新并提交文件的单向性，工作区 → 暂存区 → Git目录。 II、Git中的版本回退命令git reset和git revert在各自不同参数下的执行结果都满足工作区的版本不旧于暂存区，暂存区的版本不旧于Git目录。 Note：git reset和git revert命令在提交层面上实现回退的思路不同，前者做减法（适合在私有分支上回退），而后者做加法（适合在公共分支上回退）。 III、本质上讲： git不关心文件新旧，只关心文件是否相同（通过相同文件名的SHA-1值判断）。 若相同，直接引用已有文件的SHA-1值，Git仓库内也只会保留一份文件； 若不同，则引用更新后文件的SHA-1值，Git仓库会保有不同版本的文件。 约定更新和提交是单向的。 Note：git add命令后，新增或更新的文件会以blob对象（blob、tree、commit、tag四大对象之一）的形式首次进入./git/objects目录。 三、Git操作清单 接下来的文章将针对不同的场景需求，对Git的命令和操作进行解析和实践。本文依据不同场景对操作进行归类，以此对Git的功能有个全面的认识。 Git自助服务：git help 命令可获取命令详情 1、Git配置 配置基本信息 git config 配置用户信息 配置工具：文本编辑器、差异分析工具 配置忽略文件 vim file .gitignore .git/info/exclude $HOME/.config/git/ignore 2、Git基础操作 获取项目Git仓库 当前目录初始化 git init 现有仓库克隆 git clone 提交更新至Git仓库 跟踪新文件 git add 暂存已修改文件 git add 提交文件 git commit [-a] 撤销操作 修改最后一次提交 git commit --amend 回退Git仓库 git revert | git reset --soft 回退暂存区 git reset [--mixed] | git reset [commit] file 回退工作区 git reset --hard | git checkout [commit] file 储藏与恢复 git stach | git stash pop 查看提交记录 git fsck|git log|git log -g|git reflog 清除未跟踪文件和目录 git clean -df 查看操作 查看当前状态 git status 查看文件差异 git diff|git diff [commit]|git diff --cached commit|git diff [commit] [commit] 查看完整提交历史 git log [-g]|git reflog 3、Git远程仓库操作 管理远程仓库 查看 git remote [-v] 增加 git remote add 修改 git remote rename old-name new-name 删除 git remote rm name 远程仓库交互 抓取数据 git fetch | git pull 推送数据 git push 4、Git标签/分支 标签 标签类型 查看标签 git tag 管理标签 git tag 分支 分支概念和原理 远程分支/跟踪分支 创建分支 git branch | git checkout -b 删除分支 git branch -d 合并分支 git merge 衍合分支 git rebase 开发中的分支工作流程 5、其他补充内容 祖先引用 提交范围 双点语法 三点语法 多点范围 补丁 挑拣(cherry-pick) git调试 文件标注 二分查找 重写历史 修改最近一次提交 修改多个提交 重排提交 压制提交 拆分提交 子模块 #、参考文章 代码回滚：git reset、git checkout和git revert区别和联系 GIT科普系列3：底层存储机制Internal Objects Git 内部原理 - Git 对象 Diff程序的原理 https://en.wikipedia.org/wiki/Git","link":"/2018/01/15/VCS%E7%AE%80%E4%BB%8B/"},{"title":"fastjson升级不兼容的问题","text":"一. 问题描述又日在EDI值班时, 某研发前来询问一种令他困惑的现象, EDI线上流程执行时, 出现函数无法解析的Exception. 二. 尝试路径 这个问题出现在升级fastjson(1.28 –&gt; 1.58)之后, 怀疑是版本不兼容导致. 首先尝试用升级后的版本来重新编译函数所在的工程, 然后Deploy到私服, 重新上线. 结果导致错误升级为:&quot;NoClassDefFoundError：can not initialize class XXX&quot;. 增加日志信息, 发现是由于类冲突. 原因是Deploy函数工程时, 其pom.xml文件内依赖了不同版本的google-collections.删除后复现原始问题. 增加日志信息, 发现是类型转换错误&quot;java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to com.alibaba.fastjson.JSONObject&quot;, 原因时fastjson在1.28和1.58的jsonObject.getJSONArray(anway)方法不兼容导致的, 老版本会针对集合内的元素进行JSONObject转换, 新版本则直接new JSONArray(list). 导致执行迭代方法的时候出现不一致的情况. 三. 反思 尽量用成熟的第三方工具,优先google,apache然后再国内的工具包. 丰富日志后再行动.","link":"/2019/07/05/fastjson%E5%8D%87%E7%BA%A7%E4%B8%8D%E5%85%BC%E5%AE%B9%E7%9A%84%E9%97%AE%E9%A2%98/"},{"title":"go包和模块","text":"一、go包1、两个名词1）*.go内声明的package名，这里简称为packageName 2）*.go所在的文件夹名，这里简称为directoryName 2、先说结论1）packageName和directoryName不强制同名 2）同一目录下的packageName必须一致，否则编译错误 3）import directoryName，而非packageName 3、示例1）当前有工程结构如下 1234go-project|__go.mod|__util |__Echo.go 2）Echo.go内声明的package为utils可以和目录名util不同 1234567package utilsimport &quot;fmt&quot;func Echo(msg string) { fmt.Print(msg)} 二、go模块1、两个名词1）go.mod内声明的module名，这里简称为moduleName 2）go工程所在的远程仓库地址，这里简称为gitUrl 2、先说结论如果go工程要被其他项目引用，moduleName和gitUrl必须一致。 3、依赖解析流程go.mod引入模块的流程为： 根据指定的模块名称，下载指定仓库的指定版本到$GOPATH/src/[modulename] 解析下载的模块go.mod 校验go.mod内声明的module名称是否和引用的一致，若不一致引入失败。 引入模块的依赖，重复以上步骤 4、示例1）go-project/go.mod声明当前module为go-project 123module go-projectgo 1.18 2）提交go-project至github.com/kivihub/go-project 3）其他项目执行go get -u github.com/kivihub/go-project，报错 1234# go get -u github.com/kivihub/go-project@ef72191dgo: github.com/kivihub/go-project@v0.0.0-20220610031119-ef72191dbee9: parsing go.mod: module declares its path as: go-project but was required as: github.com/kivihub/go-project","link":"/2022/06/10/go%E5%8C%85%E5%92%8C%E6%A8%A1%E5%9D%97/"},{"title":"git工作流","text":"一、TBD：Trunk-based development1. 特点 TBD的特点是所有团队成员都在单个主干分支上进行开发。 简单易操作，减少分支切换，流行于SVN（svn trunck = git master） 2. 流程 当需要发布时，先考虑使用标签（tag）,即tag某个commit来作为发布的版本。 如果仅仅依靠tag不能满足要求，则从主干分支创建发布分支。 bug修复在主干分支进行，再cherry-pick到发布分支 二、Git Flow1. 适合场景 适合维护多个发布版本 流程较其他工作流复杂 2. 分支描述1）长期分支 develop：开发分支，稳定后可并入master； master：HEAD总处于可发布态；每个版本对应一个tag； 2）辅助分支 feature 通常是本地分支，合并回develop后删除； may from develop must merge back to develop * (develop)：git merge --no-ff，体现出特性 release 合并回master和develop后删除； may from develop must merge back to develop and master * (master)：git merge --no-ff，体现出特性 * (devlop)：git merge --no-ff，体现出特性 迁出分支后，首先修改为新版本号； hotfix May from master Must merge back to develop and master * (master)：git merge --no-ff，体现出特性 * (devlop)：git merge --no-ff，体现出特性（当release分支存在时优先合并进release分支，由release分支合并进develop） 迁出分支后，首先修改为新版本号； 三、GitHub Flow1）特点： 简单实用 2）流程 master分支中也是代表着稳定的代码。该分支已经或即将被部署在生产环境 当需要进行任何修改时，总是从master分支创建新分支。完成之后通过pull request和相关的代码审查来合并回master分支 hotfix, feature分支都遵循上面的准则； 参考 工作流对比 一个成功的GIT分支模型-GITFLOW TBD介绍 TBD和GitFlow对比 https://www.toptal.com/software/trunk-based-development-git-flow https://www.devbridge.com/articles/branching-strategies-git-flow-vs-trunk-based-development/","link":"/2020/08/19/git%E5%B7%A5%E4%BD%9C%E6%B5%81/"},{"title":"left_join时on后多条件AND","text":"一、left join的ON中多条件AND1）left join的on条件一般只写一个主键关联的字段，例如： 1SELECT * FROM product LEFT JOIN product_details ON product.id = product_details.id; 2）当left join的on条件有多个时，大部分是要通过多个条件限制结果集，应改用inner join，例如： 1SELECT * FROM product LEFT JOIN product_details ON product.id = product_details.id AND product_details.weight &gt; 30 二、实例演示1）准备两个表及初始化数据（语句来源） 123456789101112131415CREATE TABLE `product` ( `id` int(10) unsigned NOT NULL auto_increment, `amount` int(10) unsigned default NULL, PRIMARY KEY (`id`)) ENGINE=MyISAM AUTO_INCREMENT=5 DEFAULT CHARSET=latin1;CREATE TABLE `product_details` ( `id` int(10) unsigned NOT NULL, `weight` int(10) unsigned default NULL, `exist` int(10) unsigned default NULL, PRIMARY KEY (`id`)) ENGINE=MyISAM DEFAULT CHARSET=latin1;INSERT INTO product (id,amount) VALUES (1,100),(2,200),(3,300),(4,400);INSERT INTO product_details (id,weight,exist) VALUES (2,22,0),(4,44,1),(5,55,0),(6,66,1); 表数据如下： 2）执行以下SQL查询 123# 结果符合预期SELECT * FROM product LEFT JOIN product_details ON product.id=product_details.id; 123456# ON的多个条件进行AND，括号不影响结果SELECT * FROM product LEFT JOIN product_details ON product.id=product_details.id AND product.id=2;SELECT * FROM product LEFT JOIN product_details ON (product.id=product_details.id AND product.id=2); 12345SELECT * FROM product LEFT JOIN product_details ON product.id=product_details.id AND product_details.id=2;SELECT * FROM product LEFT JOIN product_details ON (product.id=product_details.id AND product_details.id=2); 1SELECT * FROM product LEFT JOIN product_details ON product.id=2; 1SELECT * FROM product LEFT JOIN product_details ON product_details.id=2; 三、left join匹配原理1）从结果集来看，参考链接： 2）匹配顺序（NLJ为例） 1SELECT * FROM A left join B ON condition1 AND condition2; 如上的LEFT 左侧表A为驱动表，右侧为被驱动表。假设当前使用NLJ的嵌套关联方法，其执行伪代码可简化如下： 12345678910111213141516List rows = new ArrayList();for rowA in table A { List rowAMatchList = new ArrayList(); for rowB in table B { joinRow = rowA join rowB; if (joinRow match (condition1 AND condition2)) { rowAMatchList.add(joinRow); } } if (empty rowAMatchList) { rowAMathList.add(rowA join null); } rows.addAll(rowAMatchList);} # 参考 https://stackoverflow.com/questions/14660330/mysql-left-join-with-multiple-tables https://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins","link":"/2021/05/28/left_join%E6%97%B6on%E5%90%8E%E5%A4%9A%E6%9D%A1%E4%BB%B6AND/"},{"title":"el中函数调用结果始终为null","text":"一、问题描述某日，一研发前来让寻求帮助，“为什么我的函数始终返回空，即使把函数修改为只包含一行抛异常的语句，也是如此。” 二、尝试路径 怀疑IDE函数编译失败，只保留了之前某个始终返回为空的版本。结果，反编译Class发现没问题； 从函数这个点向上溯源，查看调用函数的流程和表达式。结果，发现调用函数的表达式是一个三元表达式，例如“${ condition ? fn:myFunction(), null}”。 根据第2条猜测是由于研发测试时，condition始终为false导致的。根据研发提供的报文证实猜测。 三、反思 一个异常都是发生在一个完整的操作链中的一个节点。我们要做的就是根据这个故障点向上回溯排查原因，直到源头。","link":"/2019/08/10/el%E4%B8%AD%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E7%BB%93%E6%9E%9C%E5%A7%8B%E7%BB%88%E4%B8%BAnull/"},{"title":"maven插件的依赖的查找顺序","text":"maven的依赖下载和查找逻辑 优先下载标签里的依赖及其间接依赖；1）从lib-snapshot，lib-release中仓库下载到本地仓库，并copy到项目target目录； 然后下载及其依赖；1）从plugin-lib中下载插件； 2）插件的依赖 首先，判断本地m2仓库是否已经存在依赖，如果已存在则跳过； 否则，去远程plugin仓库下载； 最后关键的事情说三遍：如果本机m2仓库存在插件的依赖，则plugin不会再去插件仓库下载了。如果本机m2仓库存在插件的依赖，则plugin不会再去插件仓库下载了。如果本机m2仓库存在插件的依赖，则plugin不会再去插件仓库下载了。","link":"/2020/07/13/maven%E6%8F%92%E4%BB%B6%E7%9A%84%E4%BE%9D%E8%B5%96%E7%9A%84%E6%9F%A5%E6%89%BE%E9%A1%BA%E5%BA%8F/"},{"title":"mvn_clean_deploy出错","text":"一、执行命令：mvn clean deploy -Dmaven.test.skip=true报错如下： 1234567[ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy (default-deploy) on project myproject: Deployment failed: repository element was not specified in the POM inside distributionManagement element or in -DaltDeploymentRepository=id::layout::url parameter -&gt; [Help 1][ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException 二、原因：pom里已有distributionManagement元素： 1234567&lt;distributionManagement&gt; &lt;snapshotRepository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;name&gt;JD maven2 repository-snapshots&lt;/name&gt; &lt;url&gt;http://artifactory.jd.com/libs-snapshots-local&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; 但当前的pom的version为0.0.6，是release而非snapshot，所以其与distributionManagement的元素不匹配导致如上错误。","link":"/2020/06/02/mvn_clean_deploy%E5%87%BA%E9%94%99/"},{"title":"openfortivpn使用","text":"VPN客户端和Server之间通过某种VPN协议进行通讯，实现两个私有网络的连通。VPN协议主要有PPTP，L2TP/IPSec，OpenVPN，SSTP，IKEv2五种。本工具是fortiClientVPN的开源版本，即VPN的客户端。 商业版VPN产品，其VPN客户端和Server会支持多种VPN协议，然后协商使用其中一种，此时一般安装其对应的客户端才能正常连接。 引自：https://askubuntu.com/a/1226407 As Fortinet VPN could use several VPN protocolsAnd as we do not know which one-&gt; You’d better use the Forticlient Official client for Linux &amp; UbuntuThen you could export the vpn client xml configuration file from Windows that you will import to the Ubuntu client. 引自官方文档安装1sudo apt install openfortivpn 使用 https://github.com/adrienverge/openfortivpn Simply connect to a VPN: 1openfortivpn vpn-gateway:8443 --username=foo Connect to a VPN using an authentication realm: 1openfortivpn vpn-gateway:8443 --username=foo --realm=bar Store password securely with a pinentry program: 1openfortivpn vpn-gateway:8443 --username=foo --pinentry=pinentry-mac Don’t set IP routes and don’t add VPN nameservers to /etc/resolv.conf: 1openfortivpn vpn-gateway:8443 -u foo --no-routes --no-dns --pppd-no-peerdns Using a configuration file: 1openfortivpn -c /etc/openfortivpn/my-config With /etc/openfortivpn/my-config containing: 1234567host = vpn-gatewayport = 8443username = fooset-dns = 0pppd-use-peerdns = 0# X509 certificate sha256 sum, trust only this one!trusted-cert = e46d4aff08ba6914e64daa85bc6112a422fa7ce16631bff0b592a28556f993db For the full list of config options, see the CONFIGURATION section of 1man openfortivpn 参考 五种VPN协议介绍 how to connect ssl vpn on ubuntu","link":"/2021/09/29/openfortivpn%E4%BD%BF%E7%94%A8/"},{"title":"proxool的log4j冲突","text":"一、背景应用代码的日志框架使用slf4j，绑定log4j2实现。不使用log4j1。 近期对日志依赖调整后，发现如下异常 1234567891011121314Caused by: java.lang.NoClassDefFoundError: org/apache/log4j/ConsoleAppenderat org.logicalcobwebs.logging.impl.Log4JCategoryLog.initialize(Log4JCategoryLog.java:134)at org.logicalcobwebs.logging.impl.Log4JCategoryLog.&lt;init&gt;(Log4JCategoryLog.java:120)at org.logicalcobwebs.logging.impl.Log4jFactory.getInstance(Log4jFactory.java:134)at org.logicalcobwebs.logging.impl.LogFactoryImpl.getInstance(LogFactoryImpl.java:247)at org.logicalcobwebs.logging.LogFactory.getLog(LogFactory.java:380)at org.logicalcobwebs.proxool.configuration.PropertyConfigurator.&lt;clinit&gt;(PropertyConfigurator.java:79)... 66 moreCaused by: java.lang.ClassNotFoundException: org.apache.log4j.ConsoleAppenderat java.net.URLClassLoader.findClass(URLClassLoader.java:381)at java.lang.ClassLoader.loadClass(ClassLoader.java:424)at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)at java.lang.ClassLoader.loadClass(ClassLoader.java:357)... 79 more 二、查看proxool-0.8.0源码123456789101112131415161718192021222324252627282930313233343536373839404142package org.logicalcobwebs.logging.impl;public class LogFactoryImpl extends LogFactory { public LogFactoryImpl () { super (); // 尝试使用log4j guessConfig (); } public Log getInstance (Class clazz) throws LogConfigurationException { if (proxyFactory != null) { return proxyFactory.getInstance (clazz); // line number: 247，调用时发生异常 } return (getInstance (clazz.getName ())); } // 判断Classpath是否有log4j相关类，有的使用它作为日志框架 protected void guessConfig () { if (isLog4JAvailable ()) { proxyFactory = null; try { Class proxyClass = loadClass (&quot;org.logicalcobwebs.logging.impl.Log4jFactory&quot;); if (proxyClass != null) { proxyFactory = (LogFactory) proxyClass.newInstance (); } } catch (Throwable t) { } } } // 判断classpath是否有log4j的类：org.apache.log4j.Category protected boolean isLog4JAvailable () { try { loadClass (&quot;org.apache.log4j.Category&quot;); loadClass (&quot;org.logicalcobwebs.logging.impl.Log4JCategoryLog&quot;); return (true); } catch (Throwable t) { return (false); } }} 三、解决方案11、移除classpath中含org.apache.log4j.Category的类。如log4j-x.jar，log4j-1.2-x.jar。 2、通过配置指定日志框架为JUL。新增配置文件commons-logging.properties。 1org.logicalcobwebs.logging.Log=org.logicalcobwebs.logging.impl.Jdk14Logger 代码逻辑参考：org.logicalcobwebs.logging.impl.LogFactoryImpl#getLogConstructor。 Concrete subclass of LogFactory that implements the following algorithm to dynamically select a logging implementation class to instantiate a wrapper for. Use a factory configuration attribute named org.logicalcobwebs.logging.Log to identify the requested implementation class. Use the org.logicalcobwebs.logging.Log system property to identify the requested implementation class. If Log4J is available, return an instance of org.logicalcobwebs.logging.impl.Log4JCategoryLog. If JDK 1.4 or later is available, return an instance of org.logicalcobwebs.logging.impl.Jdk14Logger.Otherwise, return an instance of org.logicalcobwebs.logging.impl.NoOpLog. 四、解决方案21）proxool的org.logicalcobwebs.logging包的源码来自JCL包org.apache.commons.logging。 2）proxool在0.9.x，源码里不再绑定JCL，而是通过依赖形式引入。 所以，直接把proxool的版本由0.8.0升级至0.9.1，然后新增proxool-cglib-0.9.1。 12345678910&lt;dependency&gt; &lt;groupId&gt;proxool&lt;/groupId&gt; &lt;artifactId&gt;proxool&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;proxool-cglib&lt;/groupId&gt; &lt;artifactId&gt;proxool-cglib&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt;&lt;/dependency&gt; 附、proxool的CHANGE LOG Jakarta’s Commons Logging is now longer bundled with the source and is now a dependency.We had forked this component (at their version 1.02) to make it simpler for us to deploy butthere are advantages, particular with respect to configuration, to just usingthe component direct from Jakarta. 图示：proxool源码里移除了JCL的类，注意包名不同。 图示：JCL中的类","link":"/2022/01/17/proxool%E7%9A%84log4j%E5%86%B2%E7%AA%81/"},{"title":"session_cookie_token","text":"一、Session/Cookie/Token的由来Http无状态 Session和Cookie可存储用户身份标识及业务信息。 Token只用来标识用户身份。 二、Session服务器端存储用户信息和业务信息（也可配置存储到某数据源）。若不考虑使用数据源，则需要考虑请求粘连。 三、Cookie浏览器保存用户信息和业务信息（如购物车ID），每次请求都携带过去。 四、TokenToken不存储业务信息，只负责标识认证用户身份。 1）客户端可在Cookie里存储Token，请求时携带给Server； 2）Server获取Token，请求SSO服务进行认证；","link":"/2021/02/07/session_cookie_token/"},{"title":"mvn_dependency_tree和assembly不一致","text":"一、查看有效依赖 mvn dependency:tree -f pom.xml mvn dependency:list -f pom.xml 二、查看所有依赖1) 显示所有依赖： mvn dependency:tree -Dverbose -f pom.xml 2) 过滤依赖： mvn dependency:tree -Dverbose -Dincludes=org.springframework -f pom.xml 3) includes语法： -Dincludes=[groupId]:[artifactId]:[type]:[version] Note：可使用通配符* 三、有时dependency:tree和assembly的结果不一致1、原因maven-assembly-plugin和maven-depdency-plugin插件使用的解析逻辑不一致。插件的依赖解析有两种方式： 1）插件本身实现了依赖解析逻辑，由其是maven3.x（未集成aether）之前的插件。 2）插件使用aether（通过MavenProject类调用）进行依赖解析。 2、解决方案1）assembly符合预期时无需解决dependency:tree使用的老的依赖解析逻辑，如果install结果正确则无需关心。另外，可通过mvn dependency:tree -X和maven core的解析结果进行对比。 参考Maven3.x兼容笔记。 2）assembly插件升级至使用Aether解析的版本maven-assembly-plugin升级至3.1.1以上。 引自maven-assembly-plugin:3.1.1版本的修复提交日志 [MASSEMBLY-675] Maven Assembly packaging wildcard-excluded dependencies Since Maven 3 requirement, there is no need to resolve any dependenciesmanually, and we can rely on requiresDependencyResolution. Initial patchfailed when module sets were involved: instead of getting the list oftransitive/direct dependencies on the current project, they need to befetched for each project so that it encompasses the possible modules inmodule sets. 3）dependency插件进行依赖解析，assembly插件只负责拷贝pom.xml中增加插件 12345678910111213&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; NOTE：maven-dependency-plugin使用2.8时，SNAPSHOT不会替换为时间戳，参考。 package.xml 1234567891011121314151617181920212223242526272829303132&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;assembly xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/assembly-1.0.0.xsd&quot;&gt; &lt;id&gt;package&lt;/id&gt; &lt;formats&gt; &lt;format&gt;dir&lt;/format&gt; &lt;/formats&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;fileSets&gt; &lt;fileSet&gt; &lt;directory&gt;src/main/bin&lt;/directory&gt; &lt;outputDirectory&gt;bin&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;fileSet&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;outputDirectory&gt;/conf&lt;/outputDirectory&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.xls&lt;/exclude&gt; &lt;exclude&gt;**/*.cs&lt;/exclude&gt; &lt;exclude&gt;**/autotest/**&lt;/exclude&gt; &lt;/excludes&gt; &lt;/fileSet&gt; &lt;fileSet&gt; &lt;directory&gt;src/main/lib&lt;/directory&gt; &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;fileSet&gt; &lt;directory&gt;${project.build.directory}/dependency&lt;/directory&gt; &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;/fileSets&gt;&lt;/assembly&gt; 参考： https://maven.apache.org/plugins/maven-dependency-plugin/examples/filtering-the-dependency-tree.html https://stackoverflow.com/questions/32322496/why-does-mvn-dependencytree-list-one-version-but-mvn-clean-install-try-to https://stackoverflow.com/questions/17876081/maven-dependency-rename-jar-with-timestamp-suffix","link":"/2020/06/02/mvn_dependency_tree%E5%92%8Cassembly%E4%B8%8D%E4%B8%80%E8%87%B4/"},{"title":"shell脚本编写","text":"一、执行curl下载的脚本1、直接执行 1bash &lt;(curl -s 'http://demo.sh') 2、携带参数 shell脚本内通过$1,$2…获取入参。 1curl -s 'http://demo.sh' | bash -s arg1 arg2 二、读取文件内容/变量1234567891011#!/bin/bashlines=$(grep -r &quot;keyword&quot; . --include=&quot;*.txt&quot; -n)if [ &quot;$lines&quot; == &quot;&quot; ]; then echo &quot;Not Found&quot; exitfiwhile IFS=&quot;\\n&quot; read -r line; do echo $line # process linedone &lt;&lt;&lt;&quot;$lines&quot; 三、正则匹配1234567891011if [[ &quot;hello world&quot; =~ (he..o).*(world) ]]; then echo &quot;Matched&quot;fi# 匹配group获取firstGroup=${BASH_REMATCH[1]} # hellosecondGroup=${BASH_REMATCH[2]} # world# 字符串替换replaceOnce=${BASH_REMATCH[1]/l/o} # heoloreplaceAll=${BASH_REMATCH[1]//l/o} # heooo 四、Echo着色输出 着色工具：https://ansi.gabebanks.net/ 12345678910111213# 首: \\033[xxx;xxxm - 指定显示属性 # 尾: \\033[0m - 关闭所有属性# echo -e &quot;\\033[字背景颜色;文字颜色m字符串\\033[0m&quot;echo -e &quot;\\033[49mhello world!\\033[0m&quot;echo -e &quot;\\033[40mhello world!\\033[0m&quot;echo -e &quot;\\033[41mhello world!\\033[0m&quot;echo -e &quot;\\033[42mhello world!\\033[0m&quot;echo -e &quot;\\033[43mhello world!\\033[0m&quot;echo -e &quot;\\033[44mhello world!\\033[0m&quot;echo -e &quot;\\033[45mhello world!\\033[0m&quot;echo -e &quot;\\033[46mhello world!\\033[0m&quot;echo -e &quot;\\033[47mhello world!\\033[0m&quot; 颜色 背景色 前景色 Default 49 39 Black 40 30 Red 41 31 Green 42 32 Yellow 43 33 Blue 44 34 Magenta 45 35 Cyan 46 36 White 47 37 五、判断上一条命令执行是否异常123456function exit_if_error() { if [ $? -eq 1 ]; then echo -e &quot;\\033[41;33mError Happens\\033[0m&quot; exit 1; fi}","link":"/2022/11/02/shell%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99/"},{"title":"slf4j加载实现","text":"一、源码1、入口1234import org.slf4j.Logger;import org.slf4j.LoggerFactory;Logger logger = LoggerFactory.getLogger(Demo.class); 2、LoggerFactory#getLogger12345678910111213141516171819202122232425public static Logger getLogger(String name) { ILoggerFactory iLoggerFactory = getILoggerFactory(); return iLoggerFactory.getLogger(name);}public static ILoggerFactory getILoggerFactory() { // 绑定Slf4j的具体实现 bind(); // 返回slf4j实现的ILoggerFactory代理 return StaticLoggerBinder.getSingleton().getLoggerFactory();}private final static void bind() { // 找到slf4j的所有实现，并按顺序返回 Set&lt;URL&gt; staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet(); // print所有实现 reportMultipleBindingAmbiguity(staticLoggerBinderPathSet); // 通过类加载进行绑定，一般为返回顺序的第一个 StaticLoggerBinder.getSingleton(); // print最终绑定的实现 reportActualBinding(staticLoggerBinderPathSet);} NOTE： 此处需要说明下，slf4j编译问题。即StaticLoggerBinder在实现包里，而slf4j仍然在自己包里正常引用。 1）slf4j-api源码包里存在一个默认实现 123456789101112131415161718192021public class StaticLoggerBinder { private static final StaticLoggerBinder SINGLETON = new StaticLoggerBinder(); public static final StaticLoggerBinder getSingleton() { return SINGLETON; } public static String REQUESTED_API_VERSION = &quot;1.6.99&quot;; // !final private StaticLoggerBinder() { throw new UnsupportedOperationException(&quot;This code should have never made it into slf4j-api.jar&quot;); } public ILoggerFactory getLoggerFactory() { throw new UnsupportedOperationException(&quot;This code should never make it into slf4j-api.jar&quot;); } public String getLoggerFactoryClassStr() { throw new UnsupportedOperationException(&quot;This code should never make it into slf4j-api.jar&quot;); }} 2）maven编译后从jar中移除了此实现，“target/classes/org/slf4j/impl” 123456789101112131415161718&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;run&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;tasks&gt; &lt;echo&gt;Removing slf4j-api's dummy StaticLoggerBinder and StaticMarkerBinder&lt;/echo&gt; &lt;delete dir=&quot;target/classes/org/slf4j/impl&quot;/&gt; &lt;/tasks&gt; &lt;/configuration&gt;&lt;/plugin&gt; 3、LoggerFactory#findPossibleStaticLoggerBinderPathSet123456789101112131415161718192021222324static String STATIC_LOGGER_BINDER_PATH = &quot;org/slf4j/impl/StaticLoggerBinder.class&quot;;// slf4j的实现包中需要具有绑定类：org.slf4j.impl.StaticLoggerBinder。// slf4j会扫描classpath下该类。static Set&lt;URL&gt; findPossibleStaticLoggerBinderPathSet() { Set&lt;URL&gt; staticLoggerBinderPathSet = new LinkedHashSet&lt;URL&gt;(); try { ClassLoader loggerFactoryClassLoader = LoggerFactory.class.getClassLoader(); Enumeration&lt;URL&gt; paths; if (loggerFactoryClassLoader == null) { paths = ClassLoader.getSystemResources(STATIC_LOGGER_BINDER_PATH); } else { paths = loggerFactoryClassLoader.getResources(STATIC_LOGGER_BINDER_PATH); } while (paths.hasMoreElements()) { URL path = paths.nextElement(); staticLoggerBinderPathSet.add(path); } } catch (IOException ioe) { Util.report(&quot;Error getting resources from path&quot;, ioe); } return staticLoggerBinderPathSet;} 二、图谱","link":"/2021/11/01/slf4j%E5%8A%A0%E8%BD%BD%E5%AE%9E%E7%8E%B0/"},{"title":"ssh-keygen生成PEM格式密钥","text":"一、背景使用JGIT且用git协议连接时，报密钥格式错误。通过Debug发现是JSCH不支持OPENSSH格式私钥。更换为PEM格式私钥后解决。 二、JSCH不支持OPENSSH格式私钥 JSCH源码位置：com.jcraft.jsch.KeyPair#load(com.jcraft.jsch.JSch, byte[], byte[])，关键代码如下： 1234567891011121314151617181920212223242526272829303132333435363738while (i &lt; len) { if (buf[i] == 'B' &amp;&amp; i + 3 &lt; len &amp;&amp; buf[i + 1] == 'E' &amp;&amp; buf[i + 2] == 'G' &amp;&amp; buf[i + 3] == 'I') { i += 6; if (i + 2 &gt;= len) throw new JSchException(&quot;invalid privatekey: &quot; + prvkey); if (buf[i] == 'D' &amp;&amp; buf[i + 1] == 'S' &amp;&amp; buf[i + 2] == 'A') { type = DSA; } else if (buf[i] == 'R' &amp;&amp; buf[i + 1] == 'S' &amp;&amp; buf[i + 2] == 'A') { type = RSA; } else if (buf[i] == 'E' &amp;&amp; buf[i + 1] == 'C') { type = ECDSA; } else if (buf[i] == 'S' &amp;&amp; buf[i + 1] == 'S' &amp;&amp; buf[i + 2] == 'H') { // FSecure type = UNKNOWN; vendor = VENDOR_FSECURE; } else if (i + 6 &lt; len &amp;&amp; buf[i] == 'P' &amp;&amp; buf[i + 1] == 'R' &amp;&amp; buf[i + 2] == 'I' &amp;&amp; buf[i + 3] == 'V' &amp;&amp; buf[i + 4] == 'A' &amp;&amp; buf[i + 5] == 'T' &amp;&amp; buf[i + 6] == 'E') { type = UNKNOWN; vendor = VENDOR_PKCS8; encrypted = false; i += 3; } else if (i + 8 &lt; len &amp;&amp; buf[i] == 'E' &amp;&amp; buf[i + 1] == 'N' &amp;&amp; buf[i + 2] == 'C' &amp;&amp; buf[i + 3] == 'R' &amp;&amp; buf[i + 4] == 'Y' &amp;&amp; buf[i + 5] == 'P' &amp;&amp; buf[i + 6] == 'T' &amp;&amp; buf[i + 7] == 'E' &amp;&amp; buf[i + 8] == 'D') { type = UNKNOWN; vendor = VENDOR_PKCS8; i += 5; } else { throw new JSchException(&quot;invalid privatekey: &quot; + prvkey); } i += 3; continue; } ...} 从源码中可看出JSCH不支持OPENSSH格式，该格式以*—–BEGIN OPENSSH PRIVATE KEY—–*为起始。 三、ssh-keygen Man Pagessh-keygen升级后默认生成OPENSSH格式私钥，之前是PEM。 1234ssh-keygen will by default write keys in an OpenSSH-specific format. This format is preferred as it offers better protection for keys at rest as well as allowing storage of key comments within the private key file itself. 私钥类型 私钥前缀 PEM —–BEGIN RSA PRIVATE KEY—– OPENSSH —–BEGIN OPENSSH PRIVATE KEY—– 四、ssh-keygen生成PEM格式密钥1ssh-keygen -t rsa -m PEM # 参考 https://man7.org/linux/man-pages/man1/ssh-keygen.1.html https://docs.oracle.com/en/cloud/paas/integration-cloud/ftp-adapter/generate-keys-pem-format.html","link":"/2021/04/06/ssh-keygen%E7%94%9F%E6%88%90PEM%E6%A0%BC%E5%BC%8F%E5%AF%86%E9%92%A5/"},{"title":"synchronized","text":"多线程访问相同的共享可变的变量时，通常需要使用加锁的方式实现同步，避免竞态条件发生。同步的其中一个特征就是互斥，通过使访问顺序串行化，使得并发结果合法和可预期。synchronized是java的关键字，其通过java的内置锁机制实现多线程同步。 一、synchronized的三种锁形态 synchronized在jdk1.5前只有重量级锁，开销较大。为了应对低竞争的场景在jdk1.5增加了偏向锁和轻量级锁。对象的锁状态通过对象头里的markword标识。 1. 偏向锁 1）场景：在一个时刻只有一个线程请求锁，没有竞争； 2）关键参数： 12345-XX:+UseBiasedLocking # 是否开启偏向锁，jdk1.6以后默认开启-XX:BiasedLockingStartupDelay=4000 # 偏向锁延迟启动时间，因为可预想的JVM启动时会有竞争，所以设置此参数来避免升级过程-XX:BiasedLockingDecayTime=25000 # 重置撤销次数的时间阈值-XX:BiasedLockingBulkRevokeThreshold=40 # 偏向锁批量撤销阈值-XX:BiasedLockingBulkRebiasThreshold=20 # 偏向锁批量重偏向阈值 Note: 查看jvm各参数默认值java -XX:+PrintFlagsInitial 查看jvm运行参数值（其中被赋值号为:=的值是被修改过，与初始值不同）java -XX:+PrintFlagsFinal 查看jvm运行时的参数的命令jinfo -flags &lt;pid&gt; jinfo -flag &lt;name&gt; &lt;pid&gt; 3）实现原理：markword标识出偏向锁状态，且保存当前持有锁的线程ID。然后在其线程栈上隐式保存递归次数。 4）优点：在无竞争的情况下开销较小，包括cpu（无须切换上下文和线程调度）和内存（无须分配管程对象）开销。 5）缺点：**锁撤销开销较大，需要挂起锁定线程，遍历其线程栈，修改锁记录。甚至比轻量级锁和重量级锁的开销还大。**目前HotSpot使用安全点的STW和启发式撤销方法，减少撤销次数，提高性能。 6）可重偏向的条件 线程ID为空 epoch无效 Note1: 当类元数据中的epoch与类对象的对象头中的epoch值相等时，表示当前偏向锁有效；否则该偏向锁失效，可重偏向；通过引入epoch减小了重偏向的开销； Note2：在调用hashcode时会撤销偏向锁来还原hashcode的占位； Note3: 调用wait,notify会膨胀为重量级锁。触发管程对象分配和初始化； 2. 轻量级锁（也称为thin lock） 1）场景：在一段时间内请求的锁的线程较少，且持有锁的线程执行时间短，持有锁的时间短，其他等待线程在有限的自旋等待期可以得到锁。 2）实现结构——栈上锁记录 锁记录在堆栈上分配，在解释执行期间显式分配，或在编译时隐式分配。锁定记录包含一个可以放置移位标记字的位置，以及一个指向被锁定对象的指针。对象指针在分配时由解释器或编译器初始化，当锁被薄锁或胖锁时，移位的标记字被初始化。from: www.diva-portal.org/smash/get/diva2:754541/FULLTEXT01.pdf 3）锁升级过程 当一个线程试图获取一个已经被其他线程持有的轻量级锁（CAS失败）时，非所有者线程将尝试对该锁进行膨胀。**在锁膨胀期间，为对象分配和初始化重量级对象监视器结构。**膨胀线程将尝试在循环中对锁进行升级，直到成功，或直到其他线程成功地升级锁为止。from: www.diva-portal.org/smash/get/diva2:754541/FULLTEXT01.pdf Note1：调用wait,notify会膨胀为重量级锁。触发管程对象分配和初始化； Note2：管程对象不是一开始就初始化的，而是触发fat lock时才会初始化。 3. 重量级锁（也称为fat lock） 1）管程对象——monitor 通过对象关联的管程对象实现线程阻塞，唤醒机制。其主要依赖操作系统级的互斥量来实现。 2）WaitSet,EntrySet 准备争抢会进入临界区的线程会进入EntrySet； 只有一个线程会进去临界区，独占锁； 获取锁的线程执行wait方法会让出锁，并进去WaitSet； WaitSet中的线程需要被唤醒才能进入EntrySet，然后再参与竞争； 3）优点： 在多线程并发激烈的情况下性能表现好，让未获得锁的线程让出时间片和cpu使用权，减少资源消耗。 二、与juc包AQS对比AQS是抽象队列同步器用来实现同步机制，AQS也有类似synchronized的等待队列和条件队列。synchronized实现了阻塞非公平锁且只有单一条件队列，AQS提供了更多机制。 synchronized AQS 是否公平 非公平 公平和非公平都支持 是否阻塞 阻塞 阻塞和非阻塞都支持 是否支持超时 不支持 支持 条件队列数 1个 无限制 读写锁 不支持 支持 # 参考 Java 的偏向锁是怎么实现的？ - RednaxelaFX的回答 - 知乎 Evaluating and improving biased locking in the HotSpot virtual machine https://www.cnblogs.com/LemonFive/p/11248248.html https://zhuanlan.zhihu.com/p/127884116","link":"/2020/08/16/synchronized/"},{"title":"volatile","text":"volatile是对共享变量的修饰词，无法修饰局部变量。它保证了被修饰变量的可见性和禁止指令重排。 一、JMM和volatile JMM里volatile的规则：每个对变量 x 的读都能看到一个对 x 的写。所有对 volatile 变量的读写都是 volatile 动作。 该规则显示声明了volatile对可见性的保证，及暗含了禁止重排序的约定。 二、volatile在各层实现机制 内存栅栏保证了可见性和禁止重排序，禁止编译器、解释器、JIT、CPU进行指令重排且保证可见性。 1. Java语言1）实现方式：用volatile修饰共享变量 2）主要作用：标识可见性和有序性 2. Java编译器对volatile修饰的变量在java字节码中增加ACC_VOLATILE的flag，且不会该变量代码进行重排序； 3. 字节码级别1）实现方式：ACC_VOLATILE修饰变量 2）主要作用：提示JVM解释器和JIT增加内存栅栏，并禁止它们对volatile相关指令重排序； 4. JVM解释器和JIT使用JVM的OrderAccess方法在volatile相关指令位置增加内存栅栏，且不会该变量代码进行重排序； 1234567891011// linux_x86下fence方法inline void OrderAccess::fence() { if (os::is_MP()) { // always use locked addl since mfence is sometimes expensive#ifdef AMD64 __asm__ volatile (&quot;lock; addl $0,0(%%rsp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;);#else __asm__ volatile (&quot;lock; addl $0,0(%%esp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;);#endif }} 参考：*addl $0,0(%%esp)*表示将数值0加到esp寄存器中，而该寄存器指向栈顶的内存单元。加上一个0，esp寄存器的数值依然不变。即这是一条无用的汇编指令。在此利用这条无价值的汇编指令来配合lock指令，在__asm__,__volatile__,memory的作用下，用作cpu的内存屏障。 5. CPU级别 对于 Intel486 和 Pentium 处理器来说，在进行加锁操作时，总是在总线上发出 LOCK#信号，即使锁定的内存区域已经高速缓存在处理器中。 对于 Pentium 4、Intel Xeon、P6 系列处理器而言，加锁操作期间，如果锁定的 内存区域已经被高速缓存进正在执行回写内存加锁操作的处理器中，并且已经完全进 入了高速缓冲线了，则处理器不对总线发出 LOCK#信号。相反，它将修改缓存区域中的 数据，并依赖高速缓存相干性机制来保证加锁操作的执行是原子的。这个操作称为“高 速缓存加锁”。高速缓存相干性机制会自动阻止两个或多个缓存了同一内存区域的处 理器同时修改该区域的数据。 来源：IA-32 架构软件开发人员手册 第 3 卷:系统编程指南 7.1.4 I/O指令、加锁指令、LOCK前缀以及串行化指令等，强制在处理器上进行较强的排序。 来源：IA-32 架构软件开发人员手册 第 3 卷:系统编程指南 7.2.4 简单来说现代CPU会做出如下担保： 1）通过嗅探机制，缓存一致性协议或锁总线保证LOCK修饰指令的可见性； 2）保证LOCK修饰指令在CPU级别有序； 三、Unsafe实现volatileUnsafe提供了内存栅栏的方法，如下： 123456789101112131415161718192021222324public final class Unsafe { /** * Ensures lack of reordering of loads before the fence * with loads or stores after the fence. * @since 1.8 */ public native void loadFence(); /** * Ensures lack of reordering of stores before the fence * with loads or stores after the fence. * @since 1.8 */ public native void storeFence(); /** * Ensures lack of reordering of loads or stores before the fence * with loads or stores after the fence. * @since 1.8 */ public native void fullFence(); ...} 与volatile的区别 1）Unsafe可自主决定栅栏的位置，较volatile灵活。例如，可以跨方法；有点类似synchronize和Lock的区别；","link":"/2020/08/13/volatile/"},{"title":"nginx反向代理自调用时小心Header里的host","text":"一、背景最近为了响应公司“降本增效”，提高资源使用率，我们EDI小组决定要整合edi-db、edi-rest、edi-admin三个springboot应用到一个云主机上，通过Nginx反向代理进行分流。最终配置结果如下图： 附：Ngnix方向代理配置 1234567891011121314151617181920212223242526272829303132333435server { listen 80; server_name test.edi-admin.jd.com; location /{ proxy_pass http://127.0.0.1:8081; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; }}server { listen 80; server_name test.edi-rest.jd.com; location /{ proxy_pass http://127.0.0.1:8082; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; }}server { listen 80; server_name test.edi-db.jd.com; location /{ proxy_pass http://127.0.0.1:8083; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; }} 二、遇到问题edi-admin应用运行时通过HttpClient请求edi-rest模块提供的Rest时，会返回404。 这些URL经验证：1）云主机上通过curl命令访问正常；2）客户端通过postman访问正常 三、排查1. 远程debug调试edi-admin观察http的请求信息 请求URI： 1test.edi-rest.jd.com/organize/query 请求头信息如下： 12345678910111213host: test.edi-admin.jd.com, x-real-ip: 172.22.141.3, x-forwarded-for: 172.22.141.3, x-forwarded-proto: http, connection: close, user-agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:84.0) Gecko/20100101 Firefox/84.0, accept: text/html, */*; q=0.01, accept-language: en-US,en;q=0.5, accept-encoding: gzip, deflate, x-requested-with: XMLHttpRequest, referer: http://test.edi-admin.jd.com/systemComfig, cookie: xxxxxx, Content-Type: application/json;charset=utf-8 2. 观察nginx的access.log curl请求对应日志 123127.0.0.1 - - [15/Jan/2021:12:48:12 +0800] &quot;GET /organize/query HTTP/1.1&quot; 302 0 &quot;-&quot; &quot;curl/7.29.0&quot;127.0.0.1 - - [15/Jan/2021:12:49:16 +0800] &quot;GET /organize/query HTTP/1.1&quot; 302 0 &quot;-&quot; &quot;curl/7.29.0&quot;127.0.0.1 - - [15/Jan/2021:12:49:28 +0800] &quot;GET /organize/query HTTP/1.1&quot; 200 70 &quot;-&quot; &quot;curl/7.29.0&quot; 客户端Postman请求对应日志 1172.22.141.3 - - [15/Jan/2021:15:07:47 +0800] &quot;GET /organize/query HTTP/1.1&quot; 200 70 &quot;-&quot; &quot;PostmanRuntime/7.26.8&quot; edi-admin请求日志 12127.0.0.1 - - [15/Jan/2021:12:57:44 +0800] &quot;GET /organize/query HTTP/1.1&quot; 404 254 &quot;http://test.edi-admin.jd.com/systemComfig&quot; &quot;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:84.0) Gecko/20100101 Firefox/84.0&quot;127.0.0.1 - - [15/Jan/2021:12:58:09 +0800] &quot;GET /organize/query HTTP/1.1&quot; 404 252 &quot;http://test.edi-admin.jd.com/systemComfig&quot; &quot;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:84.0) Gecko/20100101 Firefox/84.0&quot; 3. 猜测验证猜测应该是edi-admin在请求时的请求头和正常有区别。经过postman验证发现，是由于edi-admin请求的Header里的host导致的异常。 1host: test.edi-admin.jd.com, 四、原因1）nginx在转发请求时会判断header里是否有host 如果header里有host，把其作为转发的目标host 否则，使用请求URI的域名host作为转发的host。 2）验证 postman中加上header：host: test.edi-admin.jd.com ，复现404错误； 再此修改header为：host: test.edi-rest.jd.com，访问正常； 3）检查edi-admin代码发现其在使用httpclient进行请求前，把请求edi-admin的header全量复制给了请求edi-rest的请求里。 12345678910private static void copyHeader(HttpServletRequest req, AbstractHttpMessage post) { Enumeration&lt;String&gt; headers = req.getHeaderNames(); while (headers.hasMoreElements()) { String name = headers.nextElement(); if (filteredHeader.contains(name.toLowerCase())) { continue; } post.setHeader(name, req.getHeader(name)); }} 五、解决修改edi-admin中复制Header的逻辑，全量复制改为只复制Cookie（为了认证）。重新部署后问题解决。","link":"/2021/01/17/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E8%87%AA%E8%B0%83%E7%94%A8%E6%97%B6%E5%B0%8F%E5%BF%83Header%E9%87%8C%E7%9A%84host/"},{"title":"wsdl获取逻辑修改事故的复盘","text":"一、事故描述EDI在对SOAP服务进行调用的时候会解析商家的wsdl。 初始逻辑是只获取http协议的地址，但是新上线的商家A的协议为https，导致无法获取请求地址，访问商家异常。 EDI侧修改解析wsdl获取地址逻辑，增加对https的支持；商家A恢复正常； 此时商家B出现了问题，其wsdl中提供了两个地址，一个是http，一个是https，但是https的地址是不可用的。这次修改支持https后，错误的获取到了https地址，导致商家B调用异常。 EDI侧再次修改解析wsdl获取地址逻辑，优先使用与wsdl地址协议相同的地址，商家B恢复正常。 而由于组织变动，之前的运维监控团队解散，无人监控到商家B的异常。导致商家B的问题到次日才发现，造成了商家货物堆积现象。 二、事故初始反思1）事故原因 商家B的wsdl不符合规范，wsdl中暴漏的服务不可用 EDI侧修改没有完全兼容之前逻辑 EDI侧上线后没有完整检查所有受影响的商家 运维团队解散，导致问题延迟发现，扩大了事故影响 2）事故预防 规范上线流程 上线前做完整商家测试 上线前通知相关方做好监控 上线时灰度验证，发现问题及时回滚 上线时观察所有受影响商家是否正常 增加监控指标，核查监控指标确定系统健康度 3）事故发现 异常监控 帮助新的运维团队订阅业务异常，做到及时发现故障 分离http调用等异常为系统异常，由EDI侧研发监控 4）事故处理 及时回滚，快速恢复故障 及时复核受影响的所有商家，通知业务侧 隔离重要商家到单独集群，降低故障率 三、更高维度反思1）运维团队监控/EDI侧监控 ——&gt; 多方边界 从监控职责上分为两方EDI平台侧和运维侧，而此次事故暴露出的是这个边界不清晰。由谁监控如果没有明确的边界，必然会造成事故延迟发现。 事故不光要从技术角度去看，还要从组织的角度上去看。一个中间件的使用方是多个部门，这时候如果没有厘清中间件、使用方、客户、实施运维团队的责任边界，那么会出现职责灰度地带。这些灰度地带一但出问题，必然没有人发现，直到问题扩大到更大的区域。 2）商家侧wsdl不合理 ——&gt; 新功能开发要基于标准，不妥协 早期wsdl只支持http实际上是对商家侧不符合标准的一种妥协。作为一个中间件，这种在原则上是不允许的。当多个商家都不符合标准，且互相冲突的时候，平台根本无法兼顾。此时只有坚守标准，才能拉齐场景。 3）多次修改上线 ——&gt; 上线要有正式书面完整流程 上线流程书面化，严格遵守，不要存在侥幸心理。","link":"/2021/07/22/wsdl%E8%8E%B7%E5%8F%96%E9%80%BB%E8%BE%91%E4%BF%AE%E6%94%B9%E4%BA%8B%E6%95%85%E7%9A%84%E5%A4%8D%E7%9B%98/"},{"title":"while(true)和for(;;)分析","text":"由字节码看，两者一致。 12345678910111213public class WhileForTest { public void forFunc() { for (;;) { System.out.println(&quot;for loop&quot;); } } public void whileFunc() { while (true) { System.out.println(&quot;while loop&quot;); } }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class jmh/WhileForTest { // compiled from: WhileForTest.java // access flags 0x1 public &lt;init&gt;()V L0 LINENUMBER 7 L0 ALOAD 0 INVOKESPECIAL java/lang/Object.&lt;init&gt; ()V RETURN L1 LOCALVARIABLE this Ljmh/WhileForTest; L0 L1 0 MAXSTACK = 1 MAXLOCALS = 1 // access flags 0x1 public forFunc()V L0 LINENUMBER 10 L0 FRAME SAME GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC &quot;for loop&quot; INVOKEVIRTUAL java/io/PrintStream.println (Ljava/lang/String;)V GOTO L0 L1 LOCALVARIABLE this Ljmh/WhileForTest; L0 L1 0 MAXSTACK = 2 MAXLOCALS = 1 // access flags 0x1 public whileFunc()V L0 LINENUMBER 16 L0 FRAME SAME GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC &quot;while loop&quot; INVOKEVIRTUAL java/io/PrintStream.println (Ljava/lang/String;)V GOTO L0 L1 LOCALVARIABLE this Ljmh/WhileForTest; L0 L1 0 MAXSTACK = 2 MAXLOCALS = 1}","link":"/2020/05/19/while(true)%E5%92%8Cfor(;;)%E5%88%86%E6%9E%90/"},{"title":"一般的分析问题","text":"分析问题的重要性分析问题是发现问题和制定解决方案之间的步骤，是两者必不可少的衔接。这个必不可少体现在两个方面：一是这个分析问题的步骤必不可少，二是分析问题的时间必不可少。换句话来说，分析问题是确保”做正确的事”，制定解决方案则是”正确的做事”。 人们面对一个问题，容易出于本能反应，第一时间在脑子里形成一个解决方案，并告诉大脑这个问题是自明的、结论是清晰的，以此来避免理性脑的参与。另外，即便被外部规章约束需要去分析问题，往往在思想上不会重视，只会花很少的时间，得出一个主观的、片面的、偏差的结论，然后快速进入到执行阶段。 缺少了问题分析的步骤和时间，那么大概率会导致得出一个本能的、非理性的、主观的、片面的、偏差的结论，错误的结论将导致错误的解决方案，哪怕你投入了更多的时间在方案上。由此，分析问题的重要性就清晰的传达了。 当认识到分析问题的重要性后，为了解决刚才提到的本能脑干扰和分析问题的全面性，下面会抽象几个分析问题的原则供分析问题时参照和纠偏。 几个一般原则1. 分析前的关键意识在开始分析问题前，需要先摆正思维意识。对那些可能影响后续问题分析的一些潜在意识或者错误思维提前进行纠正，防止干扰后续分析过程。 1.1 明确分析问题的阶段独立性：分析问题和制定解决方案分离分析问题和制定解决方案是有先后顺序的，只有正确的分析了问题，才能制定有效地解决方案，才能有的放矢。并且这个先后顺序是绝对的，不存在时间交叉，例如体现在会议章程上也应该是分离的。不能交叉是因为，一旦分析问题时就考虑解决方案就必然会带来在局限思维在解决方案上，分析问题反被解决方案约束，导致面向解决方案分析问题。 所以需要明确认识到分析问题是个独立的阶段，此阶段只分析问题，不解决问题。 1.2 警惕本能脑带来的认知偏差在丹尼尔·卡尼曼的书籍《思考，快与慢》和《噪声》中说明了本能脑(系统1)带来的一些非理性的认知偏差。我们在后续的分析过程中要警惕本能脑带来的认知偏差，可以考虑通过统计的、数学的、群组的、加权的方式去预防。理想情况下是有辩手思维，对自己的和别人的观点问一句：“是这样吗？为什么？” 1.3 要注意心中有“数”如《毛选》中《党委会的工作方法》所说“对情况和问题一定要注意到他们的数量方面，要有基本的数量分析。任何质量都表现为一定的数量，没有数量也就没有质量。”。对问题进行分析时，要对数据有敏感度，要清楚需要观测哪些数据、数据质变的临界值范围是多少、变化趋势怎么样的。基于数据去分析，可以很大限度的避免主观臆断。 1.4 分清楚假设和结论从数据中直接得来的往往不是结论，而是一种假设，需要经过实地验证。一个结论往往需要提出多个假设，以及不断地验证。例如大前研一的《思考的技术》中提到的例子：从日本和服整体销售额下滑，得出和服市场持续减小，这只是一个假设，不是结论。把假设当结论，可能导致做出截然相反的解决方案。 1.5 二八原则/帕累托原则引起问题的原因可能有多种，其中只有20%是关键原因造成了80%的问题。问题问题和解决要厘清各要素的权重，集中精力，解决关键点。 2. 质疑和验证问题的有效性问题的来源多种多样，如用户反馈、指标异常、自行发现、脑暴发现等，这些问题有可能是假问题。例如，把某些边缘的正常情况错误的认为是问题；用户根据现象，或结合历史经验，臆断出未经确认和验证的问题源；把现象当成问题；表达错误，沟通障碍，导致问题理解偏差；问题是某个根问题的衍生；等等。对问题的有效性存疑并进行验证，是正式分析前的必要准备。 2.1 确定问题粒度：对复合问题拆分为小问题分辨问题是否是一个混合问题，就过往经验来看，有的研发会有意或无意的把多个问题进行聚合性表达，也就是把多个不同的问题表达为一个复合问题。问题的分析必然是针对性的对单一问题的分析，不能有“一起看，一起分析”的思维。并且对复合问题拆分后，分析问题的难度也会下降很多，且不同的问题域范围也会导致解决方案有很大的差异。 2.2 确定问题对象：问题的主体对象及相干对象问题不是独立存在的，要认识到问题所处的环境及相关对象。如做代码治理，那么问题的主体就是代码仓库中的问题代码，其他相关对象为：研发人员、研发流程、CI/CD基建能力、团队文化、监控机制等。一个主体关联着很多相关对象，他们之间则必然有相关的影响。盘点这些对象，会给我们提供多个分析视角和对象，有更多的输入就能有更理性全面的输出。 2.3 确定问题为真和一致性：实地验证问题的有效性正如前面所说，问题源的置信度非自行验证不能确认。要去看、去复现问题，保证问题是有效的，且是理解一致的。质疑问题是否为真，可以规避许多有意或无意的因果假设。如果问题是用户提出的，在《沟通的本质》和《非暴力沟通》中都提到一个方法可以使理解达成一致：复述你听到后你理解的问题。然后在需要协作解决问题的小组内对问题达成共识，对问题的理解进行对齐，确保我们要解决的是同一个问题。 3. 全面的分析问题分析问题要全面，避免片面、主观。应该对不同对象、不同时间、不同范围来分析，基于逻辑、基于数据去分析和推导。更全面的分析问题，才能从中找出其根本原因。这个过程当然可以结合历史的经验做一些合理的假设，然后去验证这些假设的真实性。在分析时，可以把分析过程写下来，这可以更好的审视和矫正分析过程。 3.1 分析问题现状：现象、现场、复现性等分析问题的第一步当然是去到问题的第一现场，去看，去复现。这个过程也可能需要工具进行辅助，如数据采集、统计分析、网络搜索等，以及和相干人员确认问题现象。问题分析时，避免先入为主，带着结论去评估问题现状。 3.2 分析问题历史：过去如何发生、未来如何演化问题的出现是有时间维度的，通过分析过去问题如何发生和变化，来了解问题是如何产生，从中找出共性点，备后续分析。另外，通过过去问题的变化过程，也可以推测在不干预的情况下，问题是否会继续劣化，从而得出问题治理的紧急性和重要性。知道了问题是如何产生的，也可以对后续治理增量提供思路。 3.3 分析正常情况：从问题的背面看问题前面两点分析问题的现在、过去、未来，那么接下来我们不妨从更大的范围来看问题。即从哪些正常的场景、未发生问题的场景去分析为什么在这些场景下问题没有发生，他和发生问题的场景有何不同。如果能找出正常和非正常的差异，可以从另一面补充问题发生的原因。 3.4 分析问题原因：直接原因和根本原因最后是结合前面的分析来递进的思考和推导问题的直接原因和根本原因。我们要明确这两个原因的差异性，直接原因离问题更近，更容易想到，治理成本也往往更低。但是如果不解决根因，那么问题还会反复出现。 4. 群体分析和决策：离问题近的人、合作方、团队当我们得出一个结论后，为了避免个人决策导致的偏差和噪声，我们需要引入群体决策智慧。这些群体包括离问题近的人、合作方、合作团队。在和群体讨论前，最好通过文档的方式整理好问题的分析过程和结论。然后在讨论和沟通时，进行透明、非抵抗、建议性沟通，通过群体决策对问题进行定性。同时也要避免群体无责。","link":"/2024/10/11/%E4%B8%80%E8%88%AC%E7%9A%84%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98/"},{"title":"sshuttle使用","text":"一、使用命令执行sudo sshuttle -l 8888 123.232.110.116/32 -r root@10.170.223.247 二、查看结果: 查看NAT sudo iptables --list -t nat 1234Chain PREROUTING (policy ACCEPT)target prot opt source destination sshuttle-8888 all -- anywhere anywhere DOCKER all -- anywhere anywhere ADDRTYPE match dst-type LOCAL Chain INPUT (policy ACCEPT)target prot opt source destination Chain OUTPUT (policy ACCEPT)target prot opt source destinationsshuttle-8888 all – anywhere anywhereDOCKER all – anywhere !localhost/8 ADDRTYPE match dst-type LOCAL Chain POSTROUTING (policy ACCEPT)target prot opt source destinationMASQUERADE all – 172.17.0.0/16 anywhereMASQUERADE all – 172.19.0.0/16 anywhereMASQUERADE tcp – 172.19.0.2 172.19.0.2 tcp dpt:mysql Chain DOCKER (2 references)target prot opt source destinationRETURN all – anywhere anywhereRETURN all – anywhere anywhereDNAT tcp – anywhere anywhere tcp dpt:mysql to:172.19.0.2:3306 Chain sshuttle-8888 (2 references)target prot opt source destinationRETURN tcp – anywhere https://account.jetbrains.com:443REDIRECT tcp – anywhere 123.232.110.116 TTL match TTL != 42 redir ports 8888 1232. 查看端口监听`netstat -np | grep 10.170.223.247````shelltcp 0 0 192.168.137.19:39792 10.170.223.247:22 ESTABLISHED -","link":"/2020/11/11/sshuttle%E4%BD%BF%E7%94%A8/"},{"title":"从Camel中学习FluntApi设计","text":"一、 流式的好处 更接近与自然语言； 操作连贯，一行搞定（如Builder）; 二、 设计原则1. Flunt Api在程序设计时，不能完全根据类的方法来限制其层级。例如，Branch在自然语言上，其后面只能跟when和otherwise。但是程序设计时，出于Java语言的特性，类的继承等原因并不能完全限制，Branch类可能继承了父类的方法。1）自然语言： 1Branch --&gt; when / otherwise 2）编程语言： 12345678910interface ContainerDefinition { LoopDefition loop(); BranchDefinition branch(); ...}class BranchDefinition extend ContainerDefinition { BranchDefinition when(); BranchDefinition otherwise();} 2. 设计方法时注意方法的访问级别1）public方法用于客户端流式API调用的接口，尽量贴近自然语言；2）protect方法用于语句中可向子语句传递的内部方法，不会暴露给客户端；3）private方法用于本语句的逻辑实现，不会被其他任何语句调用； 三、设计方法1. 找出同级别语句，整理为结构图；如下为EDI的数据转化的Flunt Api设计：123456789101112Dt Root||___Loop| |___Break||___Branch| |___When| |___Otherwise||___Try |___Catch |___Exception 2. 根据级别分组，不同分组是隔离的；1）第一层分组： 1Loop,Branch,Try 2）第二层分组 1231)Break;2)when,otherwise3)catch,exception 3. 分析第一层分组的语句，他们之间是可以任意顺序连接的，故设计根类的方法如下：123456class DtRoot { LoopDefinition loop(); BranchDefinition branch(); TryDefinition try(); DtRoot end();} 4. 分析第二层分组，其隶属于第一层分组的某个语句，称为父语句；父语句的方法有两种设计，如下：1）返回第一层的语句； 123456789class Branch { Branch when(String expr)； ExpressionClause&lt;Branch&gt; when(); Branch otherwise();}class ExpressionClause&lt;T&gt; { T expression(Expression expr);} 2）返回第二层语句； 1234class BranchDefinition extend ContainerDefinition { WhenDefinition when(String expr); OtherwiseDefinition otherwise();} 四、EDI的实现1. 限定流程的Core，第三方只能扩展Processor（目前Processor含set,attr,validator等processor）。2. 非完全意义上的流式实现，去掉了end这类返回父语句的操作，如下所示：1）正常流式 1branch.when(expr).process(processorA).otherwise().process(processorB).endbranch() 2）edi实现 12branch.when(expr).process(processorA);branch.otherwise().process(processorB); 五、附录","link":"/2020/03/20/%E4%BB%8ECamel%E4%B8%AD%E5%AD%A6%E4%B9%A0FluntApi%E8%AE%BE%E8%AE%A1/"},{"title":"从Filter和Interceptor看责任链模式","text":"一、责任链模式责任链模式，抽象出处理器接口Handler，系统运行时会依据某种顺序把这些Handler的实现类组成调用链。客户的请求会依次经过这些处理器，直到执行完整条链或者其中的某个处理器不再向后继续调用。 1）其好处主要有： 把一系列处理逻辑进行分离，减少耦合。 因为抽象出了Handler接口，更利于扩展，可方便的增加新的处理器。 2）在构建调用链时通常有两种方式： 组合成List。 Handler内持有下一个Handler引用。 3）同样的在调用责任链时也有两种方式： 栈式递归调用，如servlet的Filter。 非栈式串行调用，如spring框架的Interceptor。 二、Filter实现方式1）Filter接口12345678910package javax.servlet;public interface Filter { public void init(FilterConfig filterConfig) throws ServletException; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException; public void destroy();} 2）构建和调用Filter链源码位置：org.apache.catalina.core.StandardWrapperValve#invoke 1234567891011121314151617181920212223242526272829303132333435import java.io.IOException;ppackage org.apache.catalina.core;final class StandardWrapperValve extends ValveBase { @Override public final void invoke(Request request, Response response) throws IOException, ServletException { // 忽略其他逻辑 // 构建FilterChain ApplicationFilterChain filterChain = ApplicationFilterFactory.createFilterChain(request, wrapper, servlet); try { if ((servlet != null) &amp;&amp; (filterChain != null)) { if (context.getSwallowOutput()) { try { SystemLogHandler.startCapture(); if (request.isAsyncDispatching()) { request.getAsyncContextInternal().doInternalDispatch(); } else { // 执行FilterChain filterChain.doFilter(request.getRequest(), response.getResponse()); } } finally { // 忽略日志逻辑 } } else { if (request.isAsyncDispatching()) { request.getAsyncContextInternal().doInternalDispatch(); } else { // 执行FilterChain filterChain.doFilter(request.getRequest(), response.getResponse()); } } } } catch (Exception e) { // 忽略异常逻辑 } }} 3）ApplicationFilterChain源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899package org.apache.catalina.core;import java.io.IOException;import java.security.PrivilegedActionException;public final class ApplicationFilterChain implements FilterChain { /** * Filters， ApplicationFilterConfig是Filter的封装类 */ private ApplicationFilterConfig[] filters = new ApplicationFilterConfig[0]; /** * 当前要执行的Filter下标位置 */ private int pos = 0; /** * filter的size */ private int n = 0; public void doFilter(ServletRequest request, ServletResponse response) throws IOException, ServletException { if (Globals.IS_SECURITY_ENABLED) { final ServletRequest req = request; final ServletResponse res = response; try { java.security.AccessController.doPrivileged( new java.security.PrivilegedExceptionAction&lt;Void&gt;() { @Override public Void run() throws ServletException, IOException { internalDoFilter(req, res); return null; } } ); } catch (PrivilegedActionException pe) { // 忽略异常逻辑 } } else { internalDoFilter(request, response); } } private void internalDoFilter(ServletRequest request, ServletResponse response) throws IOException, ServletException { // 执行FilterChain // Call the next filter if there is one if (pos &lt; n) { // 1. 从FilterChain中获取下一个Filter ApplicationFilterConfig filterConfig = filters[pos++]; try { Filter filter = filterConfig.getFilter(); if (request.isAsyncSupported() &amp;&amp; &quot;false&quot;.equalsIgnoreCase( filterConfig.getFilterDef().getAsyncSupported())) { request.setAttribute(Globals.ASYNC_SUPPORTED_ATTR, Boolean.FALSE); } if (Globals.IS_SECURITY_ENABLED) { final ServletRequest req = request; final ServletResponse res = response; Principal principal = ((HttpServletRequest) req).getUserPrincipal(); Object[] args = new Object[]{req, res, this}; SecurityUtil.doAsPrivilege(&quot;doFilter&quot;, filter, classType, args, principal); } else { // 2. 调用Filter filter.doFilter(request, response, this); } } catch (Throwable e) { // 忽略异常逻辑 } return; } // FilterChain执行到末端后，调用servlet示例真正处理请求 // We fell off the end of the chain -- call the servlet instance try { if (ApplicationDispatcher.WRAP_SAME_OBJECT) { lastServicedRequest.set(request); lastServicedResponse.set(response); } if (request.isAsyncSupported() &amp;&amp; !servletSupportsAsync) { request.setAttribute(Globals.ASYNC_SUPPORTED_ATTR, Boolean.FALSE); } // Use potentially wrapped request from this point if ((request instanceof HttpServletRequest) &amp;&amp; (response instanceof HttpServletResponse) &amp;&amp; Globals.IS_SECURITY_ENABLED) { final ServletRequest req = request; final ServletResponse res = response; Principal principal = ((HttpServletRequest) req).getUserPrincipal(); Object[] args = new Object[]{req, res}; SecurityUtil.doAsPrivilege(&quot;service&quot;, servlet, classTypeUsedInService, args, principal); } else { servlet.service(request, response); } } catch (Throwable e) { // 忽略异常逻辑 } finally { if (ApplicationDispatcher.WRAP_SAME_OBJECT) { lastServicedRequest.set(null); lastServicedResponse.set(null); } } }} 4）FilterChain的图解由以上源码逻辑可知其采用栈式递归调用方式来执行FilterChain。 FilterChain结构如下图： FilterChain执行时方法调用栈如下图： 三、HandlerInterceptor实现方式1）HandlerInterceptor接口123456789package org.springframework.web.servlet;public interface HandlerInterceptor { boolean preHandle(HttpServletRequest var1, HttpServletResponse var2, Object var3) throws Exception; void postHandle(HttpServletRequest var1, HttpServletResponse var2, Object var3, ModelAndView var4) throws Exception; void afterCompletion(HttpServletRequest var1, HttpServletResponse var2, Object var3, Exception var4) throws Exception;} 2）HandlerInterceptor调用时机1234567891011121314151617181920212223242526272829303132333435363738package org.springframework.web.servlet;public class DispatcherServlet extends FrameworkServlet { protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception { HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try { ModelAndView mv = null; Exception dispatchException = null; try { // Determine handler adapter for the current request. HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // 1. 执行HandlerInterceptor链的preHandler逻辑 if (!mappedHandler.applyPreHandle(processedRequest, response)) { // 如果拦截成功，HandlerExecutionChain内部会调用HandlerInterceptor#afterCompletion逻辑 return; } // 2. 真正调用Handler // Actually invoke the handler. mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); applyDefaultViewName(processedRequest, mv); // 3. 执行HandlerInterceptor链的postHandle逻辑 mappedHandler.applyPostHandle(processedRequest, response, mv); } catch (Throwable err) { } // 4.1 执行HandlerInterceptor链的afterCompletion逻辑 processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); } catch (Throwable err) { // 4.2 捕获processDispatchResult的异常，保证执行到HandlerInterceptor链的afterCompletion逻辑 triggerAfterCompletion(processedRequest, response, mappedHandler, ex); } finally { // 忽略 } }} 3）HandlerExecutionChain源码解析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package org.springframework.web.servlet;public class HandlerExecutionChain { private HandlerInterceptor[] interceptors; private List&lt;HandlerInterceptor&gt; interceptorList; private int interceptorIndex = -1; public HandlerInterceptor[] getInterceptors() { if (this.interceptors == null &amp;&amp; this.interceptorList != null) { this.interceptors = this.interceptorList.toArray(new HandlerInterceptor[this.interceptorList.size()]); } return this.interceptors; } // 遍历interceptors,（正序）依次调用HandlerInterceptor#preHandle boolean applyPreHandle(HttpServletRequest request, HttpServletResponse response) throws Exception { HandlerInterceptor[] interceptors = getInterceptors(); if (!ObjectUtils.isEmpty(interceptors)) { for (int i = 0; i &lt; interceptors.length; i++) { HandlerInterceptor interceptor = interceptors[i]; if (!interceptor.preHandle(request, response, this.handler)) { // 如果拦截成功，则触发HandlerInterceptor的afterCompletion逻辑 triggerAfterCompletion(request, response, null); return false; } this.interceptorIndex = i; } } return true; } // 遍历interceptors,（倒序）依次调用HandlerInterceptor#postHandle void applyPostHandle(HttpServletRequest request, HttpServletResponse response, ModelAndView mv) throws Exception { HandlerInterceptor[] interceptors = getInterceptors(); if (!ObjectUtils.isEmpty(interceptors)) { for (int i = interceptors.length - 1; i &gt;= 0; i--) { HandlerInterceptor interceptor = interceptors[i]; interceptor.postHandle(request, response, this.handler, mv); } } } // 遍历interceptors,从当前拦截器位置倒序调用HandlerInterceptor#afterCompletion void triggerAfterCompletion(HttpServletRequest request, HttpServletResponse response, Exception ex) throws Exception { HandlerInterceptor[] interceptors = getInterceptors(); if (!ObjectUtils.isEmpty(interceptors)) { for (int i = this.interceptorIndex; i &gt;= 0; i--) { HandlerInterceptor interceptor = interceptors[i]; try { interceptor.afterCompletion(request, response, this.handler, ex); } catch (Throwable ex2) { logger.error(&quot;HandlerInterceptor.afterCompletion threw exception&quot;, ex2); } } } }} 4）HandlerExecutionChain图解HandlerExecutionChain结构图： HandlerExecutionChain调用时，有拦截器返回false时： HandlerExecutionChain调用时，有拦截器无返回false时： 四、两者调用方式分析1）通过方法栈递归调用 方法栈调用时，对异常处理较方便 如果责任链太长，可能导致StackOverflow 更容易实现事务功能 每个处理器都需持有下一个处理器引用或者责任链引用 2）通过遍历列表依次调用 异常处理逻辑较复杂 责任链长度无特殊限制 每个处理器无需持有下一个处理器引用或者责任链引用 # 参考 https://zhuanlan.zhihu.com/p/146435548 https://baike.baidu.com/item/%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F/5295498?fr=aladdin","link":"/2021/05/15/%E4%BB%8EFilter%E5%92%8CInterceptor%E7%9C%8B%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F/"},{"title":"从一个pojo类来看单一性原则","text":"1. 背景一日，我写一个配置类，类似如下： 12345678910class XxxConfig { private String prop1; private String prop2; public Node toNode() { // convert to node logic return node; } ...} Note: 当时考虑toNode方法对XxxConfig的细节比较依赖，所以把这个方法放到了XxxConfig里。 2. 单一性原则 该类我分别让亮哥，阳哥review后，他们都一致建议我把toNode方法移除，因为破坏了单一性原则。缺点如下： 不符合单一性原则，toNode方法不是XxxConfig类的职责； 当两个类在不同的包时，会再成多余的依赖——XxxConfig所在的包必须依赖Node的包 修改将toNode方法抽离到调用端的convert类中。例如： 123456789 A B \\ / C* A：XxxConfig所在包* B： Node所在包* C：调用端，此处建立XxxConfig到Node的转换逻辑；","link":"/2019/12/30/%E4%BB%8E%E4%B8%80%E4%B8%AApojo%E7%B1%BB%E6%9D%A5%E7%9C%8B%E5%8D%95%E4%B8%80%E6%80%A7%E5%8E%9F%E5%88%99/"},{"title":"代码整洁之道","text":"","link":"/2021/01/29/%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93/"},{"title":"习惯复盘","text":"说明古人有云“朝三省吾身”，告诫自己和后人要时常反思、自省。以及在工作中发现，类似的事情经常会反复出现，如果能习就每日反思的习惯，从每日的具体事件中思考其更朴实、临界的知识，这些知识连带着具体事件作为上下文，就会沉淀为有价值的经验，为今后遇到相同模式的事件时提供更好的直觉和决策支撑。 另外，很多人都说“知道很多道理但依旧过不好这一生”，或许可以这样解读，这有两个原因：1）懂得的道理不够普适，不知道其适用场景和边界，不知道什么时候用；该用的时候想不起用；2）只有概念性知识，没有事实性知识，无法把知识和实际的场景联系起来，无法激发使用知识的直觉。日常反思也就是把概念性知识和事实性知识组合的过程，读取名人传记有类似的作用。 当意识到反思的重要性后，今年上半年曾在电脑上增加定时提醒，每晚十分钟，反思下当日的工作。但是坚持了几个月后，就不了了之了。主要是因为发现没有太多的反思内容，然后就逐渐流于形式，慢慢停止了这个过程。这两天读了《好好学习：个人知识管理精进指南》后有了启发，作者强调了临界知识和反思的重要性。作者也曾遇到类似的情况，他的假设是“假如反思有用，那是不是我没有正确的反思导致坚持不下去呢？”。基于这个假设，作者提出了一些反思的内容、对标内容等具体的手段去落实反思的内容、路径和深度，从反思中得到正反馈，正向促进反思行为。 所以本文主要是基于“反思是有价值的，值得去做的”的假设，来思考如何在工作中执行反思这个行为。本文主要侧重于自己的工作实践，不做完整性讨论，可参考《好好学习：个人知识管理精进指南》进行补充学习。 临界知识这个概念来自《好好学习：个人知识管理精进指南》，指通过由表及里的分析后，发现事情的根本原理或原因。可以通过5Why来发现根因。图片来源 复盘内容此处只讨论工作范畴，建议工作日早上进行回顾和反思。这里主要想细化反思内容，达到能执行的程度。反思的内容不是一成不变的，会随项目周期，项目类型等因素而不同，所以要注意随时适时调整反思内容。反思的目标来说是相对确定的，即通过反思发现更普适的知识，然后联结事实性知识，沉淀为有价值的经验。这也是一个习惯养成过程，天下难事必作于易，刚开始的反思内容可以少一点，慢慢通过正反馈，来正向促进习惯的养成。以下把反思的内容分为两个部分，固定的和变化的。 固定内容对事物规律的反思肯定有一些通用的逻辑，把这些逻辑作为固定的内容写成TodoList，每日进行核验。列表如下，随时补充： 情绪是否平和 整体视角审视项目的进度、风险，结合具体数字 正在进行的任务的进度、风险，结合具体数字 当前有预期之外的事情发生吗 当前最重要的三件事是什么 变化内容对每日接受到的随机信息，如工作相干的文章、项目信息、突发事件等，进行反思。以下列了几个有可能的思考内容。 这个信息的直接原因/根本原因是什么 有哪些改进方式 是否能发现临界知识 可以找一个相干问题进行思考","link":"/2024/11/20/%E4%B9%A0%E6%83%AF%E5%A4%8D%E7%9B%98/"},{"title":"代码治理及研发心理","text":"在经历了架构治理的多个项目，有顺利达成预期的（如废弃代码治理），也有不太符合预期的（如问题函数的存量/增量治理、服务耦合治理）。通过对比这两种情况，以及对不符合预期项目的实际case的分析、研发的反馈、指标数据分析，本文尝试分析研发收到治理任务时的心理，来理解研发做出决策的关键因素有哪些，给后续的治理任务提供更多信息。 以下分为两种场景进行讨论，一是治理不符合预期的任务，研发多采取延宕治理策略。二是治理符合预期的任务，研发采取协助治理的策略。 一、延宕治理场景 任务场景：以问题函数的增量治理场景为例，研发在提交MR后，问题函数的CI卡点会分析本次变更的函数中是否有高复杂函数和重复函数，如存在，则进行卡点提示。 治理效果：3个业务线推广后，卡点跳过率为91%，远没有达到预期，具体分析可见抽象假设和验证假设。 心理分析： 我作为研发，为了完成需求，进行了代码开发和本地测试后提交了MR。这时被一个问题函数检测的卡点拦截了，卡点检测出1个高复杂函数。 我仔细看了这个函数，嚯，竟然有249行。虽然我只增加了一个if条件，不过有一说一，这个函数确实很复杂和需要被重构。① 但是我只增加了一个if条件，改动很小呀。让我去修改，多多少少有点心理不平衡。② 这个函数有十几个人修改，经历了一年的迭代才逐渐劣化到如此。这是大家的函数，我为什么要去改呢，由别人去改不更好吗。本该是“谁污染，谁治理”，没曾想却变成了“大家污染，无人治理”，公地悲剧莫如是。③ 这种高复杂函数的修改成本看起来就很高，远高于我为了实现需求的必要变更成本。④ 修改后的验证工作也需要花更多时间，例如写单测覆盖关键路径。⑤ 随之需要承担的上线风险也高了很多，比我的血压都高。⑥ 就算我费劲改了，除了出力和承担风险外，好像也不会有什么好处。不改又不会有坏处。⑦ 再说了，上线压力这么大，这种代码优化类任务还是往后放放吧。 研发的直观体感的关键词是：治理成本高、个人收益低。 二、协助治理场景任务场景：以静态废弃代码下线场景为例，下线工具在保障安全的情况下自动下线代码，然后经过编译成功的验证后，以飞书卡片的形式推送给研发。推送给研发的任务中有八成是无风险的可自动合入的工单，研发只需要知晓即可，无需动作反馈。另外两成是低风险的手动合入工单，研发可以在收到的卡片里点击“合入”按钮即可合入，或者点击“取消合入”来取消工单。另外，卡片只在工作日的上午推送，避免假期推送后被Miss。 治理效果：合码率＞80%，超出预期。 心理分析： 我作为研发，上午到公司后收到一个废弃代码下线的推送。① 卡片设计的挺简洁，那“我”仔细看下是啥吧。哦，是关于我负责仓库的废弃代码下线信息的卡片。② 上面说已经在其他仓库下线了100万行代码，看起来应用挺广的。不过为了安全考虑，我还是看下删除的内容是什么吧。嗯，看起来没啥问题。根据文档了解到其下线原理很安全，并且这个是编译通过后才推送的工单，感觉MR合入的风险很低。③ 那我需要做什么呢？哦，这是一个自动合入工单，在3天后自动合入。流程很简洁啊，不用操作挺好的。那就这样吧，让他自动合入吧。 研发的直观体感的关键词是：承担风险低、零修改成本。 三、代码治理启示代码治理是由架构治理小组发起的，去治理研发资产的行为。这需要研发的参与，但是决定研发参与积极性的是研发承担的成本和风险。成本可细分为修改成本、验证成本。如果要提高治理效果，那么就需要改变这几个变量： 减小研发修改成本，最好是零成本。比如废弃代码下线由工具完成代码下线和生成MR；复杂函数治理由LLM进行治理。 减小研发验证成本，最好是零成本。比如依托单元测试、集成测试、流量Diff等自动验证；工具能力完备，结果置信度高。 减小研发承担风险，最好是零风险。比如废弃代码下线在编译成功后再推送给用户确认； 工具/平台/流程易上手、易理解、易操作。比如操作步骤少，信息提示准确，交互简单明了。","link":"/2025/06/27/%E4%BB%A3%E7%A0%81%E6%B2%BB%E7%90%86%E5%8F%8A%E7%A0%94%E5%8F%91%E5%BF%83%E7%90%86/"},{"title":"传记","text":"别逗了，费曼先生！2025/06/19 或许你觉得费曼这个人太过散漫，有时荒唐——但这是一种错觉。他实际上是一束激光；我们在书里看到的许多故事，不过是这束激光在燃烧钢板时飞溅出的火花。他在评审课本的时候，必得一本一本亲自看。他在参加一个会议的时候，如此不肯通融地与俗见作对。他对科学的正直品格提出的要求，使人肃然起敬。 人生得遇苏东坡 2025/07/03 点绛唇 闲倚胡床，庾公楼外峰千朵。与谁同坐。明月清风我。别乘一来，有唱应须和。还知么。自从添个。风月平分破。 苏子曰：“客亦知夫水与月乎？逝者如斯，而未尝往也；盈虚者如彼，而卒莫消长也。盖将自其变者而观之，则天地曾不能以一瞬；自其不变者而观之，则物与我皆无尽也，而又何羡乎！且夫天地之间，物各有主，苟非吾之所有，虽一毫而莫取。惟江上之清风，与山间之明月，耳得之而为声，目遇之而成色，取之无禁，用之不竭，是造物者之无尽藏也，而吾与子之所共适。 他说的是，你不要因为吾生须臾而羡长江无穷，你应该要把无穷的天地万物拿来为吾生所享受！ 岂惟无鹤无道士，并无鱼，并无酒，并无客，并无赤壁，只有一片光明空阔。 一受其成，而不可更。或主于德，或全于形。均是二者，顾予安取。仰唇俯足，世固多有。 余尝寓居惠州嘉祐寺，纵步松风亭下，足力疲乏，思欲就床止息。仰望亭宇，尚在木末，意谓如何得到。良久忽曰：“此间有甚么歇不得处？” 禅宗有一个公案，记载在《五灯会元》中。小和尚问禅师：“师父，如何才能解脱啊？”禅师问：“谁缚汝？”谁束缚了你呢？小和尚醒悟过来：“对啊，没人束缚我啊！”禅师说：“没人束缚，那你求什么解脱呢？”根本就不用求啊。这个故事还有一个延展的版本，我更喜欢，是三连问。徒弟问：“如何是解脱？”师父反问：“谁缚汝？”徒弟问：“如何是净土？”师父反问：“谁垢汝？”徒弟问：“如何是涅槃？”师父反问：“谁将生死与汝？” 为什么是毛泽东 2025/08/13 明确指出李世民的成功在于后发制人及集中优势兵力的战略战术的只有毛泽东。 影响儿童心理成长的家庭及社会地位是一个相对的概念，而不是成年人理解的绝对概念。例如皇帝的儿子社会地位极高，但排在老末的皇子，由于受到兄长们欺辱，往往心里很郁闷。农村的村主任几乎不算干部，但在小范围里却是千人、万人中的老大，这种相对优势心理对人的影响，我们称之为优势心理决定论，他决定着一个人的心志。这也是我们实在想知道毛泽东成功之道中到底是什么在起最主要的作用，而找到的一个重要的因素，就是不要只看到毛泽东出身社会下层，只是温饱无忧，对他要从事的事业来讲如同一无所有，而是要看到他拥有特殊的优势心理，无论家境还是个人他都具备相对的优势心理，他的不可思议的进步很有可能就是在优势心理不断放大的过程中实现的。优势心理很重要，这一点中国人尚未明确形成共识，是因为我们的社会尚处于变动的激荡之中，机遇和运气成分还很大。而社会结构相对已经平稳的西方有研究表明，领袖素质源自相对优势心理。 夸赞孩子和溺爱完全是两回事儿，赞扬孩子是把孩子视作一个未来不可限量的人来尊重，只是现在还很弱小，需要鼓励方能长大，溺爱则是不把孩子当作平等的人而是玩物，是弱智。赞许和溺爱不是一个层面的问题。 许多富裕的人家常常厌恶乞讨者，赶走接近他们的乞讨者，而不是伸出援助之手，他们拒绝施舍，原因是他们认为自己不够富有，他们眼睛向上看着更为富有的人，这类人一生都是锦衣玉食的可怜虫。眼睛向下的是那些心存慈悲的人们，他们是即使自己不富裕，但依然会施舍一点食物的人，他们是精神富翁。 挫折使得大部分人变得平庸，科学家做过实验，无法跨越的障碍和伤害使得凶猛的动物变得温顺不复血性，避免过早的挫折是人生保持上进心的关键。家长和老师的责任是为早年的孩童支起一片天空，而不是我们常说的让孩子经历风吹雨打，小苗需要的是阳光雨露，不是温室，但也不是狂风暴雨。 中国人没有强烈的宗教意识，不关心自己后世前生，而是关注上下两代，所以中国人是最注重自家孩子的教育的，这一点叫西方人赞叹不已。中国社会有可能在某一阶段表现得很糟糕，但中国社会的基本单元即每个家庭却长时间保持着上进心，每一个元素都是好的，需要的是外力来引导整合。外力常见的是政权强力，很少见的是来自思想和信仰的力量，而毛泽东同时具备了这两方面的力量，这一切的基础是在一师的学习中成形的。 俗话说，无志之人常立志，有志之人立长志，其实这只是一种表象。学生时代常犯的错误就是常立志，最终多数人变成了无志之人，常见的解释是由于不坚持无恒心，其实这样的解释是浅薄的。关键是坚持不是人们想象的那样，只是自己意志的因素，而是各种因素综合的结果，坚持的先决条件是方向对，路线对，不断有成方能坚持。如果外在条件不合适，当事人自己再怎么坚持也很难成功。举例来讲，一颗种子要发芽需要土壤与水分，而不是在石板上坚持。青年人求学，大多喜欢谈立志，诸如将来要当军事家、政治家、教育家等。而毛泽东则认为，离开真理来谈立志，只是对前人中有成就者的简单模仿，真正的立志，首先是寻找真理，然后按它去做，而不是张嘴就来。 学问、学问，毛泽东较早意识到学习的最好方法除了自学就是提问。而能问出问题就是进步的开端。 中国有一句老话叫作“交友须胜己，似我不如无” 我们常常能够感觉到文章好坏在于思想而不是文字，有无思想是人生分水岭 所以后来毛泽东说，马克思主义的道理千条万绪，归根结底，就是一句话：造反有理。但谁又能说有理就一定能赢呢？要想胜利靠什么呢？答案是胜利不能靠文字，也不能靠语言，而是世俗力量，是枪杆子。 要想发动农民起义就要等到秋收后，能想明白吗？其实原因比我们想的要简单，秋收后有饭吃的人，就不会革命，但没有饭吃的人就会造反，这就是革命的真相。 毛泽东不容易与强者相处，因为他想征服所有的人，但智慧和理想又促使他能够和任何人相处，这也是理解毛泽东人际关系中的关键点。 这就是毛泽东在军队推行民主的最初怪相，平等能提升战斗力，但指挥打仗靠民主决策可行不通，因为大部分人的决定并不一定是对的，尤其是在未来尚未明了的情况下，对于未来道路的选择，靠着民主决策，成功的概率不会高于百分之五十。这就是为什么从古到今绝大多数军队都不是双首长制，监军制多数情况下是要打败仗的。 对待毛泽东的态度，决定了人们未来的位置。历史不是我们后来读到的粗线条，而是由无法明了的细节组成。毛泽东如此渴望成功，为了成功，他敢于抛弃任何利益，愿意做出任何牺牲，所以绝对在意别人是否支持他。 中国人一直在追求的那个单一的终极真理可以说是不存在的，任何真理都是一套体系。这个懒是偷不得的，人类永远在选择和否定中探索，人生智慧甚至不能父子相传，只能靠每个人自己的感悟去面对人生。 我们的一生会遇到许多理论，“真正的理论在世界上只有一种，就是从客观实际抽出来，又在客观实际中得到了证明的理论。” 莽莽昆仑：粟裕大将征战轶事 2025/09/02 所谓“神仙仗”，就是战前预案准确无误；战中各种情况甚至意外都处理及时正确；战后撤离与清理战场均无任何失误。 二是任命聂凤智为全权代表，在地下组织的协同下，与刘昌义谈判，接受了刘昌义的投降，并让刘昌义所部享受起义待遇。于是，大上海顺利地回到了人民的怀抱。 粟裕后来回忆说：“全面内战爆发以前，当我们看到这场战争已经不可避免时，我们在苏中面对即将进犯的敌人，深感重担在肩，推动着我们对敌我双方情况进行调查研究，进行全面分析，推动着我们反复思索，从中寻找战争的客观规律，特别是战争初期的规律，以争取胜利。” 第二，粟裕给他的敌军资料，团以上军官，特别是师以上军官的家庭出身、成材过程、兴趣爱好、作战特点都很详细，有的还附有照片。知己知彼，百战百胜，他如此熟悉敌情，怎能不打胜仗？！ 粟裕打仗，一般在打第一仗时就已经盘算好第二、第三仗了。但决不是一成不变的，往往随着敌情变化而改变部署。 37年后，粟裕曾这样评述苏中战役：“为了迅速准确地探明并掌握新的战争特殊规律，以指导战争并赢得胜利，运筹帷幄的最高统帅部密切注视着战争初期作战，并且用心组织和诱导战区指挥员对初期作战中若干问题进行反复深入的讨论。在苏中战役过程中对一系列重大问题的探讨和争议，正是积极探索新的战争特殊规律的求实精神的表现，也是高度的战争责任感的体现；然而，只有战争的实践才可以把不同的意见统一起来，得到一个正确的答案。随着时间的推移，苏中战役提供的具体经验，有的将会失去它的作用。但是，这种从敌我双方实际情况出发，研究战争的特殊规律以指导战争的经验，对我们学习和领会毛泽东军事思想，以及研究未来战争是会长期有益的。这是苏中战役在歼灭敌人数字之外的另一重要意义。” 凡是对粟裕有所了解的人都知道，粟裕最大的嗜好就是看地图，然而，人们并不一定知道其中的奥妙。有人问粟裕：“您天天看地图，这上面究竟有什么奥妙啊？”“奥妙无穷啊！熟悉地图，熟悉地形，是军事指挥员的基本功。不谙地图，勿以为宿将。” 有一次，一侦察员回来汇报情况。粟裕突然问：“南岸桥头有十来棵小树，还在吗？”“还在。怎么，首长去过那里？”“没去过，不过，这些地图上都有。”“啊，树小，未成林，隐蔽不了几个人。”“同志，树还未成材，农民是不会去砍的。如果被砍掉了，说明敌人已进驻那里，而且已控制了桥面，为开阔视野，进一步发挥火力，才会把这些树砍掉。”粟裕一脸严肃。 “不谋万世者，不足谋一时。不谋全局者，不足谋一域”。古今中外的优秀军事家，都十分强调军事决策上的全局观念和战略远见。粟裕不仅深谙此道，而且善于把它体现在战争的实践之中。 陈毅最后说：“毛主席、党中央再次指示，在陈毅的领导下，大政方针共同商定，战役指挥交粟负责。粟裕同志，我们一如既往，军事上主要由你考虑，按照毛主席、党中央赋予的作战任务，有计划有步骤地消灭敌人。至于先打谁，后打谁，什么时间、什么地方、怎么打，请你大胆地负责考虑和指挥。”粟裕立即站起来说；“陈军长，我还是像过去那样，全力以赴当好你的助手。大事、重要事，事先及时请示；小事，一般事，事后及时汇报。” “从全局权衡利弊，经过反复思考，我认为：三个纵队暂不渡江南进，集中兵力在中原黄淮地区大量歼敌，打几个大歼灭战，尽可能地将敌主力歼灭在长江以北，更有利于实现‘打倒蒋介石，解放全中国’这个战略目标。”陈毅不由一惊，怎么，中央已两次否定，居然还坚持己见？一直微笑着的陈毅，突然严肃起来了。手中的烟已燃了大半截也不知觉，他看着粟裕说：“怎么，中央要你过江，你居然不过江？”“作为一个党员，作为一个战区指挥员，我应该把自己的想法及时地、如实地向中央汇报。当然，我也不是毫无顾虑的，主要担心自己的看法有局限性，对中央如此重大的战略决策，提出不同看法，会不会干扰统帅部的决心。因此，更想听听陈军长的意见。” 他的音乐天赋，得到音乐老师的重视与赞扬，亲自教他弹钢琴，并把琴房的钥匙给了粟裕，允许他单独到琴房练钢琴。这位音乐老师，鼓励粟裕务必沿着音乐的道路发展下去，将来不但是个全才，而且必成大器！ 毛泽东猛地站起来，走近粟裕很高兴地说：“粟裕同志，你讲得很好，也很对。你能够对过去的事一件件一桩桩地进行总结，以指导今后的作战和工作，这是很好的。但是，战争和其他事物一样，有着它内在的发展规律，作为指挥员，只能顺其规律，促进它的发展或转化，来赢得胜利。就是说对经验和教训的总结，要立足全局，从事物发展的基本规律入手，这就叫高屋建瓴。” “张参谋，敌人的铁甲车开来了，你在远处能发现吗？”粟裕在侦察员出发前问。“不知道怎样才能发现。”粟裕便教他们如何用耳朵紧贴铁轨，听铁甲车从远处开来的声音。听多了还能区分是铁甲车还是火车的声音 苏世民：我的经验和教训 2025/09/03 做大事和做小事的难易程度是一样的。所以要选择一个值得追求的宏伟目标，让回报与你的努力相匹配。 给你敬佩的人写信或打电话，请他们提供建议或与其会面的机会。你永远不知道谁愿意跟你见面。最后你会从这些人身上学到很多重要的东西，建立你在余生都可以享用的人际关系。在生命早期结交的人，会与你缔结非同寻常的感情纽带。 卢梭 忏悔录 2025/11/16 忏悔录 第一部原文：罗克伯爵就把我们两个人都辞退了，辞退时只说：罪人的良心一定会替无罪者复仇的。他的预言没有落空，它没有一天不在我身上应验。 原文：处于顺境的时候，良心的谴责就睡着了；处于逆境的时候，良心的谴责就加剧了。 原文：盖姆神父明智地教导我：最初的热情要适可而止，不然的话，后来一松懈下去，就显得太明显了。“你初来时的表现，”他对我说，“是人们以后所据以要求你的标准，你要善于使用你的力气，以便日后可以多做一些工作，但是你要注意，做事千万不要虎头蛇尾。” 原文：我手里拿着笔，面对着桌子和纸张，是从来也写不出东西的。我总是在散步的时候，在山石之间，在树林里，或是在夜间躺在床上难以成眠的时候，我才在脑袋里进行拟稿；大家可以想象，一个完全没有记性、一辈子不曾背过六篇诗的人，写作起来该是多么迟缓了 原文：他向我指出我可能遭到的危险，并对我说少年的荒唐时期总是越短越好 原文：俗话说：“剑毁剑鞘。”我的情况正是这样。我的激情给我以生命力，同时也伤害了我","link":"/2025/11/17/%E4%BC%A0%E8%AE%B0/"},{"title":"一致性hash","text":"一、一致性Hash概念 一致性哈希算法在1997年由麻省理工学院提出，它是一种分布式缓存协议，用来减轻或解决网络中的热点问题。它是一种分布式散列方案，它通过在抽象圆或散列环上为服务器或对象分配一个位置，从而独立于分布式散列表中的服务器或对象的数量进行操作。这允许服务器和对象在不影响整个系统的情况下进行扩展。 热点问题是指当一个服务器在短时间内接受到远超平时流量的客户端连接请求时，导致服务降级或不可用的现象。而通用的解决方案是通过增加缓存来缓存热点数据，由缓存截流客户的压力。一致性hash就是在这个背景下，对之前的一些中心化的缓存协议的改良，使其可以应对大量的结点导致的复杂度和及降低结点增删带来的影响。 二、Amazon的Dynamo实现1.一致性hash变种 - 虚拟结点由于一致性hash把结点随机分配到hash ring上，这会导致数据和负载的不均衡。于是Dynamo使用了其算法的变种：每个节点不是映射到hash ring的某个点，而是多个点。 具体实现是增加虚拟节点的概念，这带来了以下好处： 当一个节点不可用时（故障或例行维护），这个节点的负载会均匀分散到其他可用节点上 当一个节点重新可用时，或新加入一个节点时，这个节点会获得与其他节点大致相同的 负载 一个节点负责的虚拟节点的数量可用根据节点容量来决定，这样可用充分利用物理基础设施中的异构性信息 2. 故障策略 本篇幅内容摘录了Dynamo: Amazon’s Highly Available Key-Value Store 中文翻译的内容。 2.1 短期故障： hinted handoff（移交给其他节点处理，附带提示信息）Dynamo 采用了一种宽松的仲裁机制（sloppy quorum）：所有读和写操作在 preference list 的前 N 个健康节点上执行；注意这 N 个节点不一定就是前 N 个节点， 因为遇到不健康的节点，会沿着一致性哈希环的顺时针方向顺延。 以上图配置为例，其中 N=3，如果 A 临时不可用，正常情况下应该到达 A 的写请求就会发送到 D。这样设计是为了保证期望达到的可用性和持久性。发送到 D 的副本的元数据中会提示（hint）这个副本本来应该发送给谁（这里是 A），然后这个数据会被 D 保存到本地的一个独立数据库中，并且有一个定期任务不断扫描，一旦 A 可用了，就将这个数据发送回 A，然后 D 就可以从本地数据库中将其删除了，这样系统内的副本数还是保持不变。 NOTE：例子中设置的副本数为3，当 A 异常时会把其副本放到（A+3）的位置 D（独立空间），当 A 恢复时再从 D 移回 A 。 2.2 持久故障：anti-entropy protocol keep replicas synchronized 通过Merkle trees来快速检测副本之间的不一致性，以及最小化转移的数据量。 一个 Merkle tree 就是一个哈希树，其叶子节点是 key 对应的 value 的哈希值。 父节点是其子节点的哈希。 Merkle tree 的主要优点是： 每个分支都可以独立查看（check），节点无需下载整棵树或者整个数据集 减少检查副本一致性时所需传输的数据量 3. 增加/移除结点当一个新节点 X 加入到系统后，它会获得一些随机分散在 ring 上的 token。对每 个分配给 X 的 key range，当前可能已经有一些（小于等于 N 个）节点在负责处理了 。因此,将 key range 分配给 X 后，这些节点就不需要处理这些 key 对应的请求了，而 要将 keys 转给 X。 考虑一个简单的情况：X 加入上图中 A 和 B 之间。这样，X 就负责处理落到 (F, G], (G, A] and (A, X] 之间的 key。结果，B、C 和 D 节点就不需负责相应 range 了。因此，在收到 X 的转移 key 请求之后，B、C 和 D 会向 X 转移相 应的 key。当移除一个节点时，key 重新分配的顺序和刚才相反。 参考 一致哈希—wikipedia Dynamo: Amazon’s Highly Available Key-Value Store 中文翻译 Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web 中文翻译-未完成 consistent-hashing blog consistent-hashing blog","link":"/2021/01/19/%E4%B8%80%E8%87%B4%E6%80%A7hash/"},{"title":"你的压测结果真的符合预期吗","text":"最近大促前负责做系统压测，根据线上的某个具体业务场景做了Mock压测，根据压测时的一些监控数据得出了一个压测报告。 当观察到压测的数据能扛住峰值流量后，并没有去仔细压测的梯度数据是否合理。后经他人review后发现，梯度数据不符合线性规律。之后调整压测环境后（调整压测时间，调整RPC线程池数量，调整日志级别，调整Mock下游RPC线程池数量），才得出符合线性的数据。 事后反思得出，类似压测这种工作是有一个理论的期望结果的，当实践得出结果后，应该核对结果是否符合理论预期，如果不符合的话，肯定是压测的方式和环境有问题，需要进行调整。 简而言之，做事之前有理论期望，做事之后核对是否符合预期。","link":"/2021/04/12/%E4%BD%A0%E7%9A%84%E5%8E%8B%E6%B5%8B%E7%BB%93%E6%9E%9C%E7%9C%9F%E7%9A%84%E7%AC%A6%E5%90%88%E9%A2%84%E6%9C%9F%E5%90%97/"},{"title":"使用CPU百分位作容器缩容的参考指标","text":"一、背景基于公司的节流政策，为了减少不必要的硬件成本，各小组开始对CPU使用率较低的应用进行缩容。大部分团队都是基于内部的火眼监控平台，重点关注和缩容CPU平均使用率较低的应用，然而CPU的平均使用率会丢失一些重要信息。于是，效能部门的人，通过监控容器的数据整理出了以周为单位的CPU百分位的及其与平均值的方差的一个报表。 二、CPU百分位与SLA CPU百分位，较之于平均值显示出了更多信息，其表现出了数据集合的信息，我们可以观察多个不同的百分位点，来获取更加全面的信息。如果把平均值比作一个点，那么百分位携带的信息则可以看作是一条线。 使用举例： 1）观察TP10，TP50，TP90，TP99之前的走向可知CPU的使用的稳定性。 2）观察TP99.99，TP99，TP90，TP50 如果高位的值都很低，那么说明该应用容器的CPU闲置率较高，可通过缩容提高CPU使用率； 如果高位很高，但是中位数很低，那说明该应用会存在短时间的业务洪峰，导致CPU短时间标高；此时，就要根据SLA来判断，是否要牺牲SLA来提高资源利用率。 三、思考缩容的目标是提高资源利用率，而起初只参考CPU平均使用率，本质上是没有深入思考，CPU使用率是否能真正横量性能，是否能作为关键指标。存在思考的惰性，导致没有行之有效的方法去完成目标。以后要多问几个为什么，找个能说服自己和别人的理由才去做，也就是所谓的“做事要有方法论”，不能想当然。 # 参考 https://en.wikipedia.org/wiki/Percentile https://quickbooks-engineering.intuit.com/web-performance-what-you-dont-know-will-hurt-your-customers-fd6b19b7da07","link":"/2021/03/17/%E4%BD%BF%E7%94%A8CPU%E7%99%BE%E5%88%86%E4%BD%8D%E4%BD%9C%E5%AE%B9%E5%99%A8%E7%BC%A9%E5%AE%B9%E7%9A%84%E5%8F%82%E8%80%83%E6%8C%87%E6%A0%87/"},{"title":"使用hsdb查看运行时类","text":"1）可选，为方便起见先创建一个JAVA_HOME的软连接 ln -s /Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home jdk8 2）启动hsdb sudo java -cp jdk8/lib/sa-jdi.jar sun.jvm.hotspot.HSDB 注意，最好加上sudo，否则可能会在创建Class文件时出现No such file or directory异常。 3）连接到Java进程 ​ File | Attach to HotSpot process ...，输入Java进程号。 4）查看类 Tools | Class Browser 5）输入类包含的字符，过滤出代理类 6）点击代理类，然后点击“Create .class File” 其会在运行hsdb命令的当前目录生成class类。 7）找到class文件就可以反编译查看类","link":"/2021/05/28/%E4%BD%BF%E7%94%A8hsdb%E6%9F%A5%E7%9C%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E7%B1%BB/"},{"title":"使用msgpack实体增加字段序列异常","text":"一、MessagePackMessagePack官网如下介绍。 It’s like JSON. but fast and small. MessagePack is an efficient binary serialization format. It lets you exchange data among multiple languages like JSON. But it’s faster and smaller. Small integers are encoded into a single byte, and typical short strings require only one extra byte in addition to the strings themselves. MessagePack是一个高效的二进制序列化格式。他像Json一样可以跨语言传输数据。但是比json更小更快。短整形被编码为单字节，短字符串也只需要附加额外的几个字节。 二、查看Java对象生成的Tempalte类1）类原始信息 123456789101112131415161718192021222324252627282930package pers.kivi.javafragment.msgpack;/** * @author wangqiwei * @date 2021/05/27 23:17 */public class Person { String name; String mail; int age; public Person() { } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; }} 2）MessagePack生成的Template Template通过HSDB进行创建，参考使用HSDB查看运行时类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package pers.kivi.javafragment.msgpack;import java.io.IOException;import org.msgpack.MessageTypeException;import org.msgpack.packer.Packer;import org.msgpack.template.Template;import org.msgpack.template.builder.JavassistTemplateBuilder.JavassistTemplate;import org.msgpack.unpacker.Unpacker;public class Person_$$_Template_1983747920_0 extends JavassistTemplate implements Template { public Person_$$_Template_1983747920_0(Class var1, Template[] var2) { super(var1, var2); } public void write(Packer var1, Object var2, boolean var3) throws IOException { if (var2 == null) { if (var3) { throw new MessageTypeException(&quot;Attempted to write null&quot;); } else { var1.writeNil(); } } else { Person var4 = (Person)var2; var1.writeArrayBegin(3); if (var4.name == null) { var1.writeNil(); } else { super.templates[0].write(var1, var4.name); } if (var4.mail == null) { var1.writeNil(); } else { super.templates[1].write(var1, var4.mail); } var1.write(var4.age); var1.writeArrayEnd(); } } public Object read(Unpacker var1, Object var2, boolean var3) throws MessageTypeException { if (!var3 &amp;&amp; var1.trySkipNil()) { return null; } else { Person var4; if (var2 == null) { var4 = new Person(); } else { var4 = (Person)var2; } var1.readArrayBegin(); if (!var1.trySkipNil()) { var4.name = (String)super.templates[0].read(var1, var4.name); } if (!var1.trySkipNil()) { var4.mail = (String)super.templates[1].read(var1, var4.mail); } var4.age = var1.readInt(); var1.readArrayEnd(); return var4; } }} 由以上代码，可看出MessagePack把java里的类作为一个Array类型进行顺序序列化为二进制数据，其只会按照字段声明顺序写入其值，而不会写入字段名，如序列化mail属性的代码为：super.templates[1].write(var1, var4.mail);。 三、异常分析当实体类新增字段不是最后一个字段时，且序列化端和非序列化没有同步更新实体类时，序列化端和非序列化端的Array中的字段顺序就会不一致，反序列化就会发生异常。 参考 https://msgpack.org/ https://github.com/msgpack/msgpack/blob/master/spec.md","link":"/2021/05/28/%E4%BD%BF%E7%94%A8msgpack%E5%AE%9E%E4%BD%93%E5%A2%9E%E5%8A%A0%E5%AD%97%E6%AE%B5%E5%BA%8F%E5%88%97%E5%BC%82%E5%B8%B8/"},{"title":"共享变量","text":"共享变量一、PublicVar通过PublicVar实现共享，有两种方式： 1）修改代码，每次升级时修改对应变量值 2）无需修改代码，通过ldflags在编译时指定变量值 1、ldflags使用示例1234567891011// main.gopackage mainimport &quot;fmt&quot;var Version = &quot;&quot;func main() { fmt.Println(&quot;Version&quot;, Version) // ...} go build -ldflags &quot;-X main.Version=1.0.0&quot; -x -o product main.go 2、共享变量优点 使用简单 缺点 使用方必须引入共享变量所在module 存在package cycle import依赖风险 推荐建立单独环境module，只用来定义变量，避免循环package依赖风险。 二、运行时传参执行go程序编译后的二进制产物时，增加参数。若当前编译出的二进制产物为go-product。 1go-prudct -psm a.b.c -conf-dir conf 123456789101112131415161718192021222324252627282930313233343536package mainimport ( &quot;flag&quot; &quot;fmt&quot;)var psm stringvar confDir stringfunc main() { printOsArgs() parseFlag() lookupFlag()}func printOsArgs() { for idx, arg := range os.Args { fmt.Println(idx, arg) }}func parseFlag() { // 相同的Flag name只能解析一次 flag.StringVar(&amp;psm, &quot;psm&quot;, &quot;default&quot;, &quot;PSM&quot;) flag.StringVar(&amp;confDir, &quot;conf-dir&quot;, &quot;default&quot;, &quot;config directory&quot;) if !flag.Parsed() { flag.Parse() } fmt.Println(&quot;psm&quot;, psm) fmt.Println(&quot;confDir&quot;, confDir)}func lookupFlag() { fmt.Println(&quot;flag.Lookup psm&quot;, flag.Lookup(&quot;psm&quot;).Value)} 1、共享变量1）os.Args直接获取运行参数优点 使用方无需引入多余module 缺点 需要自行解析参数，解析稍显麻烦 2）flag解析运行参数 flag.Parse方法调用前，所定义的flag 必须不少于 实际的flag，否则解析会异常 flag.Parse方法调用后，不允许再次定义flag，解析前先判断flag.Parsed() 优点 使用方无需引入多余module 缺点 由于执行顺序无法保证，所以使用方必须都有以下逻辑 判断flag是否已解析过 若未解析过，则定义所有flag，然后进行解析 如果解析过，则通过flag.Lookup查找指定变量 三、os environment设置操作系统环境变量，go通过os.Getenv()获取。 1、共享变量优点 使用方无需引入多余module 获取逻辑简单 缺点 不适合于操作系统内运行多个差异化实例场景 四、第三方存储借助本地文件、数据库等存储。","link":"/2022/06/10/%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F/"},{"title":"依赖树查看","text":"查看依赖树一、gmcharGitHub - PaulXu-cn/go-mod-graph-chart: Draw graphs through GO MOD GRAPH output 使用方法： 12$ go install github.com/PaulXu-cn/go-mod-graph-chart/gmchart@latest$ go mod graph | gmchart 依赖多时，显示不友好。 二、deptree[ 推荐 ]GitHub - vc60er/deptree: show golang dependence like tree 使用方法： 12$ go install github.com/vc60er/deptree@latest$ go mod graph | deptree -d 3 | grep &quot;关键词&quot; 使用grep，即使依赖很多，也很容易过滤出关心的依赖。","link":"/2022/09/22/%E4%BE%9D%E8%B5%96%E6%A0%91%E6%9F%A5%E7%9C%8B/"},{"title":"关于信息同步","text":"关于信息同步把自己变透明，减少信息差公司内的项目已经变得足够复杂，一个研发很难仅凭个人经验顺利的按期完成任务。把自己变得透明，可以减少信息差，这不会让你丧失项目的掌控感，而是会带来更多的好处，例如：1）获取更多角色视角的信息输入，越多的信息，能带来更全局的解题思路；2）给项目带来更多的评审者，使项目方案逻辑更完备，减小项目落地执行的风险；3）向上及时高频同步足够信息，让上层决策者对项目进度和走向更清晰，项目走偏时能第一时间被发现。每次信息同步，都是向上对齐，避免项目路径风险；5）项目计划的同步，能让项目的执行者和参与者明确要执行事项，更好的评定任务优先级和进行进度把控；6）能带来潜在的合作伙伴和用户，信息的输出能让用户更好的发现你和了解你在做什么。 当然你可能有顾虑，比如我变得透明了，别人对我的方案挑剔怎么办？我会不会丧失项目的把控？别人的否定意见会不会对我个人credit有什么影响？诚然这些顾虑从人性角度来说是可理解的，就像三体中的黑暗丛林法则一样，人本能的希望能够隐藏、保留自己，暴露意味着风险。 所以转变这种保守自封心态非常重要，心理学上的建议可以参考下：以发展的、成长的思维去看待自身，我非生而知之者，吸收更多的他人输入，才能扩大自己的知识边界。 提炼信息人们当前处于信息爆炸的时代，上班时微信消息、飞书消息、邮件、骚扰电话、临时会议、隔壁同事新买的噪音贼大的青轴键盘等等，这些导致人们专注度变低、信息提取率下降。如果你在信息同步时，只是罗列你做的事情，那毫无意义。因为没人会花精力从中提取你的关键决策和结论是什么，毕竟这样的流水账在小学就被老师痛斥。 那么该同步哪些信息呢？ 1）同步关键决策，例如项目执行时遇到关键技术选型，解释清楚基于什么背景，根据什么思考，有什么优劣。把思考路径说清楚，这样别人就能对你的推导过程进行证伪或者证真；2）同步关键进度，例如项目的里程碑定的关键指标数据，现在数据的完成度，这样别人能感知项目是否存在风险，是否需要进行资源调配；3）同步下一步动作，让别人了解近期计划交付的内容，对齐预期，避免交付和预期不符，及时纠正下一步动作。 那么哪些不需要同步呢？非关键细节不用同步，避免增加信噪，这些信息可以通过文档链接让想深入了解的人有迹可循即可； 总体的思路是对信息进行提炼，让各位看官能短时间内、不假思索的明白你主要在做什么，为什么这么做，下一步做什么。 根据受众调整内容饱和度如果是部门内部，那么一般会在周会上以周报形式同步，可以同步更多的细节，比如，详细进展、决策、相关文档。 如果是部门外部，一般而言只需要同步关键结论即可，外部并不关心你的进度。同步太多外部不关心的内容，只会让受众对信息脱敏，降低关注度。 保证信息通知到相关人信息可以通过邮件抄送，消息@方式，通知到关心的人。这个受众可能是动态的，如果后面有人表现出兴趣，比如给你留言、询问等形式关心你的项目，你应该及时更新这个相关人名单。 想象一下，你在小群里同步时没有@某个人，那么他从主观意识上会认为这件事情暂时不用他关心，大概率会无意识的忽略消息细节，这就会导致消息延迟，对项目可能产生潜在风险。如很久之后合规人员才知道你的项目，而你的项目不合规，会导致骑虎难下，陷入两难。 同步项目预期要在项目实施前同步预期，如果有把握，那就用数据说明。如果没有把握，那么就同步出这只是试点，需要观后效。","link":"/2023/10/21/%E5%85%B3%E4%BA%8E%E4%BF%A1%E6%81%AF%E5%90%8C%E6%AD%A5/"},{"title":"为什么我的EL在测试和线上环境结果不同","text":"一. 问题描述某日在EDI值班时, 某研发前来询问一种令他困惑的现象, 在RCP环境和线上环境, 相同el表达式的计算结果不一致. el表达式类似${map.prop eq 'anyway'}, 其从一个map中获取指定属性值与某字符判等. 当map中存在prop属性时, 两个环境结果一致, 但当map中不存在该prop时, 两个环境则结果不一致. 线上环境不符合期望. 二. 尝试路径 通过RCP里的EL表达式测试工具测试类似场景, 结果符合预期. 把该流程发布到测试环境, 测试后发现与RCP表现一致. 初始认定故障原因是其编排的流程有误, EL表达式类库错误暂忽略. 开始着手review其流程, 无果. 增加日志信息, 打印出el表达式执行的语句和结果. 发现问题是线上执行的是另一个流程, 原因是测试环境和线上环境的配置不一致, 导致通过配置的内容来匹配流程, 导致结果不一致. 三. 反思 最早的尝试路径没有基于足够的上下文信息, 导致做了很多无用功. 有些问题无从下手的时候, 先丰富下上下文信息, 然后再行动.","link":"/2019/07/05/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E7%9A%84EL%E5%9C%A8%E6%B5%8B%E8%AF%95%E5%92%8C%E7%BA%BF%E4%B8%8A%E7%8E%AF%E5%A2%83%E7%BB%93%E6%9E%9C%E4%B8%8D%E5%90%8C/"},{"title":"关于会议","text":"日期 修订内容 2021/07/07 初稿 2023/11/20 警惕自证倾向 2024/10/23 追求对的决策 2025/05/27 警惕情景式结论 2025/07/08 显化隐式假设 2025/12/30 邀请拥有更多信息的评审人 一、会议类型评审会议：优先关注事情本身是否成立劳动要基于价值考量。所谓劳动，在工作中可视为是一项业务需求，一个OKR，产品运维等需要付出时间和人力成本的事件。在以往以研发思维做导向的时候，我们往往沉迷于应付需求而付出劳动，忽略了对需求的思考。例如，1）需求是不是一个伪需求，是否可以通过其他更好的方式去解决；2）需求是否附着于某项价值，一个需求如果不产生价值那么必然带来无效劳动；3）需求附着的价值是否和我的价值观有冲突，冲突要如何调停；4）当价值冲突时，是否要牺牲自己的价值而服务于其他价值； 劳动的结果必须是价值导向的，没有价值附着的劳动是无意义的。尤其是公司内部，应该摒弃以工作量定高低，而是以价值产出论优劣。 头脑风暴：先数量，后质量进行头脑风暴时应该不计较idea质量而优先关注数量，不设边界的发散思考、碰撞。 复盘会议：让踩的坑变成梯项目复盘不是论功过，而是扬长补短，须坦诚自省。按照项目时间线，进行回顾。主要复盘内容为，在项目的哪个生命周期，做了哪些关键决策。当时做这个决策的原因是什么，这个决策现在看起来是否正确，如果重新回到那个时候是否有更好的决策。项目复盘后最大的收获应该是对未来相同情景的事情提供参考经验，避免重蹈覆辙。 不可避免的是，有些公司文化是事故到人，关联绩效，这时候催生的甩锅文化，也是打工人利益自卫行为。这种情况，作为利己打工人应该能做到：对外甩锅保住绩效，对内复盘沉淀经验。 陌生会议：快速了解别人的工作当你参加了一个临时会议，你对会议中内容了解不多。那么在会上你应该关心什么呢？或者说通过什么问询方式快速了解会议内容呢。有个比较好用的问询方式：3W1H。比如：这个事情是什么（What），为什么要做这件事情（Why），什么时候启动、结束（When），这件事情是怎么做的，有什么关键技术（How）。然后就是，这个内容跟我有什么关系，如：是否对我有利/有害，是否可协作等。 二、会议冲突阐明立论，细化冲突点有些会议，有一半的时间可能都在争论，而引发争论的原因大概有以下几点： 1）没有明确提出问题，大家争论的点不同； 2）没有足够的信息量，大家有信息差； 3）问题提得比较模糊或者较大，大家就问题探讨的点不同； 4）问题提出时没有共识的原则，大家如果对一些原则没有把握住，那么起点相异必然无法求同。 也就是说，提出问题时要阐明问题是什么，细化问题到可讨论的粒度，补充信息量和原则，让大家可以共识的去开始讨论解决方案。 把会议中的挑剔者变为建议者会议中总会有些人属于指导型沟通者，如果没有控制好情绪和沟通话术，可能会被认为是批评者、挑剔者，这很容易激起另一方的情绪对立。 作为会议的主持者，落入情绪陷阱是得不偿失的。 面对会议挑剔者时，建议从会议目标出发，接受不同的声音出现，真诚沟通，把挑剔者变成建议者。比如，“那你有什么好的建议吗？”可以表露出自己的开放心态和倾听态度。这样对方可能会给以一些其他视角的建议，这有可能是完成你方案的最后一个拼图。总之，会议不是为了对抗，而是为了达成预设的目的。 三、会议决策卫生邀请拥有更多信息的人来评审风险的评估受信息的影响很大，只有信息足够多，才能确保风险评估的准确性。但是未知的信息分为两类：我知道我不知道的，我不知道我不知道的。针对第一类我们会通过信息收集来解决，而第二类有时会被忽略，因为你真的不知道。 针对我不知道我不知道的信息，又可以细分为别人知道和别人不知道。针对别人知道的，我们可以通过邀请拥有更多信息的人参与方案评审来增补信息。针对别人也不知道的，那就只有天知地知了，Go Ahead。 针对废弃接口IDL下线来说，可以邀请Overpass同学、IDL卡点同学、Kitex同学、关键IDL仓库负责人来一起评审方案。那么针对这种仓库重定向的问题就可以提早暴露出来。当然，这个过程看起来，会导致设计阶段显得很长和低效，但可以保证信息足够多，方案评审的结果足够准确。希望能正确评估这些“治未病”工作的价值。 显化隐含假设，论证因果关系有些方案的假设是隐性的，如果不显示声明，评审人很可能会忽视。这可能导致误判因果关系，如抽象假设和验证假设。评审的第一项就是方案所基于的假设，用数据和案例去论证假设的因果关系是否为真。 警惕把相关性误判为因果性，见小数决策和审查数据。 理性采纳Leader的发言如果你是项目owner，那么你的leader(+1、+2、…)给的建议最终是否采纳需要自己理想判断，不能盲目接受。因为最后是你负责结果。但是是否采纳，都需要及时同步出来。 不可否认的是，确实有些公司存在办公室政治，leader的建议可能只是命令的委婉表达，具体如何决策还是需要看办公室文化。 警惕自证倾向话说“证实是天性，证伪是理性”，人总会对自己先入的观点有偏好，大脑会倾向于证实该观点。自证倾向，会造成辨证冲突，会议很容易变成对抗的氛围。书籍《让思考成为习惯》里有一些好的建议，可以参考下。 追求对的决策，而非我的决策是对的《原则》里有句话“我的目标只是让自己正确–我并不关心正确的答案是不是来源于我。所以我学会了让自己保持极度开明的心态，允许其他人指出我可能疏忽的东西。”。会议过程要公开的、透明的、非抵抗的、建议性的沟通，沟通不是为了捍卫自己的决策，而是为了聚集群体智慧，形成群体决策，得出正确的决策。当然，正如《清晰思考：将平凡时刻转化为非凡成果》中所说，正确的决策不一定会有期望的结果，因为世界是变化的、复杂的，正确的决策只是提高了成功率，还尚未能百分百成功。即不要因错误的结果否因决策过程。 聚焦会议的讨论层级讨论的内容可能有多个抽象层级，确认本次会议要讨论的抽象层级，聚焦该层级。例如，当前会议只是对齐各方的规划，那么就不要深入了解各方的具体思路。聚焦当前层级，可以避免发散带来的低效，当发生层级跳变的时候，要提醒参会各方，是否有必要在多个层级间讨论。 警惕情景式结论要认识到一个客观事实：由于心理（反驳型人格、自证倾向、服从多数等）和情景原因，导致部分会议结论只在当时有效，会后可能会被推翻。 例如，研发A认为方案x会造成研发的打扰，所以不做方案x。而会上进行发散性提问时，可能会导致启用方案x。而研发A真正去做的时候，则又会被质疑。 四、会议流程参会者数量参考《毛泽东选集-第三卷》中的“《农村调查》的序言和跋”。 会议前-自问求自洽文档评审前前，整理自问文档、自问自答，避免文档逻辑不完备。","link":"/2025/12/30/%E5%85%B3%E4%BA%8E%E4%BC%9A%E8%AE%AE/"},{"title":"关于规划","text":"务实做规划，使其可执行上次在做23年下半年方向规划时，当时考虑到是新成立方向，所以规划内容偏形而上的概念性阐述，无法让团队同学对下半年要做的事情具象化，总体看来优先务虚。例如，描述了宏大的愿景，讲述了一堆我想做什么、以后要做成什么样，时间跨度大，不确定性强，很多事情没有经过严格论证就定了目标；反而对半年内要做的事项粗略带过，没有明确论述。总体而言，当时写的初版规划偏愿景，而非可执行的规划。 为什么规划 首先要明确规划的目的，规划不是为了画饼，不是为了给自己、给组内同事、给leader画饼，也不是一种形式。规划是在限定的时间范围，圈定人力，设定目标，论证目标合理性，然后自上而下拆解为步骤形成一个逻辑自洽完备的问题解决方案。向上对齐目标，避免目标偏差、收益/交付不符预期；向下对齐实施路径，明确团队要做的具体事项。规划经过自上、自下的校准后，会减少项目风险，提高按时交付的信心。当然，规划执行时，可能外部内部的变化，需要及时调整。如人力变化，组织变化，业务重心变化等等。我们要拥抱变化，规划不是一成不变的，要定期回顾和调整，对这些变化进行响应，并且把调整内容及时同步出来。总体而言，规划相当于对未来要做的事情，画了一条目标线，我们通过一个个的迭代逐渐趋近这条线，这样就算结果有偏差也不会太大。 悲观主义者可能会认为，规划很难百分百达成，那我干脆不做了吧，走一步算一步。这里我想到一个例子，上学的时候帮导师给本科生的实验作业进行评分，刚开始没有评分标准，学生的成绩完全靠经验去给，导致分数偏差较大，同一个分段的程序质量参差不齐。后面我设定了一个标准，程序能跑完所有的测试用例，80-90分；程序通过部分测试用例60-70分；程序无法通过测试用例，不及格；至于90-100分，需要程序符合设计模式、命名规范。当设定完标准后，得分更加合理，同分段的程序也处于同一个水准，偏差不对太大。 怎么做规划首先阐明要解决的问题，例如经过用户访谈、指标数据、竞品分析等输入，通过现象、数据、分析思路、问题拆解，得出在半年内要解决的核心问题。其他团队有个项目曾经规划通过DDD领域驱动的思维去对模型治理，但是在执行半年后发现走不通，发现用户的核心痛点不在这里，这个项目的实施反而放大了用户的问题，最终项目中止，还需要被迫回退所有修改，转而去解决被放大的问题。这个案例里，说明论述问题合理的必要性。公司是以利润为目标，驱动研发活动的，研发对软件架构理想态追逐的心理洁癖不是团队需要考虑的。 然后是阐明目标，即我要把这个问题解决到什么程度，通过数字的、量化的、可衡量的方式呈现出来。那么这个数字应该怎么定义呢，通常是需要有一个公式去辅助说明，例如要优化工单的执行时长，我通过对工单的某些步骤进行定量优化，通过步骤耗时占比，优化时长，工单数量，就可以得出半年内减少的工单耗时。计算方式和数值确定后，最后就可以和Leader一起对齐校正。 最后是实施步骤，即我要做哪些事情能够达成这个目标。步骤需要明确时间范围、Owner、里程碑、同步机制。后面的迭代就以此为输入进行任务拆分和迭代。 当遇到变化时，把变更时间，变更原因，变更内容同步更新到规划中，并同步给干系人。","link":"/2023/10/21/%E5%85%B3%E4%BA%8E%E8%A7%84%E5%88%92/"},{"title":"关于配置中心设计的思考","text":"如今配置繁杂导致运维成本加剧，我结合开发中遇到的一些问题，思考了一个完善的配置中心至少应该具备一些必要的功能，以达到配置可查，可改。 必要的功能我认为应该有以下几点： 1. 配置项全量注册 这一点需要使用配置的端遵守这一约定，避免出现“不知道有多少配置，不知道哪些配置有效”等问题。使开发，运维等相关人员能看到配置的全部，做到心有有数。 2. 区分热配置，冷配置一个配置是否允许是热修改，即修改后应用不用重启即可生效。在配置中心应该能区分出来，当然这同样需要客户端遵守约定去配置中心注册。 3. 可监控各客户端的当前配置状态，查看其是否同步能做到监控具体的某一个客户端当前的配置状态，即查看其配置视图（即客户端当前看到的配置视图）。 4. 支持配置分类可通过业务，标签等对配置进行分类，方便管理。 5. 支持配置加密，认证等安全策略有些配置有安全性要求，如数据库密码等，此时需要增加一些安全机制。具体场景具体分析。 暂时想到以上，留作以后补充。","link":"/2021/05/09/%E5%85%B3%E4%BA%8E%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E8%AE%BE%E8%AE%A1%E7%9A%84%E6%80%9D%E8%80%83/"},{"title":"关于重构时信息量的思考","text":"重构，是一种修改代码以适配新的场景或需求的一种行为。重构大部分情况不是全盘否定，而是增量协定修改。此时，我们需要了解已有的代码，及重构点。从中找出三要素：1）不变的；2）修改的；3）废弃的； 此时，可以汇总重构前后的增改信息到一个图表，一个流程图等中，起到类似版本管理中Diff的功能。好处： 1）可以全部浏览此次修改的范围； 2）对需要重构的内容进行查漏补缺； 3）方便Review，方案讨论。 更多的信息量，意味着决策会更加正确，这在重构EDI日志框架时深有体会。例如，把ES重构前后ES字段进行图表化，对增改进行着色等操作，可以快速查漏补缺。","link":"/2021/04/12/%E5%85%B3%E4%BA%8E%E9%87%8D%E6%9E%84%E6%97%B6%E4%BF%A1%E6%81%AF%E9%87%8F%E7%9A%84%E6%80%9D%E8%80%83/"},{"title":"其他","text":"经济 中国财政体制改革与变迁 宏观经济通识课 货币金字塔：从黄金、美元到比特币和央行数字货币 治大国若烹小鲜：基层治理与世道人心 牛奶可乐经济学 文学 1984 潜规则：中国历史中的真实游戏 人类简史：从动物到上帝 知行合一王阳明：1472-1529 万历十五年 太白金星有点烦 杂项 茶经 基本穿搭：适用一生的穿衣法则 衣品修炼手册 有限与无限的游戏：一个哲学家眼中的竞技世界 影响力原则 费曼学习法 非暴力沟通","link":"/2025/09/24/%E5%85%B6%E4%BB%96/"},{"title":"内存飚高排查（一）","text":"一、背景描述今日中午收到告警，EDI某应用集群的个别容器出现堆内存使用率97%告警，且持续数小时没停止。 二、排查路径 1）查看该集群请求量，与往日对比是否有剧增；从ES集群进行日志统计，发现其与往日流量无差。排除流量异常引起的堆内存飙高； 2）在内存飙高容器上执行jstack，观察是否有异常；观察线程堆栈，发现无异常。排除流程死循环等引起的异常； 3）在内存飙高容器上执行jmap -heap，jmap -histo，jmap -dump 执行jmap前先摘掉流量，避免影响系统可用性。 通过直方图可看出，有大量的IMapFolder对象产生。猜测应该是EDI流程里读取邮件的服务引起的。 恰巧此时有研发反馈其EDI的一个扫描邮箱的流程两天没日志了，印证了刚才的猜想。 5）询问研发邮箱有当前有多少邮件需要扫描研发反馈当前邮箱里有3000+邮件，其中未读邮件200+，且每个邮件都有附件。而其流程逻辑是只处理未读邮件，然后标为已读。 6）查看EDI里处理邮件源码，确认扫描逻辑源码里是扫描全部邮件到本机，然后再根据标识（如未读状态）进行过滤。根据邮件及其附件大小（附件约200KB），每次读取需要200KB * 3K = 600MB空间。这些在容器JVM配置为Xms=4G Xmx=4G上，这些对象必然会进入到老年代。而扫描又是15分钟频次的定时任务触发，必然会频繁触发FullGC。 以下为jmap -heap信息： 12345678910111213Heap Configuration: MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 4294967296 (4096.0MB) NewSize = 348913664 (332.75MB) MaxNewSize = 348913664 (332.75MB) OldSize = 3946053632 (3763.25MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 536870912 (512.0MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 536870912 (512.0MB) G1HeapRegionSize = 0 (0.0MB) 三、解决方案1）让研发把已读的邮件备份到其他文件夹2）降低定时任务频次经过以上方案修改后，内存使用恢复正常。之后研发发现其邮件仍然没有处理，而后我把后台邮件相关的日志通过log4j的Logger和Appender，修改其日志级别，并抽取到单独的日志文件进行观察。发现研发的正则表达式也错了，告诉其正确写法后解决。","link":"/2021/07/19/%E5%86%85%E5%AD%98%E9%A3%9A%E9%AB%98%E6%8E%92%E6%9F%A5%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"关于项目目标","text":"合理设定项目目标厘清项目目标很关键，付出劳动后如果预设目标不合理，那么会导致低估或否定劳动价值。在了解什么是一个好目标之前，先看以下几个真实的例子： A项目：在做的事情是解决服务部署耗时长、不稳定的问题。一个好的目标是服务部署耗时TPxx下降，部署耗时方差变小；一个错误的目标是提高需求吞吐率、需求周期。 B项目：在做的事情是App的私信。一个好的目标是用户关注数量，私信数量；一个错误目标是提升App的dau。 C项目：在做的事情是通过代码重构提升架构合理性。一个好的目标是定义代码的质量指标，如圈复杂度等；一个错误的目标是提升研发效率。 以上几个项目的错误目标与当前在做的事情是非直接的关系，当前在做的事情只是宏大叙事里的一个环节，项目对错误目标有定性的正向反馈、但是无法量化和衡量。两者之间的关系即不充分，也不必要。假如没有达到目标，也无法论断说项目是无意义的。所以一个好的项目目标和做的事情之间要有直接、因果、量化关系，且在规定时间内可达成。","link":"/2023/11/18/%E5%85%B3%E4%BA%8E%E9%A1%B9%E7%9B%AE%E7%9B%AE%E6%A0%87/"},{"title":"内存飚高排查（二）","text":"一、问题描述研发反馈EDI应用请求无响应。 二、排查路径 1）查看日志日志中发现异常信息：java.lang.OutOfMemoryError: GC overhead limit exceeded。 2）查看GC1234567$ jstat -gc 9459 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 1863680.0 1863680.0 0.0 0.0 1864704.0 1864704.0 11185152.0 11185145.3 74112.0 71884.7 9344.0 8819.3 82 7.997 3574 1139.764 1147.7611863680.0 1863680.0 0.0 0.0 1864704.0 1864704.0 11185152.0 11185152.0 74112.0 71884.7 9344.0 8819.3 82 7.997 3944 1219.075 1227.0721863680.0 1863680.0 0.0 0.0 1864704.0 1864704.0 11185152.0 11185145.1 74112.0 71884.7 9344.0 8819.3 82 7.997 3945 1219.501 1227.4981863680.0 1863680.0 0.0 0.0 1864704.0 1864704.0 11185152.0 11185145.1 74112.0 71884.7 9344.0 8819.3 82 7.997 3945 1219.501 1227.4981863680.0 1863680.0 0.0 0.0 1864704.0 1864702.6 11185152.0 11185145.0 74112.0 71884.7 9344.0 8819.3 82 7.997 3947 1219.709 1227.705 3）Dump内存jmap -dump:live,format=b,file=heap.dump [pid] 三、分析Dump文件1）根据Leak Suspects分析 由以上图可以看出是AsyncLogImpl占用较高。 由以上可推出是AsyncLogImpl中的阻塞队列导致的内存溢出。 2）根据类实例直方图分析 从类直方图中可观察出是应用的类com.jd.edi.utils.log.impl.AsyncLogImpl$LogEntry中有大量String对象导致的内存过高。然后查看该类的实例数为37,764，Top15都在1MB以上。 此时，通过GCRoot链（下图）可以分析出来是由于com.jd.edi.utils.log.impl.AsyncLogImpl的阻塞队列过长导致。 四、修改代码1）修改AsyncLogImpl中阻塞队列大小，且支持配置。 2）增加消费线程数量，且支持配置。","link":"/2021/11/13/%E5%86%85%E5%AD%98%E9%A3%9A%E9%AB%98%E6%8E%92%E6%9F%A5%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"内存飚高排查（四）","text":"一、问题描述喜闻乐见，我们的应用又又内存飚高了，FullGC告警多到麻木。老套路，dump内存开始分析。 二、分析Dump 1）查看存活大对象树图 2）从中发现有个线程下有个List，823个元素，占用内存大小3.5GB。 3）查看该集合元素值，排序后发现最大的RetainedHeap占用了33MB。 4）查看其线程栈 通过观察发现是FTP下载文件导致的内存溢出。 三、结论Camel的FTP下载应该是串行的，理论上可达的文件对象应该每线程最多一个。此处需要分析下Camel源码是如何处理文件的。","link":"/2021/11/13/%E5%86%85%E5%AD%98%E9%A3%9A%E9%AB%98%E6%8E%92%E6%9F%A5%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"分布式网络及共识协议","text":"一、分布式网络的概念1、分布式网络的必要性网络上的有些服务提供者（如消息队列，ElasticSearch，Redis，Zookeeper等）需要通过水平扩展的方式来扩展其计算能力，存储能力，故障容错能力。 2、分布式网络的分类分布式网络的根据观察角度不同，分类也多种多样。 1）结点通讯类型I、同步分布式网络 II、异步分布式网络 2）规模和授权I、封闭分布式网络 II、许可私有网络 III、无许可开放分布式网络，如比特币等区块链 3）协调类型I、有中心的分布式网络 II、无中心的对等式分布网络 3、分布式网络的挑战分布式网络带来资源水平扩展好处的同时，也带来了一些挑战： 1）应用分布式网络的系统比单机系统更加复杂，提高了理解和运维难度 2）需要协调分布式网络的各结点，维护良好的集群状态 3）维护各结点数据一致性，尽量使客户端不出现脏读，脏写 4）结点故障和恢复时有相应的故障容错机制，不影响系统的可用性、可靠性 5）允许集群能平滑扩容或缩容 4、两种故障容错1）Crash Fault Tolerance 该容错机制下，系统可以应对一定数量的结点宕机，而不影响系统可用性。但如果结点违反系统的规则，例如被黑客控制后在集群中发送错误的信息，则可能破坏集群的状态，无法提供对外服务。一般用于封闭的，有权限控制的分布式网络。 2）Byzantine Fault Tolerance 其可以处理各种类型的结点异常，例如结点发送错误的信息，只要异常结点的比例不超过安全阈值则不会影响系统的可靠性，可用性。一般用于开放的，无权限控制的分布式网络。 二、分布式网络的重要理论1、CAPCAP理论是指在一个数据共享的系统中，当发生网络分区（Network Partitions）时，只能在一致性（Consistency）和可用性（Availability）之间作出选择。网络分区是一种故障类型，不是一个选项。 EricBrewer提出该理论是为了提供一种系统设计的思路，不要只关注于ACID这种强一致性的设计。而系统的设计师在设计系统时，对这三个特性持有错误的“三选二”的观点。该观点是有误导性的。这三个特性都是不是“非黑即白的”，例如，可用性是0%-100%的一个区间值，一致性也具备多种等级，分区容错也分为整体可用还是局部大数可用。在设计系统时可以根据系统的特性进行权衡。 由于CAP的各个特性都有多态性，所以需要在使用时需要明确各个特性的范围。另外，在系统正常运行时，三个特性是可以同时满足的，只有发生了网络分区时，才需要在一致性和可用性之间进行权衡。 2、BASE和ACID同CAP提出的背景一样，BASE理论也是为了开阔系统设计的空间。使开发人员不要拘泥于ACID的优点，在特定的场景下可以牺牲强一致性提高系统的可用性。 ACID 和 BASE 代表了两种截然相反的设计哲学，分处一致性 - 可用性分布图谱的两极。ACID 注重一致性，是数据库的传统设计思路 ACID和BASE对比 BASE理论是以下特性的缩写： 1）基本可用，Basically Available 系统发生故障时，通过降级等措施保证系统仍能提供服务。 2）软状态，Soft state 对比ACID的数据强一致状态，允许系统内结点的数据处于一种中间状态（如使法定的数据节点同步的方式处于一致，允许少数结点异步达到一致），在一定时间过后达到数据最终一致性。 3）最终一致，Eventually consistent Werner Vogels对最终一致性又细分了不同的程度，如下： 因果一致性 读己之所写一致性 会话（Session）一致性 单调（Monotonic）读一致性 单调写一致性 3、FLPFLP是三位作者的名字首字母，1985年由Fischer, Lynch和Patterson发表的Impossibility of Distributed Consensus with One Faulty Process理论。该理论的结论是在异步模型中，分布式系统中只要有一个进程不可用（失去响应或暂停），就可能无法达成整体的共识。 三、共识协议1、共识协议目标共识是分布式系统一致性的描述，具体而言是分布式集群的各结点对某个值达成一致。而共识协议就是为了分布式系统对共享数据达成一致的策略和方法。 共识协议需要识别和处理由系统故障、恶意结点、网络故障导致的网络分区问题，以及故障恢复后如何重新达成一致。这期间就需要CAP中的C和A进行权衡。一种取得共识的方式是大数定律，当某结点提出一个Cadidate值后，只需要集群中大多数结点同意便认为达成共识，这其中处于另一侧网络分区的结点或恶意结点可能会破坏这种一致性，共识协议必须考虑此种情况。 共识协议的应用包含： a、哪些事务以什么顺序提交到数据库 b、状态机复制（注意primary-backup与state machine replication区别） 常见算法有Paxos，Raft。 引自：https://www.cs.cornell.edu/fbs/publications/viveLaDifference.pdf • With active replication, also known as state machine replication, each replica implements a deterministic state machine. All replicas process the same operations in the same order. • With passive replication, also known as primary backup , a primary replica runs a deterministic state machine, while backups only store copies of the primary replica’s state. The primary computes a sequence of new application states by processing operations and forward 简而言之，state machine replication的各个副本接收命令序列并执行，命令会执行多次，不适合Random这类随机的输出。primary-backup中命令只在主副本中执行一次，然后把结果同步给其他副本，可满足Random随机输出。zookeeper就属于primary-back。 c、原子广播 常见协议：zookeeper的共识算法ZAB。 原子广播用在分布式系统中，一个提议被广播到其他结点，结果要么是全部接收，要么全部拒绝。 2、常见共识算法 网络 特点 共识算法 封闭分布式网络 可靠的分布式网络（权限控制，结点数量较小） Paxos,Raft,PBFT 许可私有链 相对可靠的分布式网络（访问控制，数据保护，监管） Paxos,Raft,PBFT 无许可公链开放网络 不可靠的分布式网络（无访问控制，结点数量无限制） POW,POS # 参考 Raft Raft Paper 本仓库副本 Raft PPT 本仓库副本 分布式一致性和分布式共识协议 Elasticsearch 集群协调迎来新时代 alibabacloud - From Distributed Consensus Algorithms to the Blockchain Consensus Mechanism 阿里云栖 - 分布式系统：CAP 理论的前世今生 BASE Paper: Cluster-Based Scalable Network Services https://www.infoq.cn/article/cap-twelve-years-later-how-the-rules-have-changed/ Werner Vogels 谈最终一致性 Eric Brewer: CAP ppt Paper Study: “Impossibility of Distributed Consensus with One Faulty Process” (FLP Impossibility) 维基百科：共识协议 维基百科：state machine replication 维基百科：原子广播 https://cwiki.apache.org/confluence/display/ZOOKEEPER/Zab+vs.+Paxos Paper：Paxos vs. Viewstamped Replication vs. Zab 含primary-backup与state machine replication对比 简书：众协议 Paxos/ZAB/Raft/VR 值得注意的细节","link":"/2021/06/06/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BD%91%E7%BB%9C%E5%8F%8A%E5%85%B1%E8%AF%86%E5%8D%8F%E8%AE%AE/"},{"title":"内存飚高排查（三）","text":"一、问题描述近期线上容器频发FullGC，于是对进程执行jstack、jmap命令，保存现场信息而后分析。 二、分析Dump 1）查看byte[]对象列表 2）查看GC Root到byte[]引用链 由引用链发现byte[]内容为图片。 3）byte[]内容验证 保存图片，文件后缀为jif或者不加后缀。可通过图片工具查看。 4）原因分析 以上这些对象都被Finalizer所引用，而根据Finalizer机制，其会创建一个消费线程去依次执行队列里的方法。需要查看其线程栈java.lang.ref.Finalizer，确认Finalizer线程是否阻塞或死锁了。 三、分析JStack从当时的线程栈分析，该线程在等待与IMAP邮件服务器的断连。此时分析是由于使用IMAP处理邮件后未正确关闭导致的Finalizer阻塞在此处。 1234567891011121314151617181920212223&quot;Finalizer&quot; #3 daemon prio=8 os_prio=0 tid=0x00007f0f040d5800 nid=0x156c waiting on condition [0x00007f0ee442f000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000006fba4b440&gt; (a java.util.concurrent.locks.ReentrantLock$NonfairSync) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199) at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:209) at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:285) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.drainTo(ScheduledThreadPoolExecutor.java:1184) at java.util.concurrent.ThreadPoolExecutor.drainQueue(ThreadPoolExecutor.java:854) at java.util.concurrent.ThreadPoolExecutor.shutdownNow(ThreadPoolExecutor.java:1422) at java.util.concurrent.ScheduledThreadPoolExecutor.shutdownNow(ScheduledThreadPoolExecutor.java:786) at com.sun.mail.util.WriteTimeoutSocket.close(WriteTimeoutSocket.java:273) at com.sun.mail.iap.Protocol.disconnect(Protocol.java:578) - locked &lt;0x00000006fba6e338&gt; (a com.sun.mail.imap.protocol.IMAPProtocol) at com.sun.mail.imap.protocol.IMAPProtocol.disconnect(IMAPProtocol.java:461) at com.sun.mail.iap.Protocol.finalize(Protocol.java:664) at java.lang.System$2.invokeFinalize(System.java:1270) at java.lang.ref.Finalizer.runFinalizer(Finalizer.java:98) at java.lang.ref.Finalizer.access$100(Finalizer.java:34) at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:210) 四、查看源码从源码中发现Mail的close方法在上面逻辑发生异常时不会执行，导致未断连。 12345678910111213141516171819public void process(Endpoint endpoint, MailConfig mailConfig) { LOGGER.info(&quot;{}开始处理邮件&quot;, endpoint.getUrl()); MailReader mailReader = getMailReaderInstance(mailConfig); int success = 0; int fail = 0; MailMessage message; while ((message = mailReader.nextMessage()) != null) { boolean isSuccess = processMail(endpoint, mailReader, message); if (isSuccess) { success++; } else { fail++; } } LOGGER.info(&quot;{}处理邮件{}封,成功{}封,失败{}封&quot;, endpoint.getUrl(), success + fail, success, fail); // 此处可能由于上面异常而导致未执行 mailReader.close(); } 五、查看日志观察当天日志，确实发现出现了异常，导致mailReader.close();未执行。 1234567891011122021-11-12 16:40:37[ Thread-23631:139929940 ] - [WARN ] com.xx.xx.mail.component.ImapConsumer-run:91 - 处理邮件失败，错误消息为:This operation is not allowed on a closed folderjava.lang.IllegalStateException: This operation is not allowed on a closed folderat com.sun.mail.imap.IMAPFolder.checkOpened(IMAPFolder.java:476)at com.sun.mail.imap.IMAPFolder.copymoveMessages(IMAPFolder.java:2097)at com.sun.mail.imap.IMAPFolder.copyMessages(IMAPFolder.java:2016)at com.xx.xx.protocol.mail.core.reader.ImapReader.moveMessage(ImapReader.java:55)at com.xx.xx.protocol.mail.core.reader.MailReader.proccessComplete(MailReader.java:97)at com.xx.xx.protocol.mail.core.reader.MailReader.proccessComplete(MailReader.java:85)at com.xx.xx.protocol.mail.core.MailProcessor.processMail(MailProcessor.java:69)at com.xx.xx.protocol.mail.core.MailProcessor.process(MailProcessor.java:35)at com.xx.xx.mail.component.ImapConsumer$1.run(ImapConsumer.java:89)at java.lang.Thread.run(Thread.java:745) 六、修改代码1234567891011121314151617181920public void process(Endpoint endpoint, MailConfig mailConfig) { LOGGER.info(&quot;{}开始处理邮件&quot;, endpoint.getUrl()); MailReader mailReader = getMailReaderInstance(mailConfig); int success = 0; int fail = 0; MailMessage message; try { while ((message = mailReader.nextMessage()) != null) { boolean isSuccess = processMail(endpoint, mailReader, message); if (isSuccess) { success++; } else { fail++; } } LOGGER.info(&quot;{}处理邮件{}封,成功{}封,失败{}封&quot;, endpoint.getUrl(), success + fail, success, fail); } finally { mailReader.close(); }}","link":"/2021/11/13/%E5%86%85%E5%AD%98%E9%A3%9A%E9%AB%98%E6%8E%92%E6%9F%A5%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"分库分表","text":"一、分库分表概念 首先，需要指出的是分库分表会带来更高的复杂度，涉及分布事务，跨库联表，性能下降，配置复杂等问题，不到万不得以不要轻易使用。另外，使用分库分表依据评估3年内的数据量及数据增长趋势，来提前进行分库分表规划，而不是对已有的生产库进行临场变动。 1. 分库分表的原因 单机数据库所能承载的数据有限，且达到一定量时，性能会急速下降，无法正常使用。如果数据确实需要依赖关系型数据库，那么就必须考虑使用分库分表。 2. 分库和分表是正交概念分库分表的核心概念是专库专用，提前规划好分库分表的规则。分库和分表是两个正交的概念，互不影响。分库是指，把数据切分为多个库，而分表的概念是切分为多个表。例如在ShardingSphere里可以根据不同的路由规则来实现。 3. 水平切分和垂直切分水平切分是指把表或库，依据某个规则进行水平拆分，例如把订单表按时间维度进行切分，一个年度一张表； 垂直切分是指把表或库，根据业务进行拆分，例如把商品表和SKU表分拆到不同的库； 二、分库分表优劣分库分表的劣势： 1）复杂度提升，把单机事务膨胀为分布式事务 2）研发门槛高，运维成本大 3）有的分库分表框架可能会侵入代码 4）挎库的操作使性能较单机低 分库分表的优势： 1）打破单机容量限制，支持业务需求","link":"/2021/01/21/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"},{"title":"关于Dubbo的重试机制","text":"一、重试机制Dubbo消费端的ClusterInvoker中，只有当异常是业务的RPC异常（isBiz() == true）时不会重试。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class FailoverClusterInvoker&lt;T&gt; extends AbstractClusterInvoker&lt;T&gt; { public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException { List&lt;Invoker&lt;T&gt;&gt; copyInvokers = invokers; checkInvokers(copyInvokers, invocation); String methodName = RpcUtils.getMethodName(invocation); int len = getUrl().getMethodParameter(methodName, RETRIES_KEY, DEFAULT_RETRIES) + 1; if (len &lt;= 0) { len = 1; } // retry loop. RpcException le = null; // last exception. List&lt;Invoker&lt;T&gt;&gt; invoked = new ArrayList&lt;Invoker&lt;T&gt;&gt;(copyInvokers.size()); // invoked invokers. Set&lt;String&gt; providers = new HashSet&lt;String&gt;(len); for (int i = 0; i &lt; len; i++) { //Reselect before retry to avoid a change of candidate `invokers`. //NOTE: if `invokers` changed, then `invoked` also lose accuracy. if (i &gt; 0) { checkWhetherDestroyed(); copyInvokers = list(invocation); // check again checkInvokers(copyInvokers, invocation); } Invoker&lt;T&gt; invoker = select(loadbalance, invocation, copyInvokers, invoked); invoked.add(invoker); RpcContext.getContext().setInvokers((List) invoked); try { Result result = invoker.invoke(invocation); return result; } catch (RpcException e) { // 只有业务异常不会重试 if (e.isBiz()) { // biz exception. throw e; } le = e; } catch (Throwable e) { le = new RpcException(e.getMessage(), e); } finally { providers.add(invoker.getUrl().getAddress()); } } throw new RpcException(le.getCode(), &quot;Failed to invoke&quot;); }} 注意，Result result = invoker.invoke(invocation);会封装provider端返回的异常，最终InvokerInvocationHandler会进行recreate把异常在consumer端抛出。invoker.invoke(rpcInvocation).recreate();。 二、Consumer超时异常会封装为RpcException如下代码所示，Consumer调用超时时，会把异常封装为RpcException。也就是说，超时时会触发重试，此时若provider的方法非幂等就会有问题。 注意：provider端的超时不会抛出异常，只会记录一条日志。 12345678910111213141516171819202122public class AsyncToSyncInvoker&lt;T&gt; implements Invoker&lt;T&gt; { public Result invoke(Invocation invocation) throws RpcException { Result asyncResult = invoker.invoke(invocation); try { if (InvokeMode.SYNC == ((RpcInvocation) invocation).getInvokeMode()) { asyncResult.get(Integer.MAX_VALUE, TimeUnit.MILLISECONDS); } } catch (InterruptedException e) { throw new RpcException(&quot;Interrupted unexpectedly while waiting for remoting result to return! method: &quot; + invocation.getMethodName() + &quot;, provider: &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); } catch (ExecutionException e) { Throwable t = e.getCause(); if (t instanceof TimeoutException) { throw new RpcException(RpcException.TIMEOUT_EXCEPTION, &quot;Invoke remote method timeout. method: &quot; + invocation.getMethodName() + &quot;, provider: &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); } else if (t instanceof RemotingException) { throw new RpcException(RpcException.NETWORK_EXCEPTION, &quot;Failed to invoke remote method: &quot; + invocation.getMethodName() + &quot;, provider: &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); } } catch (Throwable e) { throw new RpcException(e.getMessage(), e); } return asyncResult; }} 三、配置重试策略由于调用超时也会重试，而网络抖动等都会造成重试。故，针对一个方法设置重试时策略要考虑provider端是否幂等： provider端方法是幂等方法，可设置重试 provider端方法非幂等方法，不可设置重试 # 其他关于超时重试这个问题，咨询了公司网关的同事，他们说网关透传RPC时遇到超时同样不会去重试，因为不能保证provider端是否是幂等的。","link":"/2021/05/30/%E5%85%B3%E4%BA%8EDubbo%E7%9A%84%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6/"},{"title":"刚发现的虫子原来很早之前就有了","text":"一、问题描述上周末，某商家上线后，导致两个问题：1）集群的启动日志没有该商家的任何启动信息；2）其他商家开始出现错误ProducerTemplate has not been started。 二、尝试路径 初步怀疑是引入新的jar包导致的问题，通过J-one的包对比工具发现并没有引入新的jar包。 下载线上包在本地运行，日志太多淹没了有用的错误信息。 删除其他商家的代码，只保留本地上线出错的商家，之后再在本地运行，发现了异常信息Caused by: java.lang.NoSuchMethodError: org.apache.commons.io.IOUtils.toString(Ljava/io/InputStream;Ljava/com.ibm.developerworks.nio/charset/Charset;)Ljava/lang/String;。 根据这个异常信息很容易定位出来，原因是jar包不兼容。更新commons-io版本,由1.3.2到2.5后解决问题 三、原因 当前运行的EDI版本增加了新的dt-processor模块，该模块依赖2.5版本的commons-io。但是运行时一直依赖的是1.3.2版本的commons-io包，由于该商家用到了新的dt-processor模块，导致触发了这段不兼容代码。 四、反思 现在出现的bug有可能是之前就有的，只不过现在因为某些条件才触发而已。 日志信息太多会让人对异常麻木，尽量减少无关的异常信息展示。例如移除其他商家，只保留当前商家，可大大提高定位异常的准确度。","link":"/2019/09/30/%E5%88%9A%E5%8F%91%E7%8E%B0%E7%9A%84%E8%99%AB%E5%AD%90%E5%8E%9F%E6%9D%A5%E5%BE%88%E6%97%A9%E4%B9%8B%E5%89%8D%E5%B0%B1%E6%9C%89%E4%BA%86/"},{"title":"单元测试才是绩效的保命符","text":"1.背景：昨日edi值班时，线上发现之前写的CsvParser有问题，问题是错把引号内的逗号也当作分隔符处理了，导致csv中的信息错位。 2. 处理 改为commons-csv第三方jar包来解析，本地测试可以正常解析带引号的csv。 发到测试环境发现也可以，准备上线。 上线前发现commons-csv插件在解析带引号的列时，会把引号去掉，于是想回滚，在原来的基础上进行修改。 后跟阳哥确认后，阳哥指出我们当时用的“is_remove_quote”这个属性原因其实是我们起初设计的不足，才被迫引入的。并且线上已有的节点的该属性都是true，这就说明在此之前没有人需要保留引号。 阳哥讨论过后，执行上线。 edi开发人员发现线上最新的一单在进行CSV解析时缺少了首行。 我在本地紧急修改后，测试再次上线。 线上再次下单，然后验证正常。 3. 总结 有时候起初的设计可能是错误的，没必要为了这个错误的设计再去延续。 CSV缺少首行的问题本地测试没有发现原因还是由于正确的单元测试。临时写的单元测试比较仓促，考虑和关注的范围的比较窄。以后写单元测试需要写完备，且通过Assert语句抛出异常。","link":"/2020/02/29/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E6%89%8D%E6%98%AF%E7%BB%A9%E6%95%88%E7%9A%84%E4%BF%9D%E5%91%BD%E7%AC%A6/"},{"title":"包冲突","text":"Jar包冲突的说法其实比较笼统，具体而言是类冲突。两个JAR包内包含了某个完全限定名相同的类。 一、Jar包冲突的场景 1、GA相同，V不同1）ClassPath存在一个错误版本JarI、可能原因 Maven依赖调停 - 错误版本的JAR短路了正确版本JAR II、产生影响 类，类方法，类属性找不到等 2）ClassPath存在两个不同版本JarI、可能原因 未使用Maven进行依赖管理 ClassPath包含SingleJar，SingleJar内嵌入了错误JAR II、产生影响 可能由于Jar包的加载顺序，导致加载了错误的依赖类。类方法，类属性找不到等 2、A相同，GV不同1）JAR包G发生变化，但缺少relocationI、产生影响 可能由于Jar包的加载顺序，导致加载了错误的依赖类。类方法，类属性找不到等 II、案例：commons-io依赖冲突 3、GAV都不同1）Slf4j此类SPI框架，依赖了多种实现 使用slf4j的框架依赖某种顺序，去加载指定类（如org.slf4j.impl.StaticLoggerBinder）所在的某个实现包。参考：slf4j加载实现源码分析 I、产生影响 可能会导致加载错误实现，导致外部配置的日志配置不生效，导致： 没有日志输出 没有日志级别控制，可能导致打印大量Debug级别日志，导致CPU飚高。 II、案例：CPU飚高案例 附，日志冲突时关键日志 12345SF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/home/kivi/Downloads/edi-rest_253244_T_7c14b96_2019.09.18-11.36.43/lib/slf4j-simple-1.7.22.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/home/kivi/Downloads/edi-rest_253244_T_7c14b96_2019.09.18-11.36.43/lib/log4j-slf4j-impl-2.9.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.slf4j.impl.SimpleLoggerFactory] 2）GAV都不同的JAR包，存在同名类I、产生影响 可能由于Jar包的加载顺序，导致加载了错误的依赖类。类方法，类属性找不到等 II、案例：发现冲突，解决冲突 二、ClassNotFoundException vs NoClassDefFoundError1、两者对比 类别 ClassNotFoundException NoClassDefFoundError 含义 找不到类定义 找不到类定义 继承 extends ReflectiveOperationException extends LinkageError 类型 反射操作引起的一种异常 一种链接错误 捕获 catch Exception/Throwable catch Error/Throwable 原因 通过反射根据指定类名无法找到类时，会引起该异常 编译时有类定义，运行时丢失类定义会引起该异常。运行时类定义丢失往往有两种情况：1）类不在ClassPath内，导致无法加载类定义，即由ClassNotFoundException引起。2）类初始化失败，导致加载不到类定义，此时会伴随着一个初始化异常（ExceptionInInitializerError）。 2、两者关系NoClassDefFoundError可由ClassNotFoundException引起。 3、两者定义 当JVM或类加载器去加载一个类定义（无论是通过普通的方法调用，还是用new语句去创建该类的实例所触发的类加载），如果该类的定义丢失，那么就会抛出NoClassDefFoundError. 被加载的类定义在当前执行类编译时是存在的，但是再也找不到了。 当应用使用类的字符串名，通过以下方式尝试去加载类，但是根据指定的名称无法找到类定义时会抛出ClassNotFoundException： 1）Class.forName() 2）ClassLoader.findSystemClass() 3）ClassLoader.loadClass() 4、实例1）ClassNotFoundExcption1234567package qiweiTest;public class ClassNotFoundExcptionTest { public static void main(String[] args) { Class.forName(&quot;anyNoexistClassName&quot;); // 任何一个不存在的className }} 2）NoClassDefErrorI、类不在ClassPath引发的异常12345678package qiweiTest;public class NoClassDefErrorTest { // 运行时，删除ClassPath中的ClassNotFoundExceptionTest.class public static void main(String[] args) { ClassNotFoundExceptionTest.class.getClass(); }} 输出： 12345678Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: qiweiTest/ClassNotFoundExceptionTest at qiweiTest.NoClassDefErrorTest.main(NoClassDefErrorTest.java:9)Caused by: java.lang.ClassNotFoundException: qiweiTest.ClassNotFoundExceptionTest at java.net.URLClassLoader.findClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) ... 1 more II、类初始化失败引发的异常12345678910111213141516171819202122232425package qiweiTest;public class NoClassDefErrorTest2 { public static void main(String[] args) { int tmp; try { tmp = InterClass.a; } catch (Throwable e) { // 异常类型：ExceptionInInitializerError e.printStackTrace(); } try { tmp = InterClass.a; } catch (Throwable e) { // 异常类型：NoClassDefFoundError e.printStackTrace(); } } static class InterClass { static int a; static { a = 1 / 0; } } 输出： 1234567java.lang.ExceptionInInitializerError at qiweiTest.NoClassDefErrorTest2.main(NoClassDefErrorTest2.java:8)Caused by: java.lang.ArithmeticException: / by zero at qiweiTest.NoClassDefErrorTest2$InterClass.&lt;clinit&gt;(NoClassDefErrorTest2.java:22) ... 1 morejava.lang.NoClassDefFoundError: Could not initialize class qiweiTest.NoClassDefErrorTest2$InterClass at qiweiTest.NoClassDefErrorTest2.main(NoClassDefErrorTest2.java:13)","link":"/2019/10/26/%E5%8C%85%E5%86%B2%E7%AA%81/"},{"title":"原来是IDE和Rest版本不同步","text":"一、问题描述昨日晚，EDI的研发在使用IDE环境时，出现无法登陆的问题，错误为“502 Bad Gateway”。 二、尝试路径 查看后台Rest服务器是否宕机。结果，Rest服务器因缺少配置而启动失败。 根据1的结果，立即回滚代码至上个正确启动的版本。 测试后发现，IDE已经可以登陆成功，但是获取到的商家信息为空。 直接通过浏览器请求Rest，发现可以正常返回json数据。 由3和4可知，IDE无法识别返回的Json数据导致的。结果是，Rest服务器修改了Rest的返回格式，IDE没有同步更新导致无法解析。 三、反思 当时是卡在第4步好长时间，然后才走到第5步。结论同样是要捋清楚整个请求发生到发生错误之间的过程。 本次事故能确定的点是1）IDE没有变化；2）服务器可以响应请求，且最近有上线；由以上两个点得出响应的内容有变化。","link":"/2019/08/10/%E5%8E%9F%E6%9D%A5%E6%98%AFIDE%E5%92%8CRest%E7%89%88%E6%9C%AC%E4%B8%8D%E5%90%8C%E6%AD%A5/"},{"title":"发现冲突，解决冲突","text":"今天在写Rest端新功能时，发现一个错误如下，明显是由于jar包冲突导致的。原因有两种：1）jar包版本错误2）两个不同artifact的jar包，包含了相同的类，导致随机加载 12345Caused by: java.lang.NoSuchMethodError: org.json.JSONObject.stringToValue(Ljava/lang/String;)Ljava/lang/Object; at org.json.XML.stringToValue(XML.java:409) at org.json.XML.parse(XML.java:343) at org.json.XML.toJSONObject(XML.java:458) at org.json.XML.toJSONObject(XML.java:429) 解决路径 确认了是第二种情况，即两个不同的jar包内有相同限定名的类； 找到包含该类的包，两种方法： 通过Grep命令：grep -r &quot;JSONObject&quot; . Debug调试：在合适的位置打断点，输入检测表达式EnumerationUtils.toList(this.getClass().getClassLoader().findResources(&quot;org/json/JSONObject.class&quot;)) ,结果如下： 排除android-json-0.0.20131108.vaadin1.jar即可","link":"/2020/02/14/%E5%8F%91%E7%8E%B0%E5%86%B2%E7%AA%81%EF%BC%8C%E8%A7%A3%E5%86%B3%E5%86%B2%E7%AA%81/"},{"title":"原则","text":"为什么写下这些原则从过往的自身经验和他处经验中总结的一些原则，蕴含了为人处事的智慧，有些关键的原则能帮助我战胜人生中时长会遇到的琐碎无聊、挫折和痛苦，促使我去思考和关注生命中本质的内容。 每日回看这些原则，正似每日擦去心灵的灰尘，使其通透玲珑，不惹尘埃。 一、生活原则第一条 人生有限，你终将死去当意识到人终将死去后，你就会聚焦到真正让你感到快乐的事情上，这些事情大概率无关世俗、无关环境影响、无关同侪压力，而是你作为人结构本身，连带着基因的偏好，去趋近符合完满心理的行为。 第二条 不要为未来忧虑 不要让将来的事困扰你，因为如果那是必然要发生的话，你将带着你现在对待当前事物的同样理性走向它们。 ——《沉思录》 第三条 以发展的眼光看问题、困境和挫折事情是变化的，以发展的眼光看问题，能更好的评估当下问题的权重，不放大问题。 第四条 记住你永远有其他的选择 这个工作做不下去了，你还可以换个工作。 这个公司干不下去了，你还可以换个公司。 这个职业干不下去了，你还可以换个职业。 人生的选择有很多，这条路走不通了，换一条试试。 第五条 尽量简化和世界的关系阿德勒心理学中有一个观念：人的烦恼主要来自人际关系。人作为社会人，通过人际关系进行连接和协同，一起参与社会活动。需要关注关系的本质是为了合作，需要甄别工作关系和人情关系。工作中弱化人情关系，关注工作关系，可以保持专注自我，避免陷入无效的人际消耗。 总之，关注工作关系，务实做事。简化人情关系，关注自身。 二、工作原则第一条 在行事前显化和验证假设及论据 明托金字塔 第二条 质疑假设和结论中的因果关系 区分相干性和因果 区分现象和原因 第三条 从目标出发思考和行事保持目标感。 第四条 复盘使经历质变为知识和洞察复盘可以促使经验知识显化，以及从事实和经验向因果和逻辑转化。因果逻辑，可以帮我们洞察新场景的隐藏规律，能让我们更适应和应变社会。 第五条 5Why和系统思考别用忙碌躲避思考，思考比盲目的行动更需要耐心和毅力。事前思考可以引导我们做正确的事，事中思考可以帮我们正确的做事，事后思考可以帮助我们显化和沉淀正确的思考模式。","link":"/2025/07/17/%E5%8E%9F%E5%88%99/"},{"title":"合并两个仓库","text":"合并两个Git仓库如果要合并两个Git仓库到，并且要保留两者的提交历史，一个仓库在主目录，另一个仓库在子目录。可以通过一下步骤进行： 步骤1: 添加远程仓库 假设你已经有一个名为repoA的本地仓库，现在需要将repoB合并进来。首先，我们需要将repoB添加为一个新的远程仓库： 1git remote add repoB &lt;repoB-url&gt; 通过这条命令，repoB 成为了一个可以访问的远程仓库。 步骤2: 获取远程仓库数据使用fetch命令从新添加的远程仓库获取所有分支和数据： 1git fetch repoB 这一步会将repoB的所有数据下载到本地，但不会自动合并到你的工作目录。 步骤3: 移动repoA 的内容到一个单独的目录为了避免合并时的内容冲突，我们先将repoA的内容移动到一个新目录下，例如repo1： 123mkdir repo1 # 目录名不与repoB的目录冲突就可以find . -mindepth 1 -maxdepth 1 ! -name .git ! -name repo1 -exec mv {} repo1/ \\;git commit -am &quot;Move existing contents of repoA into repo1&quot; 步骤4: 合并仓库现在开始实际的合并操作。首先，确保你在repoA的根目录下： 12git merge repoB/mastergit commit -am &quot;Merge repoB into repoA&quot; 这里假设你希望将repoB的master分支合并进来。命令执行后，Git会将repoB的master分支内容合并到当前分支。 说明如果要把repoA放在主目录，并保持repoA的repo-url，那么可以这么做： 在repoB中进行如上操作 在repoA中添加repoB，使用repoB的分支覆盖repoA的分支 注意分步骤执行原仓库内容移至子目录后进行commit，便于git识别rename操作。 如果使用git reset命令把步骤3和步骤4放在一个提交，那么会导致git无法正确的识别文件的历史。","link":"/2024/12/02/%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E4%BB%93%E5%BA%93/"},{"title":"因浮点精度损失了1分钱","text":"一、问题描述产品反馈与商家对账时，有单运费金额对不上：本该是10块2，可商家侧收到的是10块1毛9，莫名少了一分钱。然后紧急根据单号查询日志信息。 本场景是消费一个MQ，把消息通过数据转换文件转换为商家侧数据格式，然后推送给商家。其中出问题的字段，仅做了一个逻辑，金额单位由元转分，类似如下： 1&lt;set var=&quot;fenVar&quot; expr=&quot;${yuanVar * 100}&quot; class=&quot;long&quot;/&gt; 通过日志观察此单的yuanVar为10.2，而数据转换结果就变为了1019。第一时间反应是精度损失导致的问题，于是直接用我们的EL表达式工具进行测试，结果如下。el表达式计算${10.2 * 100}后结果为1019.9999999999999。 二、解决方案自定义一个函数如下： 123456@EDI(prefix = &quot;fn&quot;, name = &quot;yuanToFen&quot;, desc = &quot;元转分，使用BigDecimal避免损失精度&quot;)public static long yuanToFen(float yuan) { BigDecimal bigDecimal = new BigDecimal(String.valueOf(yuan)).setScale(2, BigDecimal.ROUND_HALF_UP); BigDecimal ret = bigDecimal.multiply(new BigDecimal(100)); return ret.longValue();} 然后数据转换文件中通过该函数对金额进行转换。 1&lt;set var=&quot;fenVar&quot; expr=&quot;${fn:yuanToFen(yuanVar)}&quot; class=&quot;long&quot;/&gt; 三、溯因1. 探究EL表达式相关逻辑假设当前数据转换定义如下： 1&lt;set var=&quot;test&quot; expr=&quot;${10.2 * 100}&quot; class=&quot;long&quot;/&gt; 则数据转换引擎最终会调用如下等效代码进行计算： 12345public &lt;T&gt; T evalExpr(String expr, Class&lt;T&gt; clazz) { // 此时expr为${10.2 * 100}，clazz为long.class。 ValueExpression valueExpr = exprFactory.createValueExpression(elContext, expr, clazz); return (T) valueExpr.getValue(elContext);} 通过断点调试关注以下两个逻辑： ø 浮点计算的过程及结果 ø 最终类型转换的过程及结果 1）浮点计算过程EL表达式子首先调用AstBinary的MUL进行乘法运算。 12345678910public class AstBinary extends AstRightValue { public static final Operator MUL = new SimpleOperator() { @Override public Object apply(TypeConverter converter, Object o1, Object o2) { return NumberOperations.mul(converter, o1, o2); } @Override public String toString() { return &quot;*&quot;; } };} 接下来看NumberOperations#mul方法： 1234567891011121314151617181920212223public static final Number mul(TypeConverter converter, Object o1, Object o2) { if (o1 == null &amp;&amp; o2 == null) { return LONG_ZERO; } if (o1 instanceof BigDecimal || o2 instanceof BigDecimal) { return converter.convert(o1, BigDecimal.class).multiply(converter.convert(o2, BigDecimal.class)); } if (isFloatOrDoubleOrDotEe(o1) || isFloatOrDoubleOrDotEe(o2)) { if (o1 instanceof BigInteger || o2 instanceof BigInteger) { return converter.convert(o1, BigDecimal.class).multiply(converter.convert(o2, BigDecimal.class)); } // 由于两个入参10.2和100的类型为Double和Long，故执行此方法。 return converter.convert(o1, Double.class) * converter.convert(o2, Double.class); } if (o1 instanceof BigInteger || o2 instanceof BigInteger) { return converter.convert(o1, BigInteger.class).multiply(converter.convert(o2, BigInteger.class)); } return converter.convert(o1, Long.class) * converter.convert(o2, Long.class);} 2）浮点计算结果此方法返回值类型为Double，值为1019.9999999999999。 3）类型转换过程由于数据转换指定结果类型为long，故其会调用的TypeConverterImpl#coerceToLong方法。 1234567891011121314151617181920212223protected Long coerceToLong(Object value) { if (value == null || &quot;&quot;.equals(value)) { return Long.valueOf(0l); } if (value instanceof Long) { return (Long) value; } if (value instanceof Number) { // 当前value为Double类型，故执行此处逻辑 return Long.valueOf(((Number) value).longValue()); } if (value instanceof String) { try { return Long.valueOf((String) value); } catch (NumberFormatException e) { throw new ELException(LocalMessages.get(&quot;error.coerce.value&quot;, value, value.getClass(), Long.class)); } } if (value instanceof Character) { return Long.valueOf((short) ((Character) value).charValue()); } throw new ELException(LocalMessages.get(&quot;error.coerce.type&quot;, value, value.getClass(), Long.class));} 由于当前value为Double类型，执行Long.valueOf(((Number)value).longValue());。 12345678910111213public final class Double extends Number implements Comparable&lt;Double&gt; { /** * Returns the value of this {@code Double} as a {@code long} * after a narrowing primitive conversion. * * @return the {@code double} value represented by this object * converted to type {@code long} * @jls 5.1.3 Narrowing Primitive Conversions */ public long longValue() { return (long)value; }} 4）类型转换结果Double#longValue会根据Narrowing Primitive Conversions（原生类型窄化约束）把1019.9999999999999转为1019。可见精度损失是发生在el表达式计算的结果类型转换。 NOTE： AstBinary，顾名思义是抽象语法树二目运算类，其包含了加减乘除等二目运算操作，如下图。 2. 类型窄化—浮点转Long以下摘自：https://docs.oracle.com/javase/specs/jls/se7/html/jls-5.html#jls-5.1.3 A narrowing primitive conversion may lose information about the overall magnitude of a numeric value and may also lose precision and range. A narrowing conversion of a floating-point number to an integral type T takes two steps: In the first step, the floating-point number is converted either to a long, if T is long, or to an int, if T is byte, short, char, or int, as follows: If the floating-point number is NaN (§4.2.3), the result of the first step of the conversion is an int or long 0. Otherwise, if the floating-point number is not an infinity, the floating-point value is rounded to an integer value V, rounding toward zero using IEEE 754 round-toward-zero mode (§4.2.3). Then there are two cases: If T is long, and this integer value can be represented as a long, then the result of the first step is the long value V. Otherwise, if this integer value can be represented as an int, then the result of the first step is the int value V. Otherwise, one of the following two cases must be true: The value must be too small (a negative value of large magnitude or negative infinity), and the result of the first step is the smallest representable value of type int or long. The value must be too large (a positive value of large magnitude or positive infinity), and the result of the first step is the largest representable value of type int or long. In the second step: If T is int or long, the result of the conversion is the result of the first step. If T is byte, char, or short, the result of the conversion is the result of a narrowing conversion to type T (§5.1.3) of the result of the first step. 由以上可知，当浮点转long时会执行以下步骤： 1）如果浮点时NaN，则转为0； 1Fload.NaN ==》 0 2）如果浮点是无限类型，则进行如下转换： 12Float.NEGATIVE_INFINITY ==》 Long.MIN_VALUEFloat.POSITIVE_INFINITY ==》 Long.MAX_VALUE 3）其他情况，使用 IEEE 754 向零舍入模式把浮点数舍入为Long。 3. IEEE 754及向零舍入模式1）IEEE 754浮点表示图片来源 由于计算机是机遇二进制的所以制定了IEEE 754这种浮点存储格式。使用IEEE 754的二进制表示的数必定是离散的，其无法与十进制一一对应，有时只能近似表达一个10进制数，这之间的差距称为精度损失。 例如：十进制0.2转换为二进制，执行以下操作 0.2 * 2 = 0.4，取整数0 0.4 * 2 = 0.8，取整数0 0.8 * 2 = 1.6，取整数1 0.6 * 2 = 1.2，取整数1 0.2 * 2 = 0.4，取整数0 以下会无穷重复上述步骤。 10进制0.2的2进制表示为：0.0011 0011 0011 0011 ...。在IEEE 754中尾数长度是有限的，则必然造成精度损失。 也就意味着十进制的0.2经过IEEE 754存储后，再转回十进制就会变为：0.199999999... 2）IEEE 754向零舍入所谓的向零舍入就是简单的截断小数后面值。1019.9999999就被截断为1019。 图片来源 四、使用BigDecimal1. 浮点精度损失案例123456public static void main(String[] args) { System.out.println(1.2f - 1); System.out.println(1.2d - 1); System.out.println(10.2f * 100 + &quot; 转为Long:&quot; + (long)(10.2f * 100)); System.out.println(10.2d * 100 + &quot; 转为Long:&quot; + (long) (10.2d * 100));} 12345执行结果：0.200000050.199999999999999961020.0 转为Long:10201019.9999999999999 转为Long:1019 2. BigDecimal及其精度1）八种舍入模式ø BigDecimal.ROUND_CEILING ø BigDecimal.ROUND_FLOOR ø BigDecimal.ROUND_DOWN ø BigDecimal.ROUND_UP ø BigDecimal.ROUND_HALF_UP BigDecimal.ROUND_UP的限制版，当丢弃的分数&gt;= 0.5时，进行UP，否则DOWN；即十进制的四舍五入。 ø BigDecimal.ROUND_HALF_DOWN BigDecimal.ROUND_UP的限制版，当丢弃的分数&gt;0.5时，进行UP，否则DOWN； ø BigDecimal.ROUND_HALF_EVEN this is the rounding mode that statistically minimizes cumulative error when applied repeatedly over a sequence of calculations. It is sometimes known as “Banker’s rounding,” and is chiefly used in the USA。 当在一系列计算中重复应用时，该舍入模式可以在统计上最小化累积误差。 它有时被称为“银行家的四舍五入”，主要用于美国。 BigDecimal.ROUND_UP的限制版，当丢弃的分数的左侧是奇数时，表现同BigDecimal.ROUND_HALF_UP；否则，表现同BigDecimal.ROUND_HALF_DOWN。 简而言之，主要是对舍弃的分数是0.5时，舍入结果需要是一个偶数。示例如下。 123456789105.5 -&gt; 62.5 -&gt; 21.6 -&gt; 21.1 -&gt; 11.0 -&gt; 1-1.0 -&gt; -1-1.1 -&gt; -1-1.6 -&gt; -2-2.5 -&gt; -2-5.5 -&gt; -6 ø BigDecimal.ROUND_UNNECESSARY 不需要舍入，发生舍入时，会抛出异常throw new ArithmeticException(&quot;Rounding necessary&quot;); 2）BigDecimal使用ø 优先使用字符串入参构造函数 123BigDecimal d = new BigDecimal(&quot;1.2&quot;);BigDecimal d = new BigDecimal(Double.toString(1.2d));BigDecimal d = new BigDecimal(Float.toString(1.2f)); ø 对运算结果设置合适精度 12345public long mul(float a, float b, int scale) { BigDecimal left = new BigDecimal(Float.toString(a)); BigDecimal right = new BigDecimal(Float.toString(b)); return left.multiply(right).setScale(scale, BigDecimal.ROUND_HALF_UP).longValue();} 五、结论1）在进行浮点计算时，要评估结果的精度。尤其是金额场景计算时，一定要有精度敏感。 2）在EDI里使用BigDecimal增加一个内置全局函数，提升开发效率； 3）在EDI的开发工具里考虑增加提示，当运算涉及浮点时提示是否需要关注精度问题； # 参考 Java语言规范 - Narrowing Primitive Conversion 知乎：IEEE 754格式是什么?","link":"/2021/06/06/%E5%9B%A0%E6%B5%AE%E7%82%B9%E7%B2%BE%E5%BA%A6%E6%8D%9F%E5%A4%B1%E4%BA%861%E5%88%86%E9%92%B1/"},{"title":"垃圾回收器","text":"一、垃圾收集器简介1、垃圾收集器搭配图谱 2、垃圾收集器的发展史1）单核时代 - 串行垃圾收集器 2）多核时代 - 小内存 CMS是老年代的多线程收集器，遵循了分代框架； ParNew是Serial的多线程版本，从Exact VM移植到HotSpot与CMS搭配使用 Parallel，Parallel Old是新框架下的并行垃圾收集器，考虑到维护成本，没有遵循之前的分代框架，所以与CMS无法搭配使用。 3）多核时代 - 大内存 G1取消了逻辑分代，支持更大内存； 3、垃圾收集器的性能指标1）吞吐量 2）响应时间 4、垃圾收集器的主流算法1）复制：主要用于年轻代，其中的跨带引用通过卡表来解决 2）标记整理：用于老年代 3）标记清除：用于老年代 5、JDK的默认垃圾收集器 JDK8：Parallel JDK9：G1 6、常用垃圾收集器组合 ParNew + CMS + Serial Old：偏向响应 Parallel：偏向吞吐 二、Serial垃圾收集器 1、开启参数1）年轻代：-XX:+UseSerialGC，采用复制算法 2）老年代：-XX:+UseSerialOldGC，采用标记整理算法 2、串行垃圾收集器特点1）单线程执行，无法利用多核资源； 2）单线程执行时STW工作线程； 三、Parallel垃圾收集器 Parallel是Serial垃圾收集器的多线程版本，也被称为Throughput GC，是吞吐量优先的垃圾收集器。没有实现老的分代框架，无法与CMS搭配使用。 1、开启参数1）年轻代：-XX:+UseParallelGC，采用复制算法 2）老年代：-XX:+UseParallelOldGC，采用标记整理算法 2、高级参数1）设置并行线程数：-XX:ParallelGCThreads，默认当前CPU核数。 3、parallel圾收集器特点1）多线程执行GC，吞吐量高； 2）多线程执行时依然STW工作线程； 四、ParNew垃圾收集器 只负责新生代垃圾收集，功能与Parallel Scavenge(Parallel年轻代)的收集器类似，但是可以与CMS搭配使用。 1、开启参数1）年轻代：-XX:+UseParNewGC，采用复制算法 五、CMS垃圾收集器 CMS只回收老年代，注重响应时间。但是在Oracle内部不受重视，优化项不如Parallel，至此到终都没有称为默认垃圾收集器。 1、开启参数1）老年代：-XX:+UseConcMarkSweepGC，采用标记清除算法 2、高级参数1）开启整理： 12-XX:+UseCMSCompactAtFullCollection-XX:CMSFullGCsBeforeCompaction # 多少次FullGC后压缩 2）并发线程数： 1-XX:ConcGCThreads 3）触发FullGC的老年代使用比例： 12-XX:CMSInitiatingOccupancyFraction #指定老年代触发FullGC的比例，默认92%；-XX:+UseCMSInitiatingOccupancyOnly #开启时使用使用上面的设置，否则只有第一次使用； 4）初始标记是否使用多线程： 1-XX:+CMSParallelInitiatingMarkEnable 5）执行FullGC前是否执行MinorGC 1-XX:+CMSScavengeBeforeRemark 3、CMS执行过程 初始标记：STW，扫描GC Root的直接关联对象； 并发标记：遍历所有对象，使用三色标记法+增量更新来实现 重新标记：STW，修正并发标记期间变化的对象引用关系 并发清除：清理没有被标记到的对象；若此时有新加入老年代的对象一律设置为黑色，不作清理。 并发重置：重置标记状态； 4、特点1）注重响应时间，清理时用户线程和垃圾收集线程可以同时运行； 2）复杂度高，标记过程比较复杂； 3）如果不开启整理选项，容易出现内存碎片； 4）无法处理浮动垃圾； 5）会出现concurrent mode failure，然后STW，使用serial进行收集； 六、G1取消物理分代，取而代之的是分块的region，其保留逻辑分代。可回收年轻代和老年代； 1、参数1）设置Region大小： 1-XX:G1HeapRegionSize 2）设置年轻代大小： 12-XX:G1NewSizePercent # 默认5%-XX:MaxG1NewSizePercent # 默认60% 3）设置GC时最大停顿时间： 1-XX:MaxGGPauseMillis 2、过程1）初始标记：STW 2）并发标记：同CMS 3）最终标记：STW 4）筛选回收：STW 3、gc类型1）young GC：优先新增Young Region（Eden + Survior），如果达到阈值则回收； 2）MixGC：回收Young Region，Old Region，大对象区域 3）FullGC：单线程回收所有区域，类似Serial垃圾收集器。 七、三色标记1、并法标记期间出现的问题1）漏标：需要处理，不然误回收 2）多标：浮动垃圾，下次回收； 2、漏标的解决方案1）漏标发生时操作并法标记过程中产生漏标时，会执行以下两个逻辑： I、建立新关联 - 通过增量更新记录新关联对象，供重新标记时重新扫描 未扫描到的对象被已扫描过的黑对象引用，而黑对象不会再扫描标记其关联对象； II、删除旧关联 - 通过原始快照记录被删除对象，供重新标记时标为黑色 把此对象从其旧关联删除，导致此对象只被黑对象关联，无法再被标记，而产生漏标； 2）增量更新在并发标记期间，新赋值的对象作为增量记录下来，再重新标记时扫描。 I、实现： 通过写屏障（写后屏障），把建立新关联的左值对象维护到一个表，在重新标记节点重新扫描表中的对象；黑色对象一旦新插入了指向白色对象的引用之后， 它就变回灰色对象了。 II、特点： 所有在并发标记过程中变化的引用导致由黑变灰的对象都需要重新遍历标记； 性能开销大，小内存时适用； 3）原始快照在并发标记期间，引用关系发生变化的对象一律标记为黑对象，本次不回收。 I、实现： 通过写屏障（写前屏障），把删除旧关联时的右值对象维护到一张表，重新标记时标为黑色。本次不回收。此时，表中对象有可能是被引用的对象，也有可能是垃圾对象（浮动垃圾）。 II、特点： 所有在并发标记过程中变化的节点都做标记，本次垃圾回收不处理。 性能开销小，大内存时适用； 3、CMS和G1的实现1）CMS：写屏障 + 增量更新 2）G1：写屏障 + 原始快照 八、记忆集和卡表 年轻代收集时，在扫描GCRoot时，可能会出现跨带引用，即老年代引用年轻代。为了避免扫描整个老年代，通过卡表来标记老年代的某个区域是否有对年轻代的引用。 1、基于前提跨带引用的量较小，所以通过老年代分块来粗化区域，提高效率。 2、实现1）把老年代分块，512字节为大小； 2）年轻代维护卡表，与老年代的块一一对应； 3）通过写屏障维护卡表（字节数组，一个字节对应一个老年代的块），如果发现老年代引用了年轻代则把对应的bit置为1； 4）年轻代收集时通过遍历年轻代的GCRoot和老年代的脏块中的对象，其中不可达的对象则视为垃圾，不作复制。 3、为什么不需要年轻代对应的卡表卡表只在内存分代且部分收集时需要。FullGC时会整体回收，包含方法区、老年代和年轻代，而不是单独回收老年代。也正因为此老年代和年轻代的垃圾回收器需要进行协同，而CMS无法和Parrallel协同，所以搞出来一个ParNew来和CMS协同。 # 参考 https://hllvm-group.iteye.com/group/topic/37095#post-242695 https://blogs.oracle.com/jonthecollector/our-collectors https://en.wikipedia.org/wiki/Java_version_history","link":"/2020/07/13/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/"},{"title":"同步异步和阻塞非阻塞","text":"一. 同步/异步 同步和异步一般是两个有关联（或调用）关系的任务块（或方法块）之间通讯交互和执行时序的一种描述。 同步:1）被调用模块在执行完其全部逻辑后才返回；2）调用模块需等待被调用模块执行完其代码逻辑后，再继续执行其逻辑；3）两任务模块在一次调用期间不会出现时间重叠； 异步:1）被调用模块在返回结果后，仍需一定时间才能完成其逻辑；2）调用模块无需等待被调用模块执行完其代码逻辑后，再继续执行其逻辑；3）两任务模块在一次调用期间可能会出现时间重叠； 二. 阻塞/非阻塞 阻塞/非阻塞指是否阻塞当前线程, 阻塞的是线程； 是描述某个程序执行需要依赖某个前置条件，此时若条件不满足时：1）如果选择等待就是阻塞；2）如果不等待直接返回就是非阻塞； 例子：1）BIO等待数据到达;2）等待释放锁; 参考 https://en.wikipedia.org/wiki/Asynchronous_system stackoverflow: asynchronous-vs-synchronous-execution-what-does-it-really-mean","link":"/2019/07/17/%E5%90%8C%E6%AD%A5%E5%BC%82%E6%AD%A5%E5%92%8C%E9%98%BB%E5%A1%9E%E9%9D%9E%E9%98%BB%E5%A1%9E/"},{"title":"垃圾回收","text":"一、前置问题 垃圾回收的条件是什么？ 什么是STW?为什么要有STW？ 安全点是什么？为什么要有安全点？ 对象的分配策略？ 对象分配到老年代的场景? 什么是空间担保机制？ 二、内存动态分配和垃圾收集Java语言由JVM负责内存的分配以及垃圾收集。带来的好处是这减少了程序员的工作，不容易出现内存泄漏，内存溢出，访问越界等问题。但是也带来了挑战，当需要排查内存泄漏等问题时就需要了解JVM的内存分配和垃圾收集机制。 三、垃圾回收 JVM的各个内存区域存放了不同的内容，如方法区主要是类元信息和运行时常量池，堆存放对象实例。由于类元数据信息的生命周期几乎会持续整个java进程，所以方法区的空间使用较稳定，运行中产生的垃圾较少。对象的生命周期大部分都是朝生夕死，时刻都有对象死去和新生，所以堆是垃圾收集的重点关注区域。 垃圾收集器在回收类和对象时，判断其是否是垃圾有不同的标准： 1、回收类条件1）该类的所有实例已回收 类的实例会通过类型指针应用类元信息，程序可能随时会通过该实例访问类元数据来调用某个方法等。 2）加载该类的ClassLoader被回收 ClassLoader保存了其加载类的引用。例如，方法java.lang.ClassLoader#findLoadedClass就从中查找是否加载了某个类。 3）该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。Class对象作为类元数据的镜像对象，它如果在程序中被引用，也可能会随时访问类元信息。 2、回收对象条件回收对象有两种主流方法1）引用计数，2）可达性分析。考虑到引用计数无法解决循环依赖时的垃圾回收问题，JVM选择了可达性分析。 可达性分析的操作： 1）从GCRoot开始遍历和标记所有引用关联的对象 2）标记的对象都是可达的，非垃圾对象；没有标记到的，被认为的垃圾对象； 3）垃圾对象被垃圾收集器回收 四、STW和安全点1、STW - stop the world执行垃圾回收时，垃圾回收器要求所有工作线程暂停（即STW），类似快照，在此基础上进行垃圾的回收操作。线程暂停的点就是安全点。 2、安全点安全点的设置原则 1）方法栈帧执行前后设置安全点，可以减少保存上下文的工作，且此时可认为已执行完完整的CPU指令。 2）循环尾部，考虑循环可能时较耗时的操作，故作此折中。 常见安全点位置 1）循环的末尾（原则2） 2）方法临返回前（原则1） 3）调用方法之后（原则1） 4）抛异常的位置（原则1） 五、堆的分代规则考虑到对象的生命周期不同，JVM的堆也进行了相应划分。 1、老年代：原则上存放长期存活的对象，如缓存，Class对象，线程池等； 2、年轻代：原则上存放朝生夕死的对象，如方法内的局部变量，数据转换的临时对象等； 其中，80%以上的对象基本都属于朝生夕死的，原则上不应该让其流转至老年代。因为在老年代回收对象的开销比年轻代大得多，回收算法也更复杂。 六、对象在堆各个代中的流转规则1、对象优先分配到年轻代2、分配至老年代条件1）时间维度 年龄超过-XX:MaxTenuringThreshold 后会由年轻代进入老年代。（默认15岁，CMS默认6岁） 2）空间维度 I、超过-XX:PretenureSizeThreshold的大对象直接分配到老年代（大对象指一个对象占用的连续内存较大，比如数组，大字符串）； II、年轻代的survivor的空间使用超过-XX:TargetSurvivorRatio时，根据动态年龄判断原则把大龄对象移入老年代； 3、空间担保机制-XX:+HandlePromotionFailure开启老年代的空间担保机制，其目的是为了减少fullgc次数，用历史平均值代替当前年轻代的所有对象大小，减少触发full gc的次数。 该机制会在执行minor gc之前判断老年代的剩余空间是否可以容纳所有年轻代的所有对象： 1）如果可以容纳，则执行minor gc 2）否则，继续判断老年代剩余空间是否可以容纳年轻代历史移动对象到老年的平均大小： 如果可以容纳，则执行minor gc 如果不可以容纳，则先执行full gc","link":"/2020/06/11/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"title":"多应用混合部署","text":"一、背景公司最近开源节流，为了提高硬件资源使用率，组内决定多个应用混合部署到一台容器上。 二、混合部署注意事项 评估混合部署是否面临CPU，内存，网络，磁盘等资源瓶颈 修改各应用的JVM内存配置（-Xms -Xmx），总和不超过2/3物理内存 修改各应用的监听端口，避免冲突 修改各应用的停止脚本，避免无差别停止进程 修改各应用的日志路径，避免冲突 修改相关域名的解析IP或VIP后的分流IP 更新维护监控平台下各应用的IP # 最后 暂时停止旧应用，待新应用观察一段时间无误后，再缩容容器 把混合部署的应用信息整理一个文档，方便运维。如下所示：","link":"/2021/03/04/%E5%A4%9A%E5%BA%94%E7%94%A8%E6%B7%B7%E5%90%88%E9%83%A8%E7%BD%B2/"},{"title":"大促扩容要有数据支撑","text":"一、背景今日公司按期开始618备战，其中一项为提应用的扩容需求。往年只是根据单量趋势预估大促单量，然后基于单量进行扩容。 今年受到“使用CPU百分位作容器缩容的参考指标”的影响，决定通过数据及一定的理论来支撑扩容需求。当然，提出的考量指标及公式可能不适合，也不严谨，但是“有而后优”，先通过这个方案划一个基线，然后再适场景调整。 二、操作1. 基于以往数据评估今年618的增长倍率 2. 以集群为维度，观察业务单量比例 3. 以集群为维度，观察CPU使用率 4. 拟定扩容公式1）假设： 根据CPU峰值决定扩容机器数量，可以保证SLA 假设随着业务单量增加，CPU的计算量也线型增加 2）定义： 根据以上假设，拟定达到期望使用率扩容公式： P期望：期望容器CPU峰值 P当前：当前容器CPU峰值 N期望：扩容后，达到期望使用率的容器数量 N当前：当前容器数量 两种场景： 一定单量：P期望 x N期望 = P当前 x N当前 考虑增长：P期望 x N期望 = P当前 x N当前 x 大促预估单量倍率 3）当单量倍增时可得出： 公式一，目标机器个数： N期望 = N当前 x P当前 x 大促预估单量倍率 / P期望 公式二，扩容机器个数： N扩容 = N期望-N当前 三、结论以上的方案可能不够严谨，没有考虑其他瓶颈资源。但是作为一个以方法论支撑行为的一个示例足矣。希望以后的行为皆有章可循，不盲目，有思考。","link":"/2021/04/12/%E5%A4%A7%E4%BF%83%E6%89%A9%E5%AE%B9%E8%A6%81%E6%9C%89%E6%95%B0%E6%8D%AE%E6%94%AF%E6%92%91/"},{"title":"央行的基础货币怎么流入市场","text":"央行的基础货币是怎么流入市场的 本文主要摘录一个论坛的回复（原贴地址），该贴说明了央行的基础货币是如何流入市场的，以及派生货币、货币乘数、央行资产负债表、分层货币的相关知识。可以阅读《货币金字塔：从黄金、美元到比特币和央行数字货币》了解货币历史、分层货币概念、比特币的影响。","link":"/2024/11/01/%E5%A4%AE%E8%A1%8C%E7%9A%84%E5%9F%BA%E7%A1%80%E8%B4%A7%E5%B8%81%E6%80%8E%E4%B9%88%E6%B5%81%E5%85%A5%E5%B8%82%E5%9C%BA/"},{"title":"学习","text":"全脑记忆 2021/01/29 我们为什么要睡觉 2023/11/01 在睡觉之前，参与者从海马体的短期存储位置获取记忆——一个临时仓库，对于新的记忆来说，这个仓库是一个不易长期生存的地方。但是第二天早上，情况就大不一样了。记忆搬家了。经过整夜的睡眠之后，参与者此时会从位于大脑顶部的新皮层处获取同一信息——这是基于事实的记忆的长期存储位置，记忆可以在这里安全地生存，甚至可能是永久性地留存。 换句话说，在一夜的睡眠之后，你可以重新获得睡前想不起来的记忆。就像电脑硬盘一样，一些文件已经损坏，无法访问，而睡眠会在晚上提供恢复服务。它可以修复这些记忆项目，把它们从忘记的魔掌中拯救出来，第二天早上醒来后，就能够轻松而准确地找到那些一度不可用的记忆文件。这就是那种可能在经过了一夜安眠后，突然感到“啊，对，现在我想起来了”的感觉。 运动记忆被转移到了在意识层面以下运作的大脑回路中，而不是像保存事实信息所需的那样从短期储存处到长期储存处的记忆转移。结果，那些技能行为成了本能一般的习惯，很容易从身体里流露出来，而不会感到费力和刻意。也就是说，睡眠帮助大脑实现了动作序列的自动化，使其成为第二天性，这正是许多奥运会教练在提升精英运动员的技能时的目标。 快速眼动睡眠时的梦提供了一种夜间疗法。也就是说，快速眼动睡眠时的梦会从你白天经历的困难，甚至是创伤性的情绪事件中把令你痛苦的刺剔除，于是第二天早晨醒来时，你的情绪问题就能得到缓解。 刻意练习：如何从新手到大师 2024/04/121、练习路径 建立心理表征，也就是问题和解决方式建模 → 针对薄弱点或能力边界练习 → 获得反馈，调整模型 建立心理模型，可以寻找行业出色的人，网络等一切资源 生物基础是，大脑是可塑的，刻意练习可以成长 这样读书就够了 2024/11/17知识不值钱，反思和反馈才是价值 经济学早有定论，任何市场要想健康发展，实现“良币驱逐劣币”，从来不是靠卖家的自律，而是靠买方的辨别力。 著名教育家克里提克斯（Criticos）曾说：“经验本身有价值吗？并非如此——真正有价值的是在对经验进行反思之后的智力发展。有效的学习来自有效的反思，而非积极的经验。”同样，阅读本身也不能创造价值，理解和记忆知识都不能创造价值。改变行为才有可能创造价值。并且改变行为只发生在将读来或者听来的知识内化和反思之后。 问个问题：一个月之后，你还能记住书中这段内容吗？再问个问题：无论是否看得懂，是否记得住，一个月之后，读过的这段内容会对你的生活和工作有一丁点儿影响吗？不会有影响。如果不会，是否看懂、是否记住，就不是很重要的问题。自我导向的阅读，不太关心看不懂和记不住的问题，只关心能不能通过阅读提升自己的能力，改变行为。相信你已有所感悟，对致用类阅读来说，重要的不是看懂，而是能和自己的经验发生联系；重要的不是记住，而是能够将知识用到自己的工作和生活中。 在任何一个领域、任何一本书中（包括本书）都有很多你能学习的知识，但是其中也有相当多的知识是你不需要学习的。这是没有必要读完一本书的第一个原因。第二个原因是，读得越多，不见得用得越多。不妨回忆一下，近年来你彻底读完的一本书是不是对你帮助最大的一本书？或者你读过的最厚的一本书是不是为你创造价值最多的一本书？恐怕未必。第三个原因是，只要你能将读的书在工作中用上一丁点儿，图书给你创造的价值就已经远远超过书价。 知识就像水，本身很好、很重要，但在信息时代，额外得到一份知识太容易了：且不说网上书店和搜索引擎，仅仅是打开微信、微博，就有各类知识直接推送到我们眼前。然后，人们点赞、收藏、转发……然后，就没有然后了。总之，人们为一份新知识付出的边际成本可以忽略不计，一份新知识能带来的边际利益也可以忽略不计。于是，经济学原理验证了我们的结论：知识是好东西，但不值钱。 学会提问 汉迪把这个方法内化和应用到工作中，他说：“我们不提供建议，只是不停地问为什么。这有助于人们澄清自己的观点。这是我从苏格拉底那儿学到的。” 高级学习者在阅读中常常提问，可能是追问读到的信息，也可能是追问自己过去的理念。然后，高级学习者会思考这些信息与自己有什么关系，他会搜索和对照自己过去的经验，并且追问现象背后的本质。他还会思考和规划怎样用这些新知识解决自己的实际问题。 一种提问是为了得到正确答案；另一种提问是为了进行有效学习。前者常问“是什么”“为什么”，后者常问“如何”“你都考虑哪些方面”。 善于学习的人在反思和追问时，会尽量用“如何”来取代“为什么”。例如：把“为什么客户说我的产品不实用”的问题，换为“客户是如何对我的产品形成不实用的印象的”；把“你为什么在外面找小三”的问题，换为“你是如何变得有家不愿回的”；把“为什么我找不到喜欢的工作”的问题，换为“我是如何规划自己的工作和能力的”…… 一种回答是能够给出正确答案，另一种回答是能够促进正确思考。 有时在上课中途，我会问大家记笔记了没有。很多学员都点头，有的还拿起自己的笔记翻给我看。大部分人记的都是我的原话。我赞赏这样的学习态度，而后我会告诉他们：“在成人学习中，最不值钱的就是你记的这些信息。这些都是知识，而你有无数的渠道得到这些知识。你主动创造的信息才是最有价值的。如果今明两天你最大的收获就是满满一本笔记，那就叫买椟还珠。” 熊十力要学生徐复观去读《读通鉴论》。徐很快读完，谈了许多对这本书的批评。熊十力斥之：你这个东西，怎么会读得进书！任何书的内容，都有好的地方，也有坏的地方。你为什么不先看出它好的地方，却专门去挑坏的；这样读书，就是读了百部千部，你会受到书的什么益处？读书是要先看出它的好处，再批评它的坏处，这就像吃东西一样，经过消化摄取了营养。多年后，徐复观回忆道：这对于我是起死回生的一骂。 要知道，任何对问题的描述都是在赋予经验和事实以意义，都暗含了因果推断。看似是对事实的描述，其实都可以灵活地进行诠释。所以，绝大多数情况下，未经反思的经验都是不可靠的，未经追问的问题都不是真正的问题。 拆书法学习方式 “干货式学习”仍存两个方面的误区：首先，“得到书的精华就是学习”是成人学习的歧途；其次，干货也不是书的精华。学习能力的重要维度之一就是对照信息加工出上下文，加工成对自己有价值的知识。 知识管理这个概念于20世纪80年代提出，30年间已经完善了很多。总的来说，知识管理有两大分支：学院派的知识管理和实践派的知识管理。学院派的知识管理对应学院式学习，以知识学习为中心，用更多、更好、更清晰、更系统和更易提取的知识指导科研、梳理框架、撰写论文；实践派的知识管理对应成人学习，以促进应用、解决问题、创造价值为目标，企业、军队等大型组织对其更为关注。 好好学习：个人知识管理精进指南 2024/11/22 知识管理就是通过对外部信息进行加工，提高我们改变认知或行动的速度 于是，我读书不再追求速度；相反，我会刻意放慢速度，花时间记录读书笔记——不是仅仅摘记名言，而是描述读书后受到的启发，以及这些启发和我过去的哪些经验相关。 过去，如果我做一件事情没效果，我会认为这件事情没用。而这一次，我做出一个全新的假设：反思日记一定是有用的，只是我没有做对。这个假设的重要改变在于：过去，我把责任归于外部——事情是不对的，我是没问题的；而这次，我把问题归因于自己——事情是没错的，是我的方法有问题。 有一次，我听到一个朋友说：“教育的根本定义是改变自己，改变自己对经验的解读方式。” 大前研一在《思考的技术》这本书中提到的一个方法：你在处于职员位置的时候，就要思考这样的问题——“如果我的职级比现在高两级，我会怎么做？” 日本的“经营之神”稻盛和夫认为：面对复杂的问题，要从简单的、基本的原则入手。而查理·芒格则明确提出：我们要真正认识这个世界，就必须理解并掌握重要学科的基本规律，并把它们当作基本的思维模型来处理问题。 索罗斯后来总结道：“我认识到，要存活下来就必须采取积极行动。我父亲的经验就是：如果你在那些规则已经不适用的地方遵守规则的话，你就死定了。” 穷查理宝典 2025/04/15 查理一般会先注意应该避免什么，也就是说，先弄清楚应该别做什么事情，然后才会考虑接下来要采取的行动。“我只想知道我将来会死在什么地方，这样我就可以永远不去那里啦。”这是查理很喜欢的一句妙语。 随大流只会让你往平均值靠近（只能获得中等的业绩）。 一件事情如果不值得做，就不值得把他做好。 这种现象造成的结果让我想起曾经有个乡下教师，为了便于教学，他试图将圆周率π简化成3。这违背了爱因斯坦的教导：“一切应该尽可能简单——但不能过于简单。” 富兰克林在《穷查理年鉴》中说过：“如果你想要说服别人，要诉诸利益，而非诉诸理性。 一个数学家的叹息 2025/07/04 现在，让我说清楚我到底在反对什么。不是公式，也不是背记一些有趣的事实。在某些情境下，这是可以的，就像学习词汇必须要记忆一样——这可以帮助我们创造更丰富、更微妙的艺术作品。但是，三角形面积是长方形面积的一半，这个“事实”并不重要。重要的是，以辅助线来切割的这个巧妙构思，以及这个构思可能激发出其他美妙的构思，进而引导出在其他问题上的创造性突破——光是事实的陈述绝不可能给你这些的。拿掉了创造性的过程，只留下过程的结果，保证没有人能真正全身心投入这个科目。 我可以理解训练学生娴熟于特定技巧的想法——我也会这样做。但这绝不是训练的目的。数学上的技巧，就如同其他艺术里的技巧，应该是配合背景而为的。伟大的问题、问题的历史、创意的过程——这才是完整的背景。丢给学生一个好的问题，让他们花力气去解决并尝到挫折，看看他们能得到什么。直到他们亟须一个想法时，再给他们一些技巧，但是不要给太多。 萨尔维阿蒂：不是这样！学校里的数学课关心的许多事， 都和社会上的生存能力无关——例如代数和三角函数。这些学习和日常生活完全没有关联。我只是在建议，如果我们要将这类课题放入大部分学生的基本教育之中，我们就要用活生生的、符合自然天性的方式来做。同时，如同我先前说过的，一门学科碰巧具有一些世俗上实际的用途，不代表我们必须将这个用途当作教导和学习的焦点 我们全部的人，出生到这个世界，到一定时候都会死掉，这就是人生。在这段时间里，让我们好好享受我们的心智，享受我们的心智创造出来的奇妙又好玩的事物吧。我是不知道你的情况怎样，但我可是乐在其中呢。 为什么：关于因果关系的新科学 2025/09/21思维胜于数据 我们知道，禁止言论就意味着禁止了思想，同时也扼杀了与此相关的原则、方法和工具。 我对语言的强调也源于一个坚定的信念，即语言会塑造我们的思想。你无法回答一个你提不出来的问题，你也无法提出一个你的语言不能描述的问题 我特别想强调数据在上述过程中发挥的作用。首先，请注意，我们是在完成了以下步骤之后才收集的数据：根据假设确定了因果模型，提出了我们想要解决的科学问题，推导出被估量。这与上面提到的传统统计方法形成了鲜明对比，后者甚至没有用到因果模型。 通过观察许多服用药物D的患者的存活期L，某研究者能够预测出某个具有Z特征的病人存活L年的概率。现在，假设她被调职到位于城市另一地区的医院，而那里的人口总体特征（饮食、卫生、工作习惯）与原来的地区有所不同。即使这些新特性仅仅改变了以前她所记录的变量之间的数值关系，她仍不得不重新自我训练，再次从头学习新的预测函数。这就是深度学习程序所能做的：将函数与数据拟合。而如果该研究者掌握了药物的作用机制，并且新地区的因果模型结构仍与原来保持一致，那么她在以往的训练中获得的被估量就依然有效，可被应用于新数据，产生一个新的关于特定总体的预测函数。 因果关系至梯 本书将会经常提到的一种典型的关联度量方法，即“相关分析”或“回归分析”，其具体操作是将一条直线拟合到数据点集中，然后确定这条直线的斜率。有些关联可能有明显的因果解释，有些可能没有。但无论如何，统计学本身并不能告诉我们，牙膏或牙线哪个是因，哪个是果。从销售经理的角度看，这件事也许并不重要——好的预测无须好的解释，就像猫头鹰不明白老鼠为何总是从A点跑到B点，但这不改变它仍然是一个好猎手的事实。 因果网络的三种接合形式 1.A→B→C。这种接合形式是被称为“链”接合或中介接合的最简单的表现形式。在科学中，人们常常将B视为某种机制，或“中介物”，它将A的效应传递给C。一个熟悉的例子是“火灾→烟雾→警报”。虽然我们称这个系统为“火灾警报”，但实际上它应该叫烟雾报警。火灾本身并没有引起警报，所以这里也就没有从火灾直接指向警报的箭头。火灾也不会通过任何其他的变量，比如高温来引发警报，只有火灾向空气中释放的烟雾分子才会触发警报。如果我们禁用这个链中的第二个连接，例如我们利用通风管道吸走了所有的烟雾分子，那么警报就不会被触发了。 2.A←B→C。这种接合形式被称为“叉”接合，B通常被视作A和C的共因（common cause）或混杂因子（confounder）。混杂因子会使A和C在统计学上发生关联，即使它们之间并没有直接的因果关系。一个好例子（来自大卫·弗里德曼）是“鞋的尺码←孩子的年龄→阅读能力”。穿较大码的鞋的孩子往往阅读能力较强。但这种关系是非因果的——给孩子穿大一号的鞋不会让他有更强的阅读能力！相反，这两个变量的变化都可以通过第三个变量，即孩子的年龄来解释。越年长的孩子鞋码越大，他们的阅读能力也越强。 3.A→B←C。这是最让人着迷的一种接合形式，被称作“对撞”（collider）接合。菲利克斯·艾尔威特和克里斯·文史普以好莱坞演员的三个特征为例阐释了这个接合的含义。这个例子是：才华→名人←美貌。在此，我们认定才华和美貌都有助于演员的成功，但对于一般人而言，美貌和才华完全不相关。 混杂和去混杂 但是费舍尔意识到，得到对正确问题的不确定答案比得到对错误问题的高度确定的答案要好得多。如果你向自然精灵提出了一个错误的问题，那么你就永远不会得到你想知道的答案。如果你提出了正确的问题，那么偶尔得到一个错的答案就完全不成问题了。你可以估计出答案的不确定性，因为这种不确定性来自随机化的过程（这一过程是已知的）而不是土壤各个方面的特性（这一点是未知的）。因此，随机化实际上带来了两个好处。第一，它消除了混杂偏倚（它向大自然提出了正确的问题）。第二，它使研究者能够量化不确定性 争论 多尔和希尔意识到，如果病例—对照研究中的确存在隐藏的偏倚，那么仅仅靠重复研究肯定是无法消除偏倚的。因此，他们于1951年开始了一项前瞻性研究，向6万名英国医生发放调查问卷，采集关于其吸烟习惯的信息，并对他们进行追踪调查。（美国癌症协会也在同一时间发起了一项类似的、规模更大的研究。）在短短的5年里，一些戏剧性的差异就出现了。在接受了追踪调查的医生中，重度吸烟者患肺癌死亡的概率是不吸烟者的24倍。在美国癌症协会发表的研究结果中，情况甚至更加严峻：一方面，吸烟者死于肺癌的概率是不吸烟者的29倍，而重度吸烟者死于肺癌的概率更是不吸烟者的90倍。另一方面，曾经吸烟，然后戒烟的那些人，其患病风险降低了一半。所有这些结果都表明了一个一致的结论：吸烟越多，患肺癌的风险就越高，而戒烟能降低这种风险。这是一个强有力的因果证据。医生们称此类结论为“剂量—响应效应”（dose-response effect）：如果物质A会导致生物反应B，则通常而言（但不是百分之百），更大剂量的A会导致更强的反应B。 芝加哥库克郡医院的理查德·戴维在这篇文章中写道：“在当今社会中占支配地位的群体往往会通过辩称其所支配的群体本身就基因低劣来维护自己的立场，在这种社会背景下，研究者很难保持中立。在追求‘纯粹的科学’的过程中，一位出于善意的研究者很可能会被看作或者在事实上用他的研究维护和巩固了他所憎恶的某种社会秩序。”科学家因阐明了可能导致不良社会后果的真理而受到道德斥责，类似的事件在历史中屡见不鲜。罗马教廷对伽利略思想的批判无疑是出于对当时社会秩序的真诚的关注和维护。查尔斯·达尔文的进化论和弗朗西斯·高尔顿的优生学也遭受了同样的待遇。然而，此类由新的科学发现带来的文化冲击，最终往往是通过消化了这些发现的文化重组，而不是通过对这些发现的拒斥和掩盖来解决的。这种文化重组的一个先决条件是，在各种观点派生出无数衍生主张并产生激烈交锋之前，我们要先将科学从文化中梳理出来 大量的悖论 谁能直面矛盾，谁就能触摸现实。——弗里德里希·迪伦马特（1962） 在蒙提·霍尔悖论中，主持人为我们打开了门；在伯克森的悖论中，一个粗心的研究者可能为了方便而选择以住院病人为研究对象，却没有意识到这种做法为自己的研究带来了偏倚。对撞的扭曲棱镜在日常生活中同样普遍存在。正如乔丹·埃伦伯格在《魔鬼数学》（How Not to Be Wrong）中提出的问题：你有没有注意到，在你约会的人当中，那些有魅力的人往往是混蛋？与其为解释这一现象而费力构建复杂的社会心理理论，不如考虑一种更简单的解释。你对约会对象的选择取决于两个因素：魅力和个性。你会冒险约会一个刻薄而有魅力的人，或者一个和蔼但缺乏魅力的人，你当然也会与既和蔼又有魅力的人约会，但你肯定不会与既刻薄又没有魅力的人约会。换句话说，你删掉了所有“负—负”的结果，这与你在抛掷两枚硬币的例子中所做的筛选是相同的，而正是这种筛选造成了魅力和个性之间的伪负相关。可悲的事实是，没有魅力的人可能会和有魅力的人一样刻薄，但你永远意识不到这一点了，因为你永远不会约会既刻薄又没有魅力的人。 辛普森逆转是一个纯粹的数字事实：在合并样本时，两个或多个不同的样本关于某一特定事件的相对频率出现反转，如表6.4所示。在我们的例子中，我们可以看到两组相对频率：3/40&gt;1/20（这是女性患者中服用D药者和未服用D药者的心脏病发作的相对频率），和8/20&gt;12/40（这是男性患者中用药者与不用药者的心脏病发作的相对频率）。然而，当我们把男女样本的数据合并在一起时，不等式的方向就发生了逆转：（3+8）/（40+20）&lt;（1+12）/（20+40）。如果你认为这样的逆转在数学上是不可能的，那么你很可能是误用或记错了分数的属性。很多人似乎相信，如果A/B&gt;a/b且C/D&gt;c/d，那么（A+C）/（B+D）&gt;（a+c）/（b+d）就是自然成立的。但这种民间智慧是完全错误的。我们刚才给出的例子就明确驳斥了这一判断。 假设有一项关于各年龄段群体每周的运动时间与其体内胆固醇水平之关系的研究。如图6.6（a）所示，我们以x轴表示运动时间，以y轴表示胆固醇水平。一方面，我们在每个年龄组中都看到了向下的趋势，表明运动可能的确有降低人体胆固醇水平的效果。另一方面，如果我们使用相同的散点图，但不按年龄对数据进行分层，如图6.6（b）所示，那么我们就会看到一个明显向上的趋势，表明运动得越多，人体胆固醇水平就越高。看起来我们再次遇到了BBG药物的情况，其中运动就是那个药物：它似乎对每个年龄组都产生了有益的影响，却对整个总体有害。 图6.6 辛普森悖论：对于每个年龄组来说，运动似乎都是有益的（向下的趋势线），但对整个总体而言，运动似乎是有害的（向上的趋势线）。 像往常一样，要决定运动是有益的还是有害的，我们需要考察数据背后的故事。数据显示，总体中年龄越大的人运动得越多。因为更可能发生的是年龄影响运动，而不是反过来。同时，年龄可能对胆固醇水平也有因果效应。因此我们得出结论，年龄可能是运动时间和胆固醇水平的混杂因子，我们应该对年龄进行变量控制。换言之，我们应该看的是按照年龄组别进行分层后的数据，并据其得出结论：无论年龄大小，运动都是有益的。 中介：寻找隐藏的作用机制 是的，吸烟基因与肺癌有关。它有两个变异体，一个常见，一个不太常见。继承了两份不常见变异体的人（大约占总人口的1/9）有大约77%的风险患肺癌。吸烟基因似乎也与吸烟行为有关。携带此高风险变异体基因的人似乎需要更多的尼古丁才能满足，对于他们来说，戒烟相当困难。然而，我们也有一些好消息：这些人对尼古丁替代疗法的反应比不携带此吸烟基因的人要好。 社会正义谬误 2025/09/26 你有权发表观点，但无权专断事实。——丹尼尔·帕特里克·莫伊尼汉 第一章 “机会平等”谬误 在现实世界中，就算一切能影响结果的因素在每个人那里都一样，也很少有平等的结果。就算一个社会能提供平等的机会，也就是能以同一套标准评判每个个体，背景各异的人也未必想做同样的事，更不用说花时间和精力去发展同种技能与特长了。 个体间的不平等 当美国儿童在不同的社会阶层、不同的培养方式中长大时，他们在成年后以平等能力继续发展的概率会显著降低。研究表明，由有专职工作的父母抚养的孩子，每小时听到的词语数量是依赖福利救济的家庭孩子的3倍以上。更重要的是，这些词语，在父母都有工作时大多是积极肯定的，在家庭依赖救济时经常是消极否定的 群体间的不平等 各大洲之间的差异也大相径庭。尽管论陆地面积，非洲几乎是欧洲的3倍，但论海岸线长度，欧洲要比非洲长数千公里。这听起来似乎不可能。但欧洲的海岸线蜿蜒曲折，创造了许多“天然港口”，船舶得以在此安全地停靠，躲避远海汹涌的波涛。就此而言，这些港口甚至是比更长的海岸线本身更大的优势。 长期以来，欧洲人比非洲人更频繁地从海上贸易中获益，还会令人意外吗？18世纪时，亚当·斯密已经指出这一地理差异，并且反对那些关于非洲人在种族上地位低贱的主张。其他学者也已经陆续认识到，撒哈拉沙漠以南的非洲有许多极其不利的地理条件。对此，杰出的法国历史学者费尔南·布罗代尔总结说：“在理解‘黑非洲’上，地理学比历史学更重要。” 港口仅仅是对人类经济与社会发展有重大影响的各种航道中的一种。航道之所以重要，是因为水路运输和陆路运输的成本差距相当悬殊。例如，在古代，横跨2000余英里的地中海运一件货的成本，比在路程仅75英里的内陆运同一件货的还要低。这意味着，生活在沿海的人同其他沿海人群及地点的经济与社会交流，要比生活在内陆的人同其他内陆人群或沿海同胞的交流广泛得多。 环境和人力资本 约翰·穆勒在19世纪指出，一个社会的诚实或欺诈水平是决定该社会经济状况的主要因素。穆勒以俄国的严重腐败为例，总结说它必然是“经济进步的巨大阻力”。自那时起，无论是在沙皇统治时期、苏联时期还是俄罗斯时期，腐败现象普遍存在。曾经，一些俄国人会被其同胞形容为“和德国人一样诚实”，这不啻一种默认——这样的品质在俄国人那里并不常见。反过来说，发生在英国的工业革命之所以获得了外国的资金支持，原因之一就在于，那些投资者信赖英国法律的诚实、公正。 偶发因素 你是希望航空公司的飞行员是在人口统计学意义上来自不同群体的代表，还是希望他们经过专业的筛选、能熟练应对一切复杂情况，从而提高你所乘坐航班安全抵达终点的概率？一旦我们承认许多因素会使“发展起来的能力”存在差异，“人人机会平等”就变成了在后果上非常不同于“机会均等”的主张。而结果其实比——或应该比——某些看似诱人、时髦的论说更重要。 第二章 种族谬误 “种族之间的差异”并不必然是“种族差异”——无论是在基因意义上还是在种族歧视的意义上。一些行为模式在不同种族中会导致相似的结果，因此，结果上的悬殊所能反映的，其实是出于各种原因的行为上的悬殊，而不一定意味着基因决定论或社会性的歧视。 早期的进步主义 那个时代基因决定论者的结论以及后一时期进步主义者的相反结论，最根本的问题在于他们使用经验证据的方式。在这两个时期，进步主义者都带着一种“先入之见”出发，并且在找到看似符合他们先入之见的数据时停止检验证据。这样的程序可能足以提供话题，但如果目标是求得真理，就必须继续调查，看看有无其他与最初信念相冲突的数据。 “优生学”这一术语是由弗朗西斯·高尔顿爵士提出的，它被用来描述这么一个计划：减少甚至阻止被认为基因低劣之人的生存。他说：“基于情感反对逐渐灭亡一个低贱种族的看法，在很大程度上是不合理的。”美国经济学会的开创者之一理查德·T. 埃利教授，曾这样谈论在他看来基因低劣的人群：“我们必须向落后于我们这个社会进步的、最绝望的阶层提供尽可能完善的看护，包括性别隔离和监禁措施，以阻止其繁衍。” 康芒斯教授反对自由市场竞争的理由是：“竞争是对优越种族的不尊重”，会让“所必需的事物最少的种族取代其他种族”。 后来的进步主义 在美国历史上，跨越种族界限并且就种族议题达成最广泛共识的时刻，或许是1963年马丁·路德·金在林肯纪念堂发表历史性演说之时。那时他说，自己的梦想是建立一个世界，其中的人“将不再因外在的肤色受到评判，取而代之的标准是内在的品格”。这里的要旨，是无论种族的个体平等机会。但这一议程以及它所拥有的广泛共识，后来却逐渐遭到破坏。目标从无论种族的“个体平等机会”变成了无论种族、性别等范畴的“群体平等结果”。 第三章 棋子谬误 财富再分配 这意味着，在特定的管辖范围内对“富人”提高税率的实际后果，是一个事实问题。结果不一定是可预测的，潜在的后果可能说明计划中的充公行得通，也可能说明它行不通。将税率提高×%，无法确保税收也能增长×%，甚至无法确保它会有所提高。唯有从理论和空谈回到历史事实，才能检验社会正义愿景的显性与隐性假设。 税率与税收 几个世纪之后，美国国内也出现了类似的退出征税管辖范围的情况。以马里兰州为例，该州希望通过对年收入100万美元及以上的个人提高税率，以征得至少1亿美元的额外税收。但随着新税率在2008年生效，生活在马里兰州的此类人口数从近8000降至不到6000。预期中能增加1亿多美元的税收，实际上反而减少了2亿多美元。 反过来说，税率的降低也不会理所当然地导致税收的减少。无论是提高还是降低税率，人都不是任由他人摆布的棋子。就像高税率会赶走生意人和投资人一样，低税率也可能会吸引他们。在冰岛，随着企业税税率在1991年至2001年逐渐从45%降至18%，其税收增加了两倍。 通货膨胀“税” 通货膨胀、价格上涨的最终结果是，每个人手里的货币都会贬值，无论他们收入多少。这就像一种税，从最贫困到最富有的人都要缴纳，每个人所适用的税率都与“百万富豪和亿万富豪”一样。但货币不是工厂、地产一般的有形资产，在通货膨胀期间，后者的市场价值不降反升；因此，“对货币征税”和“对有形资产征税”是两码事。这一切的最终结果是，名副其实的通货膨胀“税”会在最贫困人群那里夺走更高比例的资产：这群人不太可能有自己的工厂、地产或其他能在通货膨胀期间升值的有形资产，所以货币在其全部资产中的比例更高。 最低工资法 最低工资法会降低歧视者的歧视成本。由于政府所规定的工资水平高于一个竞争市场中的供求关系所决定的水平，“工人”和“雇主”势必像其他并非棋子的“卖方”和“买方”那样做出反应。更高的工资率会吸引更多的求职者，但更高的劳工成本往往使雇主减少所雇劳工的数量。最终的结果是，受最低工资法影响的低薪工作的求职者长期过剩。在这样的条件下，雇主就算拒绝了合格的少数族裔求职者，也能轻易从长期过剩的求职申请中签下其他不仅合格，而且不是少数族裔的求职者。这种情况下的歧视可能无须雇主付出任何代价。 歧视者的歧视成本越低，歧视越多；反之，歧视越少 “停滞的”收入增长 关于美国整体收入增长“停滞”的危言耸听的说法也由来已久。例如，从1969年至1996年，在这超过25年的时间里，美国户均实际收入——排除通货膨胀因素后的货币收入，仅仅增长了6%。但同一时期的美国人均实际收入增长了51%。这两个数据怎么可能都是对的？这是因为那些年间美国的户均人数逐渐减少。美国人口普查局表示，早在1966年，户均人数就开始减少。 第四章 知识谬误 在许多社会议题中，最重要的决策是谁来做决策。社会正义的倡导者和他们的批评者，虽然都同意许多重大社会决策最好由那些掌握最相关知识的人做出，但论及谁掌握了最相关的知识，他们的假设根本不同。这部分是因为，关于知识的内涵和外延，他们的构想根本不同。像“什么构成了知识”这样的意见差异，可追溯至成百上千年前。 重要知识 所谓“重要知识”，是能对事关人生轨迹的决策造成影响的知识。例如，控制泰坦尼克号的高级船员无疑了解许多有关船舶与航行细节的复杂知识。但在某个晚上，最重要的知识，却是关于某座冰山位置的普通知识，因为“撞上冰山”是泰坦尼克号受损沉没的根源。 孩子们 原因不难发现：到了1976年，15岁至19岁各年龄段发生过性行为的青少年未婚女性在此年龄段女性中的占比都比仅仅5年前更高。此外，当所谓的“性教育”包含以下内容时，出现这一趋势的原因也不难理解了：一个针对13岁至14岁初中学生的性教育项目，会播放四对赤身裸体的伴侣（两对同性恋、两对异性恋）进行各种露骨性行为的影像片段，性教育学者还告诫教师不得向父母或朋友展示这些资料：“若脱离了本项目的语境，许多项目资料会引起误解和麻烦。 含义 许多有耀眼成就的智识分子似乎认为，那些成就会为他们对无数议题发表的见解赋予合理性，即使许多议题远超其成就所在的领域。但一个人超越其专业领域无异于跃下悬崖。作为抢占他人决策权的基础，“智商高”和“信息少”是一种危险的组合——如果这种抢占行为发生在代决策者无须因自己犯错而付出代价的情况下，就更危险了。 第五章 言行与危险 哈耶克的深刻见解是，一个大社会之运作所必需的全部重要知识，都存在于其总体，不存在于任一特定的个体、阶层或机构。因此，一个大社会之运作及延续，需要无数持有无数重要知识片段的人通力合作。这使哈耶克反对各种导向集中控制的体制，无论是中央计划经济、为了社会正义的全面代理决策制，还是假定“社会”应对其全部成员的命运幸厄负有道德责任——在没人拥有担负这一责任所需的知识时——的体制。 优点 为了厘清那些引起争议的新议题，他们所需要的“教育”，必须使他们具备彻底审视并系统分析对立观点的技能、知识以及经验。而这正是他们在被灌输任何当前流行的事物时都不曾习得的东西。灌输式的“教育”，使一代又一代人成了容易被那些精明政客用操纵情绪的花言巧语蛊惑的工具。 反歧视行动 乔治梅森大学的法学院曾受到威胁，如果它不继续录取那些资格条件不如其他学生的少数族裔学生，它就会失去官方认证，即使数据显示这并不符合少数族裔学生自己的最大利益。“统计数据中群体代表性的悬殊态势就意味着种族歧视”这种甚嚣尘上的社会正义谬误影响重大。校园里的少数族裔学生就像人肉盾牌一样保护着学校的利益，而人肉盾牌中的牺牲者可谓不计其数。 社会契约论 2025/10/29 [法] 让-雅克·卢梭 第一卷原文：从天然状态到公民状态的转变在人类身上产生了令人瞩目的变化，使得人类行为中本能的成分被正义所取代，赋予了各项活动之前所没有的道德性。也就是说，只有当义务的呼声取代了生理冲动，当权利取代了嗜欲时，在此之前眼中只有自己的人类，方才发现必须遵守除了冲动欲望之外的原则，在听任自己的喜好之前还需要进行理智的考量。 原文：我想要做出一点说明—这一点应当是整个社会体系的基础，即基本公约并非摧毁自然的平等，相反，是用道德合法的平等取代大自然可能在人与人之间造成的不平等。也就是说，人或许在能力或天资上不平等，但通过协约在法律地位上都是平等的 第二卷原文：全体民众的意愿和公共意志之间往往有区别，后者只关乎公共利益（intérêt commun），前者关乎私人利益（intérêt privé），只是个体意志的总和而已。但这些意志中不统一部分抵消后，余下的总和便是公共意志。 原文：当全体人民为整体做出裁定时，所考虑的只有自己了。如果就此形成一种关系，那就是，一个角度下整体的人民对另一个角度下整体的人民之间的关系，对整体没有任何分割。而所裁决的内容是普遍公共的，恰如做出裁决的意志是普遍公共的。这种行为，就是我所认为的法律。 第三卷原文：我承认，假如臣民能够始终完美地服从君主，那么君主的确会希望人民变得强大，好让这股力量为自己所用，震慑周边四邻。但由于这一利益仅仅是次要的、从属的，何况顺从与强大这两项假设本身就不可兼得，那么君主自然总是更愿意选择直接有利的做法 原文：有些消耗得多，有些消耗得少，各种区别取决于下面这条原则：税收距离源头越远，负担越大。衡量捐税负担并不在于捐税数量的多少，而在于赋税取之于民再用之于民所经过的距离。 原文：由此可以得出推论，随着人民与政府之间距离的增加，赋税越来越繁重。所以在民主国家，人民负担最轻；在贵族政府中，负担略重；在君主制国家，人民承担着最沉重的赋税。所以，君主制只适合富足的国家，贵族制适合财富和规模都适中的国家，民主制则适合小而贫穷的国家。 实际上，我们越仔细思考这一问题，就越能发现自由国家与君主制国家的不同：在自由的国度，一切都为公共效益（utilité commune）而努力；在君主国家，公共力量和个体力量相互牵制，此消彼长。也就是说，专制政府的统治并不以臣民幸福为目的，而是要让臣民生活疾苦以便于统治。 原文：政治联合体的目的是什么？那就是成员的生存和繁荣。那么判断成员生存和繁荣的最可靠特征是什么呢？那就是人口数量。所以，不必另往他处寻找这个众说纷纭的特征了。在其他一切条件相同的前提下，在不借助外力、不依靠外援、没有殖民地的条件下，能让公民安居乐业、人丁兴旺的政府，毋庸置疑就是最好的政府；人民数量减少而日渐衰败的，就是最坏的政府。 原文：为了给不同事物不同的名称，我将篡夺皇权权威者称为暴君，将篡夺主权权力者称为独裁者（despote）。暴君违反的是依法统治的法律；独裁者则是将自己凌驾于法律之上。这样一来，暴君未必是独裁者，但独裁者一定是暴君。 第四卷原文：两条基本原则可以帮助我们调整这些比例关系：其一，要协商的事宜越事关重大，决定它的观点就应当越接近全体一致；其二，磋商事宜越亟待解决，就越应当降低对不同观点票数之差的要求。对于需要立刻做出决定的事务，仅仅一票之胜便已足够。第一条看起来更符合法律精神，第二条更符合实务精神。无论如何，二者有机结合才能建立起最佳比例关系，才能达到足以宣告公共意志的大多数 产业与文明：复杂社会的兴衰 205/11/25 引言 如何理解复杂社会原文：因为，他们顺从的是知识共同体内部的逻辑，而不是这个世界的真实逻辑，自然找不到真实世界的解决方案。 原文：对每一个从研究生阶段开始学术生涯的人来说，这几乎是不言自明的常识：听说过几个对导师的研究和方向高度不认可，反而能顺利写出论文毕业的？无论人文社会科学，还是理学工科，大都如此。其实，顺从本身并不是什么错，但经知识共同体如此数代的筛选的最终结果，便是问题意识与观察视角的高度一致性。 第一部分 “漏斗——喇叭”模型原文：这就像是几十年前的中国，一面有“科学技术是第一生产力”的口号，一面也有“造导弹不如卖茶叶蛋”的俗语。直到科学家和工程师成为资本的宠儿，人们对科技才真正有了尊崇之情。因此，技术发明家究竟是被社会尊崇还是被社会遗忘，恐怕并不是由观念决定的，恰恰相反，观念是经济结构和社会实践的产物。 原文：技术带来的巨大变革往往是由需求启动的，而不是由技术本身启动的；只是因为需求往往太普遍、太常见而容易被忽略。 原文：一般而言，历史学家会把第一次工业革命描述为蒸汽机、钢铁和铁路起主导作用的革命，而把第二次工业革命描述为化工、电气化和内燃机等技术产业起主导作用的革命。 原文：总之，如果站在1900年前后，我们看到的是蒸汽机汽车、内燃机汽车和电动车的“三足鼎立”，而不是内燃机汽车的一家独大。 第二部分 三流循环原文：总而言之，厘清这些概念，尤其是意识到科技革命并不等同于工业革命，我认为是十分重要的：意识到科学研究和工具的创新未必等同于产业的创新，是意识到工业社会复杂的开始。 原文：一个生活在古代社会的人，不会因为使用了蒸汽机、汽车或电脑就迈入工业社会的。他必须适应全新的生活节奏、思维方式和看待世界的角度。这正是工业革命对人类文明的意义。 原文：先有挣钱的场景，再有技术突破。因此，一场完整的产业革命周期往往起于资本流，爆发于能量流，而大规模表现为产品流。 原文：19世纪晚期的社会学家、经济学家托尔斯坦·凡勃仑（Thorstein Veblen）有这样一个观察，他说，一个工业社会的最上层和最下层有一些精神气质是相通的，比如，崇尚武勇，喜欢掠夺，相信命运的反复无常。但是，绝大部分参与工业活动的普通人阶层，他们的气质则与前两者相反，他们爱好和平，相信理性，习惯用因果关系理解事实并联系事实。造成其中区别的原因就在于，工业活动以机械操作的细节，把理性和量化因果的关系刻到了他们的骨子里。 原文：这是因为人有八种可能增加储蓄的天性（谨慎、远虑、筹划、改善、独立、进取、骄傲和贪婪），所以，实际需求量和实际消费量之间首先会出现一个差值，这个差值就是储蓄。 第三部分 产缘政治原文：在工业革命时代，是产缘政治决定地缘政治，而非地缘政治决定产缘政治。 原文：为什么人们愿意购买煤油灯而不是蜡烛？为什么人们愿意为街上长明的路灯买单？答案首先就在于“藏富于民”。这不仅仅有道德意义，而且有巨大的经济现实意义。一个民众普遍富裕的消费市场是创新的最好土壤。 原文：“骤战而骤胜，国之不祥。” 以日为鉴：衰退时代生存指南 2025/11/26 第一篇 失业潮下的决策原文：但僵尸企业却只是这轮保就业衍生代价中最小的一个部分，比僵尸企业更恐怖的是，日本将海量资金用于救助企业而不是用来发展科技，而这不仅连累了金融体系，也断送了日本高科技业的未来。 原文：由于这段经历对于那十年的毕业生伤害过于沉重，以至于日本NHK电视台在后来的纪录片中评价道：“努力拼搏奋斗的学生们却遇上了最糟糕的时代，这些学生并没有做错什么，他们只是出生在了一个坏的时代。”根据日本大藏省2020年统计，就业冰河时代的大学毕业生至今都是日本平均收入最低的群体，可以说那批大学生们花了30年都没有走出就业冰河期 原文：1992年至1995年间，面对大学生就业的严峻形势，日本政府推出了“乡村分流”与“研究生扩招”两项举措，旨在尽量延缓大学生进入就业市场的时间，以缓解就业压力。 原文：这就带来了一个可怕的问题，泡沫最疯狂阶段整个银行体系在4年时间增长了140万亿贷款，但在泡沫破裂之时这些贷款还款周期大多都不到20%。这就意味着一旦老员工们失业，他们这剩余80%的未偿贷款将只能由银行消化。从后来的发展上看，90年代后期日本银行确实遭遇了不良资产危机，但那场危机主要来自企业端债务暴雷，就这已经让银行业元气大伤，全行业在2010年后才逐渐走出衰退影响。试想一下，如果企业端与居民端同时暴雷，日本银行体系大概率将尸骨无存。 原文：简单来说乡村这套长期依赖举债基建的模式无法运行，由此用大基建营造出来的乡村就业繁荣开始破裂。 第二篇 无法与自己和解的一代人原文：“四当五落”是一个曾经响彻日本70年代家长圈的流行语。考生每天睡四小时，就能考上自己心仪的大学（当），每天睡五小时的话，就会名落孙山（落）。 原文：“做好储蓄”“不乱消费”和“低欲望生活”是日本现在年轻人应对经济下行的三件法宝。 原文：一般认为，一国经济处于高速增长时期，比较容易出现学历型社会。 原文：一般认为，经济处于停止增长时期，学历型社会将开始瓦解，学历将出现快速贬值。 原文：政府笃信通过扩招高端人才复制80年代的产业优势，日本可以迅速走出经济衰退的冲击。在此背景下，文部省启动了一场为期多年的研究生扩招计划。由于当时恰逢大学生失业潮，在就业难的背景下社会掀起了一场持续多年的考研热，研究生报名人数仅4年就翻倍增长。但此后考研潮愈演愈烈，导致研究生出现过量供应。最高峰时日本国立大学毕业生考研比例竟然高达60%，虽然政府多次调整政策，但最终这场硕博大扩招却演变成了学历大贬值。 原文：面对愈演愈烈的大学生失业潮，当时日本陷入了两难的选择，如果停止硕士扩招，则原先海量的考研学生必将开始找工作，此时的就业市场根本无法容纳如此多学生。文部省统计仅1996年一年就新增22万失业大学生，而当年参加各大学硕士笔试人数高达11万，可以说考研有效缓解了当时社会恐怖的就业压力。在大扩招无法停止的背景下，日本政府于1996年提出研究生教育质量改革与博士扩招计划。一方面，政府鼓励研究生进行博士深造以延缓就业，此后又推出博士后支援计划，最高峰是在读博士数量达到7万，博士后达到1.5万，是扩招前的整整三倍。 第三篇 就业众生相原文：新生儿的断崖式下跌，使得大量新建的妇产医院与学校迎来闲置。幼儿园成了最先受到打击的对象，90年代中期，仅东京一地每年倒闭的幼儿园数量就在30—50家左右。在老龄化加速的10年间，妇产科却成了医院里最清闲的科室。尽管日本在1995年紧急实施了“天使计划”与“紧急保育”两大刺激生育政策，但依然未能扭转颓势。 原文：由于长期的经济衰退与过量的大基建投资，2001年日本财政已经处于崩溃状态，在此背景下，政府启动了那场被无数公务员视为梦魇的大部制改革。改革后原有22个国家部门被削减至仅有12个，海量公务人员失业。 原文：2003年，由于国库无力负担庞大的教师队伍的开支，政府决定对教师身份进行改制。此后教师不再等同于国家公务员身份。政府将学校的实际管理权限移交给地方，改制后中央每年只承担教师30%的工资，剩下经费均由地方自筹。这场改革大大缓解了中央财政压力，每年仅教师工资一项就减少了1.5万亿支出。但这场改制却给地方政府带来了沉重的财政负担。社会各界普遍批评这轮改制是将教师群体作为财政负担，不负责任地扔给地方政府。 原文：在20世纪80年代，国际对医生的社会需求量多数是以人口比来计算的，表现为每千人口需要几名医生这种形式。但此形式忽略了非常重要的一点，那就是随着社会老龄化加重，老年人均就医次数比一般人高几倍，而且诊疗时间长，因此老龄化患者消耗的医疗资源并不是加法的概念，而是乘法概念 原文：从1995年开始，厚生省提出以控制成本为核心的新医师评审制度，其中降低住院支出与药品费用成为考核的重点方向。政府希望在不增加医疗预算的情况下，通过降低成本治疗更多的患者；此后更是将患者支出与医生收入晋升直接挂钩，倒逼医生主动减少患者费用。 第四篇 老龄化冲击的医疗体系原文：“医药之冬”特指20世纪90年代日本药品大控费时期。 80年代日本医药产业一度俯视全球，每年新药产出占全世界的29%，是当时仅次于美国的第二大医药帝国。 但难以想象的是，这个帝国竟在短短10年间便轰然倒塌。 90年代，由于医保出现巨额赤字危机，日本政府对药品实施强力的费用管控手段，虽然最终控制住了医药支出增长，却让整个医疗行业经历了一场难以想象的寒冬。 原文：部分药企为了盈利开始使用劣质的原料。在此背景下，坚持生产品质的良心药企反而会因成本过高而面临亏损，全行业形成了一种畸形的劣币驱逐良币态势。但劣质的原料又怎么能生产出优质的产品！ 原文：2002年厚生劳动省宣布修改新药定价机制，后来这也被视为复兴医药改革的开始。2002年的新药定价机制与1991年最大的区别，是首次对药物创新性进行分层管理。对FIC（First in class，独创新药）、Me-better和Me-too三类药物都给出了清晰的定价指引，这就是日本至今都在使用的三类比价法。 原文：其实90年代中后期，厚生省已经意识到仿制药低价竞争策略其实对降低医保支出有百害而无一利。因为站在药物经济学角度来看，仿制药替代战略实际需要的是社会效应的最大化。核心本质是实现价格、覆盖人数与疗效之间的动态平衡。低价竞争虽然在短期内降低了药品价格，但长期来看却导致质量的下降和市场信任的缺失。不仅不能控制医保支出，还会因为药品质量问题引发更高的医疗成本。更关键的是，一旦仿制药不能得到社会信任，将严重影响市场推广和使用率，患者反而会进一步要求使用价格更高的原研药，这只会变相增加医保的支出。 原文：毁誉参半的DPC支付到底是什么？简单来说就是按住院天数对医院实施奖惩制度。过去无论住院多久都可以进行报销，老年患者仅需要支付少量费用，就可以长期使用医院床位，也就是前述提到的医院养老现象。医院由于可以无限制获得医保付费，也乐见老年患者长期使用床位，这也是90年代医疗资源紧缺的一大诱因。 而DPC改革就是针对这一情况，提出医保报销按住院时长分段支付，简而言之就是住院时间越长，医院所获得的医保支付越少，倒逼患者提前出院，或者说DPC改革宣传的是效率至上，医院治愈患者的速度决定了能拿到多少奖励。 原文：医患关系的本质其实是社会发展过程中，医疗水平与经济发展之间的矛盾 第五篇 失落经济下的全民出海潮原文：先期出海的大企业最终市场份额一定会被本土企业所占据。就像日本电视被中国企业打败，韩国手机退出中国市场一样。但是那些早就融入当地供应链的企业却反而能够生存下来 后记 一个故事在日本两代人眼中的变化原文：当经济神话破灭、努力与回报脱钩时，任何美化苦难的叙事都会遭遇反噬。正如日本作家斋藤茂男在《饱食穷民》中所写：“泡沫不是经济的破裂，而是梦的破裂。” 脉络：小我与大势 2025/11/28 1 历史History原文：一个人看待历史的态度，或者说史观，比总结什么历史规律更为重要。因为一个人看待历史的方法和角度，其实就是他看待现实与未来的方法和角度。 原文：今天，但凡做过科学研究的人都知道一个基本的道理：给看到的现象找一个逻辑上能够自洽的解释是一件很容易的事情，但是这种解释通常不是造成结果的原因，而找到真正原因和结果之间的逻辑关系，是很难的 原文：虽然我们很难以古为镜，但是了解历史、研究历史依然有意义。其最大的意义在于培养看待问题的视野和角度，学会分析问题的方法，也就是史观和方法论。 原文：人类在能够运用理性思考后，在短时间里产生了思想的大爆炸，这件事发生在轴心时代。轴心时代这个名称来自德国哲学家卡尔·雅斯贝尔斯，他发现在公元前8世纪到公元前3世纪之间，在北半球从东到西，出现了中国的老子、孔子，印度的佛陀，古波斯的琐罗亚斯德，犹太民族的耶利米、以赛亚，以及古希腊的毕达哥拉斯、苏格拉底、柏拉图和亚里士多德。他们是奠定了人类思想底色的思想家，他们的思想一直在影响我们的生活。 原文：文明的长度并不决定历史的贡献 原文：经济学家许小年先生曾经表达过这样一个观点，人类历史上只发生过一件事，就是近代化。这让很多人感到困惑，我们有考古证据支持的历史已经有6000年了，怎么会只发生了这一件事？其实这个观点并不是许小年的发明，而是今天历史学家发现的。当然历史学家的表述是，在人类的文明史上，最重要的事件只有一件，就是工业革命以及因此而产生的近代化。 2 当下Now原文：对个人而言，财富是两个维度变量的乘积：一个是时间，另一个是每个人的能力和能够调动资源的数量。 原文：杜波依斯是哈佛大学第一位黑人博士，他写了一本书《黑水：面纱里的声音》（Darkwater: Voices from Within the Veil），回答了有关教育目的和社会公平的问题。杜波依斯指出了很多人对教育的误解，或者说一些错误的期望，主要有三个。 第一个误解，以为人的幸福感源自自己能拥有他人所没有的东西。 原文：第二个误解，觉得教育要让每个人都能享受同样的、最大限度的自由。 原文：可以说这是一种妄念，因为不可能每个人都能享受最大的自由。如果一个人想要有不受约束的无限自由，必然就有人会受到奴役，因此这种想法是不可能实现的。每个人获得自由的前提，其实是要先约束自己。就像之前我们说过的，有的人反对特权，其实只是反对自己没有特权，而不是反对特权本身的不合理。如果人人想的都是自己要获得特权，社会就会变成一个丛林世界，对每个人都没有好处。 原文：第三个误解，觉得既然制度有不合理的地方，就应该把这个制度推翻。 原文：那么，我们究竟应该怎样理性地面对教育中存在的问题呢？杜波依斯给出了三个很有价值的建议。 第一个建议，所有人都需要明白，教育的平等来自整个社会的平等，特别是社会分工的平等。 原文：当然，要让全社会做到尊重每一个职业需要大家的努力。为此，杜波依斯给了第二个建议。我们需要回到最根本的教育理念上：孩子必须接受教育，知道世界是什么样的，世界上存在什么，世界是如何运作的。这些事情彼此密不可分。我们不能脱离实际，只传授书本上的知识，也不能将自己与人类的思想和文明相分离。 3 社会 Society原文：柯立芝的政治理念和“无为而治”有相通之处，他相信社会自我发展的能力，相信商业社会和企业的效率。类似地，在法律方面，柯立芝也认为“人无法制定法律，我们只能发现法律”。柯立芝讲，社会中存在着一些有利于社会的习惯、规则和文化，立法机构的职责是去发现它们，并将它们提炼成法律，而不是基于主观意见闭门造车，制定不合民情的僵硬的法条。柯立芝的一句话让我很有感触。他说：“我们要广泛地、坚定地、深刻地相信人民，相信人民渴望做正确之事……国家才会长存。” 原文：今天，很多人呼吁社会公平和自由，这很好，但是如何做到社会公平和个人自由，很多人其实是一头雾水。对于这个问题，100多年前另一位古典自由主义思想家阿克顿勋爵就给出了很好的答案：“财产，而非良知，是自由的基础。 4 未来 Future原文：信托（trust），过去也被译为托拉斯，是英国人发明的一种资产管理和传承的金融工具。简单来说，它像是一个大池子，各种各样的资产都可以往里装。比如你名下有若干股票、一些债券、两栋房子和一家店铺，你可以建立一个信托，把这些资产的所有权都放到信托中。 原文：一个听众问他：科技是否能让人永生？凯文·凯利讲，永生将是一个非常糟糕的结果。他说，如果作为个体的人不死，人类就死了。他还说，世界上只有一种细胞有可能不死，那就是癌细胞，但癌细胞一旦壮大，整个机体就会死亡。 什么是权力 2025/11/30 第一章 权力 你的意志怎样被“扭曲”？原文：政治之所以险恶，在于你越是资源丰厚，就越容易被别人惦记，你爬得越高，你的敌人和潜在的敌人就越多。客观上，拥有资源越多的人越不安全。 原文：对于绝大多数普通人来说，权力只是编织公共生活网络的线绳，孟子说“不以规矩，不能成方圆”，我们之所以需要权力，就是因为我们在不得不一起生活的时候需要章法，但谁也不想被它勒住脖子，所以老子马上就会提醒我们“法令滋彰，盗贼多有”。权力是打造秩序的工具。 原文：根据人类三千年来操持权力的普遍经验，防止权力恶性膨胀的办法就只有用权力防御权力，用权力制止权力，用权力制约权力，“野心必须用野心来对抗”。对大人物、机构、小人物来说，这方面的情况都一样。 原文：第一，权力是对人的意志的扭曲，在顺从心意的情况下也很可能是扭曲。 第二，通常来说，权力的实现方式有暴力威胁、金钱收买和谎言欺骗。 第三，暴力、金钱、谎言是权力资源，而不是权力本身，它们必须通过权力炼金术实现威胁、收买、欺骗，才是权力。 第四，权力本身是空洞的，具有天生的膨胀性、私性和如魔的上手性。 原文：“权力导致腐败，绝对权力导致绝对腐败。” 第二章 权威 你为什么会“心甘情愿”地服从？原文：权威有三种基本类型：传统型、法理型和克里斯玛型。 第三章 利益 你为什么必须机关算尽？原文：经济的任务是汇集资源、制造产品、提供服务，政治的任务是汇集权力、理顺关系、实现支配。 原文：经济和政治不同，利润和利益不同，经济和利润是生活问题，而政治和利益是生死问题。 第五章 民主 你怎么当家做主？原文：“保护公民财产是正义，法不溯及既往是正义，有律师为嫌疑人辩护是正义。” 原文：民主的核心机制是开会，把会开好必须解决三个基本问题：谁有资格，什么规矩，怎么决定。 第八章 政党 你一定要不停地斗下去吗？原文：国际体系的三个特征一并导致了国家间的相互提防：（1）缺乏一个凌驾于国家之上并能保护彼此不受侵犯的中央权威；（2）国家总是具有用来进攻的军事能力；（3）国家永远无法得知其他国家的意图。有了这一担心——而且这一担心不可能完全被一劳永逸地消除——国家认为实力愈是强于对手，自己生存的几率就愈高。","link":"/2025/12/31/%E5%AD%A6%E4%B9%A0/"},{"title":"对Http响应码“302”的误判","text":"一. 问题描述今日EDI平台的运行时环境下午4点左右开始出现服务注册失败的情景, 是由于一个Rest请求异常导致的(Rest返回码为302). 二. 尝试路径 此前3天内, EDI平台的管理端环境, 运行时环境都没有上线操作. 排除引入了变化的代码. 根据以往的经验, 302错误, 一般是Rest请求时认证未通过引起的登陆重定向. 但本次请求的Url无需认证, 排除该错误. 查看Rest服务器(即管理端服务器)日志, 发现是该rest接口执行异常, 且并为捕获, 导致302重定向到错误页面.具体错误是4点左右删除数据库相关数据不完全, 导致的NPE. 三. 反思 检查变化时, 注意变化不只包含代码, 也包含数据库等依赖的外部状态. 被以往经验束缚, 武断认为302就是sso登陆问题, 导致走了弯路 删除数据应通过接口, 避免手动操作, 导致数据库状态不一致引起程序异常","link":"/2019/07/08/%E5%AF%B9Http%E5%93%8D%E5%BA%94%E7%A0%81%E2%80%9C302%E2%80%9D%E7%9A%84%E8%AF%AF%E5%88%A4/"},{"title":"字节码解释器和JIT","text":"市面上对字节码解释器的资料较少，不过我们只要把握其以下三个作用即可： 一、衔接JVM栈结构和CPU寄存器结构 解释器把Java字节码解释为汇编或机器码使其能在CPU集群器结构上运行。 二、插桩1）在代码合适位置增加安全点——GC STW 2）在代码合适位置增加内存栅栏——可见性和有序性 3）在代码合适位置增加读写屏障——GC 三色标记，维护卡表状态 4）其他一些辅助代码； 三、JMM规则下优化代码四、JITjust-in-time即时编译器，负责把热点代码编译为机器码，来优化执行速度。 图片来源 # 参考 https://www.cnblogs.com/msymm/p/9395234.html","link":"/2020/08/13/%E5%AD%97%E8%8A%82%E7%A0%81%E8%A7%A3%E9%87%8A%E5%99%A8%E5%92%8CJIT/"},{"title":"小心JS中数字精度损失","text":"一、背景昨日，有开发反应在edi的日志里发现一个异常现象：“JSON字符串反序列化后，数字值不对了”。类似如下： 1234567891011121314151617反序化前：[{&quot;itemNo&quot;: 1209740960010041001},{&quot;itemNo&quot;: 1209740960010041002},{&quot;itemNo&quot;: 1209740960010041003},{&quot;itemNo&quot;: 1209740960010041004},{&quot;itemNo&quot;: 1209740960010041005},{&quot;itemNo&quot;: 1209740960010041006},{&quot;itemNo&quot;: 1209740960010041007}]反序列化后：[{&quot;itemNo&quot;: 1209740960010041000},{&quot;itemNo&quot;: 1209740960010041000},{&quot;itemNo&quot;: 1209740960010041000},{&quot;itemNo&quot;: 1209740960010041000},{&quot;itemNo&quot;: 1209740960010041000},{&quot;itemNo&quot;: 1209740960010041000},{&quot;itemNo&quot;: 1209740960010041000}] 二、解决路径 通过日志的DevTool中查看请求数据的Response，发现是正常的；这个也通过直接查询es中的数据得到了认证。 由此判断后台的数据是正常的，大概率是由于前端JS格式化显示json时，在JS中损失了精度。 通过测试和查询资料确认JS中数字是通过IEEE-754 double-precision floating point存储的，类似Java中的double类型的存储方式，过大的数字会损失精度。 三、 参考资料 https://stackoverflow.com/questions/1379934/large-numbers-erroneously-rounded-in-javascript https://mailarchive.ietf.org/arch/msg/json/N0GtwREVuq1ZREGEMZNswRurfXI/","link":"/2020/03/06/%E5%B0%8F%E5%BF%83JS%E4%B8%AD%E6%95%B0%E5%AD%97%E7%B2%BE%E5%BA%A6%E6%8D%9F%E5%A4%B1/"},{"title":"小数决策和审查数据","text":"日期 修订内容 2024/11/19 初稿 2025/01/16 更新“审查数据”章节 2025/02/11 更新“数据分析”章节 一、小数决策进入移动互联网时代后，信息爆炸和知识膨胀，导致人们获取讯息和数据的途径变多、成本变低，更多种类、更多数量的数据被认为是一种数据资产。很多大公司都希望能从数据资产中发现某些规律，去发掘更多的企业增长信息。例如，大数据课程必提及的啤酒和纸尿裤的故事。很多企业高管反应企业的困境并不是缺少可靠的数据，而是难以从数据中发现问题，以及将分析转化为洞察和行动。 成功的决策者绝非拥有卓越的分析能力，却能在数据、经验和直觉之间取得平衡，迅速整理信息、做出判断、深入审视数据、形成敏锐的洞察力。他们知道决策不仅仅需要数据，因此不会沉迷于数据分析。他们运用一阶原理来理解一个决策是什么，为什么必须做出这个决策，以及这个决策想达到什么目的。然后他们寻找相关数据来帮助自己做出这个决策。简而言之，他们能利用不完整的信息做出明智的决策。 小数决策的核心方法有两个：逆向工作法和IWIK。 1.1 逆向工作法 逆向工作法的核心思想是决策驱动流程，而非数据驱动流程。 在工作中经常会见到有些人、有些部门强调要“通过数据驱动某某某”。初衷是期望通过客观的数据来帮助决策，但有时却并不能很好的平衡直觉、经验和数据。 他们有时会过分相信经验和直觉，主观性的带着结论去分析、解释客观的数据，这导致很难去发现正确的结论。这种把数据当做证实“预设结论”的工具，得出错误结论的过程也被称为证实性偏差；他们有时会过分相信数据，沉迷于数据分析中。例如，通过不严谨的数据采样和数据分析方法得出不符合直觉的结论。他们期望的流程是：搜集数据→分析数据→产出分析结论→驱动决策流程。这可能会导致： 1）追求更多的数据：由于收集数据前没有明确问题边界，所以对需要的数据也很模糊。为了避免遗漏大概率会追求更多的数据，不可避免的收集到与决策无关的噪声数据，导致浪费成本且带来分析的噪声。2）追求更精细的数据：在不同的项目阶段，对数据的精细度要求是不同的，少量的数据加上猜估法在某些时候也可以帮助决策。3）分析数据时由于没有目标，可能会陷入各种相干性的分析过程中，导致进行太多无关的分析和决策。 这种期望从数据为起始点去发现未知的问题的流程，不高效也不科学。作者推荐使用逆向工作法来平衡决策过程中的直觉、经验和数据。这个概念来自逆向市场研究方法，从待定的决策入手逆向回推，以便收集和分析市场研究数据。它强调先基于要解决的问题和要达到的目标构建一个决策树，其中某些节点需要去搜集数据，并通过数据的分析结果导向不同的分支。 逆向工作法强调先有决策思路，然后按需的去搜集相干的数据，避免漫无目的的搜集数据、分析数据带来的成本。针对结论先行可能会导致的证实性偏差，则通过完备决策树，丰满概率枝来解决，这会让自我意识到结论的多样性，避免先入为主。决策树见下图： 费米问题/猜估法 一个经典的费米问题“在芝加哥有多少钢琴调琴师”正是由费米本人提出的。它的估计流程如下： 大约有9,000,000 人生活在芝加哥。 在芝加哥平均每个家庭有2个人。 大约在20个家庭中有1个家庭需要定期钢琴调音。 定期调琴的钢琴每年需要调整一次。 每个调琴师大约需要2小时调琴，包括路上时间。 每个调琴师每天工作8小时，一周5天，一年50周。 每年在芝加哥需要调整的钢琴数量是： (9,000,000 人在芝加哥) / (2 人/家) × (1 架钢琴/20 家) × (1 架钢琴调整/1年) = 225,000 架钢琴在芝加哥每年被调整。 每个调琴师每年可以调整的钢琴数量是： (50 周/年)×(5 天/周)×(8 小时/天)/(1 架钢琴/2小时) = 1000 架钢琴每年/1名调琴师。 芝加哥调琴师数量： (225,000 架钢琴在芝加哥每年被调整) / ( 1000 架钢琴每年/1名调琴师) = 225名调琴师在芝加哥。 而实际上，一共有大约290名调琴师在芝加哥，与估计的225名调琴师相差不大。 如上所述，对于一个典型的费米问题，它的估计流程包括一系列估算，并将估算的结果相乘。之所以能得到如上准确的答案，并不是因为每一步都能准确的估计，而是因为高估的数值与低估的数值在相乘时，影响会被彼此抵销。 1.2 IWIK IWIK is short for ‘I Wish I Knew’. IWIK是指在分析问题和收集数据之前，提前问自己：“如果要解决这个问题，我需要知道哪些信息？”。这有点像之前提到过的“事前验尸法”。在数据收集前，通过该提问来界定问题的范围，圈定要获取的信息范围。 二、审查数据2.1 数据可视化与直觉利用数据可视化工具，把数据进行图表化，可以更好地利用直觉去发现规律，如识别异常点、变化趋势等信息。 Julia Julia中文社区：Julia是一个高性能语言，广泛用于科学计算，有各种数学库、数据处理工具和用于通用计算的包。 Gadfly.jl：使用Julia写的图形库。 plutojl：Julia编程环境-IDE。 2.2 评估数据有效性当收集到数据后，在分析数据之前要评估数据的有效性和合理性。以下是几个价值的提问，这些提问涉及到信息有时候不会进行显示声明，可能被有意或无意的被隐藏，所以可能需要一定的成本才能获取准确的答案。 提问1：数据可信度 | 数据的来源是什么？数据来源决定了数据的可信度、完整度和有效性。例如，有利益冲突的数据提供方所提供的数据，就可能存在欺瞒、粉饰的可能，可信度就较低。 提问2：数据采样方式 | 数据是何时何地收集的？我们可以通过数据的采集方式来评估数据的有效性。如数据的样本大小、采集时间、采集成本、采集对象。 国家统计局根据全国城乡居民家庭消费支出的抽样调查资料统一确定商品和服务项目的类别，设置包括：食品烟酒、衣着、居住、生活用品及服务、交通通信、教育文化娱乐、医疗保健、其他用品及服务八大类268个基本分类，基本涵盖了城乡居民的全部消费内容。全国抽选约500个市县，确定采集价格的调查网点，包括食杂店、百货店、超市、便利店、专业市场、专卖店、购物中心、农贸市场、服务消费单位等共6.3万个。其次，按照“定人、定点、定时”的方式，统计部门派调查员到调查网点现场采集价格。目前，分布在全国31个省（区、市）500个调查市县的价格调查员共4000人左右。价格采集频率因商品而异，对于CPI中的粮食、猪牛羊肉、蔬菜等与居民生活密切相关、价格变动相对比较频繁的食品，每5天调查一次价格；对于服装鞋帽、耐用消费、交通通信工具等大部分工业产品，每月调查2-3次价格；对水、电等政府定价项目，每月调查核实一次价格。最后，根据审核后的原始价格资料，计算单个商品或服务项目以及268个基本分类的价格指数。然后根据各类别相应的权数，再计算类别价格指数以及CPI。 提问3：数据完整性 | 缺少了什么？还有其他的相关数据吗？我没有看到的数据和我看到的数据相似吗？ 一叶不一定知秋。 数据的样本大小和分布决定了数据的质量，错误的采样可能导致“伯克森悖论”，也就是幸存者偏差。下图来自《隐藏的潜能》有异曲同工之妙，局部的数据是减小的，全局的数据是增长的，如果只采样到局部的数据，而忽略了全局的数据就会导致得出错误的结论。 二战期间，为了加强对战机的防护，英美军方调查了作战后幸存飞机上弹痕的分布，决定哪里弹痕多就加强哪里。然而统计学家沃德力排众议，指出更应该注意弹痕少的部位，因为这些部位受到重创的战机，很难有机会返航，而这部分数据被忽略了。 沃德（Abraham Wald）是哥伦比亚大学统计学教授，是统计决策理论和序贯分析的创始人之一。沃德针对联军的轰炸机遭受攻击后的数据，进行研究后发现：机翼是最容易被击中的位置，机尾则是最少被击中的位置。沃德的结论是“我们应该强化机尾的防护”，而军方指挥官认为“应该加强机翼的防护，因为这是最容易被击中的位置”。沃德坚持认为：（1）统计的样本，只涵盖平安返回的轰炸机；（2）被多次击中机翼的轰炸机，似乎还是能够安全返航；（3）而在机尾的位置，很少发现弹孔的原因并非真的不会中弹，而是一旦中弹，其安全返航的概率就微乎其微。 军方采用了沃德的建议，并且后来证实该决策是正确的，看不见的弹痕却最致命。它说明了统计分析中的“幸存者偏差”（survival bias）问题，那就是我们只看到了那些能够飞回来的飞机，而看不到那些被击落而没能飞回来的飞机。所以，只是根据“幸存者”的数据做出的判断很有可能是不正确的。 一个餐馆经常收到菜过咸的反馈，当厨师调整过后发现饭店的人数更少了。其原因是：反馈的是少数人，大部分人觉得口味刚好并不会反馈。餐馆没有意识到这些无回应者，最终做了错误决策。建议：在拿到数据后，先检查是否包含了无回应者。 在工作中我们经常会因为聚焦问题而容易忽略这一点。2024年的废弃静态代码治理项目中，为了提高废弃代码下线的比例，对工单未覆盖的服务、失败工单和取消工单进行了数据采集和分析。有个取消工单的原因是“自动合入工单可能会给核心服务带来风险，故取消工单”。这时如果没有意识到自己看到的只是取消工单的数据，就很可能会支持“自动合入工单类型转为手动合入”。在决策前自问下：“有没有缺少了什么？有哪些数据我没看到”，就会发现成功工单的数量远大于取消工单数量，并且把自动工单切换为手动合入后必然会导致合入率下降（自动工单合入率为80%，手动工单的只有50%）。 提问4：数据分布 | 数据线性均匀分布，还是幂律、正态分布观测采样数据的分布是否符合整体数据的分布规律，有两个考量：1）评估采样数据是否合理；如错误采样导致的伯克森悖论。2）评估指标定义是否合理；如果数据呈现幂律分布那么就要警惕使用均值计算。 提问5：计算口径 | 数据/指标是如何计算的？了解数据计算口径，评估公式合理性、计算复杂度、理解复杂度。数据是否有约束条件或前置条件，这些条件是否合理、是否显式。 例如，架构度量指标“重复MR占比”的计算口径为：MR涉及的变更函数中如果存在重复函数，就定义为重复MR。统计一段时间范围内的重复MR的数量占比作为“重复MR占比”。指标计算比较清晰，且很容易公式化，但是其隐含了一些条件，如：a.重复函数的判定范围（是判断MR修改的函数在仓库范围内有重复，还是判断MR修改的函数中是否有重复的）；b.重复函数的检查规则（文本相似度、AST相似等）；c.相似度阈值（忽略行数较少重复的阈值，认定为重复的阈值等）；d.计算频次(每个MR Commit计算一次，还是时间窗口的结束点计算一次)等。这些隐含条件会包含在计算程序中，但不一定会包含在指标的定义说明中，在理解计算口径时务必对描述中的每个名词有准确的理解。 提问6：异常值 | 数据和指标是否存在异常值？数据/指标的异常值是发现数据采集、计算偏差的一个很好的方式。这些异常值可能体现为空值、零值、非预期的负值（如年龄）、非预期的数据范围（如年龄超过200）。观测时可以重点关注最小值、最大值、平均值、中位数、维度下钻、数据分布等。 提问7：对比 | 与相关性和可比性的替代物进行比较相关性和可比性的替代物有：竞争对手的数据、不同时间的数据/历史数据、不同采样大小/范围的数据等。通过横向或纵向的比较，可以观测出数据是否准确，甚至可以对未来进行预测。 2.3 数据压测如果数据对应一个表格或者程序，可以进行设置和调试。尝试设置一些边界值（如0，1，无穷大），来验证数据的合理性。 三、数据分析 《小数决策》并未讨论以下内容，此处为了论述的系统性特而增加此节补充。 3.1 警惕伯克森悖论伯克森悖论：两个通常独立的事物会在特定场合下关联起来，由此产生的相关性容易带来认知上的偏差。 百度百科 伯克森悖论是美国医生和统计学家约瑟夫·伯克森在1946 年提出的一个问题。他研究了一个医院中患有糖尿病的病人和患有胆囊炎的病人，结果发现患有糖尿病的人群中，同时患胆囊炎人数较少；而没有糖尿病的人群中，患胆囊炎的人数比例较高。这似乎说明患有糖尿病可以保护病人不受到胆囊炎的折磨，但是从医学上讲无法证明糖尿病能对胆囊炎起到任何保护作用。他将这个研究写成了论文《用四格表分析医院数据的局限性》 ，并发表在杂志《生物学公报》上，这个问题就称为伯克森悖论。 引自：Berkson‘s Paradox|BrilliantMath&amp;ScienceWiki 大学根据许多属性挑选学生。在美国，两个常考虑的属性是高中GPA和SAT分数。这两者呈正相关，因此人们会期望在同一所学校内它们也会呈正相关。然而，并非一定如此。招生委员会接受那些有足够高GPA、足够高SAT分数或两者结合的学生。然而，那些既有高GPA又有高SAT分数的申请者可能会进入更高级别的学校，即使被录取也可能不会选择去那里。实际上参加学校的学生范围由引言中的蓝点表示。这些点显示了一个向下的趋势，尽管整体人口（红点和蓝点）显示了一个向上的趋势。这种趋势逆转就是“悖论”，尽管实际上并没有什么真正悖论的地方。这是在审查的人群中GPA和SAT分数之间的权衡结果。在示例图中，两条线是明确的分界线：低于下线的人没有被录取，高于上线的人决定不参加。然而，如果它们是概率性的，那些整体GPA + SAT分数更高的人更有可能参加，那么效果就不会那么激烈。这两条线也相对靠近。如果它们足够远，以至于只有那些分数非常低的学生被拒绝，只有那些分数非常高的学生被录取，那么在学校的学生之间仍然会存在正相关性；只是这种相关性不会像所有学生那样大。 3.2 警惕辛普森悖论 引自：知乎 - 统计因果推理入门 总体表现来看，服用药物的患者，痊愈率低于未服药的患者，但是按照男性女性划分数据后，又得出了相反的结论。这个统计结果似乎告诉我们，知道患者性别可以开出药物，否则就不能，这显然是荒谬的。那么药物是否有效，我们是应该采信总体的统计结果还是每个性别单独的统计结果呢？要了解背后的原因，我们唯有借助于因果这一工具。 例如，假设我们知道：雌激素对于患者痊愈有负面效应，那么不论服药与否，女性患者都比男性患者更难痊愈。另外，从样本数据来看，女性患者更倾向于被选中服用药物，所以随机选择一名服药者，这个人更可能是女性，与不服药比，服药者更偏向于未痊愈。因此为了评估有效性，我们应该比较同一性别的受试者，以控制雌激素的影响。 我们在这个表中，把分类标准从性别改为了血压的高低。同样的，整体看来，服用药物痊愈率更高，但是在高血压和低血压群体内部，我们却发现，不服用药物痊愈率更高，此时我们应该信任哪组统计结果呢？ 在这个案例中，假设我们知道药物会通过降低患者的血压来影响痊愈率，但是同样会产生副作用。那么在这个例子中，由于降低血压是药物影响痊愈率的结果之一，那么基于血压分类便没有意义了。（如果再治疗前便记录血压，且假定只有血压对治疗有影响，那么情况又将不同了）。 第一张表，应该基于分组数据；第二张表，应该基于汇总数据； 3.3 警惕相干性 睡醒后人会感到饥饿，不能得出睡眠会导致饥饿。 知乎：百度指数诗歌这个词为什么在每年十一月二十多号的时候出现急速增加的趋势，这几天有什么重要的日子嘛？ 3.4 数据归因 不要用数据去解释数据，数据的变化需要归因到具体的业务变化。 推荐使用拆解的方式去分析和归因，拆解法同样可用于指标制定、数据预测。","link":"/2024/11/19/%E5%B0%8F%E6%95%B0%E5%86%B3%E7%AD%96%E5%92%8C%E5%AE%A1%E6%9F%A5%E6%95%B0%E6%8D%AE/"},{"title":"尽早抽象和持续重构","text":"程序员在日常开发新的功能或重构已有功能时常会预见两种选择：1）可预见的抽象，尽早抽象，自顶向下推进重构；2）不可预见的抽象，持续迭代重构；当发现了可抽象的点时，应该尽早抽象——这是基于时间和精力成本来说最优的选择。但是囿于业务不清晰或抽象能力、看不到抽象点时，此时选择踏实的实现功能，然后持续重构也是大数路径。 一、可预见抽象时，尽早抽象在开发一个功能时或多个相似度很高的功能时，此时如果能预见性或预先识别出或抽象出他们的公共逻辑。 1. 优点：1）高度的抽象可以简化功能流程和模型；2）节省开发时间；同样逻辑写一处即可；3）节省后期修改时间；抽象合理的话代码逻辑也会比较清晰，代码更易于修改和重构； NOTE：开发加后期修改的时间可能相差数倍。 2. 难点：1）对抽象能力要求较高 二、不可预见抽象时，选择持续重构若一个功能当前无法预见或看到共同逻辑，则需要持续迭代重构；在看不到抽象的可能时，持续重构是当前最好的选择。 1. 优点：1）易于上手 2. 缺点：1）后期重构耗时较多；2）如果不足够抽象，会导致业务逻辑不足够清晰和易于理解； 三、有意识提高抽象能力这两种选择往往和抽象水平，开发经验和具体功能相关。不可一蹴而就，但需有意识提高抽象能力。","link":"/2020/07/27/%E5%B0%BD%E6%97%A9%E6%8A%BD%E8%B1%A1%E5%92%8C%E6%8C%81%E7%BB%AD%E9%87%8D%E6%9E%84/"},{"title":"工作","text":"指标陷阱 2024/09/11 复盘思维：用经验提升能力的有效方法 2025/02/101、分析问题的工具 1）清晰描述和表达问题：TECCA - 泰卡原则。即时间原则（Time）、事件原则（Event）、清晰原则（Clear）、对比原则（Contrast）、避免歧义原则（Ambiguity）。 2）5W2H：用于描述问题，可与TECCA一起使用。 3）人机料法环：用于生产质量的分析。 4）人事时地物：用于管理问题的分析。 5）5Why：即上游思维，用于分析根因。 还有一个很有意思的案例，据说美国华盛顿广场有名的杰斐逊纪念堂，因年深日久，墙面出现裂纹。为修复这些裂纹，政府已经花费了上百万美元的费用，结果却并不尽如人意。于是，为了保护好这幢建筑，有关专家进行了专门研讨。最初大家认为，损害建筑物表面的元凶是有侵蚀性的酸雨。专家们进一步研究，却发现墙体遭到侵蚀的最直接的原因是每天冲洗墙壁所用的清洁剂对建筑物的酸蚀作用。 问题一：为什么每天要冲洗墙壁呢？答案一：因为墙壁上每天都有大量的鸟粪。 问题二：为什么会有那么多鸟粪呢？答案二：因为纪念堂周围住了很多燕子。 问题三：为什么会有那么多燕子呢？答案三：因为墙上有很多燕子爱吃的蜘蛛。 问题四：为什么会有那么多蜘蛛呢？答案四：因为大厦四周有蜘蛛喜欢吃的飞虫。 问题五：为什么有那么多飞虫？答案五：因为飞虫在这里繁殖得特别快。 问题六：为什么飞虫在这里繁殖得特别快？答案六：因为这里的尘埃最适宜飞虫繁殖。 问题七：为什么这里最适宜飞虫繁殖？答案七：因为开着窗阳光充足，大量飞虫住在此处，超常繁殖。 由此发现解决问题的办法很简单，只要关上整幢建筑的窗帘即可解决政府花了几百万元都未能解决的问题。而这就是五问法的威力。 2、解决问题的工具 1）大胆假设，小心求证。（问卷、访谈、观测、专家） 2）象限法/波士顿矩阵法，对问题的优先级进行定义和筛选 3）用水平思考法想出更多的问题解决方案 3、水平思考法 通常，我们认为只有脑子灵活的人才能想出更多的主意，但实际上这可以通过后天培养，甚至我们只需要一些简单的工具就可以“思如泉涌”，想出很多的主意，而打开丰富创意大门的钥匙就是爱德华·德·波诺所创造的水平思考法了。我们先来看一个例子。某饮料企业的设计团队挖空心思思考“如何改进产品包装”，一直找不到很好的方案。后来，在一位思维训练师的指导下，大家进行了水平思考，在很短时间内找到了多个可选方案。这位思维训练师手里拿着一副像扑克牌一样的牌，叫团队中的成员随意抽出一张，这位成员抽出的是印有蜡烛的牌。随后，思维训练师让大家围绕蜡烛进行联想，大家只花了3分钟的时间，很自然地罗列了蜡烛的一系列特征：圆柱体、发光发热、多种颜色、浪漫等。接着，思维训练师引导大家把以上想到的蜡烛的特征与思考的主体“如何改进饮料的产品包装”结合起来，让蜡烛来帮助大家产生创意。很快，大家便产生了很多的创意：浪漫让大家想到开发一种情侣包装，即带有双头吸管的饮料，进而从情侣包装想到家庭包装；由圆柱体的外形想到带托的咖啡杯、红酒杯的包装；由发热想到开发带有夹层的外包装，冬季有自发热夹层给产品加热，夏季有自降温夹层给产品降温，以此来增加产品口感；由多种颜色想到随存储温度而变化颜色的包装，以及保质期渐近色柱就会变短的包装，以此来提醒商家和消费者注意产品的温度和保质期。这就是水平思考法所激发的立竿见影的效果。上述关于改进饮料包装的方法是水平思考法中一个最简单的随机输入法。随机输入法的步骤很简单。第一，随便找一个物体，这个物体可以是一辆自行车、一根蜡烛、一束玫瑰、一支笔、一个手机等；第二，找出这个随机选取的物体的一些特征；第三，将随机选取的物体的特征和需要思考的问题进行比对，问自己，这个特征对我们需要思考的问题来说有什么借鉴意义？这时候，源源不断的好主意就会涌现出来。我们再来看一个很有意思的水平思考法——概念提取，即我们从最先想到的主意开始，提取出一些概念，然后沿着这些概念进一步扩展，从而产生更多的主意。例如，针对需要解决的焦点问题——“如何鼓励员工创新”，一开始有人提出了一个想法：“用员工的名字冠名，来鼓励创新。”在这个想法的基础上，我们可以思考这个想法背后的真正目的是什么，那就是让个人有成就感。这时候我们发现，用员工的名字冠名只是让个人有成就感的方法中的一个。那么接下来，我们以“个人成就感”为固定点进行思考，又想出了多个主意：对公司创新有特殊贡献的员工，在公司特定产品上面印上其肖像，以示奖励；创立“公司名人堂”；奖励其作为“终身员工”；以其名字命名基金；奖励其为产品命名；奖励其与CEO共进晚餐等。我们还可以提取更多的概念，再以这些新的概念为固定点，想出更多的新办法。所以，总结起来，概念提取法的步骤是：（1）想出一个初始问题的解决办法；（2）当我们想出一个解决办法之后，我们要将这个办法重新定义，提取出一个核心概念；（3）以提取出来的概念作为出发点，衍生出其他更多的办法。通过两个非常容易操作的水平思考的工具，我们可以打开思路、想出多个解决问题的方案 复盘：对过去的事情做视为演练 2025/02/16 复盘得出的结论是否可靠，必须在复盘的当时作出判断，一般来说可以通过4条原则来评判： 1）复盘结论的落脚点是否在偶发性的因素上？ 2）复盘结论是只想人还是指向事？ 3）复盘结论的提出，是否有过3次以上的连续的whey或者why not的追问？ 4）是否经过交叉验证得出的结论 复盘(沈磊) 2025/02/271、5大步骤 1）梳理过程； 2）回顾目标 3）评估结果：全面对比“结果”和“目标” 在本阶段，需要评估目标和目的，完成组织的双环学习 先评估目标，在评估举措，最后评估目的。因为目标和举措更具有衡量性，而目的则稍差。直接评估目的容易空对空，言之无物，陷入空谈和逻辑假设证明。 4）分析原因：聚焦解决而非问题本身 丰田“五步问题解决法”：第一步，确定最需要优先解决的问题；第二步，澄清问题，找出问题的原因所在；第三步，执行五个“为什么”，找出根本原因；第四步，制定并测试解决方案；第五步，确认结果并进行总结。 思路模式1：聚焦问题的流程和方法，类似丰田的五步分析解决法。 虽然我们天天都在应用因果推理，日积月累，似乎早应该练就了很强的推理本领，但实际上，因果关系远非我们认为的那么简单。比如，在哲学领域，大卫·休谟认为，人们只是习惯于把前后相继的事件联系起来，但并不能严谨地证明因果关系的存在；在统计学领域，辨识相关关系与因果关系始终是需要谨慎处理的难题；在认知心理学领域，丹尼尔·卡尼曼指出人们惯用的“启发法”常常是错误的；在投资领域，查理·芒格将“重视理由的倾向”归为人类的误判心理之一；在管理领域，彼得·圣吉的应用系统动力学原理揭示了线性因果思维的局限性；而在复杂科学领域，复杂巨系统呈现出的非线性、混沌、自组织、涌现、分形等属性更是让自认为擅于因果推理的人类感到鞭长莫及。 思路模式2：聚焦解决的流程和方法，找最佳实践和做的好的。 “聚焦问题”的思路重在搞清楚究竟出了什么问题，进而探寻根本原因并设计解决方案。比如，在越南儿童营养不良的案例中，卫生状况差、农村生活贫困、清洁饮用水匮乏、居民不重视儿童营养状况等都是问题的根本原因。据此设计出的解决方案就属于“复杂度高且耗时漫长”的情况。别说执行了，只要想一想就觉得太过复杂，于是这类解决方案可以暂不考虑。没有行动，自然就不会有结果，因此就出现了一个奇怪的现象：分析鞭辟入里，对于解决问题却于事无补。“聚焦解决”的思路则另辟蹊径，重在搞清楚“怎么做有用”，寻找亮点特例，从中发现行之有效的做法，并对这些做法进行研究，看看究竟是什么因素在起作用。在越南儿童营养不良的案例中，在孩子的食物中添加小蟹、小虾和甘薯叶就是有效的做法。在通过有组织的推广后，成千上万的越南儿童从中受益。由此可见，正向思考和行动导向是“聚焦解决”思维的典型特点。 第一步，正向思考：别找问题，而是找亮点 第二步，描述亮点：不是想法是做法 第三步，推广方案：不要动作要效果 第四步，持续点亮：不要运动要机制 综合运用 在通过“评估结果”发现偏差之后，接下来的分析原因有两种应对的思维方式：看墙的“聚焦问题”和看路的“聚焦解决”。在实战中，我们建议有条件的情况下可以同时运用两种思维方式，也就是将一个团队分成两组，一组“聚焦问题”分析，一组“聚焦解决”探询。 5）总结经验：好的复盘在于生成新洞察 因此，“总结经验”重在提炼通过复盘“我们学到了什么”，而最深刻的学习来自对核心假设的重构、放弃和新增，也就是当复盘会结束时，我们最需要获得的是通过复盘获得的洞察力。那么，具体该如何总结呢？“总结经验”的主要内容之一就是画一张呈两列的表格，注明主题——意想不到的转变，并分为两个方面：原先的核心假设是什么；现在的核心假设是什么。从形式上看，这很简单，但实际上并不容易，这是我们最深刻的体会。 结构化复盘:打造能拿结果的进化型团队 2025/03/061、回顾历程的小工具 决策质量问题适合使用“推理阶梯”工具复原决策历程；偏执行过程的问题适合使用“事实看板”或“时间轴”工具。 不上班咖啡馆 2025/04/25 “在新行业里，鸡头比凤尾，离风头更近。” “到了三十多岁，年龄不是价值，专业不是壁垒，公司不是家。” 30+的六条新出路： 专业线：成为领域内专家 管理线：在组织内成为管理者 转型线：带着积累去新的行业、岗位，进体制（做公务员、考事业编） 平衡线：先以家庭为重心，度过经济压力期再找机会 自由职业线：以自己的热爱为抓手，创造自己的职业 创业线：创办一家自己的公司 “第一次工业革命的时候，因为技术进步，机器并不需要复杂的操作，工人经过简单培训就能上岗。结果在英国，童工竟然变成了就业的主力——他们听话、好管理，更不会像成年人一样聚众闹事，而且要价很低。最后，这些童工把自己父母的饭碗也抢走了。一个工人家庭往往不是靠父母，而是靠孩子养活，你能想象吗？最后，英国政府实在看不下去了，推行法律禁止了童工。” “在匈牙利有个医生叫汉斯·赛尔，一次他给小白鼠做实验，注射一种药剂，结果小白鼠纷纷死亡。他很奇怪，因为这种药剂并不会毒死小白鼠。后来他发现，杀死小白鼠的，不是药剂本身，而是注射的过程。如果太紧张，小白鼠会感受到巨大压力，因此是死于免疫力下降带来的疾病。“他第一次意识到，除了毒药，压力也会伤人，哦，是伤鼠。他继续这个研究，他让小白鼠在高压力状态下，持续地游泳，不间断地电击。几周后，他观察到，那些可怜的小家伙都患上类似的病，有一些是胃溃疡，有一些是心血管病。这些看不见的压力，竟然产生了致命的伤害。他提出一个观点：压力本身产生的伤害，和真正的疾病、毒素一样强大。” “当你在梦里的时候，捏一下自己不疼，就知道这是在梦里，因为感知绕过了思维，没法作假。当你陷入思维给你放的恐怖片，你可以数一下自己的呼吸、心跳，可以感知一下自己的右脚第二个脚趾的位置……这都是醒来的方式。你当下的感受，就是开灯的开关。” 明星员工的思维模型 2025/05/27 要素1：超越职责，关注需求要素2：挺身而出，适时后退要素3：预见问题，坚持到底要素4：寻求反馈，做出调整要素5：共同担责，轻松工作 领导者的职责： 怀斯曼认为领导者不应该单打独斗，而应该运用自己的智慧去激发周围人的最大潜能。这就像在球场上，教练的角色是在场边指挥，而非亲自下场。 超越职责： 普通员工总是将自己囿于固定职位。他们能完成公司分配给自己的工作，但同时也会变得目光短浅，以至于忽视公司的整体战略，从而偏离正轨。相反，明星员工将自己视为解决问题的人。他们不会囿于过时的组织结构，也不过分囿于自己的职位。他们不仅会完成自己的工作，而且会找到能发挥自己最大价值的工作。 明星员工不仅会完成自己的工作，同时也会关注复杂组织的罅隙和真空地带。 我们所调查的管理者表示，在98%的情况下，顶级贡献者往往会在无人提醒的情况下完成工作。相比之下，典型贡献者的比例为48%，贡献不足者的比例为12%。 当一个紧迫的问题变得棘手时，你会只顾着扮演自己的角色，把问题推给别人来处理，还是说，你会找到问题的源头？当你不再囿于固定职位而变成问题解决者时，影响力便会随之增加。 如何识别侵蚀组织生产力的背景问题： 无人认领。背景问题就像流浪狗，人人都知道它的存在，但没人知道它的主人是谁。 随口抱怨。人们喜欢发牢骚，但并不真正着手解决背景问题。 可以使用小伎俩和权宜之计规避。规避背景问题比解决它更容易。 解决方法没有正式记录。可以解决背景问题的权宜之计虽然会得到传播，但不会被记录在任何培训手册中。 具有隐性成本。在将所有权宜之计的成本累加之前，背景问题的代价看起来并不高昂。 只被部分人看见。背景问题能被受其影响最大的人感知到，但有能力解决问题的人看不见。 关注需求： 善于总结不成文规则。经过研究，我们得出一个主要结论：明星员工比普通员工更加了解职场规则。他们能总结出不成文的规则手册，即一个人在特定的工作或组织中应该遵守的行为标准。他们关注组织的需求，并能洞察身边同事所重视的事情；他们清楚自己需要完成的工作，并能找到完成工作的正确方法。 大多数管理者和组织都有一个目标，即解决其关心的一系列问题。有的时候，这些目标是有形的，以任务说明、战略方案或某一特定时期的优先事项的形式呈现。然而在动态环境中，战术目标需要随着条件的变化和新信息的出现而调整，也就是说，官方陈述的目标往往不是真正的目标。真正的目标是当下最重要的事项，它定义了成功所需的相关和必要因素。但是，真正的目标很少会被写下来。 挺身而出： 美国副总统卡玛拉·哈里斯（Kamala Harris）写道：“永远不要征求任何人的许可，只管去领导就好。” 1976年8月10日，贝蒂·威廉姆斯做出的决定改变了历史的进程，推动了该地区暴力事件的终结。她带头的意愿让她在接下来的30年里走上了倡导权益的道路。2008年6月，威廉姆斯表示：“30年的经验让我树立了一个信念，那就是没有自上而下的答案。答案不在政府那里，不仅如此，恰恰截然相反，很多时候，政府没有答案，而是问题症结所在。如果想要致力于为全世界的儿童贡献一份力量，我们就必须着手自下而上创造解决方案。”她决定努力打造出理想中的世界，而不是满足于现状。 终止当前的报告、主动请缨处理更大的问题，这是一个大胆的举动。会议室里负责把控解决方案的高层管理者本可以对梭尼的大胆举动提出质疑，但梭尼已赢得了他们的信任，成为大家乐于支持的领导者。 寻求反馈： 寻求指导，而不仅仅是反馈。由于反馈重在评价而不是改善，因此，如果你能寻求建议或指导而不仅仅是反馈，便很可能得到更多且更有分量的回应。与其让别人对你的表现给出反馈，不如寻求一些能帮助你更好地完成任务的建议或指导。你可以提出这样的问题，“我想把这件事做好，你有什么建议吗？”“你有什么建议可以帮助我下次做这件事时表现得更好吗？”“我该多做什么？”“我该少做什么？”“如果我下次只做出一个改变，你有什么建议？” 关注工作而非个人。影响人们接受反馈的最大阻碍，就是将反馈视作对我们本人的评判，而不是对我们工作的评判。 相比之下，将自我价值视为内在固有特质，是指相信自己具备稳定的价值和能力，这是明星员工具备内在价值的体现。如果一个人认为自己本身具有价值，即使明知自己会表现得很糟糕，仍然乐意尝试新鲜事物。在这种思维模式下，自我价值是独立于工作表现而存在的。我们不需要成为别人眼中有价值的人，因为我们本来就有价值。我们明白，尽管我们热爱自己的工作并能从中获得满足感，但自我价值不等于工作价值，工作并不能决定我们作为一个人的价值。 预见问题： 管理者给出的回答中，最常见的是员工没有事先尝试找出解决方案，就把问题抛给管理者。比如，有的员工“不做尝试，而是像猫一样把死耗子扔在你的大门前”。管理者的第三大烦恼是他们必须跟在员工身后督促他们完成任务，这使管理者沦为“唠叨专业户”或微观管理者。除此之外，令人猝不及防的意外也令管理者颇为烦恼，比如员工在没有补救余地的最后关头才向管理者汇报某个坏消息。这就像举办了一场让管理者颜面扫地的聚会，客人刚来赴约，而你的猫咪却在大门前扔了一只死耗子。 这听来可能很奇怪，但我真的早就思考过这些问题。因为我对待急救工作的态度向来如此：提早准备，提出尖锐的问题，找出解决方案，在心中预演计划。如果已经制定了解决方案，你就不必等到挑战来临时再跨越心理障碍了。 坚持到底： 我从辅导领导者的经验中发现，大多数变革之所以失败，通常是由于领导者野心过大，而不是缺乏野心。我们总是试图一口气尝试太多新的做法。加里·凯勒（Gary Keller）在他的著作《最重要的事，只有一件》（The One Thing）中写道：“想要成功，无须做到想象中那么自律，原因很简单：成功是做对的事，而不是把每件事都做对。” 项目一旦开始就一定要坚持完成，这种做法可能导致精力的错误分配和资源的浪费。我的一位朋友曾经半开玩笑地说，当他意识到自己把所有时间都花在了别人未来的妻子身上时，他终于下定决心分手。同样，面对低效的项目，如果我们非要等到项目快完成才决定是否放弃，就会剥夺组织本应投入在更高价值机会中的时间和资源。另外，我们还有可能把自己搞得精疲力竭。与其不惜一切代价地完成工作，不如放弃一些项目，及时止损。想要避免皮洛士式的胜利，我们应深思熟虑，并以全面的视角制定决策，不要考虑之前的行动造成的沉没成本，而要专注于一味坚持所带来的损失和机会成本。 然而，即使是言之有物的报警者也会带来不良影响。这些人会提醒上级注意潜在危险，但次数太过频繁。如果有人拉响警报却没有提供相应的解决方案，管理者会立即采取措施，在原本无须亲自参与的领域进行微观管理。 其他： 有些人认为，站在大舞台的亮光下，会让人变得伟大起来。然而亮光所揭示的，只是你在黑暗中所做的工作。——杰夫·巴耶纳鲁（Jeff Bajenaru） 为之命名：将一种行为与特定的词语或生动的意象联系起来，便于回忆和探讨。 用数据说服：如何设计、呈现和捍卫你的数据 2025/07/11第一部分 理解感知：数据图为何有用，如何发挥作用 数据沟通主要有三大挑战，如表1.1所示。 速查表：如何向他人解释数据 第三部分 数据组织：如何将数据组织为有说服力的沟通内容 用明托金字塔建立沟通结构：明托金字塔是一种着眼于最终沟通形式的思维组织工具，如图6.1所示，得名于推广者芭芭拉·明托（Barbara Minto）。明托金字塔的内核是：受众需要知道哪些信息？受众需要哪些证据才能认可你的观点？ 开始分析前就要建好金字塔：明托金字塔是大纲。刚开始研究就列好学期论文大纲，这样做有利于整理思路和研究聚焦。同理，用分叉树来建立思考框架在分析初期也是有价值的。你可以用金字塔结构来拆解问题，建立分析框架。如果你要在开始分析前就建立金字塔，你可以将金字塔理解为一组要通过数据和分析来肯定或否定的假设。科学假设会提出关于结果的假设，目的是说明哪些实验可能会否定这些假设。同理，你提出的关于“数据可能会表明什么观点”的假设，也有助于你找到能高效肯定或否定假设的分析。头脑清楚了，你就能够聚焦地运用时间和精力。接下来，你会根据实际发现来修改金字塔，正如优秀科学家会根据实验结果来调整看法。建设性分析过程的出发点与切实的明托金字塔是一样的：要明白你的分析回答了什么问题，你的受众为什么要关心这个问题。这个问题的答案就是金字塔结构的驱动力，而通往问题的道路是由一段故事铺就的。故事的主题是，为什么要进行这段分析？ 高效沟通者会将认知负荷从受众转移到自己身上。他们会解释论点的含义和相互关系。他们不会专挑有利于自身论点的证据，也会讨论看似不利的数据。具体来说，他们会：·避免提出缺乏思想的（intellectually blank）论点；·直面不利证据。 明托金字塔框架各组块内部的各点要满足以下条件：·在语法和概念两个层面对齐；·排序有意义；·相互独立，完全穷尽；·有必要且充分的证据支持。 用扎实的推理支持论点：在某个层面上，所有数据沟通都是说服性沟通，都是为了让受众相信给出的数据是成立的，分析是严格的，发现是值得信服的。这种沟通的根基是扎实的逻辑推理，有力、必要且充分的证据支持，以及一双能发现自欺欺人危害的慧眼。 无论证据多么有力，你都不能逼迫受众接受一个结论，哪怕他们相信你给出的全部证据。应当记住的一点是，只有时间才能证明任何关于未来事件的结论是对是错。对于没有人能说得准的话题，不要把话说死；如果有人这样做，那你应该警惕。 完备结构是高效沟通的基础。明托金字塔速查表见表6.8。 理解受众的评判方式 后果与自身关联越密切，受众就越会深入关注你讲的内容和证据支持。话题的关联越不清晰，受众就越会关注自身与沟通者的关系，以及信息的传递形式。你可以将这两种不同的反应想象成一根数轴的两个端点。一端是说服理论里讲的中枢处理（central processing）。当受众运用中枢处理时，他们会更关注信息本身、论证质量和数据支持，在决策中也更容易容忍高认知负荷。因此，他们在决策中可能会更注重信息的内容。另一端是周围处理（peripheral processing）。当人们运用周围处理时，他们会更依赖这些因素：消息是如何传递的，沟通者是谁，信息是否符合人类用于快捷决策的各种心理捷径。同一个人会用不同路径来处理不同的决策，乃至不同时间的同一决策。影响路径的因素有很多，但牵涉干系越大，后果越切身相关，人就越可能采取中枢处理路径，如表7.1所示。 第四部分 数据呈现与论证：如何预先准备以回应受众 如果演示者剥夺了受众的发现机会，直接告知结果，那可能就会触发受众的一种本能，即反驳任何不是亲自得出的观点或结论。抛出惊人发现的另一个危险是，你可能在受众没有完全想清楚之前就往下讲了。很少有受众会大胆举手说：“抱歉。我知道这是一张简单的折线图，我在公司也工作五年了，但我还是不完全明白预订的概念。”相反，他们会质疑你的其他结论。 沟通者相信，提问少代表讲得好，数据多能减少受众的反对意见。于是，他们堆砌图表，添加不必要的细节，目的是让自己免遭挑战。他们误以为，没有人反对就意味着大家赞同他们的结论。不要陷入这种误区，反对意味着重视。能确认受众认真听的方法不多，这就是其中一种。 受众混淆矩阵要回答两个问题： 这批受众是否预期某种现象会发生比率变化？ 这批受众是否观测到某种现象会发生比率变化？ 智能组织：数据与AI重塑的组织管理 2025/09/11数据驱动可以发现反直觉的原因 从第一性原理来看，业务端之所以能更好地应用数据驱动决策，是因为它的数据更符合科学方法的基本要求：可观察性、可重复性和可验证性。 效率关注的是“把事做对”，即以最小的投入获得最大的产出。而效能则强调“做对的事”，即确保我们的行动能够产生真正有价值的结果。 在捐献同意率低的国家（丹麦、荷兰、英国、德国），人们需要主动选择成为器官捐献者（选择加入系统）。而在捐献同意率高的国家（奥地利、法国、匈牙利、波兰），人们则被默认同意成为器官捐献者，除非他们主动选择退出（选择退出系统）。就是这么简单的不同的默认选项设置，造就了如此巨大的差异。泰勒和桑斯坦将这种通过改变选择架构来影响人们决策的方法称为“助推”（nudge）。他们认为，由于人们往往倾向于选择最容易的选项，或者保持现状，所以通过设置合理的默认选项，可以在不限制人们自由选择的前提下，引导他们做出更有利于自身或社会的决定。这种倾向被行为经济学家称为“默认效应”或“现状偏见”。 这两个试验揭示了人类行为中一些深层次的规律。首先，激励与表现之间并非简单的线性关系。小额奖励可能比无奖励的效果更差，这完全违背了我们的直觉认知。其次，这些试验暗示了一种阈值效应：只有当奖励达到一定规模时，才能产生积极影响。试验中的发现对设计有效的激励机制具有重要意义。 理查德·蒂特马斯在1970年的研究中发现，向献血者提供金钱报酬实际上降低了献血率。这一发现与格尼茨和拉切奇尼的研究结果惊人相似。在献血这样的利他行为中，金钱奖励可能会降低人们的内在动机，使献血从一种道德行为转变为一种经济交易。 人类在决策过程中不可避免地会受到认知偏差的影响。即使是最优秀的领导者也会犯错，而且往往是因为过度依赖过去的成功经验。这种现象在心理学中被称为“成功陷阱”或“经验陷阱”。这种现象最早可追溯到丹尼·米勒于1990年提出的“伊卡洛斯悖论”（Icarus Paradox）。米勒通过对多家企业进行深入研究后发现，就像希腊神话中飞得太高而坠落的伊卡洛斯，成功的公司往往会因为过度依赖过去的成功经验而陷入困境，在面对新的挑战时反应迟缓或决策错误。 “工作倒推”（working backwards）流程要求在开始任何新项目之前，先写一份新闻稿，这种方法能确保团队始终关注客户需求，而不是陷入内部偏好。 答案或许就藏在管理决策的本质之中。每一个管理决策，本质上都是对未来的一种假设 当假设思维成为组织文化的一部分，每个决策者都会自然而然地问：“我们的假设是什么？如何验证这些假设？验证结果告诉我们什么？”这样的组织才能在不确定性中保持清醒，在变化中持续成长。 员工招聘 从数据驱动的第一性原理来看，招聘本质上是一个预测候选人未来表现的过程。理想情况下，我们希望候选人在招聘过程中的表现（招聘成绩）与他们未来的工作绩效之间存在强相关性。 在人才招聘方面，谷歌利用数据分析优化了整个招聘流程。相关工作人员分析了大量的面试数据，发现传统的脑筋急转弯问题与员工的实际工作表现几乎没有相关性，因此，他们取消了这类问题。相反，他们根据数据分析结果，设计了更能预测候选人未来表现的结构化面试问题。 尽管这种做法能大幅提升招聘的效度，但随着谷歌的业务扩展，资源和时间成本的增加使得这样的面试流程难以维持。因此，谷歌依靠内部数据分析，对面试轮次和效度进行了优化。如图4-3所示，通过分析大量的历史招聘数据，谷歌发现：在第4轮面试时，面试效度已经达到86%，即此轮面试所能达到的准确率已经非常接近最佳水平。如果继续增加面试轮次，效度的提升幅度变得极小——每增加一轮面试，效度提升仅1%。虽然这种增益仍然对准确率有帮助，但相对面试消耗的资源和时间成本而言，增加面试轮次变得不再值得。 员工评估 当一个评估体系中同时夹杂了与目标无关的因素（污染），又遗漏了关键行为（缺失），最终能够真正测量到的“有效”部分就会大大缩水 通过深入的数据挖掘和验证，谷歌最终总结出了优秀管理者的八项关键行为，这些行为清晰地展现了管理者如何通过行动推动团队表现。·做一个好的教练 提供个性化反馈，支持员工技能提升和职业发展。·赋能团队，避免微观管理 给予团队信任和自主权，同时提供适时的指导。·关注团队成员的成功和福祉 理解并关心员工的需求与挑战。·高效且注重结果 帮助团队保持专注，确保任务按时高质量完成。·善于沟通 倾听并分享信息，创建开放的交流环境。·提供职业发展支持 与员工讨论职业目标，提供成长机会。·制定清晰的愿景和战略 为团队设定明确的方向，并将目标分解为可执行的计划。·具备技术能力 能够在专业领域为团队提供支持和指导。 员工与组织 要了解组织网络这张“看不见的网”，可以从图论（graph theory）与社会网络分析入手。在图论中，“节点”代表个体或实体，“边”则表示节点之间的联结。套用在企业场景里，“节点”可以是一名员工、一支团队，甚至一个外部合作伙伴，而“边”则代表信息流动、资源互换等联系。在传统的组织结构图中，人们只看到谁是上级、谁是下级，但在真实的协作环境里，存在大量“看不见”的互动。 度中心度和中介中心度这两个指标分别刻画了“联结数量”与“桥梁价值”两个不同维度的网络影响力。一个人如果度中心度高，往往在团队中坐拥较多的社交资源；若一个人中介中心度高，则通常意味着他拥有跨部门、跨团队的信息“通关权”。在组织管理中，这两类人都十分重要：前者能加速信息扩散，后者能衔接关键路径。若能识别出这类人并充分激励他们，组织的协作效率和创新潜力便可大幅提升；但若忽视了他们，则组织运行可能会在关键时刻“卡壳”。 亚马逊采用“六页纸备忘录”的无声会议模式，参会者在会议开始时要先默读详细的书面材料。这种做法与团队网络研究的发现高度吻合。通过设置强制的阅读时间，每个参与者都能充分接收和处理信息，这避免了传统会议中信息传递不均衡的现象。这种方式促使每个人在会议中做好准备，发言更具针对性，从而提升了整体会议效率和决策质量。","link":"/2025/10/10/%E5%B7%A5%E4%BD%9C/"},{"title":"工作和学习","text":"“如何学习”其实是一个个性化的问题，会因每个人的智商高低，注意力持久力，启蒙期的受教育方式，周围的同辈环境，家庭的教育，从事的职业，兴趣强度等因素而不同。本篇文章是我个人的总结，仅供大家参考。文章主要从两个方面来谈：1）学习习惯；2）学习与工作的关系； 一、 学习习惯1. 学习意愿1）强烈的学习意愿，会提高学习的效率，注意力和毅力 2）每达成一个目标都会有成就感，这个成就感会推着你向前，形成正反馈 2. 学习源 原则：第一手/权威的知识，成体系的知识，这部分知识少而精。网络上充斥着99%的二手知识，大都是知识的搬运工，还没搬全，或窥其一斑不见全貌，不成体系。 1）官方文档/书籍，拒绝不成体系的零散文章 优点是知识成体系，容易构建知识树 2）权威的论文和行业最佳实践方案 读一篇好的论文或行业标准方案，胜过无数二流知识搬运工的隔靴搔痒之作。无论是从时间还是知识细耕度来说都是非常合适的选择。 3）官方社区 优点是知识发布快，权威 4）以图索文 图像包含的信息永远比文字要立体和更有脉络，可以尝试先从谷歌图片或百度图片中搜索关键词。一般会发现很多官方或博客里的图片，比较利于快速理解。 5）付费课程 付费课程减少了知识获取的难度和时间成本，但如果走马观花始终得来浅。还有一点是，能第一时间把知识的主次帮你捋清楚，让你不一开始就陷入到知识细节，而导致无法抓住重点，学习效率变低。 就算你本身一开始就抱着抓主干忽略细节的态度去学习，可以往往一个新手是无法辨别哪些是重点的。这时有个过来人无疑可以减少你很多试错的时间。 优点： 1）花钱买时间，节省了你的时间； 2）对当前面试的点抓的比较准； 3）多个角度去看同一个知识点，弥补自己看书的知识单面性； 4）网课的大纲是很有参考价值； 5）看过书籍之后再学网课，效率更高； 6）网课过后的知识点，尽量写博客来整理脉络； 7）讲师一般在该知识点理解比较深，可能会以一个更高的纬度讲解，相当于借你一双鹰眼去学习该知识点。 缺点： 1）容易产生思维惰性； 2）若没有之前的知识积淀，网课的吸收率会很低； 3）网课的质量参差不齐，要注意甄别 4）网课由于时间有限导致知识不够细节 3. 初期 知识都充满了细节，甚至还有很多奇技淫巧。初期的时候要学会妥协，放弃这些难点，先了解知识的原理和框架。先形成一个知识树的树干，之后要做的事就是给它添枝加叶，把知识细节放到树的相应位置。每放一个新的知识点，就会让整颗树的根在大脑里扎的更深。要分清哪些是需要理解的，哪些是需要练习的。初期要理解技术原理，慢慢练习命令和操作。 关键点： 1）搭建框架 2）忽略难点 3）重复练习 4）及时复习 学习由于沙漠里刨坑，需要及时复习，不然会被时间淹没。及时复习包含两点内容：a）第一次学习一个新知识往往会忽视很多细节，需要复习来填补；b）人的记忆符合艾宾浩斯遗忘曲线，这是一种生理约束，需要把短期记忆转换为长期记忆需要重复；图片来源 4. 中期 了解知识，使用知识两个阶段往往没有明确的界限。两者相辅相成，在使用中会遇到初期学习时没有注意到的细节和问题，然后再去学习填充细节，会让知识更有深度。工作中更多的使用场景，会让知识更加立体。你也会很享受这种知其然知其所以然的状态。 1）工作使用 无他，唯手熟尔 2）博客输出和分享 分享是对你知识树一次修剪过程，你要理正知识间的关系。正如费曼学习法中所说讲故事会反哺讲故事的人。 3）把书上的知识树用符合自己认知的方式组织并形成知识树，这样理解更深且不易忘记。 5. 后期1）触类旁通类似的知识体系 二、工作1、对工作要负责 2、考虑问题至少从+1的leader角度思考 3、对已知未解问题，先思考自己能否去解决 # 写在后面的零碎话 用来赚钱比停留在看一看的层次重要，只有问题才能知识打磨的更精细 精力有限，提升单位时间内获取的知识深度，不精细的知识会被大脑遗忘 技术都是由小的逻辑单元组成的，触类旁通 知识分层，基础知识，技能知识，业务知识","link":"/2020/01/09/%E5%B7%A5%E4%BD%9C%E5%92%8C%E5%AD%A6%E4%B9%A0/"},{"title":"工厂类中使用ThreadLocal的陷阱","text":"1. 背景由于EDI已有的日志结构比较混乱，多个人都写了自己的LoggerHelper工具类。近期的工作主要是写一个新的日志框架，通过SPI方式加载Appender的实现，并替换掉之前的日志内容。 2. 初始实现LoggerFactory在实现日志框架时，我写了一个LoggerFactory，代码如下： 123456789public class LoggerFactory { private static IAppender appender = AppenderFactory.getAppender(); private static final ThreadLocal&lt;ISessionLogger&gt; loggerThreadLocal = ThreadLocal.withInitial(() -&gt; new SessionLoggerImpl(appender)); public static ISessionLogger getSessionLogger() { return loggerThreadLocal.get(); } } 3. ThreadLocal的使用写完让阳哥review后，阳哥说这个存在很大隐患：“使用这个类的人，大概率会像使用Log4j一样——把*LoggerFactory.getSessionLogger()*的返回值赋给类的某个成员变量使用”。如下所示： 1234567public class Test { private final ISessionLogger logger = LoggerFactory.getSessionLogger(); public void func() { logger.log(&quot;anything&quot;); }} 4. 两种改进方案 增加中间代理类 1234567891011public class LoggerFactory { private static final IAppender appender = AppenderFactory.getAppender(); private static final ThreadLocal&lt;ISessionLogger&gt; loggerThreadLocal = ThreadLocal.withInitial(() -&gt; new SessionLoggerImpl(appender)); public static ISessionLogger getSessionLogger() { return (ISessionLogger) Proxy.newProxyInstance(EdiLoggerFactory.class.getClassLoader(), new Class[]{ISessionLogger.class}, (proxy, method, args) -&gt; method.invoke(loggerThreadLocal.get(), args)); }} 静态方法代态工厂类 123456789public class Logger { private static IAppender appender = AppenderFactory.getAppender(); private static final ThreadLocal&lt;ISessionLogger&gt; loggerThreadLocal = ThreadLocal.withInitial(() -&gt; new SessionLoggerImpl(appender)); public static void log(String info) { loggerThreadLocal.get().log(info); } } 5. 总结工厂方法中使用ThreadLocal时需要注意： 1）工厂类获取的实例一般会赋值给成员变量，来供该类的所有方法使用； 2）获取ThreadLocal实例一般赋值给方法内的局部变量，来获取当前线程ThreadLocalMap中的实例； 3）由于工厂类和ThreadLocal的常规使用场景不一致，两者混搭时，就容易出现非预期的结果。","link":"/2019/11/08/%E5%B7%A5%E5%8E%82%E7%B1%BB%E4%B8%AD%E4%BD%BF%E7%94%A8ThreadLocal%E7%9A%84%E9%99%B7%E9%98%B1/"},{"title":"工程命名与职责","text":"工程在命名时一般也遵循api和impl分离的原则（如下是实现流程的工程结构），但是不同定义的工程对api的认识其实并不是一致的。 123my-flow|__my-flow-api|__my-flow-impl 一、项目是一个自运行的平台，service as 平台如果my-flow工程是一个后台服务，他是可以独立运行的一个平台。那么api，impl建议按照如下规则进行定义：1）my-flow-api更多情况下应该定义为core的角色和职责，其可以脱离my-flow-impl而独立运行。2）my-flow-impl是core实现时根据预留的扩展规则，而根据业务场景自定义的具体实现，可以替代或扩展已有的功能； 一般多见于SPI结构的工程，impl多为某种spi实现。 二、项目常被以一种规范而依赖，调用，service as 客户端/服务端如果工程常能清晰的划分出客户侧和服务侧。其中客户侧常需要暴露API，被客户端依赖和调用（如微服务场景）；服务侧则实现具体的业务处理。为避免客户端依赖my-flow的实现逻辑，一般作如下职责定义：1）my-flow-api：定义接口，不包含具体实现，被第三方依赖；2）my-flow-impl：实现接口定义的逻辑； 微服务下，一般为客户端依赖my-flow-api工程，通过某种RPC框架（dubbo，jsf等）调用远程的微服务实现（my-flow-impl所在）；","link":"/2020/07/27/%E5%B7%A5%E7%A8%8B%E5%91%BD%E5%90%8D%E4%B8%8E%E8%81%8C%E8%B4%A3/"},{"title":"常见分布式中间件的共识协议","text":"共识协议是分布式网络中各结点对数据达成一致的方法和策略。可参考分布式网络及共识协议 一、Redis1、集群模式 1）Redis单机模式/主备模式I、优点 容易保证数据强一致性 简单易部署，适用于Demo工程 II、缺点 有单点问题，结点宕机后严重影响系统可用性，若无备份可造成过数据丢失。 单机存储容量和性能上线较低 2）Redis主从模式 - 异步复制 I、优点 可使用读写分离策略，从结点可以分摊读的压力 II、缺点 主结点仍只有一个，存储容量和性能上限较低 主结点宕机后，需要手动切换从结点为主结点 从结点需要一个一个启动，避免主结点同步压力过大 III、主从同步过程-异步同步 当副本连接到主服务器时，它们使用 PSYNC 命令来发送它们的旧主服务器复制 ID 和到目前为止它们处理的偏移量。 这样master 可以只发送所需的增量部分。但是，如果主缓冲区中没有足够的积压，或者如果副本引用不再已知的历史记录（复制 ID），则会发生完全重新同步：在这种情况下，副本将获得数据集的完整副本， 从头开始。 Master执行bgsave以生成 RDB 文件。同时它开始缓冲从客户端接收到的所有新的写命令。 后台保存完成后，master将数据库文件传输到replica，replica将其保存在磁盘上，然后加载到内存中。 主服务器会将所有缓冲的命令发送到副本。这是作为命令流完成的，并且与 Redis 协议本身的格式相同。 IV、关键配置 min-slaves-to-write min-slaves-max-lag V、主从复制风暴 多级SLAVE，避免所有SLAVE都从主节点复制。 3）Redis哨兵模式 I、优点 在主从模式的基础上增加独立的哨兵进程，监控集群状态，自动进行主从切换 II、缺点 扩容麻烦 同主从模式，主结点仍只有一个，存储容量和性能上限较低 4）Redis Cluster/Cluster主从模式 I、优点 约定16384个槽位，分摊到集群的各个机器 分摊槽位的结点是对等的，一个发生故障不会影响其他结点的读写 可动态扩容，提升集群的处理请求的能力 通过增加主从，还可以增加故障容错能力。 II、哈希槽与哈希环 Redis Cluster does not use consistent hashing, but a different form of sharding where every key is conceptually part of what we call a hash slot. Redis集群使用哈希槽而非一致性哈希。哈希槽数量为2^14 = 16384，分摊到Redis的集群各个结点。参考一致性Hash。 2、Redis Cluster的共识 - gossip1）gossip协议gossip用于集群中各个结点用来同步集群元数据信息，如当集群状态变更时通过gossip协议把信息同步到整个集群。 2）集群节点对等 - 无需选举3）slot副本选举 - 大数选举master结点最少为3个结点，且有qurom个正常时才能选举成功。 选举步骤如下： 感知异常：当副本的master节点处于FAIL状态，master上slot数不为0，副本的与master之间的复制连接断开时间不超过给定的值保证副本数据尽可能新。 发起投票：副本增加epoch，并向集群的master节点广播FAILOVER_AUTH_REQUEST发起投票请求。且最多等待NODE_TIMEOUT * 2。 响应投票：master在发送响应FAILOVER_AUTH_ACK进行投票。且在NODE_TIMEOUT * 2内只能为同一master的所有副本投一次。副本不会响应投票请求。 结果判定：副本收到大数master投票后晋升为master。如果在NODE_TIMEOUT * 2未获取足够票，则NODE_TIMEOUT * 4后再次尝试。 4）脑裂问题 问题描述：集群master选举后，相同slot区会有两个master，如果网络故障期间旧master仍接收请求则会导致数据不一致。 解决方案 以下配置的含义为主从延迟小于10秒的slave不小于3. 12min-slaves-to-write 3 # 配置为主从的半数以上min-slaves-max-lag 10 # 主从同步最大延迟10秒 5）副本数据同步 - 默认异步 Redis Cluster is not able to guarantee strong consistency. In practical terms this means that under certain conditions it is possible that Redis Cluster will lose writes that were acknowledged by the system to the client. 以上摘自官网，Redis不保证强一致性； 集群主从模式下，默认是异步同步；此时，主结点宕机，从结点成为新的主结点，可能会丢失部分数据。 集群主从模式下，使用WAIT同步；在发生分区且超时后重新选主，也有可能造成写入旧主结点的数据丢失。 3、关于分布式锁redis同样可以实现公平锁和非公平锁，具体lua脚本可参考Redisson代码或官网文档。 二、ZookeeperZK定位是分布式的协调框架，使用ZAB协议使ZK集群达到数据共识。ZK适合作一些元数据和配置存储，其吞吐率和容量都不适合分布式存储。文档 1、ZK的共识-ZAB1）ZAB之恢复 - leader选举|同步至最新ZAB协议恢复，即触发Leader选举，促使集群恢复到一主多从的广播状态。具体有三种场景： 集群初次启动 Follower重启 Leader重启 2）ZAB之广播 - 同步复制2phase写操作统一由leader处理，然后通过2-phase方式原子广播给Follower，这保证了消息完全有序和因果有序。即便是Follower接收到写请求，也会转发给Leader。从图中可看出，ZK是一种primary-backup模式，leader会把命令的结果包装为提议广播给Follower，这保证了消息的幂等性。 ZK的集群结点数一般为3-7个，增加结点会增加读吞吐，但对写吞吐无益，适用于读多写少的场景。 1）2-phase过程 I、第一阶段： leader写入本地事务日志文件 leader发出proposal广播给follower follower收到proposal，写入本地事务日志文件，返回ACK给leader。 此时leader和follower的写入不可见。 II、第二阶段： leader收到主从总和半数以上ACK，进入commit阶段 leader将事务请求同步至内存，广播Commit命令给follower，响应给客户端。 follower收到commit请求，读取事务请求到内存 2）2-phase判定哪些提交成功 I、写入成功：半数以上主从写入本地文件成功。 II、说明：客户端未收到成功响应不代表写入失败，但是客户端收到响应必然写入成功。 2、ZK数据同步策略提议广播只要收到quorum的ack（包括leader自己在内）就会广播commit。CAP角度来看，其实现了最终一致性，而非强一致性。即如果客户端发起一个写请求，且leader返回成功后，只代表ZK集群的大数结点具备了该数据，此时如果另一个客户端在未及时同步的结点上发送读请求，则无法看到最新数据。但是ZK在使用时，Client大都基于事件监听机制去获取数据，最坏结果表现为数据更新出现延迟通知。 3、关于分布式锁zookeeper实现分布式锁时，有两种类型： 非公平锁：通过创建指定名称临时结点避免客户端宕0机，创建成功的客户端获得锁，失败的客户端监听该临时结点（大量客户端被唤醒去争强锁也被称为羊群效应）。 公平锁：通过创建有序的临时结点避免客户端宕机，序号最小的临时结点的客户端获得锁，其他客户端监听前一个零时结点，有序排队等待唤醒。 其中，可重入锁的重入的次数可以作为文件内容，随加锁和解锁进行更新； 这其中有个点需要指出，由于zookeeper并不是强一致性，客户端可能无法查到集群中最新写入的数据，但最终会达到一致。这并不影响分布式锁的实现，主要有以下原因： 客户端的写入是线性有序的； 客户端在不同时间看到的临时结点数量可能不一致，但是他们的顺序是可以保证的； 基于以上两点，客户端在create成功后，可以进行多次查询，只要查询到含自己锁的数据集合即可；然后增加前置结点的watcher。 三、Elasticsearch1、ES的存储结构 索引在数据结点上的分布 整体结构 2、ES的共识 - Zen Discovery1）集群master选举 - 类ZK https://www.elastic.co/guide/en/elasticsearch/reference/7.0/modules-discovery.html The discovery and cluster formation module is responsible for discovering nodes, electing a master, forming a cluster, and publishing the cluster state each time it changes. ES使用的集群状态共识使用的Zen Discovery。主要包含以下信息共识： 结点发现 主结点选举 构成集群 集群状态更新广播 Zen Discovery算法在7.0有了新的变化，具体参考链接 2）Index分区选举 - master从in-sync选择3）主副本同步 - 同步复制主副本之间同步的消息是操作，这点而言ES属于state machine replication。同步过程描述可参考链接。 四、KafkaKafka是一种时间流处理框架，区别于传统的MQ，例如其可以长时间存储消息，允许消息被消费多次。Kafka依赖ZK对Kafka集群状态进行维护，例如主题的分区信息，消费者的offset等信息，即依赖ZK使Kafka对集群状态达成共识。 当然kafka作为消息中间件，也具备了同样的功能： 削峰平谷 异步提速 应用解耦 1、kafka的存储结构了解存储结构前，我们先了解下各个组件的职责： Zookeeper：用于Broker的Controller选主，且存储Broker信息（含Topic，Partion）、消费者信息（消费组成员及其offset）、配置信息等。 Broker 普通Broker：接收读写请求、Topic的Partion副本同步 Controller：监听Zookeeper上的信息，集群元数据信息变更时同步给其他普通Broker Producer：发送消息到Broker上的指定主题的某个分区上。 Consumer：建立和Broker的长链接，消费指定主题的分区，并及时更新位移到Zookeeper。一个分区最多只能被一个消费分组内的一个消费者消费。 图片来源 2、kafka的共识 - 依赖ZK1）集群Controller选举 - 依赖ZK借助Zookeeper进行Controller选举。 2）Topic分区选主 - Controller从ISR选择当Topic的Partion所在的Broker故障或发生网络分区时，由Controller负责从ISR中选取其他Broker作为新的主分区。 3）副本数据同步 - 同步复制 HW：High Watermark，高水位线。其值为Topic的Partion对Consumer的可见位移，该位移取自ISR中的所有同步副本的最小值。 ISR：由Topic的主Partion所在broker维护。约定Topic的某Partion的主从副本间同步的时间小于replica.lag.time.max.ms的从副本 + 主副本的集合。 ACKS设置 acks=0：不需要等broker响应 acks=1：等待消息写入Topic的主Partion，然后响应 acks=-1/acks=all：等待消息写入Topic的主Partion后，且副本分区（主分区+从分区）写入个数超过min.insync.replicas也写入成功，然后响应。注意，默认min.insync.replicas=1，效果等同于acks=1。 4）关于一致性kafka的一致性跟acks设置有关： 当设置为0或1时，表现为弱一致性或最终一致性。 当设置为-1/all，且min.insync.replicas大于1时表现为强一制性 # 参考 ZAB协议 Paper 译文 ZK Paper：Wait-free coordination for Internet-scale systems 译文 图文翔实：实例详解ZooKeeper ZAB协议、分布式锁与领导选举 理解zookeeper选举机制 Redis cluster-tutorial 深入剖析Redis系列(二) - Redis哨兵模式与高可用集群 一万字详解 Redis Cluster Gossip 协议 Consensus Algorithm—— Gossip协议 redisson官方文档 - Distributed locks and synchronizers Elasticsearch 集群协调迎来新时代 https://www.elastic.co/guide/en/elasticsearch/reference/7.0/modules-discovery.html https://www.elastic.co/guide/en/elasticsearch/reference/6.0/docs-replication.html Sequence IDs: Coming Soon to an Elasticsearch Cluster Near You kafka学习笔记：知识点整理","link":"/2021/06/06/%E5%B8%B8%E8%A7%81%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E5%85%B1%E8%AF%86%E5%8D%8F%E8%AE%AE/"},{"title":"归约问题定位思路","text":"一、问题描述开发通过Jone编译部署时，报错如下： 1234567891011Exception in thread &quot;main&quot; java.lang.NoSuchFieldError: logger at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:212) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204) at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:86) at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:687) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:525) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:139) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:83) at com.jd.lsb.platform.PlatForm.run(PlatForm.java:65) at com.jd.lsb.platform.Main.main(Main.java:21) 二、问题定位 看异常堆栈是依赖问题，但是异常信息不清晰； 观察pom.xml最近没有发生变化，对比spring相关包也没有变化； google上问题的解决大都是修改spring-beans版本； 最终发现是开发的依赖最近发布的是singleJar，内包含了完整的依赖（内含spring5.x） 通知研发修改后解决。 三、总结 此次问题的解决思路应该参考Jar冲突，但是却没有第一时间走这个思路；这可能是缺少对过去问题的通用总结和缺少对当前错误的推导式定位思路。","link":"/2020/11/06/%E5%BD%92%E7%BA%A6%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D%E6%80%9D%E8%B7%AF/"},{"title":"常见问题","text":"一、设置BC为Diff工具设置difftool为beyondCompare 1234567# git配置文件增加如下配置即可[diff] tool = bc4[difftool] prompt = true [difftool &quot;bc4&quot;] cmd = bcompare \\&quot;$LOCAL\\&quot; \\&quot;$REMOTE\\&quot; 二、认证失败1）描述: 覆盖安装git-2.17.0-64-bit.exe后出现错误“fatal：Authentication failed for …” 2）Git环境 3）错误信息 4）原因：windows自动缓存了密码，在[控制面板] - [凭据管理器] - [Windows凭据]下，删除git凭据即可。 三、删除远程分支失败1、操作执行命令git push origin :branchA，出现异常“unable to delete remote ref does not exist”。 2、原因本地有远程分支的缓存，虽然远程已经不存在该分支，但本地执行git branch -r仍能看到。 3、解决方案执行命令git fetch --prune origin，更新本地分支缓存。 四、切换分支时对工作去要求git checkout otherbranch若要成功切换分支，当前工作区状态需要满足以下要求： 1）clean状态； 2）非clean状态； a.新增文件; b.修改已跟踪文件，且该文件在两分支的仓库内容是一致的，即共用一个blob。 c.删除文件； 五、路径通配符用于”git ls-files”, “git ls-tree”, “git add”, “git grep”, “git diff”, “git checkout”等命令中的路径参数都可以使用通配模式。 NOTE：在shell中执行git命令时，通配符需要被单引号或双引号括住。否则通配符会由shell解析而无法传递到git程序，导致路径解析错误。 12git checkout '*.xml'git checkout &quot;*.xml&quot; 参考 https://git-scm.com/docs/gitglossary.html#def_pathspec https://man7.org/linux/man-pages/man3/fnmatch.3.html stackoverflow: Is there a way to use wildcards with git checkout？ 六、合并时无法忽略文件1、问题描述在使用GitFlow工作流时，不同分支的pom.xml的版本是不同的。这在Git分支间同步代码时，总是把版本也同步过去了。 此场景下需要一个功能，合并时忽略某些特定文件，如pom.xml。 1、分析1）Git提供了.gitattributes可以指定符合pattern的文件使用指定合并策略，例如ours。但这只在冲突时生效，不符合我们的需求。 2）反向思考下，Git之所以不提供此功能可能是因为合并有时候是双向的，如果两个分支都使用自己的文件，那么他们相互合并时（master merge to dev &amp; dev merge to master），就会产生两个不同的提交。 结果就是，双向合并的提交不再是同一个结点，也无法fast-forwad。 参考 https://stackoverflow.com/questions/15232000/git-ignore-files-during-merge 七、Mac/Windows不区分大小写带来的困惑1、问题描述今日, 使用MacOs的同事在更新项目的Git仓库时, 出现一个令人困惑的情况. 具体执行序列如下: 1234567891011121314151617执行:1) git status结果: modified: ABC.xml执行: 1) git reset --hard 2) git status结果: modified: ABC.xml执行: 1) git checkout . 2) git status结果: modified: ABC.xml执行: 1) ls结果: abc.xml 2、解决路径 在我的Ubuntu环境下, 仓库处于clean状态, 且该目录下有两个文件”abc.xml”, “ABC.xml”. 发现是由于Windows, Mac操作系统的文件系统不区分大小写导致的. 3、解决方案1）在Ubuntu下删除其中一个文件, 并提交. 2）Mac, Windows环境下执行命令, 12git pull # 更新仓库git reset --hard origin/branch # reset到对应的远程分支 4、延伸同理Mac,Windows下的分支也是忽略大小写的。 八、撤销git commit –amendgit使用amend命令的频率很高，常用来修补上次提交的不足。但有时可能需要撤销amend操作，这时可以利用reflog来找到之前的revision。 九、Git merge策略参考资料 https://git-scm.com/docs/merge-strategies http://blog.plasticscm.com/2011/09/merge-recursive-strategy.html https://stackoverflow.com/questions/60049845/git-merge-strategy-what-is-the-resolve-strategy https://stackoverflow.com/questions/366860/when-would-you-use-the-different-git-merge-strategies https://www.cnblogs.com/chaoguo1234/p/5347623.html Version Control with Git 第九章 Merges 140-143页 How does ‘git merge’ work in details?","link":"/2018/04/16/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"title":"心理","text":"沟通的本质 2023/12/01 第一层次是生理需求（physiological）：充足的空气、水、食物、休息和繁衍后代的能力。第二层次是安全需求（safety）：保护人身安全并远离威胁。第三层次是社交需求（social）：超越生理和安全层次，想要与人联结的需求。第四层次是自尊需求（selfesteem）：对自我价值和认可的渴望。最后一个层次是自我实现需求（selfactualization）：强调自我潜能开发，超越自我的期许，使自己成为最棒的人。 马克·吐温（Mark Twain）就曾开玩笑：“当我还是一个14岁的孩子时，我父亲的愚昧让我几乎无法忍受身边出现这么一个老头。但当我21岁时，我惊讶地发现父亲竟然在这7年的时间里学会了这么多东西。” “头脑风暴”成功的关键是追求数量而不是质量，不管这些点子看起来有多么荒唐，不要去批判它们。一个看似牵强的想法，有时可能会引发一个更加可行的想法。另一个“头脑风暴”的准则是想法并非个人财产。他人可以自由地在先前想法的基础上，建立或修改原来的方案。先前提出的方案和后来发展的新方案，都是之后潜在解决方案。一旦伴侣克服了他们对想法的占有欲，防卫水平就会下降，双方可以一起努力找到最佳解决方案，而不必在乎是谁的点子。 在工作中堂堂正正：在恶意下保持冷静。 影响力 2023/12/18影响力是指人会被某些行为触发自动的社会心理反射，做出可预测的行为。以下是作者总结的六种触发反馈机制： 1）互惠，给与、索取、再索取。 互惠是促进人类社会稳定发展的行为准则，人们被从小教育要进行互惠行为。互惠行为还包括“拒绝—撤退”的互让互惠。 2）承诺和一致。 社会鼓励言出必行的人，这样可以减少猜疑带来的信任成本。 3）社会认同。 也就是趋同，别人做什么我也做什么。这是趋利避害的生物本能。当然这可能会带来多元无知。 4）喜好。 爱屋及乌，人的喜欢情绪会衍射，扩散到其周边事物 5）权威。 知识细分，听专家的话可以减少认知成本。 6）稀缺。 物以稀为贵，稀缺会影响价值判断。 思考快与慢 2023/12/251、可得性启发 可得性启发，是指大脑会根据想起某件事的容易程度来判断某事件出现的概率。 暗示，就近事件会改变大脑的记忆热点，来影响对某类事件概率的判断。 片面信息和反馈增强的公众传播方式，会导致群众导致概率误判，民意和专家团判断不一致。因为媒体报道小概率的事件才会有人关注，而经过媒体报道后群众会误判该事件的概率，可能会导致不必要的恐慌和公共资源投入，人们越恐慌则会导致媒体越关注，从而形成反馈增强。 2、峰终定律 指我们对一件事物的记忆仅限于高峰和结尾，事件过程对记忆几乎没有影响。 高峰之后，终点出现得越迅速，这件事留给我们的印象越深刻。作者因这个认知获得诺贝尔奖。记忆自我保存的记忆是对代表性的时刻的感受，受到高峰和结束时刻的强烈影响。我们在看别人的一生或自己的一生时，也会陷入峰终定律，忽视过程，过度关注峰值和结果。峰终定律的出现是为了让生物能记住那些威胁，更好的生存。但是确忽略了过程的重要性，忽略了体验的幸福。 3、风险偏好 获得性决策时，人趋向求稳。损失性决策时，趋向冒险。 4、乐观偏差 决策者在决策的时候很容易忽视外部意见，只关注内部意见。这导致对计划预期偏乐观。 内部意见往往基于直觉，而非统计。乐观的预期可能来自领导的压力，客户的压力，因为好的预期计划会让他们对你有信心。我们在总结完成任务的时候经常会发现他们会超出预期时间，一些看起来的意外因素，如生病，突发事件等导致计划不符合预期。但是大量的延期事件说明，决策时是基于直觉的理想计划。 这里的启发是要总结历史的偏差因素，把突发视为一种普遍因素，再结合类似项目的完成时间来进行对比，最终定一个合理的时间。书中给出的方案是: 识别问题分类 找到同类问题的统计数据作为参考线 除非有明显的调整动机，不然以参考线为准，不要相信直觉。 在以往回顾代码重构时，就是因为忽视了业务方的相似项目时间和为了给领导以信心，从直觉上对计划进行乐观估计，而当时却毫不知情。 对乐观规划进行调整的一个方法是”事前验尸“。即在计划制定后，想象以下一年后（项目结束的时候）项目失败了，我们的失败的原因可能是什么。这种方法可以提前引入质疑，主动发现乐观直觉外的影响因素。 被讨厌的勇气 2024/01/261、核心观点 核心：人生是为自己而活，通过对共同体做贡献自证人生价值，追求幸福。 说明现状：不幸的人都深陷人际关系中的他人认可，导致自卑和不喜欢自己。 解释为什么会不幸。目的论是一种人生观，是自己选择了当下生活，而不是苦难等原因导致。不幸是因为选择了通过他人认可实现自我价值的为他人而活的目的，而不是为共同体做贡献的自证价值的为自己而活的目的。 2、总结 书名有歧义。书是以对话的形式阐释阿德勒的心理学理论。理论有以下核心要点： 阿德勒开创的是个体心理学。人要为自己而活，而不是为别人而活，这样才能人人为自己而活。这需要勇气，所以阿德勒心理学也称为勇气的心理学，其中就包括被讨厌的勇气。 不同于弗洛伊德的因果论，而是目的论。也就是说你当前的状态不是由过去导致，而是由自己选择导致的。也就是决定现在的不是过去的经历，而是对过去经历赋予的意义。所以也就否定了心理创伤。也可以视为一种人生观和世界观。 所有烦恼的根源来自人际关系，是依赖认可欲证明人生价值。解决方案就是不要在意别人的看法，要有自我感，为自己而活，拥有被别人讨厌的勇气。做到课题分离，分离别人的课题和自己的课题。 不健全的自卑就是太依赖人际关系，当和别人对比有差距时，就会陷入自卑。而自卑伴生的是自负，是一种心理代偿机制。人会通过抬高与自己相关的事物来借此抬高自己。自卑不一定是贬义，如果和别人比，会陷入无尽焦虑。只有和自己比较，才能正向激励。 人只有在感到有价值时才会有勇气，抛弃人际关系带来的幸福，重新定义幸福为：自我接纳，他者信赖，他者贡献。人生有三大课题，工作课题，交友课题，爱的课题。 行为方面的目标：自立，与社会和谐共处。支撑他的心理目标为：我有能力的意识，人人都是我的伙伴的意识。第一个就是自我接纳，第二个就是他者信赖，他者贡献。 人生最大的不幸是不喜欢自己。而幸福就是贡献感。通过对共同体的贡献，可以摆脱他人认可，通过自我认可的方式就可以实现。当然，丢失了的认可欲，改为甘于平凡，敢于平凡的心态代替。人生是连续的刹那，做好当下就可以。 引用“人们想要喜欢自己，想要感觉自己有价值，为此就想要拥有“我对他人有用”的贡献感，而获得贡献感的常见手段就是寻求他人认可。” “如果能够真正拥有贡献感，那就不再需要他人的认可。因为即使不特意去寻求他人的认可，也可以体会到“我对他人有用”。也就是说，受认可欲求束缚的人不具有共同体感觉，还不能做到自我接纳、他者信赖和他者贡献。” 人生不存在普遍性的意义，而是自己赋予了他意义。通过贡献者之星引导自己去找寻意义。 噪声 2024/08/24序 噪声就像地下室漏水，它之所以能被容忍，不是因为人们认为它是可接受的，而是因为它一直未被发现。 人类判断的错误：偏差和噪声 当一组判断中的大部分错误都指向同一个方向时，我们就认为这组判断出现了偏差，偏差即平均误差。例如，整队射击手连续命中靶子的左下方；公司高管年复一年地对销售额做出过高的估计；公司对本该撤销的失败项目持续进行投资。这些都是偏差。消除一系列判断中的偏差并不能消除所有误差，消除偏差后仍然残留的误差缺少共性。它们是我们在做判断的过程中不希望存在的分歧，体现了我们将测量工具应用于实际时的不稳定性。这种变异就是噪声。噪声是本该相同的判断中出现的变异。我们用“系统噪声”这一术语来描述组织中具有同质性的专业人士，如急诊医生、量刑法官以及保险公司核保员在做决策时出现的噪声。本书的大部分内容都在讨论系统噪声的问题。 噪声类型 水平、模式、情境，噪声的3种类型 系统噪声可分为水平噪声和模式噪声。有些法官通常很严厉，而另一些法官则更宽容；一些股票预测者总是预测牛市，另一些则总是预测熊市；有些医生开的抗生素比其他医生多。水平噪声是不同个体平均判断上的变异性，判断量表的模糊性是水平噪声的来源之一。像“可能”这样的词或“0～6分量表中的4分”这样的数字对不同的人来说含义是不同的。水平噪声是判断系统中的误差的重要来源，也是减少噪声过程中的一个重要干预对象。系统噪声还包含另一种成分，这种成分通常占比更大。无论判决的平均水平如何，不同的法官对于哪种罪行应受更严厉的刑罚的看法可能有所不同。法官们的不同判决会导致对不同案件的排序不同。我们称这种变异为模式噪声［统计术语为“统计交互作用”（statistical interaction）］。模式噪声的主要来源是稳定的，如不同法官对同一案件所做出的个体化、特异性的反应。其中一些差异反映了个体（有意识或无意识）遵循的原则或价值观。例如，一位法官对偷盗者可能特别严厉，而对违反交通法规的人则较宽容；另一位法官可能刚好相反。某些潜在的原则或价值观可能非常复杂，而判断者可能对此毫无意识。例如，某位法官可能对年龄较大的偷盗者比较宽容，他自己却完全没有意识到这一点。同时，对特定案例高度个体化的反应也可能是稳定的，比如，某位法官由于觉得被告长得像自己的孩子，从而对被告产生了怜悯之情，并对被告予以宽大处理。这位法官在不同时间里遇到这种情况，他都会如此。这种稳定的模式噪声反映了法官的独特性：他们对案件的反应与他们独一无二的人格特征一样。人与人之间的细微差异通常很微妙也很有趣，但是，在需要一致性判断的系统中，这种由专业人员做出的判断间的差异是有问题的。在我们所考察的研究中，这种因个体差异而产生的稳定的模式噪声通常是系统噪声的最大来源。尽管如此，法官对特定案件的不同态度也不完全是稳定的，也就是说模式噪声也包含一个可变成分，我们称之为情境噪声。如果放射科医生在不同的日子里对同一张影像片子做出了不同的诊断，或是指纹鉴定师有时认为两个指纹是匹配的，有时则认为是不匹配的，我们就能在其中检测到情境噪声。正如上述例子所示，如果判断者没能识别出某个案例是他以前处理过的案例，我们很容易在他做判断的过程中测量出情境噪声。另一种证明存在情境噪声的方式是发现与判断无关的背景因素对判断产生了影响。例如，当法官最喜欢的足球队获胜后，他们变得较宽容；医生在下午通常会开出更多的阿片类药物。 情景噪声 你可以采用两种方式：要么隔一段时间再做出第二次判断，要么质疑自己的第一次判断，从另一个角度来看待问题。此外，不管是哪一种类型的“群体”，除非你有充足的证据表明需要对其中一次评估赋予更高的权重，否则对两次判断进行平均后的判断就是最佳判断。 你并非在所有时刻都一样。随着情绪的变化（有时候你会意识到），你的认知机制也会改变（你可能根本意识不到）。如果你面临一个复杂的判断问题，当前的情绪会影响你对这个问题的思考以及得出的结论，即便你认为你的判断没有受到情绪的影响，并且能很自信地阐明自己给出最终答案的理由。简而言之，你的判断充满噪声。 在不应该影响但实际上影响了专业判断的诸多外在因素中，压力和疲劳是两个主要因素。 群体会放大噪声 微小的差别可能导致一个群体坚定地说“是”，而本质上相同的另一个群体却坚定地说“否”。 独立做出判断是发挥群体智慧的前提条件，如果人们不是自己做出判断，而是依赖于其他人，那么群体并不会更明智。 信息级联，极易放大群体判断的噪声。 内部讨论常常会导致群体更自信、更团结、更极端，三者通常以更大的热情展现出来。 水平噪声和模式噪声会使得群体成员的观点产生不应有的差异，而且该差异比我们预期的更大。我们已经看到疲劳、情绪、可以比较等情境噪声会影响率先发言的那个人的判断，群体互动则会放大这种噪声。结果，经过商议的群体会比仅仅对个体判断进行平均的统计群体产生更大的噪声。 决策卫生 原则1：判断的目的在于准确性，而不在于个性化表达 原则2：使用统计思维，采用外部视角审视个案 原则3：对判断进行结构化，将其分解成几个独立的任务。 原则4：抵制不成熟的直觉。 原则5：获取多位判断者的独立判断，再考虑汇总这些判断。 原则6：用相对判断和相对量表会更好。 胡思乱想消除指南 2024/12/31 大多数人都有特定的思维模式，不必要的痛苦因此产生。这些模式通常被称作“错误思维”或“错误推理”，包括： 灾难化思维 非黑即白思维 以偏概全 对人错觉 消极滤镜 妄下消极结论 主观臆断 指责他人 贴标签 杞人忧天 攀比 公平错觉 马后炮 沉思录 2025/04/18 一日之始就对自己说：我将遇见好管闲事的人、忘恩负义的人、傲慢的人、欺诈的人、嫉妒的人和孤僻的人。他们染有这些品性是因为他们不知道什么是善，什么是恶。 不要让将来的事困扰你，因为如果那是必然要发生的话，你将带着你现在对待当前事物的同样理性走向它们。 只有一件事苦恼我，就是惟恐自己做出人的结构不允许的事情，或者是以它不允许的方式做出，或者是在它不允许做的时候做出。 总是观察那些你希望得到他们嘉许的人，看看他们拥有什么样的支配原则。因为那样你将不会谴责那些不由自主地冒犯你的人，你也不会想要得到他们的嘉许，只要你看清了他们的意见和口味的根源。 考虑人们在吃饭、睡觉、生产、娱乐等时候是什么样的人，然后考虑他们在不敬或傲慢，或者据其高位发怒和叱责时是什么样的人。而在不久之前他们是多少人的奴隶，是为了什么事情受人奴役，考虑过一会儿他们又将进入什么状态。 我常常觉得这是多么奇怪啊：每个人爱自己都超过爱所有其他人，但他重视别人关于他自己的意见，却更甚于重视自己关于自己的意见","link":"/2025/10/10/%E5%BF%83%E7%90%86/"},{"title":"思考","text":"底层逻辑:看清这个世界的底牌 2023/08/15 我们常说，一个人的表述大概可以分为两种：事实和观点。事实有真假，观点无对错。 但是细究起来，还可以再细分，至少可以分为四种：事实（Fact）、观点（Opinion）、立场（Stand）和信仰（Belief）（见图2-1）。 普通的人改变结果，优秀的人改变原因，顶级优秀的人改变模型。改变制度是改变结果，改变流程是改变原因，改变系统则是改变模型。 那么，如何才能挖掘自己的逻辑思维呢？有四句话可以帮助大家建立基本的逻辑素养：证有不证无，以偏不概全，证有靠举例，概全靠推理。 第一性原理 2023/09/01 在我看来，成年人学习的关键并不在于增加信息量，而在于提升自己的思维模型。在低水平的思维模型中，增加再多的内容也只是低水平的重复而已，只有提升思维模型的水平，才能让我们接纳更多高维的信息和知识。当然，想要实现这种目的，学习更多的思维模型和重要学科的重要内容是不可或缺的环节。 我们应该怎样判断一个信念是否暂时正确呢？在逻辑学领域，信念“正确”的判断标准是“逻辑三洽”，即自洽、他洽和续洽。 结构化思维 2023/10/251）5W2H思维 2）认知圈思维 3）流程思维 4）人事物思维 5）故事思维 6）客户思维 把思考作为习惯 2023/11/011、内容摘要 目标要合适。越追求完美，可能离完美越远。团队管理要有目标思维，学会目标拆解，递进完成大目标。 好决策不是想出来的，而是迭代出来的。决策之前可以停顿下，在间隙引入思考，避免决策失误。 创新不是无中生有，而是厚积薄发。创新三要点：创造闲余，思想流动，跨界思考。创新有渐进式和跃迁式，要兼顾按7:2:1投入。 习惯不能被消除，只能被替代。习惯行为设计也是情绪设计，动机、能力、提示。情绪有利于习惯养成，学会阶段庆祝。 互惠让你获得比单人更大的更久。先给与，后索取。这个《影响力》说的一致，人有回馈的社会学反射。互惠的更高一级是互相成就。 “在很多时候，从众效应是一种本能反应，不需要经过理性的计算，大脑和身体就会自动做出反应。”学会逆势思考。 别想那只大象的作者告诉了我们语言框架的危机。所谓语言框架，也叫框架效应，它指的是通过语言来塑造我们看待世界的方式，它是一种无意识的思考方式，会在潜移默化中塑造人们对外部世界的看法。 理智战胜不了情绪，只有情绪只能战胜情绪。“从脑科学的角度来说，理智和情绪是不同类型大脑活动的产物，动用的是不同层次的大脑资源。理智能帮助你解决外界的问题，却不能决定你内心的底色。所以，即便你再努力，理智也战胜不了情绪。你要做的，是唤起积极情绪，让它去替代消极情绪。” 找到意义感，让自我发展进入良性循环。“在职场上追求自我实现，首先要找到自己所做工作的意义感，这不仅能让你提高工作效率，还能帮你成为更卓越的自己。” “无论你做的是什么工作，也无论你已经从业多久，认知重塑都可以随时进行，你要让它成为自己的一种惯常的思维模式。” “就像尼采说过的：“一个人知道自己为什么而活，就可以忍受任何一种生活。” 工作和商业一样都是无限游戏，以有限的精力，报以付之一役的心态，则会陷入无尽焦虑。 多模型思维。拥有更多的思维方式，选择对的模型。 行动并不会换来回报，只有正确的决策才能。 2、观点总结 元无知：不知道自己不知道。“有一样东西你没法上网搜索，那就是你脑海里并不存在的观点。” 知识分为：方法性知识和事实性知识。纸上得来终觉浅，绝知此事要躬行。方法性知识如果没有事实性知识佐证，那很难内化为人的价值观和行为准绳，也就无法实现知行合一，外显到行为决策上。 人们更注重方法性知识而忽略了事实性知识的积累。而搜索技术的发展也带来了负面影响，谷歌效应说的就是知识触手可以，人们的记忆能力也选择了少记忆，快忘记的机制。事实性知识很重要，例如小学生即使手握新华词典也很难写出好的文章。还有一句话：你的词汇量代表你思想的深度。 知识也有诅咒，你学会了一个知识就很难理解不了解这个知识的人是怎么想的。这给沟通带来了很大的挑战，所以对齐context很重要。 人是厌损的。“损失某样东西让我们难过的程度，要数倍于得到同一件东西让我们快乐的程度。”之所以这样是人性害怕改变和面对不确定性。解决办法：聚焦关键任务，时时回顾。 证实是天性，证伪是理性。人有自证倾向，代入立场而非观点，导致离事实越来越远。解决办法：互换观点讨论，查理芒格常说的要反过来想，为了避免观点因团队趋同，需要引入新人。警惕看起来完美的选项。面对他人的自证倾向，正确定位问题，避免他人被错误的问题导入自证陷阱。 光环效应是人类心理行为一致的结果。这减小了复杂世界做决策的成本，趋利避害的本能。解决办法和影响力类似，就是分离光环和要评估的事情。 多样性视角，不同的视角带来不同的人生观世界观。多以积极的视角看问题，乐观的心态面对问题，可以带来更高的成就。因为世界是乐观者创造的。 “拥有开放式思维的人，能够在拥有积极心态的前提下，更高效地提升自己的行动力和复原力，获得更多成功的可能性” 校园学习是：知识获取，记忆塑造。职场学习是：技能提升，问题解决。提高学习效率的四中场景：营火，水源，洞穴，山顶。学习的时间管理：时间有权重，不要等分。遗忘式学习法应该参考《我们为什么睡觉》，好好睡觉，非快速眼动阶段把记忆由海马体移到大脑皮层，快速眼动阶段则进行新旧知识融合触发创新。 禅与摩托车维修艺术 2023/12/121）如果你想着快点结束某件事情，那就说明你不喜欢这件事。 但是结合《思考快与慢》，这往往是系统1的直觉，这时候需要启动系统2去思考，我为什么要快速完成这件事，我真的不喜欢他吗？ 2）斐德罗认为当前社会存在危机的原因是理性缺失。人类物质和生活条件在短时间内快速丰富，但是人的追求还停留在物质需求上，反而在精神上是缺失的，这导致在物质的温床上失眠。二十一世纪同样如此，尤其在经济快速崛起的国家，人民的精神追求依然被物质需求所裹挟，终日碌碌，没有尽头，也没有真正满足过。 3）斐德罗最早从事生物化学方面的工作。这是科学范畴，需要通过科学的方法去验证真理，先假设，然后再证明，再假设。但是斐德罗认为假设的数量增长速度超过了证明的速度，这会导致人们里真理越来越远。 清晰思考:将平凡时刻转为非凡成果 2024/09/20 一位导师曾教导我，在时间允许的情况下，避免在工作中为错误的问题寻找完美解决方案的最佳办法是分别召开两次会议：一次用来界定问题，另一次用来提出解决方案。 你应该了解三种失败保险箱：设置绊线、授权他人做出决策，以及束缚自己的双手。 问问自己：“曾经最重要的事情，目前还是最重要的吗？我错了吗？现在我在时间上更进一步了，但在进度上却没有，要怎样才能实现我的目标呢？” 自利性偏差，即以提升自我形象的方式评价事物的倾向。当在某件事情上取得成功时，我们往往会把它归功于自己的能力或努力。相比之下，当在某件事情上失败时，我们往往会把失败归因于外部因素。如果你想提升自己，就必须改变在出错后把整件事情讲述给自己的方式。 美式橄榄球队西雅图海鹰队的皮特·卡罗尔（Pete Car roll）教练和其他人一样，深知好的决策和好的结果之间的区别。2015年2月，卡罗尔在第49届超级碗比赛的最后几分钟做出了一个历史性的决策，赛后立即遭到批评，说这个决策是一个巨大的错误。那时，西雅图海鹰队以24比28的比分落后，但他们已经站在了新英格兰队的一码线上，似乎有把握得分并取得领先。在西雅图海鹰队的后场站立的是马肖恩·林奇（Marshawn Lynch），这位体重约98公斤的猛将可以说是当时美国国家橄榄球联盟中最具威力的跑卫，当天他在对阵爱国者队时已经跑了一百多码。下面是美国哥伦比亚广播公司体育频道的一篇报道，简要回顾了接下来发生的事情——以及今天人们是如何看待卡罗尔的决策的。 赛后，一位采访者对卡罗尔说：“每个人都认为这是有史以来最严重的错误。”卡罗尔的回应是：这是“有史以来最糟糕的决策结果”。他的决策过程没有问题，只不过没有实现他的意图。有时候，这就是生活。 过程原则：当你评估一项决策时，请关注你做出决策的过程，而不是结果。 保障措施：记录下你做决策时的想法，不要依赖事后回忆。试图在事后回想清楚自己在做决策时的所知所想，简直是痴人说梦。 原则 2024/09/25 我的目标只是让自己正确——我并不关心正确的答案是不是来源于我。所以我学会了让自己保持极度开明的心态，允许其他人指出我可能疏忽的东西。我发现，我能够成功的唯一途径将是：1.找到与我观点不同的最聪明的人，以便自己能够努力理解他们的推理。2.知道自己在什么时候不能有明确的意见，不急于下结论。3.逐步归纳永恒和普适的原则，对其进行测试，将其系统化。4.通过平衡风险来保持较大的回报，并降低下行波动。 要明白，规划一个好方案不一定需要很多时间。草拟和完善一个方案，可以用短短几个小时，也可以用几天甚至几周，但这个过程是必不可少的，因为它确保你将做的事是有效的。太多人犯的错误是，一心想着执行，所以几乎不花时间来规划。谨记：规划先于行动！ 谨记，你是在寻找最好的答案，而不是你自己能得出的最好答案。 教导并强化“吃一堑、长一智”的道理。为了鼓励员工将错误公开并进行客观分析，管理层需要打造相应文化，使得此举成为常态，对压制和掩盖错误的做法给予惩处。这样做是为了明确一点：一个人犯下的最严重的错误，就是不能直面自己的错误。这也是桥水强制采用问题日志的原因。 注意不要因集体决策而丧失个人责任。十分常见的是，集体做出了决定，却没有分派个人任务，因此不清楚接下来谁应当做什么。对个人职责的分派，要十分明确。 3—5人的效率高于20人。3—5个精明强干且善于思考的人以开放心态讨论，通常能找到问题的最佳答案。组建更多人的团队看起来挺好，但如果人太多，合作的效果可能适得其反，即便其中有很多聪明、有才华的人。给团队增加成员的共生效果是逐步递增的（2+1=4.25），直至到达一个顶点，过了顶点后将不再产生增效，反而带来效率递减。这是因为：（1）边际效益随团队人数增多而减少（两三个人可以贡献大部分重要的观点，增加更多人不会有更多的好点子）；（2）团队人数过多时，其互动效率低于小团队的互动效率。当然，实际中最好的结果取决于人员的素质和他们带来的不同观点，以及团队管理的好坏。 当心那些混淆目标和任务的人，因为如果他们分不清楚，你就不能信任他们并给他们委派职责。清楚目标的人通常能有大局观。一种测试方法是：问一个高层次的问题：“目标XYZ的进展如何？”好的回答是先指出关于XYZ整体进展的总体情况，如果需要，再分述各任务情况来支持论证。只见任务不见目标的人只会讲任务完成情况。 毛泽东选集 2024/10/14湖南农民运动考察报告 《湖南农民运动考察报告》是一个很好的报告分析示例。从农民问题严重性（农民工会影响人数之广，运动之迅猛）来说明议题的重要性。然后从时间顺序分析：农民工会是如何发展的（细分到不同类别农民，如何在不同时间段，如何进入工会）、做了哪些事情（返回政权、族权、神权、夫权）、不同阶级的不同视角看法。其中，分析了革命者的积极看法和乡绅地主的消极看法的缘由。并对“不好的事情”进行认可，认为这是革命所必须的，“矫枉必须过正”。行为或有瞎呲，但从本质上是进步的，应该给与支持，不应该打压。最后，详细列举了农民工会所做的14件大事。举证来证实前面的观点。 反对本本主义 你对于那个问题不能解决吗？那末，你就去调查那个问题的现状和它的历史吧！你完完全全调查明白了，你对那个问题就有解决的办法了。一切结论产生于调查情况的末尾，而不是在它的先头。只有蠢人，才是他一个人，或者邀集一堆人，不作调查，而只是冥思苦索地“想办法”，“打主意”。须知这是一定不能想出什么好办法，打出什么好主意的。换一句话说，他一定要产生错办法和错主意。许多巡视员，许多游击队的领导者，许多新接任的工作干部，喜欢一到就宣布政见，看到一点表面，一个枝节，就指手画脚地说这也不对，那也错误。这种纯主观地“瞎说一顿”，实在是最可恶没有的。他一定要弄坏事情，一定要失掉群众，一定不能解决问题。 不根据实际情况进行讨论和审察，一味盲目执行，这种单纯建立在“上级”观念上的形式主义的态度是很不对的。为什么党的策略路线总是不能深入群众，就是这种形式主义在那里作怪。盲目地表面上完全无异议地执行上级的指示，这不是真正在执行上级的指示，这是反对上级指示或者对上级指示怠工的最妙方法。 我们说马克思主义是对的，决不是因为马克思这个人是什么“先哲”，而是因为他的理论，在我们的实践中，在我们的斗争中，证明了是对的。我们的斗争需要马克思主义。 初次从事调查工作的人，要作一两回深入的调查工作，就是要了解一处地方（例如一个农村、一个城市），或者一个问题（例如粮食问题、货币问题）的底里。深切地了解一处地方或者一个问题了，往后调查别处地方、别个问题，便容易找到门路了。 实践论 常常听到一些同志在不能勇敢接受工作任务时说出来的一句话：没有把握。为什么没有把握呢？因为他对于这项工作的内容和环境没有规律性的了解，或者他从来就没有接触过这类工作，或者接触得不多，因而无从谈到这类工作的规律性。及至把工作的情况和环境给以详细分析之后，他就觉得比较地有了把握，愿意去做这项工作。 认识的过程，第一步，是开始接触外界事情，属于感觉的阶段。第二步，是综合感觉的材料加以整理和改造，属于概念、判断和推理的阶段。只有感觉的材料十分丰富（不是零碎不全）和合于实际（不是错觉），才能根据这样的材料造出正确的概念和论理来。 认识从实践始，经过实践得到了理论的认识，还须再回到实践去。认识的能动作用，不但表现于从感性的认识到理性的认识之能动的飞跃，更重要的还须表现于从理性的认识到革命的实践这一个飞跃。抓着了世界的规律性的认识，必须把它再回到改造世界的实践中去，再用到生产的实践、革命的阶级斗争和民族斗争的实践以及科学实验的实践中去。这就是检验理论和发展理论的过程，是整个认识过程的继续。 &lt;农村调查&gt;的序言和跋 第一是眼睛向下，不要只是昂首望天。没有眼睛向下的兴趣和决心，是一辈子也不会真正懂得中国的事情的。 第二是开调查会。东张西望，道听途说，决然得不到什么完全的知识。 到会的人，应是真正有经验的中级和下级的干部，或老百姓。我在湖南五县调查和井冈山两县调查，找的是各县中级负责干部；寻乌调查找的是一部分中级干部，一部分下级干部，一个穷秀才，一个破产了的商会会长，一个在知县衙门管钱粮的已经失了业的小官吏。他们都给了我很多闻所未闻的知识。 所以，一切实际工作者必须向下作调查。对于只懂得理论不懂得实际情况的人，这种调查工作尤有必要，否则他们就不能将理论和实际相联系。“没有调查就没有发言权”[3]，这句话，虽然曾经被人讥为“狭隘经验论”的，我却至今不悔；不但不悔，我仍然坚持没有调查是不可能有发言权的。 反对党八股 党八股的第一条罪状是：空话连篇，言之无物。我们有些同志欢喜写长文章，但是没有什么内容，真是“懒婆娘的裹脚，又长又臭”。 党八股的第二条罪状是：装腔作势，借以吓人。有些党八股，不只是空话连篇，而且装样子故意吓人，这里面包含着很坏的毒素。 党八股的第三条罪状是：无的放矢，不看对象。 党八股的第四条罪状是：语言无味，像个瘪三[8]。 党八股的第五条罪状是：甲乙丙丁，开中药铺。 党八股的第六条罪状是：不负责任，到处害人。 第七条罪状是：流毒全党，妨害革命。 第八条罪状是：传播出去，祸国殃民。 在延安文艺座谈会上的讲话 我们讨论问题，应当从实际出发，不是从定义出发。如果我们按照教科书，找到什么是文学、什么是艺术的定义，然后按照它们来规定今天文艺运动的方针，来评判今天所发生的各种见解和争论，这种方法是不正确的。我们是马克思主义者，马克思主义叫我们看问题不要从抽象的定义出发，而要从客观存在的事实出发，从分析这些事实中找出方针、政策、办法来。我们现在讨论文艺工作，也应该这样做。 党委会的工作方法 四、不懂得和不了解的东西要问下级，不要轻易表示赞成或反对。有些文件起草出来压下暂时不发，就是因为其中还有些问题没有弄清楚，需要先征求下级的意见。我们切不可强不知以为知，要“不耻下问”[2]，要善于倾听下面干部的意见。先做学生，然后再做先生；先向下面干部请教，然后再下命令。各中央局、各前委处理问题的时候，除军事情况紧急和事情已经弄清楚者外，都应该这样办。这不会影响自己的威信，而只会增加自己的威信。我们做出的决定包括了下面干部提出的正确意见，他们当然拥护。下面干部的话，有正确的，也有不正确的，听了以后要加以分析。对正确的意见，必须听，并且照它做。中央领导之所以正确，主要是由于综合了各地供给的材料、报告和正确的意见。如果各地不来材料，不提意见，中央就很难正确地发号施令。对下面来的错误意见也要听，根本不听是不对的；不过听了而不照它做，并且要给以批评。 六、要“抓紧”。就是说，党委对主要工作不但一定要“抓”，而且一定要“抓紧”。什么东西只有抓得很紧，毫不放松，才能抓住。抓而不紧，等于不抓。伸着巴掌，当然什么也抓不住。就是把手握起来，但是不握紧，样子像抓，还是抓不住东西。我们有些同志，也抓主要工作，但是抓而不紧，所以工作还是不能做好。不抓不行，抓而不紧也不行。 七、胸中有“数”。这是说，对情况和问题一定要注意到它们的数量方面，要有基本的数量的分析。任何质量都表现为一定的数量，没有数量也就没有质量。我们有许多同志至今不懂得注意事物的数量方面，不懂得注意基本的统计、主要的百分比，不懂得注意决定事物质量的数量界限，一切都是胸中无“数”，结果就不能不犯错误。例如，要进行土地改革，对于地主、富农、中农、贫农各占人口多少，各有多少土地，这些数字就必须了解，才能据以定出正确的政策。对于何谓富农，何谓富裕中农，有多少剥削收入才算富农，否则就算富裕中农，这也必须找出一个数量的界限。在任何群众运动中，群众积极拥护的有多少，反对的有多少，处于中间状态的有多少，这些都必须有个基本的调查，基本的分析，不可无根据地、主观地决定问题。 系统之美 2024/10/21 防止“公地悲剧”有以下三种方式：方式一：教育、劝诫。帮助人们看到无节制地使用公共资源的后果，号召并激发人们的美德品行。劝说人们有所节制，以社会舆论谴责或严厉惩罚来威慑违规者。方式二：将公共资源私有化。将公共资源分割给个人，每个人都要对自己行为的结果负责。如果某些人缺乏自控力，对资源的使用超出了其所拥有的资源的承载能力，他们也只能自食其果，伤害不到其他人。方式三：对公共资源进行管制。哈丁将这种选择称为“达成共识，强制执行”。管制可以采取很多种形式，从对某些行为的严格禁止，到配额制、许可制、税收调控以及鼓励措施等。要想奏效，管制必须有强制性的监管和惩罚措施。 应对“政策阻力”最有效的方式是，设法将各个子系统的目标协调一致，通常是设立一个更大的总体目标，让所有参与者突破各自的有限理性。如果每个人都能为了同一个目标而和谐地相处，其结果将令人惊奇。 “在你看来，好像有一个精确的合理租金水平，在这个水平之上，房客就被剥削了，而在这个水平之下，你又被压榨了。但事实上，并不存在这样一条明确的线。在你和房客之间，是一个较大的灰色区域——在这个区域之内，你们都可以达成合理的交易。所以，别再自寻烦恼了，照常过你的日子去吧。” 荷兰在住房开发过程中安装电表的故事，一些电表被安装在地下室，另外一些则被安装在前厅。在房间没有其他区别的情况下，后者家庭的电力消耗比前者低30%，差别仅仅在于电表是否被安装在更容易被人们看到的位置。 适时退出:以退为进的决策智慧 2024/10/22 坚持并不总是最好的决定，还要看实际情况。而实际情况随时都在发生变化。毅力成就了阿里——伟大的拳击冠军，几乎无人能与之匹敌——但也毁掉了他，因为这种毅力让他对那些在外人看来明显预示着“退出”的征兆视而不见。这就是毅力的有趣之处。它会让你坚持去做艰难而值得的事，也会让你坚持去做艰难但不值得的事。诀窍在于找出其中的区别。 成功不在于坚持。成功的关键在于选择正确的事情来坚持，并退出其他事情。 “关门时间”就是指登山者停止攀登的时间，即使没有到达目的地也要返回营地。“关门时间”是为了保护登山者，避免他们在下山过程中遇到危险，因为下山比上山更需要技巧。 管理咨询业有一条著名的启示法则：第一次想到解雇某人的时候，是付诸行动的最佳时机。这条法则旨在让企业更快地做出决定，因为大多数管理者不愿意解雇员工，导致这些员工留下来的时间越来越久。 我们会把自己拥有的东西看得比同等物品更重。理查德·塞勒率先将这种认知错觉命名为“禀赋效应”。事实上，他正是在1980年那篇提出“沉没成本”的论文里引入了禀赋效应，并将其描述为“相比取得一件物品所愿意付出的代价，人们往往要求更高的补偿才会放弃它”。 更加严肃地说，这给那些想要更好做出退出决定的企业提供了一个好策略：尽可能分而治之。让一些人做出开始的决定，让另一些人做出结束的决定。对于机构投资者客户，我建议将这种策略作为改善卖出决策的一种方式。让一个委员会批准购买什么，让另一个委员会批准何时卖出什么。当然，这只有在团队规模足够大的情况下才可行。 总结一下本书所讨论的内容，我们之所以很难退出，是因为我们害怕两件事：一是失败，二是浪费了时间、精力和金钱。 我们担心退出就意味着失败，但我们到底失败在哪里呢？退出一件不再值得坚持的事情，这不是失败。这是成功。我们理所当然地认为，失败就是在没有达成目标的情况下退出，比如未能冲过终点线。但是，如果你继续追求一些失去价值的东西，难道就不是失败吗？我们何不重新定义失败，将之视为未能遵循一个好的决策过程？成功意味着遵循一个好的决策过程，而不仅仅是冲过终点线，尤其是在终点线有误的情况下。也就是说，适当地遵循终止标准，听取退出教练的建议，并认识到我们在过程中取得的进步非常重要。 我们也要重新定义“浪费”。浪费时间、精力和金钱意味着什么？问题在于，我们往往会用一种后顾性思维来考虑这些事情。我们觉得如果放弃某件事，就意味着浪费了我们投入的一切。但这些资源已经用掉了。你不可能再把它们要回来。我们要用前瞻性思维来考虑浪费的问题。也就是说，在一些失去价值的事情上多花一分钟、一点精力或一美元，才是真正的浪费。 小数决策 2024/11/11详见：小数决策和审查数据 思考的技术 2024/12/12 大前研一 向麦肯锡学习逻辑思维 不要把假设和结论混为一谈。 分析数据后所整理出来的资料，只不过是假设。但是大部分企业经营者或工商业者，就把这个假设当结论了。 也就是自己感觉有十足的把握，确定这个结论绝对没错之前，一定要挪动双脚亲自走访现场。事实上，我从来没有一次是在企划室中研究数字之后就得出结论的。 科学思考 卡宁厄姆自英国有名的贵族学校伊顿公学（Eton School）毕业后，考进了剑桥大学，是位非常典型的优等生，他对逻辑构成、重点分析都执行得非常透彻而深入。就连在一般对话时，不论我说什么，他都会咄咄逼问：“有何证据？”“你是基于什么分析而这么说的？”“为什么会有这个结论？”当时我并不了解公司其他人的做法，所以下意识地认为这应该就是麦肯锡式的做法，后来才知道，事实上根本不是这么回事。 我是在一无所知的情况下进入麦肯锡的，所以我比别人加倍努力。其中一项就是思维能力的训练。当时我是从横滨出发去公司上班的，所以每天早上就利用从横滨到东京车站的二十八分钟通勤时间，给自己一道题目，然后思考如何解决问题。例如，一眼看到垂吊式的车厢广告，就以这个广告为题目，思考：“如果这家广告公司的总裁要我协助他们公司提高业绩，我该怎么做？”当脑子习惯思考之后，思考速度自然会加快，于是我就从每天一道题目，进步到每隔一个车站都可以思考一道新的题目。看到一个不同的广告，马上就提出假设“如果这么做一定热卖”，然后思索该搜集什么资料、该怎么做分析，等等，也就是说，我在训练自己的脑子，可以立即将解决问题的所有过程组合起来。 这就是组织解决问题的思维训练。题目是无所不在的，如果你也能像我一样训练自己的脑力，就一定能够提升解决问题的能力。一天努力看不出差距，可是天天努力，很快就有明显的差别了。最后，我给大家一道题目，既可以训练思维，又对工作非常有实际效用。这道题目就是：“如果你的职位比现在高两级，你会怎么做？”每一家公司、每一个企业，应该有各种不同的问题。如果你现在是员工，就以中层领导的立场来思考；如果你现在是中层领导，就以高层领导的立场来思考。请做深层思考，想一想如果你是领导，你会怎么解决公司的问题。 区分现象和原因 他们所罗列的问题只不过是现象，而逆转现象并不是解决方案。只看到现象，绝对无法找出问题的真正原因以及能够对症下药的解决方法。日本在研讨各种议题的时候，十之八九都无法区别现象和原因，因为参与议题研讨的人根本就不具备正确的思路。不可仅凭现象做判断。 会发生某种现象，一定有其原因。但是懒得找原因，只以现象做判断，提出解决方法，这种解决方案绝不会是正确的。 思维训练 为什么要做这样的练习呢？在江户川堤防走上十公里，单凭这种行为就可以让你看到很多平常看不到的景致。新景观使平常没有用到的脑部思维逻辑得以锻炼。住在附近的人，都是如此度过休闲时光，或是自己上了年纪之后，会不会也到这样的场所来打打棒球呢？像这样接触到与平常上班生活所看到的不同的景色，脑部就会跟着灵活起来。接着，试着对自己提出问题。首先，想想要不要搬到这附近来住呢？如此一来，开始在脑袋里思考一些正面和负面的情形，放眼望去，绿油油的一片，环境也不错、购物和学校不知道怎么样、夏天说不定很多蚊子，等等。如果又想到下次也带孩子们来走走，这时思维又会开始运转，想着到那时要做些什么、若是开车来不知有没有停车场、午餐是先去便利店买好，还是到这附近来烤肉呢，等等问题。更进一步想到若这个堤防上可以盖房子的话，自己真想要拥有这样的房子，问题接二连三陆续出现。想着建设部门一定不会核准在这个地方盖房子，但万一真的可以，自己要盖一栋怎样的房子。或是想着对岸好像也不错，于是又开始想好的一面和坏的一面。然后想下次来的时候，走过桥去对面看看吧。看到河川的对岸，堤防外的江户川区，是密密麻麻杂乱无章的住宅区，看到这番景象，突然心头涌上一股对国家的怒气，为什么我们得在这个狭小的地区比邻而居挤在一起，而不能在这一片广大的土地上盖房子呢？而且这边的景观远比对岸漂亮许多。接着又想洪水泛滥而不需负责的前提之下，交通部门若是允许在这片土地上建造住宅区，成本一定很低廉，或是不知道要找哪个机构进行交涉才对，等等问题。随后开始思考照今天所走十公里的距离来计算，可以盖上几栋房子。若简单地计算出四十万户，然后再对自己提问：那么对于这一片土地，是否还有更好的利用方法呢？诸如此类的问题不断在脑海中涌现，而这些问题一定是以前所没有思考过的。 “思考”，就是对自己提出疑问 我的人生就是这样不断进行思考。走路的时候，绝对不会发呆，一定是边走边思考，因此，头脑运转的机会非常多。如此连续不断地思考，就能产生许多经验和构想。“思考”，就是常常提出疑问，然后自己努力寻求解答。在“当下若没有找到答案就会死”这样的强迫观念之下，将自己所拥有的数据从脑袋中调出来加以分析，然后找出可以说服自己的解答。其实，这种事情大家也都可以做到。 拆解法 能预知五年后的世界的思维逻辑 先分解功能再进行思考 具备预知性，也就是说，能够看清楚现在正发挥作用的力量，并知道它在未来是否依然可以持续发挥作用。不仅如此，还要能够辨别出这个倾向是否会越来越强，还是只能维持甚至转弱。能够预先知道目前在起作用的几个要素当中，哪个才是影响未来最重要的要素，有了这样的思维逻辑，才算是具备预知性的条件。 巨人的工具 2025/02/12 有一种简单的练习可以极大的提高你的思维能力，让你注意到小时的痛苦（无论是身体上的、心理上的还是感情上的），当然，这项练习并不仅仅与痛苦有关。 关注消失的事物有两个益处： 1）增加心理愉悦：心理愉悦含幸福的感觉来到和痛苦感觉的消失两种，关注到痛苦的消失，也会让人变得平静。 2）增加对消失的事物、看不见的事物提升敏感度。避免幸存者偏差。 百知思维模型 2025/12/31 第1部分 认知自我：让自己变优秀的模型原文：心理账户的计算差异是由多个因素造成的，包括收入差异、支出差异、用途差异、规划差异和观念差异等。 原文：前景理论是解释现象（告诉你为什么）的理论，而不是指导行动（告诉你怎么办）的理论。理论是正确的，但如果用理论的“正确”不合时宜地否定自己“正确”的行为，那将是彻头彻尾的“错误” 原文：在利益面前，人人都是守财奴；在损失面前，人人都是冒险家。 原文：信息加工、传递的过程受到三个方面的限制：客观信息暴露的有限性、主观观察信息的有限性和个人表达转述的有限性。 原文：首因效应与近因效应 ——一头一尾，都很深刻 原文：1957年，心理学家洛钦斯（A. S. Luchins）明确了一个心理学效应——首因效应（Primacy Effect），主要是指人会根据最初接收到的信息形成一种不易改变的印象。首因效应又叫第一印象效应或第一刻板印象效应。 原文：同年，洛钦斯又通过实验发现了近因效应（Recency Effect）。所谓近因效应，是指当人们接触一系列事物时，最新出现的刺激会影响人们对这些事物的印象。 原文：这个模型的大意是：我们在做一个决定时，需要想象一下，在10分钟后，自己会怎么看待现在的决定，会不会后悔；在10个月后，自己会如何思考10个月前做过的这个决定；在10年后，自己又会如何看待10年前做过的这个决定。 原文：10+10+10旁观思维模型 ——站在未来，回望当下 原文：共鸣的对象，仅仅是相对一致的观点，但一致的观点，并不等于事实。 第2部分 认知世界：探究人性、洞察世界的模型原文：管理学上有两个基础概念，“管理幅度”和“管理层次”。“管理幅度”是指管理者能够直接管理（领导、指挥和监督）的下一级人员或部门的数量；“管理层次”是指组织或机构中从最高管理者到基层人员之间的层级数目。 原文：路径依赖存在于人类生活的各个方面。从基因演化到自然变迁，从人生选择到企业发展，人们每做一种选择，都会或多或少地受到之前的选择，直至最初的选择带来的一系列影响。路径依赖可以看成一连串的“因果链条”。环节上的每一次选择都是上一次选择的“果”，同时又是下一次选择的“因”。 原文：机会成本（Opportunity Cost，OC）也被称为替代性成本，是我们在决策时所面临的多项选择中，被放弃的价值最高的选项。奥地利经济学家弗里德里希·冯·维塞尔（Friedrich Freiherr von Wieser）认为，只要有选择、取舍存在，机会成本便存在。美国经济学家尼可拉斯·格里高利·曼昆（Nicholas Gregory Mankiw）也曾指出：“某个事物的机会成本，就是为得到这个东西所放弃的东西。” 原文：1955年，历史学家和政治学家西里尔·诺斯古德·帕金森（Cyril Northcote Parkinson）发现，某些企业在成长过程中会朝着机构臃肿的方向发展。他在《经济学人》上发表的一篇幽默短文中，第一次使用了“帕金森定理”这个俗语来说明这些现象。 这之后，帕金森不断深入研究并发现，随着业务扩展或战线拉长，企业的效率会逐渐降低，员工的积极性也会不断下降，资源被浪费的现象越来越严重。 原文：管理学家劳伦斯·彼得（Laurence J. Peter）通过对美国工商、教育、军政等各个组织中的失败实例进行分析和归纳，发现了一个层级组织的管理规律：在这些具有层级组织的机构中，大家普遍遵循“若称职，就提拔”的规则，组织中的每一层人员最终都会在一个他不胜任的位置上。 原文：另外，不是所有“看上去”的彼得现象，都遵循“彼得定律”，因为定律本身忽略了一些其他情况。 1.忽略了个人成长需要时间：每个人在新岗位中需要适应时间，而很多能力也是需要真正在这个岗位上才会得到培养或被激发。 原文：贝勃定律（Bob’s Law）是一个社会心理学效应：当人经历过一个强烈刺激后，再施与刺激对这个人来说就变得微不足道了。简言之，在心理感受上，第一次的大刺激能冲淡第二次的小刺激。这种刺激无论是正向的（好事儿）还是负向的（坏事儿），都遵循贝勃定律。 第3部分 思考与分析：能帮我们解决问题的模型原文：创造技法源自创造学。它能帮助人们高效而稳定地创造出新奇事物。这些技法通常分为“头脑风暴法”“列举法”“设问法”三种。其中，设问法中有一个非常受欢迎的方法，那就是奥斯本检核表法。 原文：3C战略三角模型，由著名管理学家和经济评论家大前研一提出。这个模型表达了成功的战略有三个关键因素，分别为公司本身（Corporation）、顾客（Customer）、竞争者（Competitor）。这三个因素形成三角关系，制定任何经营战略时都必须将它们考虑进来。大前研一还强调：只有将公司、顾客与竞争者整合在同一个战略内，竞争优势才是可持续的。 原文：PEST分析模型，是由格里·约翰逊（Gerry Johnson）和凯万·斯科尔斯（Kevan Scholes）两位学者在《战略管理》一书中提出的。它主要用于分析企业或行业面临的宏观外部环境。 PEST分析模型包括政治（Politics）、经济（Economy）、社会（Society）和技术（Technology）这四个因素，因此也被称为PEST分析法或STEP分析法。 原文：对应到PEST上，政策就是天，它有阴有晴，但阶段性稳定；经济就是水，它有多有少，时有变化；社会就是土，它有地域性，相对稳定且复杂；技术就是肥，它是能催生、能助长的外力。 原文：实际上，SWOT分析是基于“内部和外部、有利和不利”的坐标构建的四个象限，如下页图所示。具体来说，内部的有利因素构成优势（Strengths），内部的不利因素构成劣势（Weaknesses），外部的有利因素构成机会（Opportunities），外部的不利因素构成危机（Threats）。因此，在归类有利因素或不利因素时，我们并不需要关心某一因素是现在已经存在的，还是未来即将发生的。我们只需要清楚它是属于内部自身的还是外部环境的，然后把这些好的因素或是坏的因素归类到相应的象限中。不管是优势、劣势、机会、危机，里面都可以有当下正在发生的和未来可能发生的。 第4部分 沟通与学习：搞定关系、助力成长的模型原文：RICE全科问诊模式可以为各行业的“病症”探寻到病根。这个问诊模式具备普适性的原因在于，RICE中的每一次提问都会获得一个对方的关键信息：“问原因”可以获得他所面对的背景信息；“问想法”可以获得他主观的思考与判断；“问忧虑”可以获得他价值观下的关注点；“问期望”可以获得他自己想达到的目标。背景、思考、价值、目标，就组成了诊断对方问题的四个要素。 原文：莫塔五问，“全科医生”在诊断时通常会考虑以下五个问题： 1.病人的症状或体征可能有哪些常见原因？ 2.有什么重要的不能被忽略的疾病吗？ 3.有什么容易被遗漏的病因吗？ 4.病人是否患有潜在的常被掩盖的疾病？ 5.病人是不是有什么话还没有说？ 原文：一问，找出所有可能的原因。 二问，找出其中重要的原因。 三问，检查没考虑到的原因。 四问，追查其他相关联的原因。 五问，搜查未提及（被埋没）的更多原因。 原文：五遍沟通法具体是： 第1遍：上级自己先交代清楚； 第2遍：要求下属复述一遍； 第3遍：与下属探讨事项的目的； 第4遍：与下属探讨应急预案； 第5遍：让下属提出个人见解。 交代一遍、复述一遍、明确目的、制定预案、提出见解。这五次传递，可以帮助员工全面了解工作任务。 原文：所谓FFC赞美法，就是指在赞美一个人时，先用细腻的语言来表达自己的感受（Feeling）；再通过陈述事实（Facts）中的某些细节，让对方相信你的感受是真的；最后通过比较（Compare），把对方“捧”起来。 原文：SCQA模型是一个“结构化表达”工具，由麦肯锡咨询顾问巴巴拉·明托在《金字塔原理》中提出。这个模型的四个英文单词是Situation（情景）、Complication（冲突）、Question（疑问）和Answer（回答）。 S—情景，指的是事情发生的背景，能把听者带入进来，引起共鸣。 C—冲突，指的是在这个情景下，你想表达的困难或矛盾。 Q—疑问，指的是根据冲突提出的问题，能引发对方一同思考。 A—解答，指的是问题的解决方案，也是你要表达的中心思想。 原文：PREP是一种高效、干练的表达方式，强调以终为始，结论先行。PREP就是一个基本贯彻金字塔原理的表达技巧。虽然它并不完全按照金字塔原理的“下一层的N个子结论”框架展开，但在语言的线性结构中，它已经诠释了金字塔原理的核心（结论先行，再言其他）。因此，PREP是一个非常值得经常使用的表达方式。 PREP的四个字母分别表示： P（Point）：表达观点、结论； R（Reason）：解释原因，进行论证； E（Example）：列举例子，提供论据； P（Point+）：升华观点，重申结论。 原文：隐性知识：包括个人感悟、经验、体验和认识等，它是一种深藏于个体大脑中的、“难以言表”的感觉或认知； 显性知识：包括通过提炼和总结得到的语言、形成的文字、影像、模型或其他可视化载体，是可以“表达出来”的知识。 原文：共有知识与公共知识。共有知识是指大家都知道，但彼此并不知道对方知道的知识。公共知识则是指大家都知道，并且还知道其他人也知道的知识。与此类似，信息层面也有共有信息与公共信息的区别。 所谓的共鸣激发，就是一部分的共有信息或知识被公布出来后，在转变为公共信息或知识的过程中，可以释放出巨大的能量，产生共鸣 原文：利用“已完成”的BUG，也能达到“弱化记忆”的目的。增强记忆虽好，但并不是所有的事情都记得越深刻越好。对于想要“弱化”的记忆，同样可以从蔡氏效应中获得启发。 原文：在效率维度上，实现利益绑定，就可以实现“你让我高效，你就能高效”的良性循环。 第5部分 计划与行动：让你想清楚、动起来的模型原文： OGSM主要包含以下内容： Objective—目的，用来指引企业发展方向，又叫长期目标，用文字描述。 Goals—目标，用来明确阶段成果，又叫短期目标，用来支撑长期目标，用数字描述。 Strategies—策略，是实现目的和目标的方式，即怎么做能达到目标，用文字描述。 Measures—测量，具体要完成什么事务，做到什么标准，用数字描述。 原文：所谓奥卡姆剃刀（Ockham’s Razor），核心含义只有八个字：“若无必要，勿增实体”。它的意思是一个事物如果没有存在的必要，就不要轻易主动增加它或者被动让它出现；如果它出现了，就需要像剃刀剃掉多余的毛发一样，把它去掉。这听起来只是一个很简单的道理，而实际上奥卡姆剃刀对于世界的发展和人的成长都有重要意义。 第6部分 总结与展望：让你一直进步的模型原文：KISS模型，由Keep（保持）、Improve（改进）、Stop（停止）和Start（开始）四个单词首字母组成。意思是：“我要坚持什么？改进什么？停止做什么？开始做什么？”核心思想是“总结过去”加“面向未来”。","link":"/2025/12/31/%E6%80%9D%E8%80%83/"},{"title":"手动合并分支的技巧","text":"一、背景使用Git时常用的合并分支操作是通过merge命令，但是某些情况下不适合使用merge命令（例如合并的目标分支已经重构的面目全非，有些模块甚至都移到其他仓库），此时手动合并比较保险。 二、手动合并手动合并分支时，可以通过一些操作简化，假设要把branch1的内容合并至branch2: 1）第一种方式 通过git merge-base branch1 branch2，找到公共提交结点revision； 通过git diff revision branch1来查看差异 根据差异来手动合并代码； 2）第二种方式 通过git merge-base branch1 branch2，找到公共提交结点revision； 先检出branch1:git checkout branch1，然后通过git rebase -i revision，把从公共提交结点后的所有的提交合成一个提交； 通过检查该提交的文件变化来手动合并代码； Note:第二种方式branch1自公共提交后的提交历史，必须是线形（不能有merge commit），否则rebase操作需重新解决冲突，徒增工作量；","link":"/2019/12/12/%E6%89%8B%E5%8A%A8%E5%90%88%E5%B9%B6%E5%88%86%E6%94%AF%E7%9A%84%E6%8A%80%E5%B7%A7/"},{"title":"扩展点的设计","text":"一、什么是扩展点 本质是面向接口编程； 扩展点是一类在系统开发时预留的特殊接口，系统在运行时会动态寻找，装载和执行这类接口的实现。以此来实现对指定功能的扩展，且不需要对已有系统做任何修改。 只要符合扩展点的契约，任何人在任何时间都可以去扩展特定功能，而不必关心程序的主体逻辑。 如果不使用扩展点，增加功能势必会修改程序的主体。 系统开发时，提炼出扩展点，也是系统中各个功能模块抽象度较高的一种表现； 二、扩展点的优点 符合开闭原则 框架的Core是稳定的，扩展已有的功能更简单，只需要两步：1）开发新扩展功能；2）加入运行时依赖； Core中可以独立完整运行，并可以限定扩展的范围，且也很容易控制扩展对Core功能造成影响。 三、如何设计扩展点 首先要明白要扩展什么？ 抽象出要扩展的接口 写出扩展加载逻辑等Core逻辑，这个最小的内核，可以独立运行。 常见的扩展点的加载逻辑有： 1）Java JDK SPI； 2）Spring SPI; 3）eclipse 扩展点； 四、EDI中的扩展点 Flow的结点支持扩展； 日志框架支持扩展； RPC框架支持扩展； DT支持的协议是扩展的，目前支持X12，Edifact； DT的功能结点也是扩展的；","link":"/2020/03/21/%E6%89%A9%E5%B1%95%E7%82%B9%E7%9A%84%E8%AE%BE%E8%AE%A1/"},{"title":"扩展接口SmartInitializingSingleton","text":"一、调用时机1）AbstractApplicationContext#refresh 12345678910111213141516171819202122232425262728293031323334353637383940414243public void refresh() throws BeansException, IllegalStateException { synchronized (this.startupShutdownMonitor) { StartupStep contextRefresh = this.applicationStartup.start(&quot;spring.context.refresh&quot;); // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try { // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); StartupStep beanPostProcess = this.applicationStartup.start(&quot;spring.context.beans.post-process&quot;); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); beanPostProcess.end(); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. // 此处进行Bean实例化 finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); } } } 2）AbstractApplicationContext#finishBeanFactoryInitialization 12345678910111213141516171819202122232425262728293031protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) { // Initialize conversion service for this context. if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) { beanFactory.setConversionService( beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); } // Register a default embedded value resolver if no BeanFactoryPostProcessor // (such as a PropertySourcesPlaceholderConfigurer bean) registered any before: // at this point, primarily for resolution in annotation attribute values. if (!beanFactory.hasEmbeddedValueResolver()) { beanFactory.addEmbeddedValueResolver(strVal -&gt; getEnvironment().resolvePlaceholders(strVal)); } // Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early. String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) { getBean(weaverAwareName); } // Stop using the temporary ClassLoader for type matching. beanFactory.setTempClassLoader(null); // Allow for caching all bean definition metadata, not expecting further changes. beanFactory.freezeConfiguration(); // Instantiate all remaining (non-lazy-init) singletons. // 此处进行bean实例化 beanFactory.preInstantiateSingletons(); } 3）DefaultListableBeanFactory#preInstantiateSingletons 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public void preInstantiateSingletons() throws BeansException { // Iterate over a copy to allow for init methods which in turn register new bean definitions. // While this may not be part of the regular factory bootstrap, it does otherwise work fine. List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); // Trigger initialization of all non-lazy singleton beans... for (String beanName : beanNames) { RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) { if (isFactoryBean(beanName)) { Object bean = getBean(FACTORY_BEAN_PREFIX + beanName); if (bean instanceof FactoryBean) { FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean; boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) { isEagerInit = AccessController.doPrivileged( (PrivilegedAction&lt;Boolean&gt;) ((SmartFactoryBean&lt;?&gt;) factory)::isEagerInit, getAccessControlContext()); } else { isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); } if (isEagerInit) { getBean(beanName); } } } else { getBean(beanName); } } } // Trigger post-initialization callback for all applicable beans... // 此处调用SmartInitializingSingleton#afterSingletonsInstantiated for (String beanName : beanNames) { Object singletonInstance = getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) { StartupStep smartInitialize = this.getApplicationStartup().start(&quot;spring.beans.smart-initialize&quot;) .tag(&quot;beanName&quot;, beanName); SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) { AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; { smartSingleton.afterSingletonsInstantiated(); return null; }, getAccessControlContext()); } else { smartSingleton.afterSingletonsInstantiated(); } smartInitialize.end(); } } } 由上面源码可知SmartInitializingSingleton#afterSingletonsInstantiated会在所有非惰性Bean都初始化完成后再调用的。 二、使用场景可以实现一些等所有bean都加载后，可以做以下： 1）进行一些全局性工作 例如MBeanExporter，等所有bean都注册后再统一进行MBean注册。 123456789101112131415161718192021public class MBeanExporter extends MBeanRegistrationSupport implements MBeanExportOperations, BeanClassLoaderAware, BeanFactoryAware, InitializingBean, SmartInitializingSingleton, DisposableBean { /** * Kick off bean registration automatically after the regular singleton instantiation phase. * @see #registerBeans() */ @Override public void afterSingletonsInstantiated() { try { logger.debug(&quot;Registering beans for JMX exposure on startup&quot;); registerBeans(); registerNotificationListeners(); } catch (RuntimeException ex) { // Unregister beans already registered by this exporter. unregisterNotificationListeners(); unregisterBeans(); throw ex; } }} 2）对某些bean进行再加工 例如Ribbon的LoadBalancerAutoConfiguration，通过该接口把Ribbon拦截器注入RestTemplate。 123456789101112131415161718192021222324252627@Configuration(proxyBeanMethods = false)@ConditionalOnClass(RestTemplate.class)@ConditionalOnBean(LoadBalancerClient.class)@EnableConfigurationProperties(LoadBalancerRetryProperties.class)public class LoadBalancerAutoConfiguration { @LoadBalanced @Autowired(required = false) private List&lt;RestTemplate&gt; restTemplates = Collections.emptyList(); @Autowired(required = false) private List&lt;LoadBalancerRequestTransformer&gt; transformers = Collections.emptyList(); @Bean public SmartInitializingSingleton loadBalancedRestTemplateInitializerDeprecated( final ObjectProvider&lt;List&lt;RestTemplateCustomizer&gt;&gt; restTemplateCustomizers) { return () -&gt; restTemplateCustomizers.ifAvailable(customizers -&gt; { for (RestTemplate restTemplate : LoadBalancerAutoConfiguration.this.restTemplates) { for (RestTemplateCustomizer customizer : customizers) { customizer.customize(restTemplate); } } }); } // ...}","link":"/2021/07/04/%E6%89%A9%E5%B1%95%E6%8E%A5%E5%8F%A3SmartInitializingSingleton/"},{"title":"打包后-JAR包名为时间戳orSNAPSHOT","text":"一、现象通过maven-assembly-plugin插件打包，发现lib里有的Jar包格式为artifact-demo-1.0.SNAPSHOT.jar，而有的格式为artifact-demo-1.0.20211123.202203-4.jar。 有个明显的现象是执行mvn clean package命令时，所编译的module后缀皆为SNAPSHOT。 二、跟踪1. 查看Maven日志1）Jar名为SNAPSHOT的关键日志 1232021-11-23 16:18:07,621 [DEBUG] Adding dependency artifact com.xxx.xxx:xxx-client:jar:1.2.2-SNAPSHOT.2021-11-23 16:18:07,623 [DEBUG] Adding artifact: com.xxx.xxx:xxx-client:jar:1.2.2-SNAPSHOT with file: /export/mavenRepository/repository/com/xxx/xxx/xxx-client/1.2.2-SNAPSHOT/xxx-client-1.2.2-SNAPSHOT.jar to assembly location: lib/xxx-client-1.2.2-SNAPSHOT.jar.2021-11-23 16:18:07,623 [DEBUG] Adding file: /export/mavenRepository/repository/com/xxx/xxx/susf-client/1.2.2-SNAPSHOT/xxx-client-1.2.2-SNAPSHOT.jar to archive location: lib/xxx-client-1.2.2-SNAPSHOT.jar 2）Jar名为时间戳的关键日志 1232021-11-23 16:18:07,621 [DEBUG] Adding dependency artifact com.xxx.xxx:xxx-client:jar:1.2.2-SNAPSHOT.2021-11-23 16:18:07,623 [DEBUG] Adding artifact: com.xxx.xxx:xxx-client:jar:1.2.2-SNAPSHOT with file: /export/mavenRepository/repository/com/xxx/xxx/xxx-client/1.2.2-SNAPSHOT/xxx-client-1.2.2-SNAPSHOT.jar to assembly location: lib/xxx-client-1.2.2-20211123.202203-4.jar.2021-11-23 16:18:07,623 [DEBUG] Adding file: /export/mavenRepository/repository/com/xxx/xxx/susf-client/1.2.2-SNAPSHOT/xxx-client-1.2.2-SNAPSHOT.jar to archive location: lib/xxx-client-1.2.2-20211123.202203-4.jar 结论：以上过程发生在Assembly插件执行阶段，其把本地仓库中的jar复制到指定的lib目录下。此时会有差异，有的保留了SNAPSHOT，有的替换为时间戳。 2. 调试Assembly插件1）获取Assembly源码 12$ git clone git@github.com:apache/maven-assembly-plugin.git$ git checkout maven-assembly-plugin-2.2.1 2）入口方法：org.apache.maven.plugin.assembly.archive.task.AddArtifactTask#execute 123456789final String fileNameMapping = AssemblyFormatUtils.evaluateFileNameMapping(outputFileNameMapping, artifact, configSource.getProject(), moduleProject, moduleArtifact, project, configSource);final String outputLocation = destDirectory + fileNameMapping;final File artifactFile = artifact.getFile();logger.debug(&quot;Adding artifact: &quot; + artifact.getId() + &quot; with file: &quot; + artifactFile + &quot; to assembly location: &quot; + outputLocation + &quot;.&quot;);if (fileMode != -1) { archiver.addFile(artifactFile, outputLocation, fileMode);} else { archiver.addFile(artifactFile, outputLocation);} 3）生成文件名：org.apache.maven.plugin.assembly.utils.AssemblyFormatUtils#evaluateFileNameMapping 打断点，查看outputFileNameMapping值为：${artifact.artifactId}-${artifact.version}${dashClassifier?}.${artifact.extension}。生成的Jar包是否是时间戳，差异处在于${artifact.version}的值。 下面代码设置artifact的context值。 123456789interpolator.addValueSource(new PrefixedObjectValueSource( &quot;artifact.&quot;, artifact));interpolator.addValueSource(new PrefixedObjectValueSource( &quot;artifact.&quot;, artifact.getArtifactHandler()));if (artifactProject != null) { interpolator.addValueSource( new PrefixedObjectValueSource( &quot;artifact.&quot;, artifactProject)); if (artifactProject.getArtifact() != null ) { interpolator.addValueSource( new PrefixedObjectValueSource( &quot;artifact.&quot;, artifactProject.getArtifact())); }} 4）TODO跟踪artifactProject何时非空 # 参考 https://stackoverflow.com/questions/2516860/maven-how-to-create-assembly-with-snapshot-artifacts-without-timestamps-file-na","link":"/2021/11/23/%E6%89%93%E5%8C%85%E5%90%8E-JAR%E5%8C%85%E5%90%8D%E4%B8%BA%E6%97%B6%E9%97%B4%E6%88%B3orSNAPSHOT/"},{"title":"抓包分析http请求超时","text":"一、问题背景EDI某商家回传场景近期高频出现Http回传商家超时现象，关键堆栈如下： 12345678910111213141516171819202122232425262728Caused by: java.net.SocketTimeoutException: Read timed out at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) at java.net.SocketInputStream.read(SocketInputStream.java:170) at java.net.SocketInputStream.read(SocketInputStream.java:141) at org.apache.http.impl.io.SessionInputBufferImpl.streamRead(SessionInputBufferImpl.java:137) at org.apache.http.impl.io.SessionInputBufferImpl.fillBuffer(SessionInputBufferImpl.java:153) at org.apache.http.impl.io.SessionInputBufferImpl.readLine(SessionInputBufferImpl.java:280) at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:138) at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:56) at org.apache.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:259) at org.apache.http.impl.DefaultBHttpClientConnection.receiveResponseHeader(DefaultBHttpClientConnection.java:163) at org.apache.http.impl.conn.CPoolProxy.receiveResponseHeader(CPoolProxy.java:157) at org.apache.http.protocol.HttpRequestExecutor.doReceiveResponse(HttpRequestExecutor.java:273) at org.apache.http.protocol.HttpRequestExecutor.execute(HttpRequestExecutor.java:125) at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:272) at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186) at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89) at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110) at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56) at org.apache.camel.component.http4.HttpProducer.executeMethod(HttpProducer.java:334) at org.apache.camel.component.http4.HttpProducer.process(HttpProducer.java:193) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ... 41 more 于是拉上云主机运维同事，京东云同事和商家侧研发，一起通过抓包来定位问题。 二、网络拓扑拓扑图如下： 为避免信息泄流，现设定如下： 1）我侧服务实例网卡：192.168.0.1 2）我侧NATGW对内网卡：192.168.1.1 3）我侧NATGW对外网卡：114.11.11.11 3）商家侧NATGW对外网卡：42.44.44.44 4）商家侧实例网卡：172.1.1.1 三、排查路径 相关同事在我侧服务实例网卡，NATGW两个网卡，商家侧NATGW两个网卡，商家侧服务实例网卡开启抓包。等待超时问题复现。超时发生后，分析如下tcp包。 1）分析我侧服务实例网卡的数据包 由图中可看出在2021-05-20 14:12:46开始连续重传了几次数据没收到商家侧响应（图不全，后面应该会一直重试30秒，同我侧NATGW） 2）分析我侧NATGW的对内网卡数据包 由图中可看出在2021-05-20 14:12:46直到14:13:15重传了30秒后，一直未收到响应，我侧发送了[FIN]结束会话。 3）分析我侧NATGW的对外网卡数据包 由图中可看出在2021-05-20 14:12:46直到14:13:15重传了30秒后，一直未收到响应，我侧发送了[FIN]结束会话。（同其对内网卡）。 4）分析商家侧NATGW对外网卡数据包 由图中可看出商家NATGW接收到请求，也执行了重传30秒超时后发送[FIN]。 5）分析商家侧NATGW对内网卡数据包 由图中可看出，建立链接后，商家内部服务实例ACK侧失败。且没有收到商家侧NATGW对外网卡的数据包。 由此可推断商家NATGW的对外网卡和对内网卡间链接中断。 6）分析商家服务实例网卡数据包 商家侧的数据包没有2021-05-20 14:12:46的HTTP类型请求，验证了上述逻辑。 三、问题结论1）原因： 我侧HTTP请求时使用的线程池，第二次请求会复用前一个TCP port。 商家侧NATGW两个网卡，检测到TCP port空闲10分钟后会断开与我侧TCP链接，当我侧再次请求且复用之前TCP port时会失败（10分钟是由上次成功的时间间隔推算得出）。 2）修改方案： 我侧HTTP请求不再使用链接池。 其他进行抓包时需要把tcp_timestamps设为0，查看方式：cat /proc/sys/net/ipv4/tcp_timestamps。参见：http://bbs.jfh.com/topic/18471","link":"/2021/05/20/%E6%8A%93%E5%8C%85%E5%88%86%E6%9E%90http%E8%AF%B7%E6%B1%82%E8%B6%85%E6%97%B6/"},{"title":"排序","text":"一、二分类目1. 快速排序 选定某值，保证两侧的值分别小于和大于该值。 12345678910111213141516171819202122public static void sort(int[] arr, int left, int right) { if (left + 1 &gt; right) { return; } int leftbak = left; int rightbak = right; int key = arr[left]; while (left &lt; right) { while (left &lt; right &amp;&amp; arr[right] &gt;= key) { right--; } arr[left] = arr[right]; while (left &lt; right &amp;&amp; arr[left] &lt;= key) { left++; } arr[right] = arr[left]; } arr[right] = key; sort(arr, leftbak, left - 1); sort(arr, left + 1, rightbak);} 含重复元素的快排-三相切分快排 //TODO 2. 归并排序 分治思路，把一个整体进行二分到最小单元，然后进行归并。归并时可视为两个有序集的合并。 123456789101112131415161718192021222324public static void sort(int[] arr, int left, int right, int[] tmp) { if (left == right) { return; } int mid = (left + right) / 2; // divde [left, right] sort(arr, left, mid, tmp); sort(arr, mid + 1, right, tmp); // merge int leftCur = left; int rightCur = mid + 1; int i = 0; while (leftCur &lt;= mid || rightCur &lt;= right) { if (leftCur &gt; mid || (rightCur &lt;= right &amp;&amp; arr[leftCur] &gt; arr[rightCur])) { tmp[i++] = arr[rightCur++]; } else { tmp[i++] = arr[leftCur++]; } } while (--i &gt;= 0) { arr[right--] = tmp[i]; }} 二、比较类目1. 选择排序 每次选取第i小的元素，进行交换排序，目标是已排序的子集是最终有序集合的前缀。 1234567891011121314151617public static void sort(int[] arr) { for (int i = 0; i &lt; arr.length - 1; i++) { int min = i; for (int j = i + 1; j &lt; arr.length - 1; j++) { if (arr[j] &lt; arr[min]) { min = j; } } swap(arr, i, min); }}public static void swap(int[] arr, int i, int j) { int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp;} 2. 插入排序 把当前元素插入已部分排好序的相应位置，目标是只关注当前元素放置合适的位置 12345678910111213public static void sort(int[] arr) { for (int i = 1; i &lt; arr.length; i++) { for (int index = i; index &gt; 0 &amp;&amp; arr[index - 1] &gt; arr[index]; index--) { swap(arr, index, index - 1); } }}public static void swap(int[] arr, int i, int j) { int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp;} 3. 冒泡排序 n个元素的集合，最多遍历n轮，目标是在每轮把错位的最大元素进行归位 123456789101112131415161718192021public static void sort(int[] arr) { // 外层循环为轮次，最多循环n次 for (int i = 0; i &lt; arr.length - 1; i++) { boolean hasSwap = false; for (int j = 0; j &lt; arr.length - i - 1; j++) { if (arr[j] &gt; arr[j + 1]) { swap(arr, j, j + 1); hasSwap = true; } } if (!hasSwap) { break; } }}public static void swap(int[] arr, int i, int j) { int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp;} 三、堆排序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class HeapSort { public void sort(int[] arr) { if (arr == null || arr.length &lt;= 1) { return; } // 1. 构建大顶堆 for (int i = 1; i &lt; arr.length; i++) { shiftUp(arr, i); } System.out.println(&quot;over&quot; + Arrays.toString(arr)); // 2. 取顶元素-排序 for (int end = arr.length - 1; end &gt; 0; end--) { swap(arr, 0, end); shiftDown(arr, end - 1); System.out.println(&quot;heap&quot; + Arrays.toString(arr)); } } void shiftDown(int[] arr, int end) { int cur = 0; int parentL; int parentR; while (true) { parentL = (cur + 1) * 2 - 1; if (parentL &gt; end) { break; } parentR = parentL + 1; int max; if (parentR &gt; end) { max = parentL; } else { if (arr[parentL] &gt; arr[parentR]) { max = parentL; } else { max = parentR; } } if (arr[max] &gt; arr[cur]) { swap(arr, cur, max); cur = max; } else { break; } } } void shiftUp(int[] arr, int i) { int parentIndex = -1; do { if (parentIndex != -1) { i = parentIndex; } parentIndex = (i + 1) / 2 - 1; if (parentIndex &lt; 0) { break; } } while (arr[i] &gt; arr[parentIndex] &amp;&amp; swap(arr, i, parentIndex)); } boolean swap(int[] arr, int left, int right) { Util.swap(arr, left, right); return true; }}","link":"/2021/09/12/%E6%8E%92%E5%BA%8F/"},{"title":"拦截器实现的细节","text":"1. 拦截器细节 前置处理按拦截器列表的顺序执行； 后置处理按拦截器列表的逆序执行； 后置处理的异常需捕获后统一抛出； 2. 代码示例 1234567891011121314151617181920212223242526272829303132public class InterceptorChain {private List&lt;IInterceptor&gt; interceptorList = new ArrayList&lt;&gt;();public void registerInterceptor(IInterceptor interceptor) { interceptorList.add(interceptor);} public void beforeHandle(Object obj, Callable task) { if (CollectionUtils.isEmpty(interceptorList)) { return; } for (IInterceptor interceptor : interceptorList) { interceptor.beforeHandle(obj, task); }}public void afterHandle(Object obj, Callable task) { if (CollectionUtils.isEmpty(interceptorList)) { return; } List&lt;Throwable&gt; throwableList = new ArrayList&lt;&gt;; for(int i = interceptorList.size(); i &gt; -1; i--) { try { interceptorList.get(i).afterHandle(obj, task); } catch (Throwable throwable) { throwableList.add(throwable); } } ExceptionUtils.throwExceptionIfNotEmpty(throwableList);}}","link":"/2020/03/31/%E6%8B%A6%E6%88%AA%E5%99%A8%E5%AE%9E%E7%8E%B0%E7%9A%84%E7%BB%86%E8%8A%82/"},{"title":"抽象假设和验证假设","text":"Created At: 2025/06/27 旧的假设这个文档也算是2025Q2针对问题函数治理的CI卡点方案的复盘。CI卡点方案开发了近一个季度，目前在3个试点业务线进行了启用，但是卡点数据不符合预期。具体而言是卡点的跳过率高达90%，且有业务线因业务迭代压力大把卡点又禁用了。 该方案基于两个假设： 业务侧有诉求和意愿：存量治理时有3个业务POC反馈，希望能增加CI卡点来增量的去治理问题函数。因为存量治理负担太大，研发没有整块的时间去治理。 MR卡点拦截率不高，研发对这种低频的、有明确年度目标的优化项有改造的意愿。 指标的结果证明这两个假设为假。即业务侧POC的诉求和一线研发的修改意愿不是等价的，两者的角色不同，行为心理也不同。POC希望有增量方案方便项目管理，研发的改造成本并没有降低。 通过对跳过的MR进行分析，发现这些MR涉及的问题函数有以下特征： 高复杂函数：用户修改行数少，表现为修改某个if条件、修改某个if块、修改某个case when、增加日志等。 重复函数组：框架类代码较多，工具误报率高。 需要补充的是高复杂函数往往是多人修改，函数复杂度是随时间逐渐劣化的，属于典型的公地悲剧。研发都希望优化该函数，但不希望自己去优化。 新的假设问题函数的治理本质是工程师文化的规则化落地，研发修改意愿不高的本质是这件事情不足够重要/收益不明朗。当然，我们可以采取自上而下的强制推改，结合红黑榜给研发压力，但是这种牺牲credit的行为无法长久，不适合做常态化的治理机制。 基于废弃代码治理过程我们验证了一个假设：下线废弃代码即使对研发开发体验提升不明显，但是工具侧自动下线代码和研发只负责确认，是可以达到公司范围推改的。 基于这个假设，针对问题函数的治理可以延伸出两个新的假设： LLM工具自动进行函数修复，研发只负责确认。可以提高治理率。 LLM工具的重构结果准确度高，研发确认成本低。 验证假设旧的假设没有做快速验证，出现了结果不符合预期的情况出现。针对新的假设，我们需要进行小成本验证。验证思路为挑选合作业务线的问题函数通过LLM进行重构，然后发起MR，和研发一起CR。从中验证新的假设：工具的准确度、研发的合入意愿。 验证通过后，再考虑自动化、流程化、平台化。 总结 对项目立项的原因/充分条件进行分析，区分哪些是假设，哪些是事实。对其中的假设进行显示声明和有步骤的验证。假设验证通过后，再进行详细的方案设计、自动化、流程化、平台化。大前研一在《思考的技术》中有几段话与本文相契，见下面引用。 区分假设和结论 不要把假设和结论混为一谈。 分析数据后所整理出来的资料，只不过是假设。但是大部分企业经营者或工商业者，就把这个假设当结论了。 区分现象和原因 他们所罗列的问题只不过是现象，而逆转现象并不是解决方案。只看到现象，绝对无法找出问题的真正原因以及能够对症下药的解决方法。日本在研讨各种议题的时候，十之八九都无法区别现象和原因，因为参与议题研讨的人根本就不具备正确的思路。 不可仅凭现象做判断。会发生某种现象，一定有其原因。但是懒得找原因，只以现象做判断，提出解决方法，这种解决方案绝不会是正确的。 思考习惯 卡宁厄姆自英国有名的贵族学校伊顿公学（Eton School）毕业后，考进了剑桥大学，是位非常典型的优等生，他对逻辑构成、重点分析都执行得非常透彻而深入。就连在一般对话时，不论我说什么，他都会咄咄逼问：“有何证据？”“你是基于什么分析而这么说的？”“为什么会有这个结论？”当时我并不了解公司其他人的做法，所以下意识地认为这应该就是麦肯锡式的做法，后来才知道，事实上根本不是这么回事。","link":"/2025/06/27/%E6%8A%BD%E8%B1%A1%E5%81%87%E8%AE%BE%E5%92%8C%E9%AA%8C%E8%AF%81%E5%81%87%E8%AE%BE/"},{"title":"数据密集型系统设计","text":"link processon","link":"/2022/01/16/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"title":"文件正确写入bom","text":"0. 什么是BOM(byte order mark, 字节序标记)？bom可认为是unicode编码格式的一个标识。bom的字符为\\uFEFF，不同编码格式下会encoding为不同的字节序，如下图： 1. BOM作用 确定字节序，大端序 or 小端序（用于16-bit,32bit编码） 确定文本流为Unicode编码格式 确定当前使用的哪种Unicode编码格式 2. 细说UTF-8下的字节序 String.valueOf(‘\\ufeff’).getBytes(“utf-8”)，得到bom在utf-8下的字节序：0xef,0xbb,0xbf 若某字符串起始字符为\\ufeff，则通过*String#getBytes(“utf-8”)*产生含bom的utf-8字节数组 3. Java写入Bom示例：1）使用PrintStream#write(int i)，该方法写入的是字节，即最低位字节 源码： 123456789101112131415161718192021222324252627282930/** * Writes the specified byte to this stream. If the byte is a newline and * automatic flushing is enabled then the &lt;code&gt;flush&lt;/code&gt; method will be * invoked. * * &lt;p&gt; Note that the byte is written as given; to write a character that * will be translated according to the platform's default character * encoding, use the &lt;code&gt;print(char)&lt;/code&gt; or &lt;code&gt;println(char)&lt;/code&gt; * methods. * * @param b The byte to be written * @see #print(char) * @see #println(char) */ public void write(int b) { try { synchronized (this) { ensureOpen(); out.write(b); if ((b == '\\n') &amp;&amp; autoFlush) out.flush(); } } catch (InterruptedIOException x) { Thread.currentThread().interrupt(); } catch (IOException x) { trouble = true; } } Demo: 1234PrintStream out = System.out;out.write('\\ufeef'); // emits 0xefout.write('\\ufebb'); // emits 0xbbout.write('\\ufebf'); // emits 0xbf 1234PrintStream out = System.out;out.write(0xef); // emits 0xefout.write(0xbb); // emits 0xbbout.write(0xbf); // emits 0xbf 2）PrintStream#print(char c)，该方法写入的char。 源码 1234567891011/** * Prints a character. The character is translated into one or more bytes * according to the platform's default character encoding, and these bytes * are written in exactly the manner of the * &lt;code&gt;{@link #write(int)}&lt;/code&gt; method. * * @param c The &lt;code&gt;char&lt;/code&gt; to be printed */ public void print(char c) { write(String.valueOf(c)); } Demo 12PrintStream out = System.out;out.print('\\ufeff'); 3）StringWriter.write(int c), 写入的是char，同PrintStream#print。 源码 123456/** * Write a single character. */ public void write(int c) { buf.append((char) c); } 参考 Byte order mark - wikipedia how-to-add-a-utf-8-bom-in-java - stackoverflow","link":"/2019/12/26/%E6%96%87%E4%BB%B6%E6%AD%A3%E7%A1%AE%E5%86%99%E5%85%A5bom/"},{"title":"断言","text":"一、业务代码中禁用Assert assert在非测试执行时是默认关闭的，需要加-ea参数才能开启； 避免非测试用例中写assert，不然会被自己蠢哭；","link":"/2020/12/24/%E6%96%AD%E8%A8%80/"},{"title":"方法返回集合的副本，避免污染","text":"1. 背景昨日晚，edi开发人员反应线上有个商家从下午3点13分开始签名校验一直失败，导致业务无法正常处理。该集群近期没有上线，重启操作，一起都是那么莫名其妙。 2. 解决路径 通过查看日志发现签名校验的原数据在3点13分前后不一致，类似如下： 1234// 3点13分前：appSercretKey{&quot;key1&quot;: value1, &quot;key2&quot;: value2}// 3点13分后：appSercretKey&quot;{\\&quot;key1\\&quot;: value1, \\&quot;key2\\&quot;: value2}&quot; 查看流程中签名原数据的el表达式，类似：${prop.appSecretKey}${fn:toJson(body)} 查看函数： 1234567891011@EDI(prefix = &quot;fn&quot;, name = &quot;toJson&quot;, desc = &quot;将obj转为Json字符串&quot;)public static String objectToJson(Object obj) { if (obj == null) { return null; } if (String.class.isInstance(obj)) { return (String) obj; } else { return JSON.toJSONString(obj); }} 中间错误的判断：1）被“反序化”节点名称迷惑，认为输入的body可能前后不一致，String或Map导致走了上面函数的不同分支；后通过日志和代码逻辑确认body没有被反序列化。2）怀疑并发产生的问题；后通过测试没有复现，并且并发的问题一般都是偶发的问题，可当时的问题是自某个时间点后问题一直都在 通过仔细对比3点13分前后的数据，发现输入之后肯定是调用了toJson的方法，导致加上了引号。并且确认上面的函数在正常情况下会因为是字符串类型直接返回。 以上，推测大概率并没有调用上面的函数，而是有商家自定义同名函数，覆盖了全局函数导致异常。通过搜索发现确实有另一个商家自定义了相同的fn:toJson函数。 通过日志查询发现就是3点13分，该商家确实有请求。 由此，返回去确认代码的逻辑发现，虽然商家的函数都是隔离的，但是在组合全局函数和商家函数时，由于全局函数返回的map不是副本，导致其他商家的函数会被注册进来。主要逻辑如下： 123456789101112 private static Map&lt;String, Method&gt; getGlobalFunctionList() { return globalFunctionMap;}public static Map&lt;String, Method&gt; getFunctionList() { Map&lt;String, Method&gt; functionList = getGlobalFunctionList(); Map&lt;String, Method&gt; partnerFunctionList = getPartnerFunctionList(); if (partnerFunctionList != null) { functionList.putAll(partnerFunctionList); } return functionList;} 总结函数的返回值，尽量是副本或者是unmodify的。否则就有被污染的风险。以上的函数也做了如下修改： 12345678910111213141516private static Map&lt;String, Method&gt; getGlobalFunctionList() { return new HashMap(globalFunctionMap);} public static Map&lt;String, Method&gt; getFunctionList() { Map ret = new HashMap(); Map&lt;String, Method&gt; functionList = getGlobalFunctionList(); if (functionList != null) { ret.putAll(functionList); } Map&lt;String, Method&gt; partnerFunctionList = getPartnerFunctionList(); if (partnerFunctionList != null) { ret.putAll(partnerFunctionList); } return ret;}","link":"/2020/03/06/%E6%96%B9%E6%B3%95%E8%BF%94%E5%9B%9E%E9%9B%86%E5%90%88%E7%9A%84%E5%89%AF%E6%9C%AC%EF%BC%8C%E9%81%BF%E5%85%8D%E6%B1%A1%E6%9F%93/"},{"title":"日常使用-Chrome","text":"一、常用插件 Chrome简洁高效得到了很多人的青睐。本文总结下我的使用习惯： 开通账号启动同步功能 DevTool 书签管理 插件 Adblock Plus - 广告拦截 Infinity - 标签业美化 OneTab - 收缩Tab页 SimpRead - 提升阅读体验 Tampermokey - 脚本管理 划词翻译 - 翻译 Autofill - 表单自动填充（对应火狐上的AutoFormer） Imagus - 鼠标悬停查看大图 Better History - 浏览器历史 蓝岚日历 - 公历，农历，节日 附图 二、常用网址 codelf-程序员变量命名 数据结构可视化 在线工具箱子 mysql官方测试数据库 三、油猴常用插件 Userscript+ : 显示当前网站所有可用的UserJS脚本 Jaeger CSDN Blog极至简化 csdn 复制 Github, code cloud md file directory 百度廣告(首尾推廣及右側廣告)清理 知乎免登录 知乎增强 解锁B站大会员番剧、B站视频解析下载；全网VIP视频免费破解去广告；全网音乐直接下载；油管、Facebook等国外视频解析下载；网盘搜索引擎破解无限下载等 四、常见问题问题1：在chrome里键盘敲击一次会出现两个字符浏览器油猴插件里的”网页复制解除”脚本引起的，禁用后恢复。","link":"/2020/01/08/%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8-Chrome/"},{"title":"日常使用-Mac","text":"一、常用软件 Cinch – 拖动到顶部最大化窗口 Go2Shell – 访达里当前位置打开终端 cdto – 访达里当前位置打开终端 iTerm2 + zsh + Oh My Zsh – 终端 iStat Menus – 系统状态监控 scrollreverser – 鼠标翻转，鼠标和触摸板独立翻转 Stats – 系统状态监控 Maccy - 剪切板工具，类似Ubuntu的Clipboard Indicator Snipaste - 剪切板工具，带pin AltTab - 同Windows AltTab，支持同应用间切换 Spectacle - 窗口最大化/在屏幕间移动窗口快捷键配置： Alfred - 快查 二、常见问题1、逻辑鼠标滚轮失灵 位置：系统偏好设置｜安全性与隐私｜隐私｜辅助功能 操作：针对逻辑驱动，未勾选的进行勾选，已勾选的取消再重新勾选。 2、Mac交换双屏幕内容 how-can-i-swap-the-primary-display-automatically-in-a-dual-monitor-setup 步骤： 下载cscreen 新建一个脚本swap_src.scpt 1do shell script &quot;/opt/homebrew/bin/cscreen -l | perl -lane 'print $F[0] if $F[1] == 2' | xargs -I id /opt/homebrew/bin/cscreen -i id -p&quot; 3.使用quicksilver绑定脚本到快捷键 3、Mac外接键盘Home/End键改为跳行首/行尾 https://blog.csdn.net/howeres/article/details/122388484 创建默认的按键映射文件 12$ mkdir -p ~/Library/KeyBindings$ vim ~/Library/KeyBindings/DefaultKeyBinding.dict 写入映射内容 12345678910111213141516171819{ /* Remap Home/End keys */ /* Home Button*/ &quot;\\UF729&quot; = &quot;moveToBeginningOfLine:&quot;; /* End Button */ &quot;\\UF72B&quot; = &quot;moveToEndOfLine:&quot;; /* Shift + Home Button */ &quot;$\\UF729&quot; = &quot;moveToBeginningOfLineAndModifySelection:&quot;; /* Shift + End Button */ &quot;$\\UF72B&quot; = &quot;moveToEndOfLineAndModifySelection:&quot;; /* Ctrl + Home Button */ &quot;^\\UF729&quot; = &quot;moveToBeginningOfDocument:&quot;; /* Ctrl + End Button */ &quot;^\\UF72B&quot; = &quot;moveToEndOfDocument:&quot;; /* Shift + Ctrl + Home Button */ &quot;$^\\UF729&quot; = &quot;moveToBeginningOfDocumentAndModifySelection:&quot;; /* Shift + Ctrl + End Button*/ &quot;$^\\UF72B&quot; = &quot;moveToEndOfDocumentAndModifySelection:&quot;;} 重启电脑 4、SentinelOne卸载后，无法联网 删除方法 系统设置 | 网络 | 过滤条件 -&gt; 停用SentinelOne并删除 5、Mac的ctrl + w失灵无法关闭浏览器标签 重新插拔键盘 6、Mac外接显示器接的键盘失灵 https://github.com/xxxzc/xps15-9570-macos/issues/58 尝试以下步骤： 1）更新已有的必要更新，重启Mac 2）重启后若仍失灵，则直接操作Mac电脑，锁屏再解锁。然后观测是否恢复 #参考https://zhuanlan.zhihu.com/p/37195261https://pilotmoon.com/scrollreverser/","link":"/2020/06/20/%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8-Mac/"},{"title":"日常使用-Ubuntu","text":"一、常用软件 使用Ubuntu作为工作机一年多，较之于Windows，有以下几个优点： 1）干扰更少，从此告别弹窗广告； 2）包管理更成熟，命令apt install xxx让安装从未如此简单； 3）开源软件更多，大都比较精巧； 4）命令操作更流畅，ssh/scp/ftp/maven/vim/git…信手拈来； 本文介绍下，Ubuntu工作机下的常用软件： 1、系统 Gnome插件 System Monitor Indicator - 顶部栏显示系统监控信息 Simple system monitor - 顶部栏显示系统监控信息 Dynamic Panel Transparency - 顶栏透明设置 Clipboard Indicator - 剪切板Gnome扩展 Remove Dropdown Arrows - 移除顶栏右侧向下箭头 Hide Activities Button - 移除顶栏左侧Activities按钮 TopIconsFix - 系统托盘修复，顶栏显示wine运行中程序 键鼠多设备共享 Synergy - 局域网多设备共享键鼠 Barrier - 局域网共享键鼠（开源） 浏览器 chrome - 浏览器 firefox - 浏览器 截图/录屏 Shutter - 截屏/编辑工具 Flameshot - 截屏/编辑工具（支持Pin功能） Peek - 录屏生成gif/mp4，便于客户答疑 翻译软件 GoldenDict - 翻译程序，可绑定有道等翻译网站，长于查词 CopyTranslator - 翻译程序，长于翻译文本 壁纸 Variety - Ubuntu壁纸管理 komorebi - 动态壁纸 音乐/视频 网易云 酷狗 VLC - 视频 办公 WPS - 办公软件 Xmind - 脑图 Typora - markdown编辑器_收费 marktext - markdown编辑器_免费 Thunderbird - 邮件 Conky - 桌面显示系统监控信息 配置 Dukto - 局域网通讯 - ubuntu 20.04安装 Tweaks - 美化 SwitchHosts openfortivpn - compatible with Fortinet VPNs zsh + ohmyzsh（自动补全 &amp; 语法提示插件）- shell 2、开发 Eclipse - Java开发 Intellij IDEA - Java开发 Sublime Text - 编辑器 Beyond Compare - 文件比较 Meld - 文件比较 JD-GUI - Java反编译 VisualVM - Java堆分析工具 Mysql Workbench - mysql客户端 Postman - http接口测试工具 SoapUI - soap测试工具 Virtual Box - 虚拟机 Terminator - 终端分屏 classpy - 查看java字节码 sshuttle - 穷人的VPN FileZilla - FTP客户端 Git - 版本控制 maven - 项目构建 Vim - 编辑器 PrettyZoo - zookeeper可视化工具 KeyStore Explorer - keytool GUI工具，管理cacerts证书库 EDIdEv SefReader - SEF文件读取工具 gvm - go版本管理工具 附桌面 二、常见问题1、重启Gnome操作Alt + F2 然后输入r，然后回车。 2、设置文件默认打开应用 文件上右键 -&gt; Properties 在Open With的tab下选择合适应用 3、Launcher增加应用图表示例增加IDEA社区版图标到任务栏 1234cd /usr/share/applications/touch jetbrains-idea.desktop # 创建文件chmod 644 jetbrains-idea.desktop # 设置权限sudo vim jetbrains-idea.desktop # 参见下面内容 12345678910[Desktop Entry] Version=1.0Type=ApplicationName=IntelliJ IDEA Community EditionIcon=/opt/idea-IC-203.7148.57/bin/idea.svgExec=&quot;/opt/idea-IC-203.7148.57/bin/idea.sh&quot; %fComment=Capable and Ergonomic IDE for JVM Categories=Development;IDE;Terminal=falseStartupWMClass=jetbrains-idea-ce 然后正常打开应用后，右键任务栏图表，会出现“Add to Favorites”。点击即可添加到任务栏。 4、开机启动程序延迟启动 参考：https://www.linuxuprising.com/2020/11/how-to-launch-startup-applications-with.html 进入以下目录找到自启动的应用desktop文件，~/.config/autostart或者/etc/xdg/autostart/； 编辑应用对应的desktop文件，可通过以下两种方式实现延迟启动： 1）配置延迟参数X-GNOME-Autostart-Delay=10 12345678910[Desktop Entry]Name=MyAppGenericName=My appComment=Application to do somethingExec=myappTerminal=falseType=ApplicationIcon=myappCategories=GNOME;GTK;UtilityX-GNOME-Autostart-Delay=10 2）命令参数增加sleep指令bash -c &quot;sleep &lt;xx&gt; &amp;&amp; &lt;original_command&gt;&quot; 123456789[Desktop Entry]Name=MyAppGenericName=My appComment=Application to do somethingExec=bash -c &quot;sleep 7 &amp;&amp; myapp&quot;Terminal=falseType=ApplicationIcon=myappCategories=GNOME;GTK;Utility 附：需要设置延迟启动的应用 软件 延迟启动方式 非延迟的问题 Synergy 延迟参数 异常：system tray is unavailable don’t close your window System Monitor Indicator sleep命令 状态栏异常显示为三个点 5、Terminal退出无响应SSH链接1）按键步骤： Enter ~，(shift + `) . 2）～？可查看帮助 3）ssh手册：man ssh 123456789101112131415161718192021222324252627282930313233343536ESCAPE CHARACTERS When a pseudo-terminal has been requested, ssh supports a number of functions through the use of an escape character. A single tilde character can be sent as ~~ or by following the tilde by a character other than those described below. The escape character must always follow a newline to be interpreted as special. The escape character can be changed in configuration files using the EscapeChar con‐ figuration directive or on the command line by the -e option. The supported escapes (assuming the default ‘~’) are: ~. Disconnect. ~^Z Background ssh. ~# List forwarded connections. ~&amp; Background ssh at logout when waiting for forwarded connection / X11 sessions to ter‐ minate. ~? Display a list of escape characters. ~B Send a BREAK to the remote system (only useful if the peer supports it). ~C Open command line. Currently this allows the addition of port forwardings using the -L, -R and -D options (see above). It also allows the cancellation of existing port- forwardings with -KL[bind_address:]port for local, -KR[bind_address:]port for remote and -KD[bind_address:]port for dynamic port-forwardings. !command allows the user to execute a local command if the PermitLocalCommand option is enabled in ssh_config(5). Basic help is available, using the -h option. ~R Request rekeying of the connection (only useful if the peer supports it). ~V Decrease the verbosity (LogLevel) when errors are being written to stderr. ~v Increase the verbosity (LogLevel) when errors are being written to stderr. 6、sudo取消输入密码 see：https://linuxconfig.org/configure-sudo-without-password-on-ubuntu-20-04-focal-fossa-linux 1234567891011121314151617181920212223242526272829303132333435$ sudo vim /etc/sudoers## This file MUST be edited with the 'visudo' command as root.## Please consider adding local content in /etc/sudoers.d/ instead of# directly modifying this file.## See the man page for details on how to write a sudoers file.#Defaults env_resetDefaults mail_badpassDefaults secure_path=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin&quot;# Host alias specification# User alias specification# Cmnd alias specification# User privilege specificationroot ALL=(ALL:ALL) ALL# Members of the admin group may gain root privileges%admin ALL=(ALL) ALL# Allow members of group sudo to execute any command%sudo ALL=(ALL:ALL) ALL# Disable sudo password for below userskivi ALL=(ALL) NOPASSWD:ALL# See sudoers(5) for more information on &quot;#include&quot; directives:#includedir /etc/sudoers.d 7、通过Chrome安装gnome扩展参考：https://zhuanlan.zhihu.com/p/36265103 1）ubuntu上执行命令： 1apt install chrome-gnome-shell 2）浏览器安装插件：chrome-gnome-shell 3）浏览器点击该插件，搜索gnome扩展并安装 8、SSH免密登陆1234567$ mkdir ~/.ssh# 修改权限$ chmod 700 ~/.ssh# 添加公钥$ vim ~/.ssh/authorized_keys# 修改权限$ chmod 600 ~/.ssh/authorized_keys 参考：man ssh or http://linuxcommand.org/lc3_man_pages/ssh1.html Directory or File Man Page Recommended Permissions Mandatory Permissions ~/.ssh/ There is no general requirement to keep the entire contents of this directory secret, but the recommended permissions are read/write/execute for the user, and not accessible by others. 700 ~/.ssh/authorized_keys This file is not highly sensitive, but the recommended permissions are read/write for the user, and not accessible by others. 600 ~/.ssh/config Because of the potential for abuse, this file must have strict permissions: read/write for the user, and not writable by others. It may be group-writable provided that the group in question contains only the user. 600 /.ssh/identity/.ssh/id_dsa~/.ssh/id_rsa These files contain sensitive data and should be readable by the user but not accessible by others (read/write/execute). 600 /.ssh/identity.pub/.ssh/id_dsa.pub~/.ssh/id_rsa.pub Contains the public key for authentication. These files are not sensitive and can (but need not) be readable by anyone. 644 9、安装中文字体https://help.accusoft.com/PrizmDoc/v12.2/HTML/Installing_Asian_Fonts_on_Ubuntu_and_Debian.html 12$ sudo apt-get install language-pack-zh*$ sudo apt-get install chinese* 10、安装微软字体https://linuxhint.com/ttf-mscorefonts-installer/ 1234567891011$ sudo add-apt-repository multiverse$ sudo apt update$ sudo apt install ttf-mscorefonts-installer# 点错时，可通过以下命令重新安装$ sudo apt install -reinstall ttf-mscorefonts-installer# 重建字体缓存$ sudo fc-cache -vr# 查看字体$ fc-list 11、配置Chrome字体 Ubuntu安装的chrome，其默认字体非等宽。阅读网页时感觉很别扭，安装完上面字体后修改chrome字体。 12、鼠标右键增加Terminator1）安装nautilus-actions 1$ sudo apt-get install nautilus-actions 2）打开软件 3）配置动作 4）配置命令 路径：/usr/bin/terminator 参数：--working-directory=%d/%b 5）首选项中取消菜单中的根菜单 6）去掉之前的’在终端打开’ 1$ sudo apt remove nautilus-extension-gnome-terminal 7）重启系统 13、多工作区间禁止任务栏共享任务栏只显示当前工作区打开的窗口的OPEN状态，参考。 1$ gsettings set org.gnome.shell.extensions.dash-to-dock isolate-workspaces true 14、配置蓝牙驱动位置 123$ cd 20201202_LINUX_BT_DRIVER$ sudo make install INTERFACE=all$ reboot 15、Dock透明度1$ gsettings set org.gnome.shell.extensions.dash-to-dock background-opacity 0.2 16、更新Chrome到最新版本12$ wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb$ sudo dpkg -i google-chrome-* 17、微信在任务栏显示两个图标1）启动微信程序 2）终端执行 12$ xprop WM_CLASSWM_CLASS(STRING) = &quot;wechat.exe&quot;, &quot;Wine&quot; 3）终端执行 12$ sudo find / -name &quot;*weixin*.desktop&quot;/home/kivi/.local/share/applications/com.qq.weixin.deepin.desktop 4）修改~/.local/share/applications/com.qq.weixin.deepin.desktop 1234567891011121314151617#!/usr/bin/env xdg-open[Desktop Entry]Encoding=UTF-8Type=ApplicationX-Created-By=Deepin WINE TeamCategories=chat;Icon=com.qq.weixin.deepinExec=&quot;/opt/apps/com.qq.weixin.deepin/files/run.sh&quot; -f %fName=WeChatName[zh_CN]=微信Comment=Tencent WeChat Client on Deepin Wine6# StartupWMClass修改为第二步获取的命令，区分大小写StartupWMClass=wechat.exe MimeType=NoDisplay=falseTerminal=false 5）重新打开微信即可 18、微信登陆后取消Wine system tray按转Gnome扩展TopIconsFix，enable即可。 19、配置gvm，使不同go版本复用mod cache1$ vim $GVM_ROOT/scripts/env/use 在gvm_use方法最后增加一行``export GOMODCACHE=’/home/{YOUR_USER_NAME}/go/pkg/mod’`。然后在执行一次命令gvm use即可。","link":"/2019/12/25/%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8-Ubuntu/"},{"title":"日常使用-杂","text":"1 VIM强制保存只读文件:w !sudo tee % 2 Typora关闭拼写检查 3 VS studio以Tab方式打开新文件settings.json里添加 1&quot;workbench.editor.showTabs&quot;: true 附加：下图为打开settings.json方式：","link":"/2021/01/31/%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8-%E6%9D%82/"},{"title":"日志先行，Debug其次","text":"1. 背景今日回想起一个月之前的一个场景，研发反馈了一个异常，大概是他传入了一个整型，调用了函数Integer.parseInt方法，但是始终报错 1234Exception in thread &quot;main&quot; java.lang.NumberFormatException: For input string: &quot;110&quot; at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) at java.lang.Integer.parseInt(Integer.java:580) at java.lang.Integer.parseInt(Integer.java:615) 2. 原因通过日志没有看出端倪，于是通过我通过远程断点调试，发现是由于数字前面存在不可见字符（输入来源是excel）。 此种场景下，通过日志无法精确定位原因，只能通过断点调试来解决； 3. 总结为了减少定位异常的时长，我们优先选择记录详细的日志，就像飞机的黑匣子一样，记录系统的运行状态，关键参数，异常信息等。 定位问题优先日志先行，然后辅之以其他手段。能通过日志解决一定要优先增加日志。","link":"/2020/08/30/%E6%97%A5%E5%BF%97%E5%85%88%E8%A1%8C%EF%BC%8CDebug%E5%85%B6%E6%AC%A1/"},{"title":"时区与时间：Mysql，JDBC，JVM","text":"0. Mysql的TimeStamp、DateTime1）TimeStamp 时间范围：’1970-01-01 00:00:01’ UTC to ‘2038-01-19 03:14:07’ UTC. 以整数格式存储，代表自epoch后的秒数。 存储大小为4个字节（不考虑小数部分），即4*8=32位，除去最高位的符号位，所能表达的最大数为2^31=2,147,483,648； 2）DateTime 时间范围：’1000-01-01 00:00:00’ to ‘9999-12-31 23:59:59’ 存储占用5个字节 1234561 bit sign (1= non-negative, 0= negative)17 bits year*13+month (year 0-9999, month 0-12)5 bits day (0-31)5 bits hour (0-23)6 bits minute (0-59)6 bits second (0-59) 40 bits = 5 bytes //来源：mysql官网 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667##### 3）时区对DateTime和TimeStamp的影响&gt; 以下为mysql官网11.2.2的测试案例&gt; 说明：unix_timestamp是当前时区相对于1970年的秒数；```shellmysql&gt; CREATE TABLE ts ( -&gt; id INTEGER NOT NULL AUTO_INCREMENT PRIMARY KEY, -&gt; col TIMESTAMP NOT NULL -&gt; ) AUTO_INCREMENT = 1;mysql&gt; CREATE TABLE dt ( -&gt; id INT NOT NULL AUTO_INCREMENT PRIMARY KEY, -&gt; col DATETIME NOT NULL -&gt; ) AUTO_INCREMENT = 1;mysql&gt; SET @@time_zone = 'SYSTEM';mysql&gt; INSERT INTO ts (col) VALUES ('2020-01-01 10:10:10'), -&gt; ('2020-01-01 10:10:10+05:30'), ('2020-01-01 10:10:10-08:00');mysql&gt; SET @@time_zone = '+00:00';mysql&gt; INSERT INTO ts (col) VALUES ('2020-01-01 10:10:10'), -&gt; ('2020-01-01 10:10:10+05:30'), ('2020-01-01 10:10:10-08:00');mysql&gt; SET @@time_zone = 'SYSTEM';mysql&gt; INSERT INTO dt (col) VALUES ('2020-01-01 10:10:10'), -&gt; ('2020-01-01 10:10:10+05:30'), ('2020-01-01 10:10:10-08:00');mysql&gt; SET @@time_zone = '+00:00';mysql&gt; INSERT INTO dt (col) VALUES ('2020-01-01 10:10:10'), -&gt; ('2020-01-01 10:10:10+05:30'), ('2020-01-01 10:10:10-08:00');mysql&gt; SET @@time_zone = 'SYSTEM';mysql&gt; SELECT @@system_time_zone;+--------------------+| @@system_time_zone |+--------------------+| EST |+--------------------+mysql&gt; SELECT col, UNIX_TIMESTAMP(col) FROM dt ORDER BY id;+---------------------+---------------------+| col | UNIX_TIMESTAMP(col) |+---------------------+---------------------+| 2020-01-01 10:10:10 | 1577891410 || 2019-12-31 23:40:10 | 1577853610 || 2020-01-01 13:10:10 | 1577902210 || 2020-01-01 10:10:10 | 1577891410 || 2020-01-01 04:40:10 | 1577871610 || 2020-01-01 18:10:10 | 1577920210 |+---------------------+---------------------+mysql&gt; SELECT col, UNIX_TIMESTAMP(col) FROM ts ORDER BY id;+---------------------+---------------------+| col | UNIX_TIMESTAMP(col) |+---------------------+---------------------+| 2020-01-01 10:10:10 | 1577891410 || 2019-12-31 23:40:10 | 1577853610 || 2020-01-01 13:10:10 | 1577902210 || 2020-01-01 05:10:10 | 1577873410 || 2019-12-31 23:40:10 | 1577853610 || 2020-01-01 13:10:10 | 1577902210 |+---------------------+---------------------+ 解释说明：a）若不指定时区偏移 DateTime与时区无关，存储和查询的操作不会做时区转换，即查询的值等于存储时的字符串表示的时间 TimeStamp与时区有关，存储时根据当前时区转为相对GMT的时间戳，查询时根据当前时区解析时间戳为当前时区的时间。 b）若指定时区偏移（since mysql 8.0.19） DateTime存储时把指定时区的Date Time转为当前时区的Date和Time，然后存储，查询时原样取出，不做时区转换。即只在存储时转换。例如：设置当前时区为System(ESG, -05:00)，insert时指定DateTime为2020-01-01 10:10:10+05:30，根据时区的东加西减算法，需要减去10:30, 得到2019-12-31 23:40:10-05:00。存储2019-12-31 23:40:10 TimeStamp存储时根据指定的时区转为相对GMT的时间戳，查询时根据当前时区解析时间戳为当前时区的时间。 1. MysqlWorkbench/Navicat1）数据库客户端可以通过命令设置session时区； 2. JDBC1）JDBC的三个配置项：useLegacyDatetimeCode，useTimezone，serverTimezone useLegacyDatetimeCode: (驱动8.0已废弃) Default: true Since: 5.1.6 Use code for DATE/TIME/DATETIME/TIMESTAMP handling in result sets and statements that consistently handles time zone conversions from client to server and back again, or use the legacy code for these datatypes that has been in the driver for backwards-compatibility? Setting this property to ‘false’ voids the effects of “useTimezone,” “useJDBCCompliantTimezoneShift,” “useGmtMillisForDatetimes,” and “useFastDateParsing.” useTimezone: (驱动8.0已废弃)Default: falseSince: 3.0.2Convert time/date types between client and server time zones (true/false, defaults to ‘false’)? This is part of the legacy date-time code, thus the property has an effect only when “useLegacyDatetimeCode=true.” serverTimezone：Since version: 3.0.2Override detection/mapping of time zone. Used when time zone from server doesn’t map to Java time zone 2）JDBC调解时区以timestamp为例，如果数据源的url时区配置为serverTimezone=GMT，则会对读取到的timestamp进行时区转换。若果当前时区为东八区，则会对时间+8； 3. 结论 不考虑SQL中指定时区，则mysql在读取或写入时不会对datetime根据时区来做转换； JDBC会调解时区，所以要保证mysql服务器和serverTimezone一致； 参考资料1.Mysql 官网11.2.2 The DATE, DATETIME, and TIMESTAMP Types10.9 Date and Time Data Type Representation（存储格式）5.1.14 MySQL Server Time Zone Support5.3 Configuration Properties for Connector/J6.3 Configuration Propertieshttps://dev.mysql.com/doc/index-connectors.html函数unix-timestamp6.5 Java, JDBC, and MySQL Types 2.其他https://stackoverflow.com/questions/7605953/how-to-change-mysql-timezone-in-a-database-connection-using-javaHow to Set the JVM Time Zonehttps://stackoverflow.com/questions/26515700/mysql-jdbc-driver-5-1-33-time-zone-issuehttps://stackoverflow.com/questions/930900/how-do-i-set-the-time-zone-of-mysql/16066034一次JDBC与MySQL因“CST”时区协商误解导致时间差了14或13小时的排错经历 时间戳（UnixTimestamp）与 《2038年问题》Java与MySQL时间戳传递/存储/协调问题–userLegacyDatetimeCode–userTimezone–serverTimezone","link":"/2020/04/28/%E6%97%B6%E5%8C%BA%E4%B8%8E%E6%97%B6%E9%97%B4%EF%BC%9AMysql%EF%BC%8CJDBC%EF%BC%8CJVM/"},{"title":"替换日志框架过程中对重构的思考","text":"新的SPI日志框架开发完成后，便着手替换之前的日志逻辑，即用新的日志框架来重构之前的代码。在这个过程中，如果遵循正确的方法会使这个周期缩短，准确率也会提高，以下是在此次重构过程中总结的几条经验。 1. 动手之前先了解日志的业务逻辑，并统计涉及修改的类 1）程序中的代码逻辑几乎都暗合具体的业务逻辑，重构已有的逻辑之前，要了解已有的逻辑。2）统计需要修改的类，预估工作量。 2. 根据业务逻辑，由主及次的对涉及到的类进行修改由主及次的去重构，基于以下的事实：1）主要的逻辑往往包含了复杂的逻辑，需要集中精力去修改；2）次要的逻辑往往逻辑比较简单，只需要机械的替换即可，不需花费太多的精力；3）随着重构时间的拉长，人的厌倦感会增加，精力会损耗;所以，由主及次的修改往往会使重构的效率大幅增加。 3. 测试阶段暂时注释旧代码（不要删除），正式发布时剔除注释的旧代码测试阶段以注释的方式保留旧代码有以下好处：1）这样方便比对，比用版本控制去溯源要方便，所见所得。2）替换时，可以很方便的查找之前已经执行的替换，直接拷贝稍作修改即可。 4. 在新的feature分支或hotfix分支上进行重构不影响已有环境。 5. 一次重构尽量控制保证变化的可测性，若过多变化需要拆解为多次重构 重构一定要结合测试，而如果要确保测试的可行性和准确性，就要控制每次重构的变化量。 重构是一个迭代的过程：重构A –&gt; 测试A –&gt; 重构B –&gt; 测试B … 如果变化过多，需要拆分。例如本次日志框架的重构的早期目标为a.替换原有的日志框架;b.修改已有的字段名称；最终我决定先完成a，因为a+b无法完整测试。 6. 初期建议本地测试，通过IDEA remote连接调试比较方便，减少（定位错误-&gt;修改-&gt;发布）的时间周期END. 写在后面针对本次日志框架的重构，我总共重构了两次，以下是耗时列表（不包含测试时间）： 次序 重构方式 旧代码处理方式 耗时 第一次 不分主次 删除旧代码 2天 第二次 先主后次 注释旧代码 0.8天","link":"/2019/11/21/%E6%9B%BF%E6%8D%A2%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%AF%B9%E9%87%8D%E6%9E%84%E7%9A%84%E6%80%9D%E8%80%83/"},{"title":"日常使用-IDEA&amp;Goland","text":"一、常用插件及配置 导入GoLand配置： File -&gt; Manage IDE Settings -&gt; Import Settings… 1. 常用插件1）IdeaVim - 集成vim基础操作 2）Maven Helper - 查看依赖树，便于排除依赖等 3）Maven Dependency Helper - 便捷查询maven坐标 4）Free Mybaits puglin - 支持接口和mapper跳转等 5）Translation - 翻译 6）SequenceDiagram - 生成时序图 7）Rainbow Brackets - 括号着色 8）GrepConsole - 日志着色 9）FindBugs-IDEA - 代码审查 10）Java Stream Debugger - Stream可视化Debug 11）GenerateAllSetter 12）leetcode editor 13）gittoolbox 14）Awesome Console - 控制台增强，如文件地址可以点击打开 2. 常用配置1）配置maven目录 2）配置编辑器的tab栏 3）配置keymap为eclipse 4）设置常用快捷键 5）跳转快捷键 场景：ctrl + Click点击函数跳转，修改为command + Click。 6）设置字体大小 7）打开内存使用器 View | Appearance | Members in Navigation Bar 8）设置用户信息 1234/** * @author wangqiwei * @date ${YEAR}/${MONTH}/${DAY} ${HOUR}:${MINUTE} */ 9）社区版Git的View中显示Local Changes 取消勾选：Settings | Preferences | Version Control |Commit 的Use non-modal commit interface 二、常见问题1. cannot find symbol尝试：1）删除.idea/ 2）执行mvn idea:module 2. External Libraries下出现Libraray root如果IDEA的”External Libraries”下出现”Libraray root”，那么其有可能和项目的pom文件的依赖有冲突，此时需要执行以下操作：1）删除.idea/2）删除xxx.iml3）重新导入工程 3. 替换tab为空格1）取消勾选 Preferences - Editor - Code Style - Java页面的Use tab character。 2）对已有的文件进行替换tab替换（如粘贴代码后可执行本操作） Edit | Convet Indents | To Spaces 4. idea的terminal中切换输入法卡死1）goto Help | Edit Custom VM options… 2）Add -Drecreate.x11.input.method=true to a new line 3）restart IDEA 参考：https://youtrack.jetbrains.com/issue/JBR-2444 5. Fix unresolved reference in GoLand 方法一 &gt;&gt; See More 方法二 6. 含中文的文件无法显示/无法创建原因：当前系统字符集问题第一步：查看当前字符集 1echo $LANG 第二步：如果不是zh_CN.UTF8，则Google安装中文字符集 第三步：按照完成后，重启IDE即可 7. Goland中的System Environment与Terminal不一致 https://intellij-support.jetbrains.com/hc/en-us/community/posts/360000497650/comments/360000793320 If you set the variable in a terminal inside the IDE, those won’t be automatically sent to the run configurations. You have to use the way mentioned above to set environment variables. Go to Run | Edit Configurations… | Templates | Go Build and set the environment variables there. Then all new run configurations will inherit those. If you wish to set the variables for the terminal specifically, then go to Settings/Preferences | Tools | Terminal | Environment Variables. Note: the environment variables set here will only affect the GoLand terminal after it’s closed and started again. And they will not affect the Run Configurations. 如果你使用的是zsh，那么你可以把变量配置到/etc/zsh/zshenv，然后source ~/.zshrc。具体原因可查看命令解释man zsh。","link":"/2020/09/01/%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8-IDEA&Goland/"},{"title":"架构度量项目复盘","text":"一、指标建设阶段1）资源有限，项目周期长 指标数量较多（23个指标），且开发人力少（1-1.5人力），项目周期验证较长（近半年才完成指标开发和看板搭建）。 2）定义了23个指标，最后经验证只有三个指标（热点代码复杂度、热点代码重复度、服务耦合）有明确的优化价值，占比13%。 初始定义多的原因：对于要度量的问题以及如何解决问题没有想清楚，期望通过较多的指标来发现问题。“定义指标→发现问题”的路径，不如“发现问题→定义指标”的路径具有落地性。另外，指标计算口径较复杂，较难理解，后期调整为简单的计算口径。 价值不高的原因：距离业务较远，难以定义出业务真正关心的指标，导致指标偏主观，陷入隔靴搔痒的境地。 试点阶段未拦截的原因：试点服务验证时未发现问题，是因为有个错误的思想“未怀疑指标有问题，而是认定服务无问题”。正确的思路是：抱着指标可能有问题，先验证指标是否有问题。即应该验证指标是否有效，然后再进行建设和推广。 二、指标推广阶段1）业务认同度低，推广成本高 架构优化收益偏长期，业务痛感不深，一线研发不愿意投入人力优化，用户价值 = (新体验 - 旧体验)- 替换成本中的用户价值不高。研发在大部门的问卷的负向反馈，也证明了这点。 2）指标度量有局限性，需要结合研发的经验进行判断，研发负担大 指标度量的内容偏通用，发现的问题抽象层级较低。 指标数据不包含业务属性、需求背景等信息，需要结合研发的经验进行判断。例如，不再迭代不需要治理、隔离性设计导致的重复、多团队协作导致的权责分散等。 这导致推广过程需要对研发进行打断，需要研发参与标记、修改、验证三个阶段，研发负担较大。 3）静态废弃代码下线项目不在预先的23个指标中，反应出架构优化方向并没有清晰的路线 早期聚焦在热点代码的治理，直播侧建设完整的静态下线工具后，在决定进行静态代码下线。 这里有两个问题：对价值的判断前后不一致；未聚焦在一个点，精力太过分散。 处于跟随者的角色，对于治理的目标和路径不清晰。 4）服务耦合要解决的问题域过大，难以推进 三、其他 早期对架构优化项目只有大体的治理思路，没有足够清晰的目标、治理路径，以及对解决问题优先级的判断。 与业务没有建立信任和协作关系，业务的架构优化需求不会上浮到本部门，业务倾向于自治或者和兄弟团队合作。另外业务团队的一些优化项目，我们由于缺失业务Context，往往觉得优化价值低，也很难想到这里有痛点问题需要解决。 业务侧对架构优化看法：业务成熟后，单点优化的空间越来越小，需要深入理解业务才能发掘出有价值的优化点。 架构理念难以统一，也是导致难以推进的一个因素。 随着架构治理的过程，发现了更多的可治理点，如MR阶段架构治理卡点、建设架构治理的平台、废弃资产治理等。这说明，有些事如果方向是对的，即便现在没有足够的数据做支撑，也可以激进一点，敢于投入，才能发现和验证其价值。","link":"/2025/01/13/%E6%9E%B6%E6%9E%84%E5%BA%A6%E9%87%8F%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%9B%98/"},{"title":"架构治理事故复盘","text":"一、架构治理事故简述废弃接口治理专项在经过平台前置校验和风险评估后，选择了通过飞书推送卡片给用户，逾期自动合入MR的策略。 平台前置校验 * 平台监测无流量120天 → 用户确认下线 → 流量灰度拦截 → 流量正式拦截 → 生成IDL接口下线MR 风险评估 IDL codegen代码场景，编译阶段提示接口不存在，不会影响线上服务 泛化调用场景，小流量上线阶段调用异常触发告警，不会造成线上高危影响 这次事故是由于未考虑到Codebase的IDL仓库有重定向所导致的IDL被多PSM复用的场景，导致删除PSM A废弃接口的同时，删除了与其共用IDL的PSM B的的接口。且IDL自动合码后，依赖PSM B的上游是定时拉取IDL最新版本进行泛化调用，没有小流量灰度阶段，导致事故发生。 二、治理原则-效率 OR 稳定性架构治理是一项在不改变系统原有功能的基础上进行的配置、IDL、代码、流程等方面的治理，旨在优化系统架构，提升系统稳定性、系统性能、研发效率。但架构治理有些专项工作的收益偏长期、业务不受益甚至要承担风险，比如废弃接口下线。 这种优化项如果作为既定目标确定要去推进，但是研发不受益导致配合度不高。就废弃接口下线来说，通过前置校验和风险评估后，从客观来讲，采取消息通知和逾期系统自动操作的方式是比较理想的。但由于这里面弱化了用户的响应，虽然提高了效率，可以达成更大、更激进的目标，但是一定程度上会有稳定的风险。一旦出现事故，整套流程就是备受质疑的点。 在实现目标时，效率和稳定性上偶尔会有冲突，目标越激进越冲突。从执行者角度来看，我起初出于目标管理和理性判断决策了自动合入的策略，但是事故之后，由于未感受到有容错机制，所以决策思路转向为稳定第一，以后的所有方案要满足程序正义。执行者没有得到制度上的容错，只能以制度作为功能设计的第一原则，不会再去量化和权衡效率、风险、稳定性，即便一个高效率方案的事故风险为千万分之一，也选择放弃。 缺乏容错和稳定第一，恐怕就是各大公司内缺乏创新的一个原因吧。我虽不愿，奈何不系之舟随波浮沉。乐观来看，自动合入导致的事故，只能说是个坏的决策结果，而不能说是坏的决策。 三、治理目标-架构治理目标管理团队和专项目标在遇到事故后，会调整稳定性的权重。由于近因效应和记忆易得性会影响事故概率的判断，会导致把稳定性的权重调增的过高。尤其是在没有机制容错的情况下，团队行事准则会变成目标和事故双导向。此时会自下而上，调整架构治理目标，降低预期。比如，审慎的砍掉所有看得见的有风险的事项，毕竟哪个团队也不想短期内出现2次事故。 目标会自底向上进行传导，逐级向上修正预期。最坏的结果是与顶层目标冲突，或者逐级修正后收益小和进展慢导致价值低估，最终导致架构治理项目停滞。转而把人力投入到短期有益、低风险的事项中去，但是当真的决定去做这样的事时，需要先问下，你真的找到这样的事了吗？还是陷入了指标陷阱，追逐数据而非解决问题。 四、方案评审-邀请拥有更多信息的人见关于会议 五、流程设计-架构治理和程序正义当无容错机制时，程序正义是唯一选择。任何通过量化手段得到的低风险评估，在事故面前都苍白无力。程序正义体现在通过卡点转移责任、通过流程体现合规、避免质疑和挑战现有的流程、不做优于少做、少做优于多做、不出问题优于解决问题。 程序正义的褒义体现在它保证了正常流转的下限，但同时僵化了流程。如果期望通过公司文化的务实创新、敢为极致等口号来解决此类问题，只是空想。响应口号需要承担打破流程、流程失灵的风险，风险由执行者承担，那么文化就只是一个大家心照不宣的笑话，无人会去遵守。 六、事故定责-制度的容错机制制度容错是指，意识到系统的复杂性，在复杂的系统中做的一些事情会有一些固有风险。意识到风险是客观存在的，无论事务的执行者是谁都无法避免，那么在制度层面给与容错，才能保持创新的持续存在。 七、事故流弊-奖惩细则决定做事原则事故流弊是指事故定责的影响。因为事故对绩效的影响，事故复盘会上往往会陷入立场争辩，而非问题求真。大家各执一词、拼声量、拼程序正义，最大程度上说着无法被证伪的谎言。事故定责，是关键事项的关键反馈，会影响个人和团队在后续做事上的原则，短则影响个人在当前公司的时间，长则影响个人的整个职业生涯。 结语先求存，再求真。","link":"/2025/12/17/%E6%9E%B6%E6%9E%84%E6%B2%BB%E7%90%86%E4%BA%8B%E6%95%85%E5%A4%8D%E7%9B%98/"},{"title":"查看文件变更","text":"一、查看文件每行修改人 当文件中的某行被别人修改后，可通过该命令查看 git blame file 二、查看文件变更记录 1、git log12git log --all file/directorygit log --graph --all file/directory 注意：当文件或目录被别人删除时，需要先在工作区间重新创建该文件或目录。因为git log后指定的文件必须在工作区存在, 否则会报错。最好加上--all选项来显示所有分支的修改历史；否则只会显示当前分支的修改，可能会因缺少相应信息导致难以理解。 2、git log –follow 针对有过rename操作的文件，需要增加–follow才会返回rename前的历史 1、命令解释 git help log中这样解释–follow参数–follow: Continue listing the history of a file beyond renames (works only for a single file). --follow参数只针对文件有效，对目录无效。Git不会跟踪目录的rename操作。 2、案例12git log A.txt # 显示红色区域的提交git log --follow A.txt # 显示蓝色区域的提交 案例一 案例二 案例三 参考 Is there a trick to git log –follow a directory which has been renamed? - Stack Overflow How to git log with renamed files - makandra dev","link":"/2018/07/17/%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E5%8F%98%E6%9B%B4/"},{"title":"模糊的异常信息让人蒙圈","text":"一、问题描述昨天，一个研发同时在使用EDI的IDE在本地运行时报错，原因是由于jsf泛化不支持枚举，把流程发布到测试环境后解决。其中有个问题令我困惑，就是异常堆栈显示的抛出异常的位置并不是真正的位置。 二、原因 发生异常的子流程设置了全局异常捕获，把异常信息封装为固定的格式返回。 直到遇到数据校验结点，校验子流程的结果时，校验失败，并抛出了校验的异常。异常信息是上个结点的数据的内容。 三、反思 产生困惑的原因是，校验结点的异常信息描述不清楚。","link":"/2019/09/27/%E6%A8%A1%E7%B3%8A%E7%9A%84%E5%BC%82%E5%B8%B8%E4%BF%A1%E6%81%AF%E8%AE%A9%E4%BA%BA%E8%92%99%E5%9C%88/"},{"title":"检出文件夹时注意事项","text":"一、使用场景使用git时有时需要恢复某个文件夹到指定的revision，命令为git checkout revision directoryPath。 二、注意事项假设仓库有两个提交A–&gt;B 1、提交详情A提交时仓库目录如下： 1234test|__dir01 |__text01.txt |__text02.txt B提交时仓库目录如下： 123456test|__dir01 |__text01.txt（修改） |__text02.txt（修改） |__text03.txt（新增） |__text04.txt（新增） 2、错误操作此时在B执行git checkout A test/dir01,结果为 1）text01.txt,text02.txt两个文件恢复到提交A的版本； 2）text03.txt,text04.txt仍会保留； 仓库目录如下所示： 123456test|__dir01 |__text01.txt（A的版本） |__text02.txt（A的版本） |__text03.txt |__text04.txt 3、目录恢复的正确命令此时在B执行rm -rf test/dir01/*和git checkout A test/dir01两个命令。 执行后仓库目录如下所示： 1234test|__dir01 |__text01.txt（A的版本） |__text02.txt（A的版本）","link":"/2019/12/18/%E6%A3%80%E5%87%BA%E6%96%87%E4%BB%B6%E5%A4%B9%E6%97%B6%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"},{"title":"架构治理的若干思考","text":"一、治理的必要性代码和服务是需求的实体化表现，是由研发活动的产物。需求的变化和研发活动的复杂性决定了软件熵增的事实。治理动作是减熵的过程，目的是为了在更长期的范围维持需求的迭代效率。例如，有些需求是偏定制的，则必然给代码引入新的判断逻辑，提高其复杂度；有些功能已经废弃了，其逻辑在代码却并未被删除；需求的变化，也导致代码逻辑的不连贯，理解和修改成本高；从人的角度来看，人员的变动、经验的不同、开发习惯不同、团队文化不同、组织奖惩机制不同都会在代码中引入更多的复杂度。另外，研发人员依赖的工具，如CI/CD、基础组件、自动化平台工具等都会反向影响编码行为。 如果不做治理，放任其自然发展，则软件复杂度必然会随时间逐渐变大。治理时间越滞后，治理成本越高。例如，某客户端和服务端的模型出现每月新增70+字段的线性膨胀问题；迭代时间较长仓库中会出现一些超高认知复杂度的函数，且仍处于频繁变更状态；更多的需求的仓库，也包含了更多的废弃代码和废弃实验。这些历史债务多多少少都被开发者感觉到了，但是其迫于需求迭代效率，上线压力，结合修改风险，往往选择忍耐和不治理，只满足当下的需求上线即可。 研发对于软件劣化的趋势的容忍是可以理解的，当与他们沟通时他们表示有意愿去重构，但是迫于上面的原因往往选择延宕重构时机。要解决这个问题，推动治理需要具备这几个条件：1）认知到治理的必要性，给研发和组织以治理的动机；认识治理的必要性在概念上，研发和组织应该很容易达成一致，难点在于治理成本和收益；2）治理不冒进；我们虽然提倡治理，但是反对不顾成本的治理；例如一个生命周期快结束的服务，就没有必要投入大成本去治理；多服务共用的模型治理，就要考虑多业务方的资源和协同，定制从增量到存量的递进策略；多服务涉及数据库表多写的架构改造，就要结合风险高低和治理成本，考虑是否优先考虑治理增量的方式；多服务域之间的跨域访问，也要结合跨域风险和建设切面管控的治理成本，进行合理的落地策略。3）治理不”机会主义”，不要因为存在困难，而处于”等等看”，”后面再说”的消极，惰性行为中。要认识到治理的越早，其成本越小。 二、架构度量指标架构问题有时不受重视可能就像“漏水的地下室”，不是不治理，而是不知道有问题。通过架构度量指标体系，可以帮助我们时时监测我们关注的指标，及时发现和预警问题，提供指标数据，驱动架构改善。 2.1 问题先于指标架构度量指标初始定义了23个指标，并耗费了近1年的时间来建设完整的指标体系，最后只有1个指标（服务开发耦合指标）不经修改的被用于架构优化专项中，转化率较低。初衷是期望通过定义指标来发现问题，这体现在定义的指标数量多、覆盖广，导致人力成本和时间成本居高不下。当不知道要解决的问题具体是什么时，就陷入了高成本的数据采集、指标定义中。 从治理效率以及是否能更好的落地来看，更好的方式是先发现问题（区分问题和现象、具体的问题、可解决的问题），对问题进行定义和诊断后再制定相应的指标来衡量问题的解决状态。也就是问题先于指标：发现问题→定义问题→定义指标→度量问题。问题需要是具体的，有具体的解决方案的，而不是抽象的，概念性的。这里要区分问题和现象，问题是缺陷和需要解决的，现象不一定是缺陷和需要解决。 例如，1）“MR影响接口数”指标期望通过MR涉及的方法及其调用链路得出影响的对外接口数，影响的接口数量多就说明接口间耦合大。其中接口耦合的概念就是抽象的，无法联想到具体的问题，也就没有具体的解决方案。尝试通过指标去发现问题，就容易陷入把现象当做问题的窠臼。接口耦合度高的仓库归因来看大都是修改了较低分层所致，如工具类，dao 层。2）另外，“服务开发耦合”指标期望通过需求中服务的共现情况来发现耦合开发的服务组。服务开发耦合也是一个较抽象的概念，归因后发现是受微服务架构影响，单个微服务的功能粒度较小，一个大的需求势必要覆盖更多的服务数量，共现开发只是一个现象，而不是一个问题。 2.2 警惕指标陷阱 《指标陷阱》详细列举的过度迷信指标带来的危害，本节强调以下3点：1）指标可能带来短期主义，大的目标往往很难去量化，能量化往往是局部的、短期的，如果组织只通过能量化的指标去考核，那么会导致那些无法量化的任务无人关心、无人去做，致使大目标的失败；2）指标可能会导致忽视经验价值；例如，美国的越战指挥官使用敌人尸体数量衡量战争局势，忽略了军队士气的决定性作用；3）指标可能会带来作弊；例如，医院如果考核医生的手术成功率，就会导致疑难杂症无人诊治； 我们发起的架构优化项目，就针对这些指标陷阱做了相应的对抗措施：1）明确告诉参与改造的研发，修改不是强制的，指标不是唯一的；要结合研发自己的判断来决定是否需要修改，我们重视指标结果，同时也重视研发的经验。2）允许研发对那些认为不需要修改的函数进行标记和说明，同时也会避免出现指标作弊，出现应付式修改。研发结合自己的判断，对那些修改成本过高、不再迭代、计划下线、废弃函数、监测异常、业务合理的函数标记为不修改，在优化项目组看来是可接受的，也是合理的。3）持续跟踪打标过程、Review打标结果、Review改造结果，防止研发在打标和改造过程中进行指标作弊。 2.3 不要迷信指标迷信指标可以说是指标陷阱的一种，指标是对需要度量的事物的有限的表达，不一定准确和完整，它可以帮助做决策，但不是比不可少。 1）要明白指标只是从某一个维度去衡量好坏，而要度量的对象往往多维度的，一个软件往往是在一定条件约束下产生的，是多方妥协统一之后的结果。一个指标可能是劣化的，而对立的另一个指标可能是优良的。例如，单体服务和微服务他们在某些指标来看可能既好又坏，如伸缩性指标，开发耦合指标。 2）指标衡量的可能是一种现象，至于这种现象是不是问题，需要细分和观测，反过来确定指标对问题发现的置信度。例如，多个服务的开发耦合指标高，只能说明他们存在一起开发耦合的现象，需要具体分析是否是必要耦合，如是否是为了运行时伸缩、隔离做的妥协，是不是微服务拆分后大需求带来的必要耦合。 3）指标可能无法真实反应现实。要根据指标指标发现问题的准确性，来适时调整指标。如果指标无法真实反应真实情况，那么考虑下掉他。 4）有些创新型的项目早期也很难有足够数据去构建指标，此时指标就不是必须的。另外要评估Oncall的成本，亲自去值班体验下可能会得到比指标更多的信息； 2.4 定义好的指标1）区分度量的现象还是问题。 例如，服务共现开发指标其实度量的是一种现象。服务共现开发不一定是问题。明确区分指标度量的是现象和问题，可以给指标置信度进行定性。并决定了其应用和推广方式，以及推广过程中研发的参与度。 2）准确的和置信的。 如果一个指标是为了发现问题，那么通过指标发现的集合里的问题比例就代表指标的准确性。例如，我们通过服务开发耦合次数作为指标去评估服务间的耦合度可能就不是一个好的指标，因为服务开发耦合可能是因为“微服务架构下服务的功能粒度较小，一个大需求确实需要修改多个微服务”，这往往被认为是正常的；诚然，会有一些因为新增响应字段导致服务级联修改的非必要耦合，但是如果这个问题场景占比很小的情况下，这个指标就失去了准确性和置信度，也就变得没有那么重要和有意义。 3）简单的可理解的。 一个好的指标不在于说运用了很多数据概念和公式，而在于简单直接可理解。例如，归一化指标不一定受[0,1]区间的约束，而非把一个指标运用加权、缩放等公式放到该区间内。公式能被直接的理解，更能让研发直观感受到要度量内容的好坏程度。 4）在精不在多。 指标数量多了会带来较高的收集成本、分析成本和改造成本。这给指标使用者、监测者带来了更多的工作量。这时候要考虑缩减指标数量：a.需要分析下是否存在同质化的指标他们都在衡量同一个内容；例如服务端架构度量指标中的函数行数指标、函数认知复杂度指标、函数圈复杂度指标三个指标就是同构的，那么就考虑只保留一个，减少建设成本。b.需要分清主次，那些是核心指标，那些是非核心指标，哪些是必要的，哪些是非必要的；c.需要明确指标作用域，哪些指标是对外，哪些是对内。对那些同质化的、次要的、非必要的指标进行删除或减少。 5）是需要改进的。 指标建立只是第一步，建立后需要制定策略去改善他。如果一个指标制定后不去改善他，那么请把它删掉。关注不需要改善的指标，没有实际意义。如果确实需要观测一些无法改变的指标，那么请明确把它标记为“观测性数据”，与指标做区分。例如架构度量指标中的MR指标，只用来观测MR变化趋势和数量，这就是观测数据，而不是指标。 2.5 验证指标和警惕自证倾向指标定义完成后，需要找试点服务进行有效性验证。验证其是否能有效发现问题（如发现问题比例）、置信度。指标验证过程需要避免自证倾向，别提前假设指标一定是正确的，它一定可以发现问题，然后带着预期去进行验证，这样会产生证实性偏差。例如架构指标在试点阶段，就没有避免自证倾向，前置认定指标是有效的，模糊了试点服务验证的目标，导致无效指标没有在试点阶段被拦截，造成后期推广阶段的人力开销。 2.6 架构指标和人效关系在治理推广过程中，经常有研发会问到”这个指标改善后会提升多少人效？”。实事求是来说：大部分的架构指标（如函数认知复杂度、服务扇入扇出等）都无法得出与人效的量化关系。代码优化和人效收益之间的逻辑链路太长，不确定性和需要做的假设太多，无法做出有意义的量化。只能定性而非定量的去看他们的关系：架构优化对人效的收益是长期的，也只是影响人效收益的一个因素，整体而言可定性为有正相干关系。 架构指标使用的目的更多的是发现架构薄弱点从而去改进它。其作为观测指标来驱动架构改进，业务只需要关注和改进它发现的问题即可。 三、专项治理到长期治理3.1 专项治理/运动式治理的优缺点1）专项治理适合短期、临时、重大的事项推进，不适合常规性事务。代码治理是一项长期的工程师文化践行事务，不能完全寄希望于专项，而抱着毕其功于一役的想法。从更长期的角度来看，需要建设一套更为易用、自动化的机制浸入到研发活动中，使其作为研发活动的一部分。 2）专项虽然无法解决根本问题，但是专项有一个优点是自上而下的关注度、投入度，以及对架构优化的认可度。这时对那些权责不清楚、历史负债大、平时畏难的重点问题可以得到治理。 3.2 长期治理的思路考虑到不同的团队有不同的工程师文化，那么代码治理的常态化方案如果要持久有效和长效运作，就需要最大限度的减少研发的治理成本。尤其是代码治理中很多治理项无法很好的量化收益的情况，降低治理成本尤为重要。 治理成本具体而言包括问题修改成本、验证成本和承担的变更风险。例如，优化高复杂函数任务，从2024Q3-2025Q2期间的存量治理和增量卡点治理来看，结果都没有达到预期。其本质原因是研发的治理成本很高（修改成本+验证成本+承担的风险）。现在看来通过LLM进行治理，结合单测覆盖和集成测试，研发只负责确认，这可以大大减小治理成本，提高修改率。 所以，长期治理的思路是： 1）让工具/平台承担大部的治理成本，研发仅负责复核和采纳治理结果。 2）易用、易理解、易操作的流程，减少研发的认知和操作负荷。 四、理想架构和实际架构的距离我们用存储耦合指标发现了存在多服务多写同一张表的问题，而当我们与这些服务的负责人沟通时，大都表示”这是个问题，但是目前不会去改”。这表明在架构治理过程中经常会出现的一个现象，即便大家都认可什么是好的架构，以及架构的优化方向，但是在实际的迭代活动中，靠研发自发的去优化和改善是不现实的。原因大概有以下几点： 1）收益难以量化：架构优化类任务收益偏长期，且难以量化。无法量化的工作，在研发的工作表就会始终锚定在重要但一点也不紧急的区域内。用户价值 = (新体验 - 旧体验) - 替换成本中的用户价值小或者感受小，难以驱动优化过程。 2）改造成本高：在代码治理早期的推改中，主要依托于“平台识别问题 → 推送给研发 → 研发修改”的治理流程。改造成本主要在研发侧，具体包含修改成本、验证成本和承担的变更风险。若改造成本高，那么研发的修改意愿必然降低。 3）考核/奖励机制：架构优化在各团队的不同投入度，也反应出leader对该工作的看法。如果Leader在绩效考核时认可架构优化工作的价值和业务功能建设是等同的，那么才能激发研发的优化动力。 4）部分标准模糊/对于好的架构无法达成一致：在一些模糊地带，如什么是好的架构在软件界没有明确清晰的规则，另外随着软件规模，该标准也会变化。这就很难引导研发去做出正确优化。且在实践中，不同的部门实践也可能大相径庭。例如，之前试图定义公司范围内的服务创建规范来使架构更加统一和易管理。但是，客观情况是不同部门对好的架构规范的理解是不一致的；另外，不同的业务可能有不同的架构妥协条件，在客观限制内构建和演进服务。这就导致很难统一认知，这件事的最后结果仅仅是产出了一个无足轻重、无人关心的架构建议文档，可以说是毫无用处。 那么，对于口径无法统一的标准，如果不是必要或有强外力推动，建议不要去强制规范，遵循客观中事物存在不统一的情况。 5）理想架构脱离实际：有的理想架构偏学院派，可以应付小而美的Demo程序或小规模软件，但是无法应用到复杂的软件中来。理想架构如果仅仅是好的、符合审美的是不够的，还应该是易懂、易用。就如秦始皇强制推行视觉美的小篆失败，最终人们用脚投票选择简单易用的隶属最终完成书同文。所以，如《毛选》所说，要从实际出发，而不是从定义出发。 五、治果还是治因无论是通过度量指标还是通过专家诊断发现潜在问题，在治理时一般都会拆分为存量治理和增量治理，其各自对应着治果和治因。 1）治果。治理已经发现的问题，通过指标的变化来衡量治理效果。 2）治因。根据对问题的理解不同、对原因可能无法达成一致，甚至会模糊直接原因和根本原因。例如，如果一个团队的超复杂函数比例比较高，其直接原因可能是需求压力大、没有code review、没有CI检测和卡点，根本原因则可能是基建能力不足、团队工程师文化缺乏。当然，有时直接原因和根本原因确实很难达成一致，这里区分直接原因和根本原因的目的在于使用5WHY（上游思维）来发现更上一层的原因，从更上游解决问题的成本更低收益更大（系统性思维中的正反馈回路）。 治理方案必然要结合治理成本及其收益来综合评估，选择一个多方可接受的方案。 六、如何驱动业务参与架构治理从2024年Q3和Q4的架构优化专项来看，这种非自上而下的、非强制的架构治理专项，能有效推动业务参与治理主要有两点： 1）治理收益明显，业务愿意投入成本去治理； 2）治理成本比较低，业务可以用较少的成本完成治理； 那些治理收益不明显或投入较高的事项，业务治理意愿不高，往往会搁置任务不做处理。例如，服务开发耦合治理仅有1/30的改造率，远远低于预期。 这给我们一些启示： 1）选择合适的治理项：从用户视角出发，选择合适的治理内容，避免自嗨：痛点 &gt; 爽点 &gt; 痒点。 2）减小研发治理成本：提高工具能力和自动化水平，让工具承担更多的治理成本，减小研发的治理成本。例如，让工具承担修改成本和验证成本，这样研发只需要承担很小的确认成本和风险。","link":"/2024/10/01/%E6%9E%B6%E6%9E%84%E6%B2%BB%E7%90%86%E7%9A%84%E8%8B%A5%E5%B9%B2%E6%80%9D%E8%80%83/"},{"title":"浏览器跨域","text":"一、什么是跨域？要先理解跨域，先理解同源的概念。1） 同源是指两个uri的协议，域名和端口三者完全一致。 2） 跨域可理解为同源的反义。 二、浏览器为什么要限制跨域？由于浏览器的Cookie是存储在一起的，浏览器并没有区分。此时如果不限制同源，则会出现CSRF。比如访问你在浏览器里先登陆了银行的网站，银行把一些敏感信息写入了Cookie，之后你访问其他网站时都会携带这个Cookie，若果被恶意网站获取就容易被盗取银行信息。 浏览器厂商Netscape 为了避免出现这种高风险的行为，于是提出同源的安全策略来**限制（不是完全禁止）**跨域的发生。 三、浏览器的同源策略各大主流浏览器都制定了自己的同源策略实现，主要有以下几类：1）Same-origin policy for DOM access，使用iframe标签场景。 – 限制比较宽松，一般允许加载；2）Same-origin policy for XMLHttpRequest，也就是ajax。– 限制比较严格。3）Same-origin policy for cookies – 限制严格，防止CSRF。 但其中共同点都是同源的限制基本都是针对脚本的（即ajax），而对Html的标签则比较宽松，基本都允许加载（但无法跨域读取）。而常见的JSONP解决跨域的思路也是通过把跨域请求伪装为的标签来实现的。 四、两种跨域解决方案 两者都需要与被访问后台服务协商，即被访问的端需要对其他域的访问做出改动。 1.JSONP **基于浏览器不限制标签跨域。**因为很多图片和JS都是共享在网络的其他域的服务器上的，禁止标签的跨域会带来很大的不便。 1） JSONP是从服务端返回的数据格式而言的。一般的Rest的返回值为JSON格式，采用JSONP来解决跨域，需要服务器返回JSON的padding格式，也就是JavaScript格式，其内容为JavaScript函数的调用。 2）简单示例 位于localserver.com的foo.html 12345678910111213&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=&quot;text/javascript&quot;&gt; function jsonp_callback(data){ console.log(data); }; &lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;http://remoteserver.com/remote.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 位于remoteserver.com的remote.js 1jsonp_callback({&quot;data&quot; : &quot;远程返回数据&quot;}); 3）使用JS和Jquery实现JSONP JS需要开发人员自己通过js代码来生成用来访问远程服务的元素; Jquery支持JSONP，在ajax里设置dataType为jsonp即可; 2.CORS 基于浏览器允许的跨域策略，需要服务端设置Access-Control-Allow-Origin 参考资料 JSONP 的工作原理，JSONP Demo讲解 为什么浏览器要限制跨域访问? 原生js和jquery两种方法实现jsonp跨域 https://en.wikipedia.org/wiki/Same-origin_policy https://www.w3.org/Security/wiki/Same_Origin_Policy https://web.dev/same-origin-policy/ https://code.google.com/archive/p/browsersec/wikis/Part2.wiki#Same-origin_policy https://developer.mozilla.org/zh-CN/docs/Web/Security/Same-origin_policy","link":"/2020/04/21/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%B7%A8%E5%9F%9F/"},{"title":"用tcpdump、wireShark分析sftp连接时readtimeout","text":"一、背景近期公司推上云，于是把某集群的非公有云机器缩容了。导致有个商家的sftp上传失败，后通过日志发现之前成功的日志也都是非公有云容器。关键堆栈如下： 1234567891011121314151617Caused by: org.apache.camel.component.file.GenericFileOperationFailedException: Cannot connect to sftp://testuser@demo.sftp.com.cn:22 at org.apache.camel.component.file.remote.SftpOperations.connect(SftpOperations.java:149) at org.apache.camel.component.file.remote.RemoteFileProducer.connectIfNecessary(RemoteFileProducer.java:214) at org.apache.camel.component.file.remote.RemoteFileProducer.recoverableConnectIfNecessary(RemoteFileProducer.java:206) at org.apache.camel.component.file.remote.RemoteFileProducer.preWriteCheck(RemoteFileProducer.java:133) at org.apache.camel.component.file.GenericFileProducer.processExchange(GenericFileProducer.java:114) at org.apache.camel.component.file.remote.RemoteFileProducer.process(RemoteFileProducer.java:58) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.SendProcessor$2.doInAsyncProducer(SendProcessor.java:178) at org.apache.camel.impl.ProducerCache.doInAsyncProducer(ProducerCache.java:445) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:173) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ... 96 moreCaused by: com.jcraft.jsch.JSchException: Session.connect: java.net.SocketTimeoutException: Read timed out at com.jcraft.jsch.Session.connect(Session.java:565) at org.apache.camel.component.file.remote.SftpOperations.connect(SftpOperations.java:121) ... 106 more 二、排查路径 预备：申请线上环境的运维权限和堡垒机，登陆线上机器； 观察以往日志里 同一台公有云机器运行时，sftp下载正常，但是上传超时 线上机器执行sftp的命令，查看是否正常 sftp通过命令连接登陆有点慢 上传和下载速度都很快，测试速度为90 kb/s 线上机器通过log4j抽取SftpOperations的日志 发现sftp的connectTimeout为10秒 且出现反复重连现象 相关日志如下： 12345678910112020-12-08 11:40:32[ JSF-BZ-22000-14-T-692:52229673 ] - [TRACE] org.apache.camel.component.file.remote.SftpOperations-connect:150 - Cannot connect due: Cannot connect to sftp://testuser@demo.sftp.com.cn:222020-12-08 11:40:33[ JSF-BZ-22000-14-T-692:52230673 ] - [TRACE] org.apache.camel.component.file.remote.SftpOperations-connect:112 - Reconnect attempt #3 connecting to + sftp://testuser@demo.sftp.com.cn:222020-12-08 11:40:33[ JSF-BZ-22000-14-T-692:52230674 ] - [TRACE] org.apache.camel.component.file.remote.SftpOperations-connect:117 - Session isn't connected, trying to recreate and connect.2020-12-08 11:40:33[ JSF-BZ-22000-14-T-692:52230674 ] - [DEBUG] org.apache.camel.component.file.remote.SftpOperations-createSession:263 - Using knownhosts file: ../conf/ssh_knownhosts2020-12-08 11:40:33[ JSF-BZ-22000-14-T-692:52230675 ] - [DEBUG] org.apache.camel.component.file.remote.SftpOperations-createSession:288 - Using known hosts information from file: ../conf/ssh_knownhosts2020-12-08 11:40:33[ JSF-BZ-22000-14-T-692:52230677 ] - [DEBUG] org.apache.camel.component.file.remote.SftpOperations-createSession:295 - Using StrickHostKeyChecking: no2020-12-08 11:40:33[ JSF-BZ-22000-14-T-692:52230677 ] - [TRACE] org.apache.camel.component.file.remote.SftpOperations-connect:120 - Connecting use connectTimeout: 10000 ...2020-12-08 11:40:39[ JSF-BZ-22000-14-T-683:52235816 ] - [TRACE] org.apache.camel.component.file.remote.SftpOperations-connect:117 - Session isn't connected, trying to recreate and connect.2020-12-08 11:40:39[ JSF-BZ-22000-14-T-683:52235816 ] - [DEBUG] org.apache.camel.component.file.remote.SftpOperations-createSession:263 - Using knownhosts file: ../conf/ssh_knownhosts2020-12-08 11:40:39[ JSF-BZ-22000-14-T-683:52235818 ] - [DEBUG] org.apache.camel.component.file.remote.SftpOperations-createSession:288 - Using known hosts information from file: ../conf/ssh_knownhosts2020-12-08 11:40:39[ JSF-BZ-22000-14-T-683:52235820 ] - [DEBUG] org.apache.camel.component.file.remote.SftpOperations-createSession:295 - Using StrickHostKeyChecking: no 线上机器执行tcpdump，然后下载本地后使用wireshark分析tcpdump -i 网卡名称 -vv host sftp域名 -w tcpdump.pcap 从wireshark里发现两个问题：1）我方机器等待对方包10秒还没有返回时，会发送FIN，表示不再接受数据2）由于我方关闭后仍收到之前sftp服务器发出的包（即RST上面的SSHv2包），我方机器会发送RST，表示重置连接 三、解决方案由以上可知sftp连接会超过10秒，故设置为30秒后解决。 NOTE：下载正常是它和上传使用的不是一套代码（下载使用的是自己封装的部分配置，而上传使用的是camel原生配置），而这两部分的默认超时时间不同。","link":"/2020/12/08/%E7%94%A8tcpdump%E3%80%81wireShark%E5%88%86%E6%9E%90sftp%E8%BF%9E%E6%8E%A5%E6%97%B6readtimeout/"},{"title":"版本管理","text":"一、应用与其依赖随着软件工程的发展，为了减小工程复杂度，分层和解耦越来越成为共识。应用也由庞大的单体应用进行了服务化拆分，单独拆分的微服务具备低复杂度、易升级、高伸缩性等优点。微服务间通过网络和其他微服务进行连接，组成了更大的逻辑应用。 为了减少代码重复和减小复杂度，在工程实践时应用代码往往也需要拆分（我们称之为功能模块），进行单独的版本控制和版本管理，原应用以依赖的形式的引入拆分的功能。这样的好处很多，如方便模块复用减少代码重复、功能模块仓库可以使用更简单的分支模型管理、功能模块的版本管理更容易。另外在面对应用定制部署时，只需要灵活组合功能模块即可，减小了复杂度。 复杂度一直是软件工程的大敌，随着软件的迭代，运维的成本也会随之升高。控制住复杂度，能更好的响应需求，延长应用的腐化时间。把应用解构为多模块以依赖的形式引入，拆分前后应用在功能逻辑上仍是同构的，但大大削减了开发，管理，运维的复杂度。 此处我们可以把拆分后的功能模块称为模块工程，依赖模块仓库的应用称为聚合工程。 二、版本管理目标版本管理的目标是保证应用稳定，通过版本划分应用功能代际，使其能平稳升级及安全回退。工程实践时：借助版本号对应用版本和应用模块（也就是应用依赖）进行管理，使应用提供的功能集与模块的版本号绑定。 版本号约定 [major version]：主版本号，重大版本升级时修改 [minor version]：次版本号，小版本升级时修改 [batch version]：修订版本号，FixBug时修改，一般只用于稳定版本。 快照版本： [major version].[minor version].0-SNAPSHOT，如1.1.0-SNAPSHOT 稳定版本： [major version].[minor version].[batch version]，如1.1.1 三、版本管理原则版本管理原则是为了实现版本管理目标，给予工程实践的一些操作指导原则，非绝对。 1、单体应用仓库拆分为按功能内聚的功能模块仓库 单体应用仓库模块复用难、多版本分支管理复杂、快速迭代难，实践时以功能簇为单位进行拆分，不同功能簇位于不同仓库。 想象一下，一个迭代需求反映在模块仓库时就很少会出现交叉开发和交叉上线现象，在可以简化分支开发模型的同时，也可以简化模块版本规划。即便出现交叉开发和上线，那么并行度也很低，此时可通过版本占位和短期发布分支解决，如下图所示。 2、功能模块仓库建议使用TBD工作流 随着GitFlow分支模型被炒的火热，好多团队也跟风的使用它作为工作流。在选择分支模型时，没有最好的，只有更合适的。 每个分支模型都有其适用的场景，GitFlow和TBD对比而言，有以下几个差异： 1）GitFlow分支类型多，目的是使开发距离主干（版本发布）更远。TBD分支则少的多，除主干分支外不会存在开发分支，开发距离主干（版本发布）更近。 2）GitFlow比TBD有更加严格的流程，往往适用于团队规模大且新手多的情况（团队成员可信度低）。TBD则推崇一天至少一次的主干合并，快速迭代，适合团队规模小和团队成员经验丰富（团队成员可信度高）。 3）GitFlow适合大型的，复杂的、开源的项目开发，而TBD则使用于小型的，低复杂度，公司内部的项目开发。 4）GitFlow由流程驱动，TBD由Team驱动。 在如上我们对单体应用进行拆分后，模块仓库的复杂度也线性下降。此时适用TBD特性，更简单的分支模型使规则更易于遵守，执行过程中噪点更少。 3、应用（即聚合工程）通过依赖方式引入和关联功能模块 应用代码拆分为多个模块仓库后，在组织应用功能时通过依赖方式引入模块功能。具体而言，Java工程实践时，把模块仓库的代码发布为Maven构件至Maven私服，应用通过pom.xml依赖对应构件的版本。 4、应用（即聚合工程）通过BOM统一约束第三方依赖 关于第三方依赖，使用Maven对Java工程进行管理时，最好使用一个BOM工程对他们进行版本约束。这样可以把第三方依赖收口到一处，将来面临依赖升级（如近期的log4j-core Bug升级）时，只需要修改一处即可。 我们当然也需要对BOM工程也进行版本管理，这样才能实现多应用环境下的灰度升级。另外建议在BOM工程里增加CHANGELOG，用来说明依赖变更的原因，便于溯源。 5、不同环境或定制部署的应用通过不同聚合工程对模块功能不同版本的依赖实现 应用拆分后还带来一个好处，那就是简化了应用的差异化部署。在应用的不同聚合工程里差异化的声明模块版本就可以实现，避免了在单体仓库管理的复杂度。 6、线上应用依赖稳定（RELEASE）的功能模块版本，而非快照版本 线上环境的聚合工程一定要使用稳定版本，因为快照版本可能被复写，无法保证不同时间打的包是一致的。为此Maven的release插件的prepareMOJO可以对此进行检测，如下的第2步。命令mvn release:prepare。 release:prepare的步骤： Check that there are no uncommitted changes in the sources Check that there are no SNAPSHOT dependencies Change the version in the POMs from x-SNAPSHOT to a new version (you will be prompted for the versions to use) Transform the SCM information in the POM to include the final destination of the tag Run the project tests against the modified POMs to confirm everything is in working order Commit the modified POMs Tag the code in the SCM with a version name (this will be prompted for) Bump the version in the POMs to a new value y-SNAPSHOT (these values will also be prompted for) Commit the modified POMs 7、应用（即聚合工程）全量引入功能模块依赖及声明版本，也就是做到declared used dependency 使用Maven进行依赖管理时，建议全量的声明应用模块的版本，避免传递依赖。Maven进行依赖调停时，可能结果并不符合你的预期，如你的期望依赖版本可能被其他路径更短的间接错误依赖短路，或者被同深度的先声明的错误间接依赖短路。 为此Maven的dependency插件的analyzeMOJO可以分析pom.xml中used and declared、used and undeclared、unused and declared的依赖集。命令：mvn dependency:analyze。在使用时，我们需要关注undeclared的依赖，unused的不用关注，因为聚合工程里原则上没有java代码，所有的模块依赖都是unused，即便一个普通工程也有很多SPI等方式加载的依赖，在编译时是unused。 8、使用版本而不是分支进行版本管理 据观察，存在一些工程直接使用分支进行版本管理，即编译时指定分支，在该分支上进行代码全量编译和打包。这属于早期单体应用仓库统一管理代码的现象，此时即便模块有版本号，那么也相当于是快照版本，每次编译都是新的快照，这使得版本号失去了意义。 应用拆分后，我们要严禁杜绝这种使用分支进行版本管理的方式。 9、模块功能版本变更时，仓库级整体变更 模块仓库包含了内聚的功能簇，也就是说模块仓库也可以聚合多个子模块。当个别模块应需求而改变时，此时建议仓库级别升级版本，而非单子模块升级。 这样做的好处很多，如： 1）管理简单，打标签无需加子模块前缀，在仓库里也容易定位变更位置。 2）整体升级可避免同一功能簇版本参差现象，当功能簇的各个子模块版本一致时，我们就可以确定当前功能簇是稳态的，而不用去检查某个版本是否处于某个安全区间，如[1.2.0, 1.4.0) 10、代码仓库内各分支应该是同构的，即潜在可合并 无论采用那种分支模型进行开发，都避免不了同一时刻多分支并存的现象。我们原则上要求，一个仓库内的多个分支应该是同构的，他们最终将通过合并（merge或cherry-pick）方式趋同。 如果两个分支处于异构态，无法进行合并那么可以认为是两个主体，应尽早拆分避免相互影响，减小复杂度。","link":"/2022/01/23/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/"},{"title":"由日志框架的异常处理引发的思考","text":"1. 背景最近在写新的基于SPI日志框架时，起初当判断当前没有Appender实例时，我会抛出异常来阻断系统。阳哥Review后建议“捕获日志框架的所有异常，不要影响应用的正常逻辑”。 2. 解决方案 参考Slf4j的实现，没有找到Appender实例时，只打印error日志。 SessionLogger设置动态代理，来catch其所有的方法，避免异常上浮。 12345678910111213141516171819private static final ThreadLocal&lt;ISessionLogger&gt; loggerThreadLocal = new ThreadLocal() { private final IAppender appender = AppenderFactory.getAsyncAppender(); @Override protected ISessionLogger initialValue() { ISessionLogger sessionLogger = new SessionLoggerImpl(); sessionLogger.setAppender(appender); return (ISessionLogger) Proxy.newProxyInstance(getClass().getClassLoader(), new Class[]{ISessionLogger.class}, (proxy, method, args) -&gt; { try { Object ret = method.invoke(sessionLogger, args); return ret; } catch (Throwable throwable) { return null; } }); } }; 3. 反思一个系统的异常处理逻辑要分模块的去考虑，考虑该模块在系统的所处的位置。 日志框架是系统的辅助模块。它的异常不能上浮到应用逻辑里，即不能因为日志记录异常而影响整个系统的业务处理。 不久前开发的Maven插件用来编译生成线上的运行包。如果执行异常，则其生成的代码大概率是错误的。此时一定要抛出异常来中断Maven打包过程，避免运行错误的代码。","link":"/2019/11/11/%E7%94%B1%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6%E7%9A%84%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E5%BC%95%E5%8F%91%E7%9A%84%E6%80%9D%E8%80%83/"},{"title":"看堆栈，勿急躁","text":"总结昨日，遇到有个异常堆栈，由于只重点关注了最后的causeby，忽略了前面重要的异常信息（Encode esponse error），导致定位时间加长。 此次经历的教训是，观察异常堆栈不能急躁，要一层一层的往下看。这样才能更快定位错误。 附异常堆栈123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103com.jd.edi.utils.exception.runtime.ProcessorRunningException: Encode response error at com.jd.lsb.edi.flow.camel.processor.exception.ExceptionProcessor.process(ExceptionProcessor.java:66) at org.apache.camel.processor.DelegateSyncProcessor.process(DelegateSyncProcessor.java:63) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.FatalFallbackErrorHandler.process(FatalFallbackErrorHandler.java:82) at org.apache.camel.processor.RedeliveryErrorHandler.deliverToFailureProcessor(RedeliveryErrorHandler.java:1063) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:474) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:97) at com.jd.lsb.edi.flow.camel.processor.redirect.SubflowProcessor.processSync(SubflowProcessor.java:63) at com.jd.lsb.edi.flow.camel.processor.redirect.SubflowProcessor.process(SubflowProcessor.java:50) at org.apache.camel.processor.DelegateSyncProcessor.process(DelegateSyncProcessor.java:63) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.processor.Pipeline.process(Pipeline.java:138) at org.apache.camel.processor.Pipeline.process(Pipeline.java:101) at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201) at org.apache.camel.component.direct.DirectProducer.process(DirectProducer.java:62) at org.apache.camel.processor.SharedCamelInternalProcessor.process(SharedCamelInternalProcessor.java:186) at org.apache.camel.processor.SharedCamelInternalProcessor.process(SharedCamelInternalProcessor.java:86) at org.apache.camel.impl.ProducerCache$1.doInProducer(ProducerCache.java:541) at org.apache.camel.impl.ProducerCache$1.doInProducer(ProducerCache.java:506) at org.apache.camel.impl.ProducerCache.doInProducer(ProducerCache.java:369) at org.apache.camel.impl.ProducerCache.sendExchange(ProducerCache.java:506) at org.apache.camel.impl.ProducerCache.send(ProducerCache.java:246) at org.apache.camel.impl.DefaultProducerTemplate.send(DefaultProducerTemplate.java:148) at com.jd.lsb.edi.flow.camel.EdiProducerTemplate.request(EdiProducerTemplate.java:28) at com.jd.lsb.edi.flow.camel.service.impl.CamelFlowEngineImpl.executeFlow(CamelFlowEngineImpl.java:450) at com.jd.lsb.edi.service.provider.invoker.AbstractProviderInvoker.startFlow(AbstractProviderInvoker.java:119) at com.jd.lsb.edi.service.http.provider.invoker.HttpProviderInvoker.executeProcess(HttpProviderInvoker.java:36) at com.jd.lsb.edi.service.http.provider.invoker.HttpProviderInvoker.executeProcess(HttpProviderInvoker.java:14) at com.jd.lsb.edi.service.provider.invoker.AbstractProviderInvoker.invoke(AbstractProviderInvoker.java:62) at com.jd.lsb.edi.service.provider.invoker.AbstractServiceProvider.execute(AbstractServiceProvider.java:86) at com.jd.lsb.edi.service.provider.publisher.AbstractInvokePublisher.executeServiceProvider(AbstractInvokePublisher.java:173) at com.jd.lsb.edi.service.provider.publisher.AbstractInvokePublisher.invoke(AbstractInvokePublisher.java:74) at com.jd.lsb.edi.service.http.provider.publisher.HttpServicePublisher.invoke(HttpServicePublisher.java:43) at com.sun.proxy.$Proxy47.processHttp(Unknown Source) at sun.reflect.GeneratedMethodAccessor829.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at com.jd.jsf.gd.filter.ProviderInvokeFilter.reflectInvoke(ProviderInvokeFilter.java:140) at com.jd.jsf.gd.filter.ProviderInvokeFilter.invoke(ProviderInvokeFilter.java:100) at com.jd.jsf.gd.filter.ProviderConcurrentsFilter.invoke(ProviderConcurrentsFilter.java:62) at com.jd.jsf.gd.filter.ProviderTimeoutFilter.invoke(ProviderTimeoutFilter.java:39) at com.jd.jsf.gd.filter.ProviderMethodCheckFilter.invoke(ProviderMethodCheckFilter.java:78) at com.jd.jsf.gd.filter.ProviderInvokeLimitFilter.invoke(ProviderInvokeLimitFilter.java:54) at com.jd.jsf.gd.filter.ProviderHttpGWFilter.invoke(ProviderHttpGWFilter.java:47) at com.jd.jsf.gd.filter.ProviderGenericFilter.invoke(ProviderGenericFilter.java:118) at com.jd.jsf.gd.filter.ProviderContextFilter.invoke(ProviderContextFilter.java:73) at com.jd.jsf.gd.filter.ExceptionFilter.invoke(ExceptionFilter.java:49) at com.jd.jsf.gd.filter.SystemTimeCheckFilter.invoke(SystemTimeCheckFilter.java:79) at com.jd.jsf.gd.filter.FilterChain.invoke(FilterChain.java:275) at com.jd.jsf.gd.server.ProviderProxyInvoker.invoke(ProviderProxyInvoker.java:67) at com.jd.jsf.gd.server.JSFTask.doRun(JSFTask.java:123) at com.jd.jsf.gd.server.BaseTask.run(BaseTask.java:27) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: Encode response error at com.jd.lsb.edi.component.jsf.JsfProducer.process(JsfProducer.java:98) at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:148) at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548) ... 56 moreCaused by: com.jd.jsf.gd.error.JSFCodecException: Encode response error at com.jd.jsf.gd.codec.hessian.HessianCodec.encode(HessianCodec.java:92) at com.jd.jsf.gd.protocol.JSFProtocol.encode(JSFProtocol.java:125) at com.jd.jsf.gd.protocol.ProtocolUtil.encode(ProtocolUtil.java:47) at com.jd.jsf.gd.server.JSFTask.doRun(JSFTask.java:148) ... 6 moreCaused by: java.lang.RuntimeException: Serialized class com.jd.eclp2.wms.rtw.domain.domains.RtwMainQuerySimpleResult must implement java.io.Serializable Java field: private java.util.List com.jd.eclp2.wms.rtw.domain.common.Page.aaData Java field: private com.jd.eclp2.wms.rtw.domain.common.Page com.jd.eclp2.wms.rtw.domain.response.RtwCommonPageResponse.pageResult at com.jd.com.caucho.hessian.io.JavaSerializer$FieldSerializer.serialize(JavaSerializer.java:315) at com.jd.com.caucho.hessian.io.JavaSerializer.writeInstance(JavaSerializer.java:263) at com.jd.com.caucho.hessian.io.JavaSerializer.writeObject(JavaSerializer.java:227) at com.jd.com.caucho.hessian.io.Hessian2Output.writeObject(Hessian2Output.java:408) at com.jd.jsf.gd.codec.hessian.HessianCodec.encodeResponse(HessianCodec.java:175) at com.jd.jsf.gd.codec.hessian.HessianCodec.encode(HessianCodec.java:84) ... 9 moreCaused by: java.lang.RuntimeException: Serialized class com.jd.eclp2.wms.rtw.domain.domains.RtwMainQuerySimpleResult must implement java.io.Serializable Java field: private java.util.List com.jd.eclp2.wms.rtw.domain.common.Page.aaData at com.jd.com.caucho.hessian.io.JavaSerializer$FieldSerializer.serialize(JavaSerializer.java:315) at com.jd.com.caucho.hessian.io.JavaSerializer.writeInstance(JavaSerializer.java:263) at com.jd.com.caucho.hessian.io.JavaSerializer.writeObject(JavaSerializer.java:227) at com.jd.com.caucho.hessian.io.Hessian2Output.writeObject(Hessian2Output.java:408) at com.jd.com.caucho.hessian.io.JavaSerializer$FieldSerializer.serialize(JavaSerializer.java:313) ... 14 moreCaused by: java.lang.IllegalStateException: Serialized class com.jd.eclp2.wms.rtw.domain.domains.RtwMainQuerySimpleResult must implement java.io.Serializable at com.jd.com.caucho.hessian.io.SerializerFactory.getDefaultSerializer(SerializerFactory.java:269) at com.jd.com.caucho.hessian.io.SerializerFactory.getSerializer(SerializerFactory.java:243) at com.jd.com.caucho.hessian.io.Hessian2Output.writeObject(Hessian2Output.java:406) at com.jd.com.caucho.hessian.io.CollectionSerializer.writeObject(CollectionSerializer.java:102) at com.jd.com.caucho.hessian.io.Hessian2Output.writeObject(Hessian2Output.java:408) at com.jd.com.caucho.hessian.io.JavaSerializer$FieldSerializer.serialize(JavaSerializer.java:313) ... 18 more","link":"/2020/11/13/%E7%9C%8B%E5%A0%86%E6%A0%88%EF%BC%8C%E5%8B%BF%E6%80%A5%E8%BA%81/"},{"title":"看源码的姿势","text":"一、前置问题 为什么看源码？ 看源码的方式有哪些？ 二、看源码是指看优秀的源码看源码的初衷有很多： 1）为了学习好的编码规范； 2）为了学习设计模式； 3）为了定位问题原因； 4）为了了解运行原理； 5）等等 三、看源码三级别1. 雾里看花：佛系看源码；1）收获较小，过目既忘； 2）属于碧海潮生铺面而来，最终一场空； 2. 众里寻他千百度：带着问题看源码；1）通过这种方式你会收获问题的解决方案； 2）属于单向信息流，能被很好的接收。 3. 高山流水遇知音：带着问题和自己的解决方案，然后看源码；1）通过这种方式你不仅会收获问题的解决方案，同时也可以学到如何优化你的方案，等于是源码作者教你重构代码； 2）一种双向的信息流； Note：本方法是我亦师亦友的同事告诉我的，听完之后感觉醍醐灌顶； 四、看源码的方法1）先尝试读源码注释（类注释，方法注释） 2）先试想下自己会如何实现，对比着看源码 3）可以只关注主干逻辑，次要逻辑可跳过（如异常处理、分支处理逻辑） 3）断点调试，写不同场景的测试用例、打断点、观察对应变量 4）复杂功能，边读源码边画图（流程图、结构图、类图等） *","link":"/2020/05/14/%E7%9C%8B%E6%BA%90%E7%A0%81%E7%9A%84%E5%A7%BF%E5%8A%BF/"},{"title":"科学的剥离其他中间件","text":"一、背景近期在商家内部本地部署EDI时，遇到一个问题： 1）商家内部没有不具备JSF注册中心等基础设施； 2）EDI应用代码中使用JSF与京东内部服务交互，其贯穿了管理端和运行时； 3）JSF线程启动时，如果连接注册中心失败会阻塞应用启动； 二、操作解决该问题时先后进行了两种操作方式： 第一种方式1）操作：代码中移除JSF的Provider和Consumer定义，然后对应在使用其服务时增加判空逻辑； 2）结果：当尝试通过第一种方式去移除JSF依赖时，发现工作量不可控，且对应用端代码改动很大。 第二种方式1）操作：修改JSF集成Spring时的FactoryBean，通过同名复写的方式重写其生成Consumer和Provider Bean的逻辑——生成默认的哑对象。最终达到，使JSF静默。从而避免修改应用层代码。 通过阅读其源码发现，其JSF有一个配置当其处于JUNIT模式时，会处于哑模式。 2）结果：通过配置把JSF配置为JUNIT模式后，在无修改应用代码的情况下完成应用正常启动和运行 三、结论一个问题的解决位点可能有多个，在动作前要思考完整的场景，综合考虑其优缺点，然后择优做之。","link":"/2021/08/27/%E7%A7%91%E5%AD%A6%E7%9A%84%E5%89%A5%E7%A6%BB%E5%85%B6%E4%BB%96%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"title":"第三方组件的中间层","text":"1. 背景最近在写一个rpc的中间层，目前主要为了屏蔽jsf两个版本的差异，并为以后兼容dubbo提供基础。 2. 早期尝试最早实现的方式是，依照Jsf当前的类抽象出对应的通用类，实现一套自定义的接口，异常及工厂类。由此遇到的问题是： POJO转换比较繁琐； 工厂类的逻辑实现繁琐； 与具体实现耦合太高； 3. 最后方案我把demo给阳哥review后，阳哥说这样耦合太重。整改如下： 改为简单的抽象接口，提高灵活度; 通过map传递参数; 把装配的逻辑放在底层实现; 把中间层做薄 接口定义如下： 12345public interface IRpcService { &lt;T&gt; T createConsumer(Class&lt;T&gt; clazz, Map options); &lt;T&gt; IProviderConfig&lt;T&gt; createProvider(Class&lt;T&gt; clazz, Map options);} 4. 反思针对第三方的组件做中间层，如果直接以代理的方式来实现会耦合太高，反之抽象出简单的接口，把中间层做薄，会更加的灵活","link":"/2019/12/03/%E7%AC%AC%E4%B8%89%E6%96%B9%E7%BB%84%E4%BB%B6%E7%9A%84%E4%B8%AD%E9%97%B4%E5%B1%82/"},{"title":"签名验证异常","text":"1. 背景前两天edi的开发和商家联调时，根据双方协定的签名规则生成签名后，访问商家，商家侧返回验证失败； 2. 解决路径 我获取了edi侧的签名源数据和签名结果，发送给商家开发人员，让其对比差异； 商家开发人员对比出商家侧的body体中多了转义字符“\\”（此步商家侧判断错误，导致第三步走了弯路）; 我查看了双方的文档和代码后确认我方发送给商家的body体转义无误；然后重新让商家侧对比差异； 商家侧重新对比后发现是我方body体中有个“+”，在商家侧被解析成了空格; 由此判断是由于UrlEncode问题，url编码会把空格编码为“+”； 3. 原因 京东侧请求商家的Http请求类似： 123456POST 商家urlHTTP/1.1Host: test-gateway.jdwl.comContent-Type: application/x-www-form-urlencodedcontext=abcdef+abcdef 其中的context的值包含了需要urlEncode的字符“+”，但由于我们edi流程结点的配置方式，使得edi框架暂时无法对所有的键值进行UrlEncode操作，需要开发手动增加；而此处开发忘记加UrlEncode导致数据无法正常发送给商家侧； 商家侧接收到数据后，先进行UrlDecode，把context的“+”解析为空格。导致双方签名的源数据不一致，而验签失败。 4. 解决方案京东侧对参数增加UrlEncode后验签通过。","link":"/2020/03/20/%E7%AD%BE%E5%90%8D%E9%AA%8C%E8%AF%81%E5%BC%82%E5%B8%B8/"},{"title":"类加载机制","text":"一、前置问题 类加载顺序是什么？是严格有序的吗？ 验证过程验证的什么内容？ 什么是双亲委派？为什么要采用双亲委派？ 什么是全盘委托？ 什么情况下需要自定义类加载器？ 三种类加载器分别加载哪里的类？ ClassLoader,URLClassLoader, AppClassLoader的各自职责？ findClass和loadClass的区别? UrlClassPath的实现原理？ 自定义类加载器一般需要实现哪个方法？ 自己写一个String类可以被classloader加载吗？ 类加载到哪里了？方法区还是堆？ 二、JVM结构图 三、类加载顺序1、加载顺序 类加载是指类加载器把类字节码加载到方法区，然后在堆上创建对应的class对象来封装对方法区的数据结构。 加载 -&gt; 验证 -&gt; 准备 -&gt; 解析 -&gt; 初始化 1）加载：classloader从其可见的资源路径中加载指定的java字节码，即class文件； 2）验证：验证class文件的正确性； 3）准备：给类的静态变量分配空间并赋予默认值； 4）解析：解析符号引用为直接引用，其中符号指类的静态方法的方法名替换为该方法所在的内存地址指针，也叫直接引用 5）初始化：执行类构造器方法，即把类的静态变量初始化为指定的值，执行静态代码块。 这个顺序是开始执行的顺序，不是串行执行，通常是在一个过程执行中触发下一个过程。 2、ClassLoader.load vs Class.forName1）方法说明123456789101112// initialize：是否执行类初始化操作，即是否执行&lt;cinit&gt;方法。Class.forName(String className, boolean initialize, ClassLoader loader)// 等价于：Class.forName(String className, true, currentLoader)// currentLoader为`真正加载当前类的classLoader`（最后被委托的类加载器，执行defineClass方法的类加载器实例），`非线程上下文的ClassLoader`Class.forName(String className)// resolve：是否解析类，即是否解析符号为直接地址ClassLoader.load(String className, boolean resolve)// 等价：ClassLoader.load(String className, false)ClassLoader.load(String className) 2） 关联点Class.forName最终也是调用ClassLoader去加载类的。 3）区别I、是否执行类初始化操作 Class.forName可以控制是否执行类初始化操作； ClassLoader不会触发类初始化操作； 案例：数据库驱动需要使用Class.forName来触发静态库注册驱动； II、是否会解析数组类型 Class.forName会解析数组类型，如[Ljava.lang.String; ClassLoader不会解析数组类型，加载时会抛出ClassNotFoundException; III、是否有缓存 类是缓存真正加载类的ClassLoader里的，此时需要避免委托给应用类加载器，而使用自定义类加载器去加载类；考虑打破双亲委派或指定AppClassLoader不可见路径； 只要指定每次加载类的ClassLoader即可实现热加载； 12345678910111213141516171819202122232425262728293031323334353637383940public class HotLoadClassTest { private final File path = new File(&quot;/Users/kivi/Documents&quot;); @Test public void testClassForName() throws Throwable { Class aClass = Class.forName(&quot;MyString&quot;, true, new MyClassLoader(new URL[]{path.toURL()})); aClass.getDeclaredMethod(&quot;echo&quot;).invoke(null); /** 替换MyString实现，可加载最近类 **/ aClass = Class.forName(&quot;MyString&quot;, true, new MyClassLoader(new URL[]{path.toURL()})); aClass.getDeclaredMethod(&quot;echo&quot;).invoke(null); } @Test public void testClassLoader() throws Throwable { Class&lt;?&gt; aClass = new MyClassLoader(new URL[]{path.toURL()}).loadClass(&quot;MyString&quot;); aClass.getDeclaredMethod(&quot;echo&quot;).invoke(null); /** 替换MyString实现，可加载最近类 **/ aClass = new MyClassLoader(new URL[]{path.toURL()}).loadClass(&quot;MyString&quot;); aClass.getDeclaredMethod(&quot;echo&quot;).invoke(null); } public static class MyClassLoader extends URLClassLoader { public MyClassLoader(URL[] urls) { super(urls); }}public class MyString { private static int invokeTime = 0; static { System.out.println(&quot;here is MyString static block&quot;); } public static void echo() { System.out.println(&quot;第&quot; + (invokeTime++) + &quot;次被调用&quot;); }} 4）数据库驱动注册与Class.forName1234567891011121314package com.mysql.cj.jdbc;public class Driver extends NonRegisteringDriver implements java.sql.Driver { public Driver() throws SQLException { } // 数据库驱动注册时必须使用Class.forName加载类，以此来保证执行注册逻辑的静态代码块 static { try { DriverManager.registerDriver(new Driver()); } catch (SQLException var1) { throw new RuntimeException(&quot;Can't register driver!&quot;); } }} 四、类加载器1、加载器类型 加载器 实现 加载路径 备注 启动类加载器 C++实现 加载jre/lib下的rt.jar等核心包 扩展类加载器 Java实现 加载jre/lib/ext扩展目录的包 Lancher的内部类 应用加载器 Java实现 加载classpath的包 Lancher的内部类 自定义类加载器 Java实现 自定义路径 2、类继承结构 类 职责 关键方法 ClassLoader 1）实现双亲委派；2）加载类字节码到内存； loadClass(), defineClass() URLClassLoader 根据URL定位资源 findClass(), getResource(), getResources() AppClassLoader 定义应用类加载器的资源路径（System.getProperty(“java.class.path”)） ExtClassLoader 定义扩展类加载器的资源路径（System.getProperty(“java.ext.dirs”)） 五、双亲委派和全盘委托 1）双亲委派是指先由父加载器去加载，如果父加载器无法找到类，再由自身加载。 2）全盘委托是指当一个ClassLoader装载一个类时，除非显示地使用另一个ClassLoader，否则该类所依赖及引用的类也由这个CladdLoader载入。 六、SPI的ServiceLoader加载类原理由于ServcieLoader类加载器的是启动类加载器，其无法加载应用的类，故获取当前线程的上下文类加载器来加载META-INF/services下声明的类。 123456public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt; { public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) { ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl); }} 七、自定义类加载器应用开发时有些业务场景往往需要自定义类加载器，原因一般有以下几种： 1）资源隔离；例如多租户系统，Tomcat的多应用等 2）热加载，热部署； 3）加载非classpath中的资源； 以上的情景中有些需要打破双亲委派； 八、自定义的java.lang.String类无法被加载1）如果不自定义类加载器，则双亲委派机制始终加载rt.jar的String类； 2）如果自定义类加载器，打破双亲委派，但是由于defineClass里约束了不能加载以*java.*起始的类，会抛出异常。 1234567891011121314151617181920212223242526272829public abstract class ClassLoader { protected final Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len, ProtectionDomain protectionDomain) throws ClassFormatError { protectionDomain = preDefineClass(name, protectionDomain); String source = defineClassSourceLocation(protectionDomain); Class&lt;?&gt; c = defineClass1(name, b, off, len, protectionDomain, source); postDefineClass(c, protectionDomain); return c; } private ProtectionDomain preDefineClass(String name, ProtectionDomain pd) { if (!checkName(name)) throw new NoClassDefFoundError(&quot;IllegalName: &quot; + name); // Note: Checking logic in java.lang.invoke.MemberName.checkForTypeAlias // relies on the fact that spoofing is impossible if a class has a name // of the form &quot;java.*&quot; if ((name != null) &amp;&amp; name.startsWith(&quot;java.&quot;)) { throw new SecurityException (&quot;Prohibited package name: &quot; + name.substring(0, name.lastIndexOf('.'))); } if (pd == null) { pd = defaultDomain; } if (name != null) checkCerts(name, pd.getCodeSource()); return pd; }} 九、sun.misc.Launcher类该类初始化时主要执行以下动作： 1）初始化扩展类加载器，parentClassLoader为null（因为启动类加载器由c++实现）； 2）初始化应用类加载器，并设其parentClassLoader为扩展类加载器； 3）设置sun.misc.Launcher#loader为应用类加载器；（java.lang.ClassLoader#getSystemClassLoader返回的就是该字段） 4）设置当前线程的ContextClassLoader为应用类加载器； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public Launcher() { // Create the extension class loader ClassLoader extcl; try { extcl = ExtClassLoader.getExtClassLoader(); } catch (IOException e) { throw new InternalError( &quot;Could not create extension class loader&quot;, e); } // Now create the class loader to use to launch the application try { loader = AppClassLoader.getAppClassLoader(extcl); } catch (IOException e) { throw new InternalError( &quot;Could not create application class loader&quot;, e); } // Also set the context class loader for the primordial thread. Thread.currentThread().setContextClassLoader(loader); // Finally, install a security manager if requested String s = System.getProperty(&quot;java.security.manager&quot;); if (s != null) { // init FileSystem machinery before SecurityManager installation sun.nio.fs.DefaultFileSystemProvider.create(); SecurityManager sm = null; if (&quot;&quot;.equals(s) || &quot;default&quot;.equals(s)) { sm = new java.lang.SecurityManager(); } else { try { sm = (SecurityManager)loader.loadClass(s).newInstance(); } catch (IllegalAccessException e) { } catch (InstantiationException e) { } catch (ClassNotFoundException e) { } catch (ClassCastException e) { } } if (sm != null) { System.setSecurityManager(sm); } else { throw new InternalError( &quot;Could not create SecurityManager: &quot; + s); } }","link":"/2020/06/10/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/"},{"title":"算法题型总结","text":"一、链表常见题1、链表翻转方法 递归后序遍历进行处理 图示 123456789101112131415161718192021222324252627282930/*** 25.K个一组反转链表*/public ListNode reverseKGroup(ListNode head, int k) { ListNode cursor = head; int count = 0; while (count &lt; k &amp;&amp; cursor != null) { cursor = cursor.next; count++; } if (count &lt; k) { return head; } ListNode newHead = doReverse(head, cursor); ListNode next = reverseKGroup(cursor, k); head.next = next; return newHead;}private ListNode doReverse(ListNode node, ListNode target) { if (node.next == target) { // 最后一个节点 return node; } ListNode head = doReverse(node.next, target); ListNode tmp = node.next.next; node.next.next = node; node.next = tmp; return head;} 题目 奇升偶降链表排序 206. 反转链表 25. K 个一组翻转链表 2、链表合并方法 空头节点、双指针、优先级队列 题目 奇升偶降链表排序 3、链表遍历方法 空头节点、快慢指针 123456789101112131415161718192021/*** 287. 寻找重复数* 给定一个包含 n + 1 个整数的数组 nums ，其数字都在 [1, n] 范围内（包括 1 和 n），可知至少存在一个重复的整数。* 假设 nums 只有 一个重复的整数 ，返回 这个重复的数 。* 你设计的解决方案必须 不修改 数组 nums 且只用常量级 O(1) 的额外空间。**/public int findDuplicate(int[] nums) { int slow = 0; int fast = 0; do { slow = nums[slow]; fast = nums[nums[fast]]; } while(slow != fast); fast = 0; while (slow != fast) { fast = nums[fast]; slow = nums[slow]; } return slow;} 题目 138. 复制带随机指针的链表 141. 环形链表 142. 环形链表 II 287. 寻找重复数 - 可视为找环形链表入口 143. 重排链表 二、字符串常见题1、字符匹配方法 动态规划+备忘录，KMP 12345678910111213141516171819202122232425262728public class KMP { private int[][] dp; private String pat; public KMP(String pat) { this.pat = pat; int M = pat.length(); // dp[状态][字符] = 下个状态 dp = new int[M][256]; // base case dp[0][pat.charAt(0)] = 1; // 影子状态 X 初始为 0 int X = 0; // 当前状态 j 从 1 开始 for (int j = 1; j &lt; M; j++) { for (int c = 0; c &lt; 256; c++) { if (pat.charAt(j) == c) dp[j][c] = j + 1; else dp[j][c] = dp[X][c]; } // 更新影子状态 X = dp[X][pat.charAt(j)]; } } public int search(String txt) {...}} 题目 10.正则表达式匹配 28. 实现 strStr() - KMP 2、公共子序列方法 动态规划，二分法 题目 1143.最长公共子序列 392. 判断子序列 最长递增子序列 354. 俄罗斯套娃信封问题 - 首升尾降 转为求尾单调递增子序列 3、括号问题方法 借助栈，遍历时维护插入数和需要数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/*** 32. 最长有效括号*/public int longestValidParentheses(String s) { Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); // 以i结尾的有效长度 int[] dp = new int[s.length()]; int max = 0; for (int i = 0; i &lt; s.length(); i++) { if (s.charAt(i) == '(') { // 遇到左括号，记录索引 stack.push(i); dp[i] = 0; } else { // 遇到右括号 if (!stack.isEmpty()) { // 配对的左括号对应索引，[leftIndex, i] 是一个合法括号子串 int left = stack.pop(); dp[i] = i - left + 1; // 这个合法括号子串的长度 if (left &gt; 0) { dp[i] += dp[left - 1]; } max = Math.max(max, dp[i]); } else { // 没有配对的左括号; dp[i] = 0; } } } return max;}/*** 1541. 平衡括号字符串的最小插入次数*/public int minInsertions(String s) { int leftInsert = 0; int rightInsert = 0; int rightNeed = 0; int n = s.length(); for (int i = 0; i &lt; n; i++) { char c = s.charAt(i); if (c == '(') { if (rightNeed % 2 == 1) { rightInsert++; rightNeed++; } else { rightNeed += 2; } } else { if (rightNeed == 0) { leftInsert++; rightNeed++; } else { rightNeed--; } } } return leftInsert + rightInsert + rightNeed;} 题目 20. 有效的括号 1541. 平衡括号字符串的最少插入次数 32. 最长有效括号 - 使用dp数组 921. 使括号有效的最少添加 4、回文方法 递推，从中间向两侧扩展 123456789101112131415161718192021222324252627282930313233343536/*** 5.最长回文子串*/public String longestPalindrome(String s) { String ret = &quot;&quot;; for (int i = 0; i &lt; s.length(); i++) { String sub1 = lp(s, i, i); String sub2 = lp(s, i, i+1); if (sub1.length() &lt; sub2.length()) { String tmp = sub1; sub1 = sub2; sub2 = tmp; } if (sub1.length() &gt; ret.length()) { ret = sub1; } } return ret;}private String lp(String s, int left, int right) { while (left &gt;= 0 &amp;&amp; right &lt; s.length()) { if (s.charAt(left) == s.charAt(right)) { left--; right++; } else { break; } } left++; if (right &gt; left) { return s.substring(left, right); } else { return &quot;&quot;; }} 题目 5. 最长回文子串 - 递推 or 从中间向两边扩展 516. 最长回文子序列 三、数组/字符串通用解法1、单调函数二分查找二分查找法 1234567891011// 单调递减函数上，搜索左侧值while (left &lt;= right) { int mid = left + (right - left) / 2; int midVal = func(mid); if (midVal &gt; target) { left = mid + 1; } else { right = mid - 1; }}return left; 题目 1011.D天内运送包裹能力-隐式二分查找 162. 寻找峰值 33. 搜索旋转排序数组-判断在哪个递增区间 4. 寻找两个正序数组的中位数 - 两个数组 410. 分割数组的最大值 - 难于发现隐示二分查找 875. 爱吃香蕉的珂珂 - 隐示二分查找 2、二维数组排序首尾两个元素进行排序，第一个元素排序基于问题解决方案，第二个排序用于简化编程（只处理当前元素，不会处理之前扫描过的元素） 题目 435. 无重叠区间 - 尾升即可 452. 用最少数量的箭引爆气球 - 尾升即可 1024.视频拼接 - 首升尾降 1288. 删除被覆盖区间 - 首升尾降 56. 合并区间 - 首升尾降 354. 俄罗斯套娃信封问题 - 首升尾降 转为求尾单调递增子序列 普通解法容易超时 3、二维数组求交集双指针+计算交集（计算交集左右边界） 1234567891011121314151617181920212223242526272829303132// 986. 区间列表的交集public int[][] intervalIntersection(int[][] firstList, int[][] secondList) { int firstIndex = 0; int secondIndex = 0; List&lt;int[]&gt; ret = new ArrayList&lt;&gt;(); while (firstIndex &lt; firstList.length &amp;&amp; secondIndex &lt; secondList.length) { int[] first = firstList[firstIndex]; int[] second = secondList[secondIndex]; int[] intersect; if (first[1] &lt; second[1]) { intersect = getIntersect(first, second); firstIndex++; } else { intersect = getIntersect(second, first); secondIndex++; } if (intersect != null) { ret.add(intersect); } } return ret.toArray(new int[][]{});}int[] getIntersect(int[] left, int[] right) { if (right[0] &gt; left[1]) { return null; } int[] ret = new int[2]; ret[1] = left[1]; ret[0] = Math.max(left[0], right[0]); return ret;} 题目 986. 区间列表的交集 4、差分数组转为相对落差图 1234567891011121314151617181920212223242526272829303132333435363738394041424344/*** 1109.航班预定统计*/public int[] corpFlightBookings(int[][] bookings, int n) { int[] incSum = new int[n + 1]; for (int[] booking : bookings) { int start = booking[0]; int end = booking[1]; incSum[start - 1] += booking[2]; incSum[end] -= booking[2]; } int[] ret = new int[n]; ret[0] = incSum[0]; for (int i = 1; i &lt; n; i++) { ret[i] = ret[i - 1] + incSum[i]; } return ret;}/*** 134.加油站*/public int canCompleteCircuit(int[] gas, int[] cost) { int min = Integer.MAX_VALUE; int cur = 0; int ret = -1; for (int i = 0; i &lt; gas.length * 2; i++) { cur += gas[i % gas.length]; cur -= cost[i % gas.length]; if (i &lt; gas.length) { if (cur &lt; min) { min = cur; ret = (i + 1) % gas.length; } } else { if (cur &lt; min) { return -1; } } } return ret;} 题目 1109.航班预定统计 134. 加油站 - 遍历两次 253. 会议室 II - 计算重叠 5、前缀和123456789101112131415161718/*** 560.和为K的连续子数组*/public int subarraySum(int[] nums, int k) { int[] sum = new int[nums.length + 1]; for (int i = 0; i &lt; nums.length; i++) { sum[i + 1] = sum[i] + nums[i]; } int ret = 0; for (int i = 0; i &lt; sum.length; i++) { for (int j = i + 1; j &lt; sum.length; j++) { if (sum[j] - sum[i] == k) { ret++; } } } return ret;} 560. 和为 K 的连续子数组 6、用Map降低时间复杂度经典题目：切分子数组 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778bool isPossible(vector&lt;int&gt;&amp; nums) { unordered_map&lt;int, int&gt; freq; unordered_map&lt;int, vector&lt;vector&lt;int&gt;&gt;&gt; need; for (int v : nums) freq[v]++; for (int v : nums) { if (freq[v] == 0) { continue; } if (need.count(v) &amp;&amp; need[v].size() &gt; 0) { // v 可以接到之前的某个序列后面 freq[v]--; // 随便取一个需要 v 的子序列 vector&lt;int&gt; seq = need[v].back(); need[v].pop_back(); // 把 v 接到这个子序列后面 seq.push_back(v); // 这个子序列的需求变成了 v + 1 need[v + 1].push_back(seq); } else if (freq[v] &gt; 0 &amp;&amp; freq[v + 1] &gt; 0 &amp;&amp; freq[v + 2] &gt; 0) { // 可以将 v 作为开头 freq[v]--; freq[v + 1]--; freq[v + 2]--; // 新建一个长度为 3 的子序列 [v,v + 1,v + 2] vector&lt;int&gt; seq{v, v + 1, v + 2}; // 对 v + 3 的需求加一 need[v + 3].push_back(seq); } else { return false; } } // 打印切分出的所有子序列 for (auto it : need) { for (vector&lt;int&gt;&amp; seq : it.second) { for (int v : seq) { cout &lt;&lt; v &lt;&lt; &quot; &quot;; } cout &lt;&lt; endl; } } return true;}/*** 28.最长连续序列*/public int longestConsecutive(int[] nums) { Map&lt;Integer, Integer&gt; endLength = new HashMap&lt;&gt;(); int max = 0; for (int num : nums) { if (!endLength.containsKey(num)) { int beforeEnd = num - 1; int curLength; if (endLength.containsKey(beforeEnd)) { curLength = endLength.get(beforeEnd) + 1; } else { curLength = 1; } endLength.put(num, curLength); max = Math.max(max, curLength); int nextEnd = num + 1; while(endLength.containsKey(nextEnd)) { int newLength = endLength.get(nextEnd) + curLength; endLength.put(nextEnd, newLength); nextEnd++; max = Math.max(max, newLength); } } } return max;} 题目 28. 最长连续序列 659. 分割数组为连续子序列 7、DFS/回溯/深度遍历/暴力破解1234567891011121314151617181920212223242526// 695. 岛屿最大面积public int maxAreaOfIsland(int[][] grid) { int max = 0; for (int i = 0; i &lt; grid.length; i++) { for (int j = 0; j &lt; grid[0].length; j++) { if (grid[i][j] != 0) { max = Math.max(max, dfs(grid, i, j)); } } } return max;}int[] direction = new int[]{-1, 0, 1, 0, -1};private int dfs(int[][] grid, int row, int col) { if (row &lt; 0 || col &lt; 0 || row &gt;= grid.length || col &gt;= grid[0].length || grid[row][col] == 0) { return 0; } int ret = 1; grid[row][col] = 0; for (int i = 0; i &lt; 4; i++) { ret += dfs(grid, row + direction[i], col + direction[i + 1]); } return ret;} 题目 130. 被围绕的区域 37. 解数独 51. N 皇后 695. 岛屿的最大面积 698. 划分为k个相等的子集 - 需要多次合适剪枝，很容易超时 79. 单词搜索 797. 所有可能的路径 931. 下降路径最小和 8、数组排列12345678910111213141516171819// 78.子集public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) { dfs(nums, 0, new LinkedList()); return ret;}List&lt;List&lt;Integer&gt;&gt; ret = new ArrayList&lt;&gt;();private void dfs(int[] nums, int i, LinkedList&lt;Integer&gt; route) { if (i == nums.length) { ret.add(new ArrayList(route)); return; } dfs(nums, i + 1, route); route.add(nums[i]); dfs(nums, i + 1, route); route.removeLast();} 题目 39. 组合总和 46. 全排列 77. 组合 - 排列 78. 子集 - 排列 9、二维数组对角线遍历通过row+col的和判断是处于向上/向下，来计算下个坐标。 题目 498. 对角线遍历 10、双指针123456789101112131415161718192021// 82. 删除排序链表中重复元素public ListNode deleteDuplicates(ListNode head) { ListNode dummy = new ListNode(); dummy.next = head; ListNode slow = dummy; ListNode fast = head; while (fast != null) { if (fast.next != null &amp;&amp; fast.val == fast.next.val) { int skipVal = fast.val; while (fast != null &amp;&amp; fast.val == skipVal) { fast = fast.next; } } else { slow.next = fast; slow = slow.next; fast = fast.next; } } slow.next = null; return dummy.next;} 题目 18. 四数之和 209. 长度最小的子数组 26. 删除有序数组中的重复项 27. 移除元素 283. 移动零 — 可看作删除零 + 补零 43. 字符串相乘 83. 删除排序链表中的重复元素 82. 删除排序链表中的重复元素 II 11、双指针+窗口1234567891011121314151617181920212223242526272829303132333435public boolean checkInclusion(String s1, String s2) { Map&lt;Character, Integer&gt; need = new HashMap&lt;&gt;(); for (char c : s1.toCharArray()) { need.put(c, need.getOrDefault(c, 0) + 1); } Map&lt;Character, Integer&gt; window = new HashMap&lt;&gt;(); // 需要满足的字符数 int target = need.keySet().size(); int count = 0; int left = 0; int right = 0; while (right &lt; s2.length()) { char c = s2.charAt(right++); if (need.containsKey(c)) { window.put(c, window.getOrDefault(c, 0) + 1); if (window.get(c).equals(need.get(c))) { count++; } } while (right - left &gt; s1.length()) { char toDel = s2.charAt(left++); // 逻辑与上面对称 if (need.containsKey(toDel)) { if (window.get(toDel).equals(need.get(toDel))) { count--; } window.put(toDel, window.get(toDel) - 1); } } if (count == target &amp;&amp; right - left == s1.length()) { return true; } } return false;} 题目 438. 找到字符串中所有字母异位词 567. 字符串的排列 3. 无重复字符的最长子串 340. 至多包含 K 个不同字符的最长子串 76. 最小覆盖子串 12、单调队列题目 239. 滑动窗口最大值 - 也可用优先级队列+RemoveMap 13、单调栈题目 42. 接雨水 - 也可以直接找出最大，分两侧计算 496. 下一个更大元素 I - 从后往前构建单调栈 503. 下一个更大元素 II - 循环查找时，把数组扩为2倍 739. 每日温度 - 从后往前构造单调栈 14、负数代表下标存在用元素的正负，替代Map来标识元素是否存在 题目 41. 缺失的第一个正数 448. 找到所有数组中消失的数字 645. 错误的集合 - 找到重复和丢失的数字 15、二维数组螺旋遍历123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/*** from https://labuladong.gitee.io/algo/2/21/57/**/List&lt;Integer&gt; spiralOrder(int[][] matrix) { int m = matrix.length, n = matrix[0].length; int upper_bound = 0, lower_bound = m - 1; int left_bound = 0, right_bound = n - 1; List&lt;Integer&gt; res = new LinkedList&lt;&gt;(); // res.size() == m * n 则遍历完整个数组 while (res.size() &lt; m * n) { if (upper_bound &lt;= lower_bound) { // 在顶部从左向右遍历 for (int j = left_bound; j &lt;= right_bound; j++) { res.add(matrix[upper_bound][j]); } // 上边界下移 upper_bound++; } if (left_bound &lt;= right_bound) { // 在右侧从上向下遍历 for (int i = upper_bound; i &lt;= lower_bound; i++) { res.add(matrix[i][right_bound]); } // 右边界左移 right_bound--; } if (upper_bound &lt;= lower_bound) { // 在底部从右向左遍历 for (int j = right_bound; j &gt;= left_bound; j--) { res.add(matrix[lower_bound][j]); } // 下边界上移 lower_bound--; } if (left_bound &lt;= right_bound) { // 在左侧从下向上遍历 for (int i = lower_bound; i &gt;= upper_bound; i--) { res.add(matrix[i][left_bound]); } // 左边界右移 left_bound++; } } return res;} 题目 54. 螺旋矩阵 四、二叉树1、层级遍历/广度遍历方法 借助双端队列 12345678910111213141516171819202122232425public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) { if (root == null) { return new ArrayList&lt;&gt;(); } Deque&lt;TreeNode&gt; queue = new ArrayDeque&lt;&gt;(); queue.offer(root); List&lt;List&lt;Integer&gt;&gt; ret = new ArrayList&lt;&gt;(); while (!queue.isEmpty()) { int size = queue.size(); List&lt;Integer&gt; item = new ArrayList&lt;&gt;(); ret.add(item); for (int i = 0; i &lt; size; i++) { TreeNode node = queue.removeFirst(); item.add(node.val); if (node.left != null) { queue.add(node.left); } if (node.right != null) { queue.add(node.right); } } } return ret;} 题目 102.二叉树层级遍历 103. 二叉树的锯齿形层序遍历 199. 二叉树的右视图 752. 打开转盘锁 773. 滑动谜题 - 简化操作：可利用一维数组保存可交换的坐标 2、先序/中序/后序遍历题目 112.路径总和 113.路径总和 II 124.二叉树中的最大路径和 129. 求根节点到叶节点数字之和 1373. 二叉搜索子树的最大键值和 236. 二叉树的最近公共祖先 297. 二叉树的序列化与反序列化 538. 把二叉搜索树转换为累加树 - 中序遍历 543. 二叉树的直径 - 后序遍历 652. 寻找重复的子树 - 后序遍历 3、完全二叉树/利用节点位置12345678910111213141516171819202122232425// 662.二叉树最大宽度public int widthOfBinaryTree(TreeNode root) { if (root == null) { return 0; } dfs(root, 1, 1); return max;}// 记录每层的最左节点位置List&lt;Integer&gt; depthFirst = new ArrayList&lt;&gt;();int max = 1;private void dfs(TreeNode node, int depth, int id) { if (node == null) { return; } if (depthFirst.size() == depth - 1) { depthFirst.add(id); } else { max = Math.max(max, id - depthFirst.get(depth - 1) + 1); } dfs(node.left, depth + 1, id * 2); dfs(node.right, depth + 1, id * 2 + 1);} 题目 662. 二叉树最大宽度 - 先序遍历，通过记录位置计算 958. 二叉树的完全性检验 - 层级遍历 4、二叉搜索树123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596// 96. 不同的二叉搜索树public int numTrees(int n) { mentor = new int[n+1][n+1]; return count(1, n);}int[][] mentor;int count(int left, int right) { if (left &gt;= right) { return 1; } if (mentor[left][right] != 0) { return mentor[left][right]; } int ret = 0; for (int mid = left; mid &lt;= right; mid++) { int leftNum = count(left, mid - 1); int rightNum = count(mid + 1, right); ret += leftNum * rightNum; } mentor[left][right] = ret; return ret;}// 95. 不同的二叉搜索树II，https://mp.weixin.qq.com/s/kcwz2lyRxxOsC3n11qdVSwpublic List&lt;TreeNode&gt; generateTrees(int n) { if (n == 0) return new LinkedList&lt;&gt;(); // 构造闭区间 [1, n] 组成的 BST return build(1, n);}/* 构造闭区间 [lo, hi] 组成的 BST */List&lt;TreeNode&gt; build(int lo, int hi) { List&lt;TreeNode&gt; res = new LinkedList&lt;&gt;(); // base case if (lo &gt; hi) { res.add(null); return res; } // 1、穷举 root 节点的所有可能。 for (int i = lo; i &lt;= hi; i++) { // 2、递归构造出左右子树的所有合法 BST。 List&lt;TreeNode&gt; leftTree = build(lo, i - 1); List&lt;TreeNode&gt; rightTree = build(i + 1, hi); // 3、给 root 节点穷举所有左右子树的组合。 for (TreeNode left : leftTree) { for (TreeNode right : rightTree) { // i 作为根节点 root 的值 TreeNode root = new TreeNode(i); root.left = left; root.right = right; res.add(root); } } } return res;}// 98. 验证二叉搜索树 - 后序遍历boolean isValid = true;public boolean isValidBST(TreeNode root) { dp(root); return isValid;}// 最小值和最大值private int[] dp(TreeNode node) { int[] left = node.left == null ? new int[]{node.val, node.val} : dp(node.left); int[] right = node.right == null ? new int[]{node.val, node.val} : dp(node.right); if (!isValid) { return null; } if ((node.left != null &amp;&amp; left[1] &gt;= node.val) || (node.right != null &amp;&amp; node.val &gt;= right[0])) { isValid = false; return null; } else { return new int[]{left[0], right[1]}; }}// 98. 验证二叉搜索树 - 先序遍历public boolean isValidBST(TreeNode root) { return isValidBST(root, null, null);}/* 限定以 root 为根的子树节点必须满足 max.val &gt; root.val &gt; min.val */boolean isValidBST(TreeNode root, TreeNode min, TreeNode max) { // base case if (root == null) return true; // 若 root.val 不符合 max 和 min 的限制，说明不是合法 BST if (min != null &amp;&amp; root.val &lt;= min.val) return false; if (max != null &amp;&amp; root.val &gt;= max.val) return false; // 限定左子树的最大值是 root.val，右子树的最小值是 root.val return isValidBST(root.left, min, root) &amp;&amp; isValidBST(root.right, root, max);} 题目 240. 搜索二维矩阵 II - 右上角为根的二叉搜索树 701. 二叉搜索树中的插入操作 95. 不同的二叉搜索树 II - 构造二叉搜索树 + 二叉树序列化 + 全排列 96. 不同的二叉搜索树 98. 验证二叉搜索树 - 先序和后序都可以 5、构造二叉树题目 654. 最大二叉树 105.从先序和中序遍历序列构造二叉序 106. 从中序与后序遍历序列构造二叉树 五、动态规划方法 状态转移方程 + 状态压缩（可选）+ 正确遍历方向。 当有明显的一维/二维坐标规律移动，不是跳动的情况时，可以通过正向方式递推。否则使用自顶而下的递归更容易。如514. 自由之路不适合用正向。 1、01背包12345678910111213141516171819202122/*** 518.零钱兑换*/public int change(int amount, int[] coins) { int n = coins.length; int[][] dp = new int[n + 1][amount + 1]; // base case for (int i = 0; i &lt;= n; i++) dp[i][0] = 1; for (int i = 1; i &lt;= n; i++) { for (int j = 1; j &lt;= amount; j++) { if (j - coins[i-1] &gt;= 0) { // dp[i-1][j]不选择当前，dp[i][j-coins[i-1]]选择当前 dp[i][j] = dp[i - 1][j] + dp[i][j - coins[i-1]]; } else { dp[i][j] = dp[i - 1][j]; } } } return dp[n][amount];} 题目 416. 分割等和子集 518. 零钱兑换 II - 完全背包问题 2、其他题目 121.买卖股票的最佳时机 122.买卖股票的最佳时机 II 123.买卖股票的最佳时机 III 188. 买卖股票的最佳时机 IV 714. 买卖股票的最佳时机含手续费 309. 最佳买卖股票时机含冷冻期 1312. 让字符串成为回文串的最少插入次数 152. 乘积最大子数组 - 难点转移方程 53. 最大子数组和 213. 打家劫舍 II - 环形 337. 打家劫舍 III - 树形 300. 最长递增子序列 312. 戳气球 - 转移方程 + 遍历方向 322. 零钱兑换 329. 矩阵中的最长递增路径 354. 俄罗斯套娃信封问题 - 也可转为最长递增子序列和二分法 514. 自由之路 583. 两个字符串的删除操作 - 编辑距离 712. 两个字符串的最小ASCII删除和 - 编辑距离 72. 编辑距离 62. 不同路径 651. 4键键盘 - 需要合适剪枝 887. 鸡蛋掉落 - 需要二分减小复杂度 六、数据结构设计12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// 855. 考场就坐class ExamRoom { Queue&lt;int[]&gt; queue = new PriorityQueue&lt;&gt;((i1, i2) -&gt; { int sub = distance(i2) - distance(i1); if (sub == 0) { return i1[0] - i2[0]; } else { return sub; } }); int n; Map&lt;Integer, int[]&gt; start = new HashMap&lt;&gt;(); Map&lt;Integer, int[]&gt; end = new HashMap&lt;&gt;(); public ExamRoom(int n) { this.n = n; // 开区间好运算 queue.offer(new int[]{-1, n}); } int distance(int[] interval) { int x = interval[0]; int y = interval[1]; if (x == -1) { return y; } if (y == n) { return n - 1 - x; } return (y - x) / 2; } void addInterval(int[] interval) { queue.offer(interval); start.put(interval[0], interval); end.put(interval[1], interval); } void delInterval(int[] interval) { queue.remove(interval); start.remove(interval[0]); end.remove(interval[1]); } public int seat() { int[] interval = queue.peek(); int seat; if (interval[0] == -1) { seat = 0; } else if (interval[1] == n) { seat = n - 1; } else { seat = (interval[0] + interval[1]) / 2; } delInterval(interval); addInterval(new int[]{interval[0], seat}); addInterval(new int[]{seat, interval[1]}); return seat; } public void leave(int p) { int[] fromInterval = start.get(p); int[] toInterval = end.get(p); int[] merge = new int[]{toInterval[0], fromInterval[1]}; delInterval(fromInterval); delInterval(toInterval); addInterval(merge); }} 题目 146. LRU 缓存 155. 最小栈 170. 两数之和 III - 数据结构设计 225. 用队列实现栈 232. 用栈实现队列 295. 数据流的中位数 341. 扁平化嵌套列表迭代器 - 惰性展开 355. 设计推特 460. LFU 缓存 855. 考场就座 895. 最大频率栈 七、算法1、DIJKSTRA题目 1514. 概率最大的路径 1631. 最小体力消耗路径 - DFS可以AC 743. 网络延迟时间 787. K 站中转内最便宜的航班 2、拓扑排序1234567891011121314151617181920212223242526272829303132333435363738class Solution { public int[] findOrder(int numCourses, int[][] prerequisites) { int[] inbouds = new int[numCourses]; List&lt;Integer&gt;[] srcTargetList = new List[numCourses]; for (int i = 0; i &lt; numCourses; i++) { srcTargetList[i] = new ArrayList&lt;&gt;(); } for (int[] pre : prerequisites) { inbouds[pre[0]]++; srcTargetList[pre[1]].add(pre[0]); } Queue&lt;Integer&gt; zeroInbounds = new ArrayDeque&lt;&gt;(); for (int i = 0; i &lt; numCourses; i++) { if (inbouds[i] == 0) { zeroInbounds.offer(i); } } int[] ret = new int[numCourses]; int count = 0; while (!zeroInbounds.isEmpty()) { int cur = zeroInbounds.poll(); ret[count++] = cur; for (int target : srcTargetList[cur]) { inbouds[target]--; if (inbouds[target] == 0) { zeroInbounds.offer(target); } } } if (count == numCourses) { return ret; } else { return new int[]{}; } }} 题目 207. 课程表 - 拓扑 or DFS 210. 课程表 II 23. 拓扑 3、分治题目 241. 为运算表达式设计优先级 4、并查集计算连通性-参考 12345678910111213141516171819202122232425262728293031323334353637383940class UF { // 记录连通分量 private int count; // 节点 x 的节点是 parent[x] private int[] parent; /* 构造函数，n 为图的节点总数 */ public UF(int n) { // 一开始互不连通 this.count = n; // 父节点指针初始指向自己 parent = new int[n]; for (int i = 0; i &lt; n; i++) parent[i] = i; } public void union(int p, int q) { int rootP = find(p); int rootQ = find(q); if (rootP == rootQ) return; // 将两棵树合并为一棵 parent[rootP] = rootQ; // parent[rootQ] = rootP 也一样 count--; // 两个分量合二为一 } /* 返回某个节点 x 的根节点 */ private int find(int x) { // 根节点的 parent[x] == x while (parent[x] != x) x = parent[x]; return x; } /* 返回当前的连通分量个数 */ public int count() { return count; }} 优化版： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class UF { // 连通分量个数 private int count; // 存储一棵树 private int[] parent; // 记录树的「重量」 private int[] size; // n 为图中节点的个数 public UF(int n) { this.count = n; parent = new int[n]; size = new int[n]; for (int i = 0; i &lt; n; i++) { parent[i] = i; size[i] = 1; } } // 将节点 p 和节点 q 连通 public void union(int p, int q) { int rootP = find(p); int rootQ = find(q); if (rootP == rootQ) return; // 小树接到大树下面，较平衡 if (size[rootP] &gt; size[rootQ]) { parent[rootQ] = rootP; size[rootP] += size[rootQ]; } else { parent[rootP] = rootQ; size[rootQ] += size[rootP]; } // 两个连通分量合并成一个连通分量 count--; } // 判断节点 p 和节点 q 是否连通 public boolean connected(int p, int q) { int rootP = find(p); int rootQ = find(q); return rootP == rootQ; } // 返回节点 x 的连通分量根节点 private int find(int x) { while (parent[x] != x) { // 进行路径压缩 parent[x] = parent[parent[x]]; x = parent[x]; } return x; } // 返回图中的连通分量个数 public int count() { return count; }} 题目 323. 无向图中连通分量的数目 990. 等式方程的可满足性 5、贪心题目 11.盛最多水的容器 55. 跳跃游戏 - 45的简化，只求是否能到终点 45. 跳跃游戏 II - 更新每一跳最远位置 八、数学1、计算器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// 772.计算器IIIpublic int calculate(String s) { LinkedList&lt;Character&gt; list = new LinkedList&lt;&gt;(); for (char c : s.toCharArray()) { list.add(c); } return dp(list);}private int dp(LinkedList&lt;Character&gt; list) { LinkedList&lt;Integer&gt; valueStack = new LinkedList&lt;&gt;(); LinkedList&lt;Character&gt; signStack = new LinkedList&lt;&gt;(); while (list.size() != 0) { char c = list.removeFirst(); Integer val = null; if (c == '(') { val = dp(list); } else if (c == '+' || c == '-' || c == '*' || c == '/') { signStack.add(c); } else if (c == ')') { break; } else { val = 0; while (true) { val = val * 10 + (c - '0'); if (list.size() != 0 &amp;&amp; Character.isDigit(list.get(0))) { c = list.removeFirst(); } else { break; } } } if (val == null) { continue; } valueStack.add(val); while (!signStack.isEmpty() &amp;&amp; (signStack.getLast() == '*' || signStack.getLast() == '/')) { int num2 = valueStack.removeLast(); int num1 = valueStack.removeLast(); char signChar = signStack.removeLast(); if (signChar == '*') { valueStack.add(num1 * num2); } else { valueStack.add(num1 / num2); } } } while (signStack.size() != 0) { char signChar = signStack.removeFirst(); int num1 = valueStack.removeFirst(); int num2 = valueStack.removeFirst(); if (signChar == '+') { valueStack.push(num1 + num2); } else { valueStack.push(num1 - num2); } } return valueStack.get(0);} 题目 224. 基本计算器 227. 基本计算器 II 772. 基本计算器 III 8. 字符串转换整数 (atoi) 2、随机数题目 380. O(1) 时间插入、删除和获取随机元素 - 数组 + Map + Rand函数 382. 链表随机节点 - 遍历链表，每个元素选中概率为1/n 398. 随机数索引 - 同382 470. 用 Rand7() 实现 Rand10() - 可通过1/2和1/5凑 710. 黑名单中的随机数 - 利用黑明单元素到正常元素的映射 3、字典序力求局部递增/递减 or 多叉树计算前缀根的节点数 题目 31. 下一个排列—尾部降序子序列，找到大于之前的元素进行交换，然后降序序列两两交换变为升序 316. 去除重复字母 402. 移掉 K 位数字 440. 字典序的第K小数字 - 10叉树，难点求前缀根的节点数 4、数学规律1234567891011121314151617181920212223242526272829303132333435// 870.优势洗牌-田忌赛马 https://labuladong.gitee.io/algo/2/22/64/public int[] advantageCount(int[] nums1, int[] nums2) { int n = nums1.length; // 给 nums2 降序排序 PriorityQueue&lt;int[]&gt; maxpq = new PriorityQueue&lt;&gt;( (int[] pair1, int[] pair2) -&gt; { return pair2[1] - pair1[1]; } ); for (int i = 0; i &lt; n; i++) { maxpq.offer(new int[]{i, nums2[i]}); } // 给 nums1 升序排序 Arrays.sort(nums1); // nums1[left] 是最小值，nums1[right] 是最大值 int left = 0, right = n - 1; int[] res = new int[n]; while (!maxpq.isEmpty()) { int[] pair = maxpq.poll(); // maxval 是 nums2 中的最大值，i 是对应索引 int i = pair[0], maxval = pair[1]; if (maxval &lt; nums1[right]) { // 如果 nums1[right] 能胜过 maxval，那就自己上 res[i] = nums1[right]; right--; } else { // 否则用最小值混一下，养精蓄锐 res[i] = nums1[left]; left++; } } return res;} 题目 172. 阶乘后的零 793. 阶乘函数后 K 个零 191. 位1的个数 204. 计数质数 221. 最大正方形 372. 超级次方 - 平方的递推方程a^123 = a^3 * (a^12)^10 48. 旋转图像 - 用两次翻转代替旋转 870. 优势洗牌 - 田忌赛马 969. 煎饼排序 - 选当前范围最大的翻转到底部 5、脑筋急转弯题目 292. Nim 游戏 877. 石子游戏 319. 灯泡开关 - 平方根 391. 完美矩形 - 三重判断：面积 + 顶点数 + 奇数点为最终顶点 九、编程细节1、Integer类型用equals进行判断相等 2、Interger类型用Integer.compare方法进行比较，防止直接减溢出。 3、链表操作时，可增加一个空头节点，易处理第一个节点的删除情况。","link":"/2022/02/28/%E7%AE%97%E6%B3%95%E9%A2%98%E5%9E%8B%E6%80%BB%E7%BB%93/"},{"title":"索引备份实践","text":"一、备份目标1）备份原因迁移备份线上ES数据到备份ES，后期计算TPS、单量等数据。 2）优化措施目标：减小存储压力和提高迁移速度。 1、备份索引不设置副本 备份数据只用来统计分析，不需要高可用。 2、只迁移spanId为end的日志结点 备份内容只关注session数据（spanID），不关心具体处理内容。 3、迁移部分字段，过滤extend_1,extend_2,extend_3等字段，source大小变为1/10 用于统计分析，去除无关大字段。 二、备份过程 从源ES备份到目标ES，备份过程只在目标es操作。 1）建立和源ES相同的索引可通过模板或者Mapping创建。 123456789$ POST _template/xxx_tpl{ &quot;settings&quot; : { &quot;index&quot; : { &quot;number_of_replicas&quot; : &quot;0&quot; # 副本修改为0，减少备份容量 } }, ...} 2）配置reindex.remote.whitelistreindex.remote.whitelist为源ES地址。 3）登陆目标ES，执行脚本 https://www.elastic.co/guide/en/elasticsearch/reference/6.8/docs-reindex.html 可执行多个索引迁移任务，多个reindex任务会并行执行，例如以10天为一个区间进行迁移； 1234567891011121314151617181920212223# wait_for_completion把任务设为异步任务，避免中断$ POST _reindex?wait_for_completion=false{ &quot;source&quot;: { &quot;remote&quot;: { &quot;host&quot;: &quot;http://source ES:9200&quot;, # 源ES &quot;username&quot;: &quot;xxx&quot;, &quot;password&quot;: &quot;xxx&quot; }, &quot;index&quot;: &quot;xxx_2021.05.30&quot;, &quot;_source&quot;: [&quot;appCode&quot;, &quot;traceId&quot;, ... ], # 非全量迁移字段，减小存储压力和迁移速度 &quot;size&quot;: 10000, # size字段取值参考下一节&quot;reindex-size取值优化&quot; &quot;query&quot;: { # 增加查询条件，非全量迁移document &quot;match&quot;: { &quot;spanId&quot;: &quot;end&quot; } } }, &quot;dest&quot;: { &quot;index&quot;: &quot;xxx_2021.05.30&quot;, &quot;op_type&quot;: &quot;create&quot; }} 4）查看跟踪任务 https://www.elastic.co/guide/en/elasticsearch/reference/6.8/tasks.html 123456# 查看任务$ GET _tasks/[taskID]$ GET _tasks?detailed=true&amp;actions=*reindex# 取消任务$ POST _tasks/[taskID]/_cancel 三、reindex-size取值优化size设置要合理，参考两个原则： 1）size &lt;= 100002）size*docNum &lt; bufferSize1234567891011121314151617181920212223242526272829303132333435363738394041424344{ &quot;completed&quot; : true, &quot;task&quot; : { &quot;node&quot; : &quot;mxMIBxgNS3ek5URhsxmQkw&quot;, &quot;id&quot; : 2964624, &quot;type&quot; : &quot;transport&quot;, &quot;action&quot; : &quot;indices:data/write/reindex&quot;, &quot;status&quot; : { &quot;total&quot; : 0, &quot;updated&quot; : 0, &quot;created&quot; : 0, &quot;deleted&quot; : 0, &quot;batches&quot; : 0, &quot;version_conflicts&quot; : 0, &quot;noops&quot; : 0, &quot;retries&quot; : { &quot;bulk&quot; : 0, &quot;search&quot; : 0 }, &quot;throttled_millis&quot; : 0, &quot;requests_per_second&quot; : -1.0, &quot;throttled_until_millis&quot; : 0 }, &quot;description&quot; : &quot;&quot;&quot;reindex from [host=es-nlb-xxx.xxx.com port=9200 query={ &quot;match&quot; : { &quot;spanId&quot; : &quot;end&quot; }} username=xxx password=&lt;&lt;&gt;&gt;][xxx_2021.05.30] to [xxx_2021.05.30]&quot;&quot;&quot;, &quot;start_time_in_millis&quot; : 1624958356693, &quot;running_time_in_nanos&quot; : 778599920, &quot;cancellable&quot; : true, &quot;headers&quot; : { } }, &quot;error&quot; : { &quot;type&quot; : &quot;illegal_argument_exception&quot;, &quot;reason&quot; : &quot;Remote responded with a chunk that was too large. Use a smaller batch size.&quot;, &quot;caused_by&quot; : { &quot;type&quot; : &quot;content_too_long_exception&quot;, &quot;reason&quot; : &quot;entity content is too long [118324742] for the configured buffer limit [104857600]&quot; } }} 四、Reindex失败定位1）定位方式1、任务索引查询：.task/task/[taskID] https://www.elastic.co/guide/en/elasticsearch/reference/6.8/docs-reindex.html If the request contains wait_for_completion=false then Elasticsearch will perform some preflight checks, launch the request, and then return a task which can be used with Tasks APIs to cancel or get the status of the task. Elasticsearch will also create a record of this task as a document at .tasks/task/${taskId}. This is yours to keep or remove as you see fit. When you are done with it, delete it so Elasticsearch can reclaim the space it uses. 2、任务API查询：GET _tasks?detailed=true&amp;actions=*reindex 3、根据ES运行日志定位 2）定位案例0、前置操作 最近迁移索引时，迁移到一半reindex任务就中断了，且前两种方式没有记录。遂观察ES日志。 1、查看目标ES日志 1234567891011121314151617181920212223242526272829302021-11-12 20:18:23 [2021-11-12T20:18:16,964][INFO ][c.j.e.p.a.a.AuthActionFilter] [coordinating-1] action：'indices:data/write/index' require Authorization2021-11-12 20:18:23 at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_222]2021-11-12 20:18:23 at org.elasticsearch.tasks.TaskManager.storeResult(TaskManager.java:203) ~[elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:76) ~[elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 [2021-11-12T20:18:16,965][WARN ][o.e.t.LoggingTaskListener] [coordinating-1] 376642151 failed with exception2021-11-12 20:18:23 at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:395) ~[elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_222]2021-11-12 20:18:23 at org.elasticsearch.index.reindex.remote.RemoteScrollableHitSource.lambda$cleanup$2(RemoteScrollableHitSource.java:149) ~[?:?]2021-11-12 20:18:23 org.elasticsearch.ElasticsearchSecurityException: Authorization required2021-11-12 20:18:23 at org.elasticsearch.tasks.TaskResultsService.storeResult(TaskResultsService.java:134) ~[elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:87) ~[elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_222]2021-11-12 20:18:23 at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:139) ~[elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_222]2021-11-12 20:18:23 at org.elasticsearch.tasks.TaskResultsService.doStoreResult(TaskResultsService.java:159) ~[elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:165) ~[elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:139) ~[elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 at com.jdcloud.es.plugin.authentication.action.AuthActionFilter.apply(AuthActionFilter.java:159) ~[?:?]2021-11-12 20:18:23 at java.lang.Thread.run(Thread.java:748) [?:1.8.0_222]2021-11-12 20:18:23 at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:624) [elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:71) ~[elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_222]2021-11-12 20:18:23 at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:71) ~[elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:81) ~[elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:81) ~[elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_222]2021-11-12 20:18:23 at org.elasticsearch.action.support.TransportAction$TaskResultStoringActionListener.onFailure(TransportAction.java:205) ~[elasticsearch-6.5.4.jar:6.5.4]2021-11-12 20:18:23 org.elasticsearch.ElasticsearchSecurityException: Authorization required2021-11-12 20:18:23 [2021-11-12T20:18:16,964][WARN ][o.e.t.TaskManager ] [coordinating-1] couldn't store error SocketTimeoutException[null]2021-11-12 20:22:51 [2021-11-12T20:22:44,620][INFO ][o.e.c.m.MetaDataIndexTemplateService] [master-0] adding template [kibana_index_template:.kibana] for index patterns [.kibana] 从异常日志中看到reindex的任务出现了couldn't store error SocketTimeoutException。 2、查看源ES日志 12021-11-12 20:18:19 [2021-11-12T20:18:16,955][WARN ][o.e.t.TransportService ] [master-1] Received response for a request that has timed out, sent [36620ms] ago, timed out [6603ms] ago, action [internal:discovery/zen/fd/ping], node [{node-6}{luQIob0aT-63YllGaZ7ecA}{3gE6HKHAS72YtgubIzZEvQ}{11.77.76.176}{11.77.76.176:9300}{zone_id=az1}], id [208747742] 3、猜测原因 由源ES和目标ES的异常信息可推测出应该是请求源ES超时导致任务中断。 4、修改验证 https://www.elastic.co/guide/en/elasticsearch/reference/6.8/docs-reindex.html It is also possible to set the socket read timeout on the remote connection with the socket_timeout field and the connection timeout with the connect_timeout field. Both default to 30 seconds. 根据文档描述增加超时参数，修改后迁移语句如下： 1234567891011121314151617181920212223$ POST _reindex?wait_for_completion=false{ &quot;source&quot;: { &quot;remote&quot;: { &quot;host&quot;: &quot;http://source ES:9200&quot;, &quot;socket_timeout&quot;: &quot;2m&quot;, # 增加超时参数，2min &quot;username&quot;: &quot;xxx&quot;, &quot;password&quot;: &quot;xxx&quot; }, &quot;index&quot;: &quot;xxx_2021.05.30&quot;, &quot;_source&quot;: [&quot;appCode&quot;, &quot;traceId&quot;, ... ], &quot;size&quot;: 10000, &quot;query&quot;: { &quot;match&quot;: { &quot;spanId&quot;: &quot;end&quot; } } }, &quot;dest&quot;: { &quot;index&quot;: &quot;xxx_2021.05.30&quot;, &quot;op_type&quot;: &quot;create&quot; }} 修改后4800W数据耗时3小时迁移成功。 # 参考 https://www.elastic.co/guide/en/elasticsearch/reference/6.8/docs-reindex.html https://www.elastic.co/guide/en/elasticsearch/reference/6.8/tasks.html https://www.elastic.co/guide/en/elasticsearch/reference/6.0/reindex-upgrade-remote.html https://discuss.elastic.co/t/not-whitelisted-in-reindex-remote-whitelist/111070 提高reindex效率","link":"/2021/11/05/%E7%B4%A2%E5%BC%95%E5%A4%87%E4%BB%BD%E5%AE%9E%E8%B7%B5/"},{"title":"笔记本通过网线分享网络给台式机","text":"一、环境 一个笔记本，windows 10 一个台式机，Ubuntu 20.04LTS 一个网线 其中笔记本可以通过无线上网。 二、三步配置1）通过网线连接笔记本和台式机网线的线序没有关系，现在网卡可以自动识别线序。 2）配置笔记本侧配置无限网络的Internet连接共享，步骤： 右键WLAN无线连接，选择属性 - 共享 勾选：允许其他网络通过此计算机的Internet连接来连接 家庭网络连接 里选择有线网卡 记录下无线网卡的DNS地址和有线网卡的IP地址，供台式机配置。 3）配置台式机侧 配置DNS和笔记本无线网卡一致 配置IP/mask和笔记本有线网卡在一个网段 其他有时候通过以上配置后，笔记本和台式机可以互相ping通，但是台式机无法上网。尝试重置笔记本网卡： 123451. 按键盘Win+R打开&quot;运行&quot;,输入cmd然后按Ctrl+Shift+回车,以管理员身份打开命令提示符2. 在打开的命令提示符窗口中粘贴运行下面的命令:netsh int ip resetnetsh winsock reset3. 重启电脑 附台式机静态路由 常见问题1）通过使用网络共享的方式发现台式机访问网络很慢。 先尝试设置笔记本设置网卡带宽，路径：无线网卡上鼠标右键 | 属性 | 配置 | 高级 | Channel Width for 5GHz； 如果当前是20 MHz Only，则改为Auto； 如果当前是Auto，则改为20 MHz Only； 如果网速没有恢复，则在笔记本上打开设备管理器，把无线网卡、有线网卡卸载，然后重启机器 2）windows重启后，台式机无法上网 windows无线网卡的网络共享关闭再打开，就可恢复 3）windows休眠唤醒后，两者都无法上网 关闭windows无线网卡的网络共享 禁用windows无线网卡，然后在启动 打开windows无线网卡的网络共享","link":"/2021/01/20/%E7%AC%94%E8%AE%B0%E6%9C%AC%E9%80%9A%E8%BF%87%E7%BD%91%E7%BA%BF%E5%88%86%E4%BA%AB%E7%BD%91%E7%BB%9C%E7%BB%99%E5%8F%B0%E5%BC%8F%E6%9C%BA/"},{"title":"线程同步","text":"一、奇偶交替1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class PrintTest { static volatile int count = 1; public static void printZero() { System.out.print(&quot;0&quot;); } public static void printOdd() { System.out.print(count); } public static void printEven() { System.out.print(count); } public static void print(int n) throws InterruptedException { ReentrantLock lock = new ReentrantLock(); Condition zeroCond = lock.newCondition(); Condition oddCond = lock.newCondition(); Condition evenCond = lock.newCondition(); Thread zero = new Thread(() -&gt; { lock.lock(); while (count &lt;= n) { zeroCond.await(); if (count &lt;= n) { printZero(); } if (count % 2 == 1) { evenCond.signal(); } else { oddCond.signal(); } } lock.unlock(); }); Thread odd = new Thread(() -&gt; { lock.lock(); while (count &lt;= n) { oddCond.await(); if (count &gt; n) { return; } printEven(); count++; zeroCond.signal(); } lock.unlock(); }); Thread even = new Thread(() -&gt; { lock.lock(); while (count &lt;= n) { evenCond.await(); if (count &gt; n) { return; } printOdd(); count++; zeroCond.signal(); } lock.unlock(); }); zero.start(); odd.start(); even.start(); lock.lock(); zeroCond.signal(); lock.unlock(); zero.join(); odd.join(); even.join(); }}","link":"/2022/03/24/%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/"},{"title":"线程池剖析","text":"一、前置问题 线程的状态转换 为什么要使用线程池 线程池的继承体系 线程池使用的场景 线程数的设置规则 线程池的状态转换 线程池的关键参数 线程池的接收任务后的执行流程 线程池的异常处理 submit和exec的区别 线程池的拒绝策略 二、进程和线程 进程是分配资源的最小单位，进程间资源隔离 线程是CPU调度的最小单位 一个进程往往包含多个线程，多个线程在进程内可共享进程的资源 多线程可简化编程，把涉及并发和多步的问题域映射为多线程； 三、线程的状态通过java.lang.Thread#getState方法可以获取当前线程状态，其用枚举标识。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * A thread can be in only one state at a given point in time. * These states are virtual machine states which do not reflect * any operating system thread states. * * @since 1.5 * @see #getState */ public enum State { /** * Thread state for a thread which has not yet started. */ NEW, /** * Thread state for a runnable thread. A thread in the runnable * state is executing in the Java virtual machine but it may * be waiting for other resources from the operating system * such as processor. */ RUNNABLE, /** * Thread state for a thread blocked waiting for a monitor lock. * A thread in the blocked state is waiting for a monitor lock * to enter a synchronized block/method or * reenter a synchronized block/method after calling * {@link Object#wait() Object.wait}. */ BLOCKED, /** * Thread state for a waiting thread. * A thread is in the waiting state due to calling one of the * following methods: * &lt;ul&gt; * &lt;li&gt;{@link Object#wait() Object.wait} with no timeout&lt;/li&gt; * &lt;li&gt;{@link #join() Thread.join} with no timeout&lt;/li&gt; * &lt;li&gt;{@link LockSupport#park() LockSupport.park}&lt;/li&gt; * &lt;/ul&gt; * * &lt;p&gt;A thread in the waiting state is waiting for another thread to * perform a particular action. * * For example, a thread that has called &lt;tt&gt;Object.wait()&lt;/tt&gt; * on an object is waiting for another thread to call * &lt;tt&gt;Object.notify()&lt;/tt&gt; or &lt;tt&gt;Object.notifyAll()&lt;/tt&gt; on * that object. A thread that has called &lt;tt&gt;Thread.join()&lt;/tt&gt; * is waiting for a specified thread to terminate. */ WAITING, /** * Thread state for a waiting thread with a specified waiting time. * A thread is in the timed waiting state due to calling one of * the following methods with a specified positive waiting time: * &lt;ul&gt; * &lt;li&gt;{@link #sleep Thread.sleep}&lt;/li&gt; * &lt;li&gt;{@link Object#wait(long) Object.wait} with timeout&lt;/li&gt; * &lt;li&gt;{@link #join(long) Thread.join} with timeout&lt;/li&gt; * &lt;li&gt;{@link LockSupport#parkNanos LockSupport.parkNanos}&lt;/li&gt; * &lt;li&gt;{@link LockSupport#parkUntil LockSupport.parkUntil}&lt;/li&gt; * &lt;/ul&gt; */ TIMED_WAITING, /** * Thread state for a terminated thread. * The thread has completed execution. */ TERMINATED; } 四、线程池1、为什么使用线程池 减少线程创建和销毁的开销 提高响应速度，因为去掉了线程创建的时间 更好的管控线程，例如控制线程创建数，避免线程创建过多导致资源耗尽 2、使用场景 使用线程池处理的任务不能有依赖关系，否则会导致并发度下降，甚至会有死锁发生； 常用于处理执行时间较短，但又数量大的任务； 3、继承体系 4、线程池的状态12345678910111213141516/*** RUNNING: Accept new tasks and process queued tasks* SHUTDOWN: Don't accept new tasks, but process queued tasks* STOP: Don't accept new tasks, don't process queued tasks,* and interrupt in-progress tasks* TIDYING: All tasks have terminated, workerCount is zero,* the thread transitioning to state TIDYING* will run the terminated() hook method* TERMINATED: terminated() has completed*/ // runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; 5、线程池数量线程数量 = ((线程等待时间 + 线程CPU时间) / 线程CPU时间) * CPU个数 五、ThreadPoolExecutor1、初始化参数123456789101112131415161718192021222324252627282930313233343536/** * Creates a new {@code ThreadPoolExecutor} with the given initial * parameters. * * @param corePoolSize the number of threads to keep in the pool, even * if they are idle, unless {@code allowCoreThreadTimeOut} is set * @param maximumPoolSize the maximum number of threads to allow in the * pool * @param keepAliveTime when the number of threads is greater than * the core, this is the maximum time that excess idle threads * will wait for new tasks before terminating. * @param unit the time unit for the {@code keepAliveTime} argument * @param workQueue the queue to use for holding tasks before they are * executed. This queue will hold only the {@code Runnable} * tasks submitted by the {@code execute} method. * @param threadFactory the factory to use when the executor * creates a new thread * @param handler the handler to use when execution is blocked * because the thread bounds and queue capacities are reached * @throws IllegalArgumentException if one of the following holds:&lt;br&gt; * {@code corePoolSize &lt; 0}&lt;br&gt; * {@code keepAliveTime &lt; 0}&lt;br&gt; * {@code maximumPoolSize &lt;= 0}&lt;br&gt; * {@code maximumPoolSize &lt; corePoolSize} * @throws NullPointerException if {@code workQueue} * or {@code threadFactory} or {@code handler} is null */ public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { …… } 1）corePoolSize：线程池核心线程数，即使空闲也不会结束； 2）maximumPoolSize：线程池可创建的最大线程数 3）keepAliveTime：非核心线程等待任务的最大时间，超过该时间线程会终止 4）unit：时间单位 5）workQueue：存放任务的阻塞队列 6）threadFactory：线程工厂，可用于定制线程的名称和异常处理等； 7）handler：线程池的饱和策略，当阻塞队列放满且线程达到最大值时，新提交的任务会通过具体的饱和策略进行处理。 AbortPolicy：默认策略，抛出RejectedExecutionException异常； DiscardPolicy: 忽略，不执行任何逻辑； DiscardOldestPolicy: 抛弃旧的任务，然后再次提交任务 CallerRunsPolicy: 提交任务的线程执行任务 2、提交任务：submit和execute区别1）submit会调用newTaskFor方法封装任务为FutureTask，然后调用execute，返回FutureTask。 1234567891011121314151617181920212223242526272829303132public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; { public void run() { if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try { Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) { V result; boolean ran; try { result = c.call(); ran = true; } catch (Throwable ex) { result = null; ran = false; setException(ex); } if (ran) set(result); } } finally { // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); } } } FutureTask执行时会catch任务执行的异常，调用Future.get方法时会抛出异常； 2）execute没有返回值，不会包装runnable为FutureTask，Woker执行异常时会导致Worker线程结束。 3、原理当通过sumite或execute提交一个任务时，有以下3个场景： 1）如果线程池的线程数小于corePoolSize 新建核心线程，并把提交的任务作为该线程处理的第一个任务； 2）如果线程池的线程数不小于corePoolSize 把任务加入阻塞队列； 3）如果加入阻塞队列失败 新建非核心线程，并把提交的任务作为该线程处理的第一个任务； 4）如果核心线程池已到达最大值 执行跑和策略 4、线程池关闭1）shutdown：调用后会设置线程池状态为SHUTDOWN，不再接受新任务，新任务会执行拒绝策略，阻塞队列里已有任务仍会处理。 2）shutdownNow：调用后会设置线程中断标志，设置线程池状态为STOP。然后会移除阻塞队列里的任务。getTask时发现处于STOP时，会减少worker数，然后返回null。 5、异常处理1）线程中断异常：woker会退出，但是退出前在runworker方法中finally块会执行worker-1操作。 2）任务执行异常：提交的任务被封装为FutureTask，里面捕获了所有异常，不会导致woker退出。 所以即使设置了setUncaughtExceptionHandler，也会感知不到任务失败。所以还是在任务中增加try-catch最好。 六、ScheduledThreadPoolExecutor1、前置问题I、类继承层级 II、使用场景 III、执行原理 IV、任务执行时间超出period或delay后的处理逻辑 V、DelayedWorkQueue实现原理 VI、ScheduledThreadPoolExecutor和Timer的区别 VII、scheduleAtFixedRate和scheduleWithFixedDelay的区别 2、类继承层级 3、使用场景I、服务注册发送心跳 II、定时拉取FTP文件 III、EDI里定时执行git pull，同步git仓库 IV、分布式锁 4、初始化参数123public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler);} 1）corePoolSize：线程池核心线程数； 2）threadFactory：线程工厂，可用于定制线程的名称和异常处理等； 3）handler：线程池的饱和策略，当阻塞队列放满且线程达到最大值时，新提交的任务会通过具体的饱和策略进行处理。 AbortPolicy：默认策略，抛出RejectedExecutionException异常； DiscardPolicy: 忽略，不执行任何逻辑； DiscardOldestPolicy: 抛弃旧的任务，然后再次提交任务 CallerRunsPolicy: 提交任务的线程执行任务 5、整体执行流程I、把任务封装为ScheduledFutureTask II、把任务加入优先级队列，任务会在队列内排序 III、若线程数小于核心线程，则增加线程 6、提交任务过程1）4个提交任务方法1234567891011// 添加延迟任务public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit)// 添加延迟任务public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit)// 添加固定速率的周期任务public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)// 添加固定延迟的周期任务public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) 2）提交过程I、把任务封装为：ScheduledFutureTask，包含任务的执行时间、序列号、执行间隔，用于优先级队列排序。 ScheduledFutureTask会捕获所有异常并设置失败标志位，防止Worker线程退出。 II、添加任务到DelayedWorkQueue，一个阻塞的优先级队列。队列使用ReentrantLock的条件队列，防止竞争。 III、调用ensurePrestart，若当前woker小于core，则新增一个worker。 7、队列取任务过程java.util.concurrent.ScheduledThreadPoolExecutor.DelayedWorkQueue#take 1）通过reentrantLock加锁，进入以下循环逻辑 ==循环体开始== 2）队列为空时，available.await() 进入lock的条件队列等待，让出锁。 3）队列非空时 首个任务到执行时间：取出任务 首个任务不到执行时间： leader不为空，available.await()进入lock的条件队列等待，让出锁。 leader为空，设置自身为leader，available.awaitNanos(delay)进入lock的条件队列等待超时，等待结束后，设置leader为null。 ==循环体结束== 4）leader为空时，且队列非空时，唤醒条件队列 5）unlock NOTE：queue中的leader超时等待（TIMED_WATING）阻塞队列中的第一个任务，其他woker则等待（WATING）被leader唤醒。 8、任务取消和异常处理123456789101112131415ScheduledThreadPoolExecutor$ScheduledFutureTask /** * Overrides FutureTask version so as to reset/requeue if periodic. */ public void run() { boolean periodic = isPeriodic(); if (!canRunInCurrentRunState(periodic)) cancel(false); else if (!periodic) ScheduledFutureTask.super.run(); else if (ScheduledFutureTask.super.runAndReset()) { setNextRunTime(); reExecutePeriodic(outerTask); } } 1）调用FutureTask#cancel方法，会把任务标示为取消态；然后在ScheduledFutureTask#run中调用runAndReset时会判断状态，如果不是NEW则直接返回false；于是会忽略执行逻辑和再次把任务添加到任务队列的逻辑； NOTE：可以设置setRemoveOnCancelPolicy为true，直接在cancel时把任务从队列中移除，而不用等到任务执行，这可以避免有的任务的延迟很长，短时间内执行不到，占用队列的空间； 2）任务异常时，runAndRest会返回false，于是会忽略把任务添加到任务队列的逻辑； 9、下次执行时间计算1）schedule方法：非间隔任务 2）scheduleAtFixedRate方法：本次执行时间 + 间隔 3）scheduleWithFixedDelay方法：本次结束时间 + 间隔 NOTE：period的符号区分fixRate（正）和FixDelay（负）。 10、Timer对比1）线程 timer为单线程，某任务执行时间长会影响其他任务。 ScheduledThreadPoolExecutor为线程池任务不会相互影响。 2）执行时间 timer使用操作系统时间，一旦操作系统时间改变，影响调度 ScheduledThreadPoolExecutor使用相对时间，不受操作系统时间影响 3）异常处理 timer不会捕获异常，一旦任务跑出异常，则调度线程也会终止，其他任务不会再执行 ScheduledThreadPoolExecutor，捕获异常，会保证线程数 4）任务优先级 timer按系统时间执行，系统时间重置时会有影响 ScheduledThreadPoolExecutor基于相对时间，且支持排序，DelayedWorkQueue内有优先级队列 11、源码1）ScheduledFutureTask I、关键属性 time：任务触发的时间 period：任务执行的间隔，如果是fixRate，则是正数；如果是fixDelay，则是负数； sequenceNumber：序列号，为任务的提交顺序 II、实现比较接口，为任务插入优先级队列排序提供支持 先按time排序； 若time相同，再按Sequence排序； 123456789101112131415161718public int compareTo(Delayed other) { if (other == this) // compare zero if same object return 0; if (other instanceof ScheduledFutureTask) { ScheduledFutureTask&lt;?&gt; x = (ScheduledFutureTask&lt;?&gt;)other; long diff = time - x.time; if (diff &lt; 0) return -1; else if (diff &gt; 0) return 1; else if (sequenceNumber &lt; x.sequenceNumber) return -1; else return 1; } long diff = getDelay(NANOSECONDS) - other.getDelay(NANOSECONDS); return (diff &lt; 0) ? -1 : (diff &gt; 0) ? 1 : 0; } III、任务执行后，重置下次的执行时间；并发任务再次插入优先级队列； 如果是fixRate，则下次执行时间是本次执行时间 + 时间间隔 如果是fixDelay，则下次执行时间是当前时间 + 时间间隔 1234567private void setNextRunTime() { long p = period; if (p &gt; 0) time += p; else time = triggerTime(-p); } 2）DelayedWorkQueue I、内含一个无界的PriorityQueue - 小顶堆实现 II、为减少不必要的定时等待，其实现了一个主从模式变体的等待模型。 1234567891011121314151617static class DelayedWorkQueue extends AbstractQueue&lt;Runnable&gt; implements BlockingQueue&lt;Runnable&gt; {/*** 指定在队列的最前面等待任务的线程。* 这种主从模式的变体减少不必要的定时等待。当一个线程成为leader线程时，它只等待下一个延迟过去，而其他线程则无限期地等待。* 在从take（）或poll（…）返回之前，leader线程必须向其他线程发出信号，除非其他线程在此期间成为leader。* 每当队列的头被替换为具有较早到期时间的任务时，leader字段将通过重置为null而失效，并向某些等待线程（但不一定是当前的leader）发出信号。* 因此，等待线程必须做好准备，以便在等待期间获得和失去领导权。**/Thread leader = null;private final ReentrantLock lock = new ReentrantLock();/*** 条件队列，唤醒条件：1）队首的任务到达执行时间；2）需要启用新的线程成为leader。**/private final Condition available = lock.newCondition();}","link":"/2020/08/31/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%89%96%E6%9E%90/"},{"title":"缓存常见问题","text":"一、缓存失效问题1、缓存穿透1）现象：查询一个不存在的数据，即在缓存层和存储层都不存在。 2）解决： I、布隆过滤器 类似hash，返回存在不一定存在，返回不存在就一定不存在。缺点是需要灌入所有输入。 II、缓存空对象+超时时间 2、缓存击穿/失效1）现象：缓存中Key批量过期，导致大量请求击穿到数据库。 2）解决： I、缓存定期刷新，错开缓存失效时间 II、分布锁同步请求； 3、缓存雪崩1）现象：缓存层崩溃后，请求直接打向存储层，导致存储层也级联崩溃。 2）解决： I、增强缓存：多级缓存，缓存提前水平扩容 II、访问存储层限流：对访问存储层进行限流，防止雪崩 二、缓存和Mysql双写一致性问题1、缓存和Mysql双写可能导致不一致的关键点： 1）双写顺序，先写Mysql，然后再写缓存，因为Mysql支持回滚，而缓存不支持。 2）网络故障，网络故障导致第一层写入顺序和第二层写入顺序不一致。 2、解决方案 1）双写改为，两删一写+同步 I、删除缓存数据 II、写入数据到Mysql III、删除缓存数据 IV、监听Mysql Binlog，同步写操作至缓存 2）延时双删 + 重试 I、删除缓存数据 II、写入数据到Mysql III、延迟一段时间，再删一次缓存数据 IV、延迟删除失败后，进行重试","link":"/2022/03/14/%E7%BC%93%E5%AD%98%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"title":"落盘机制","text":"一、Redis1、落盘策略AOF日志会先写入操作系统系统的内存缓冲区，当缓冲区满、超过指定时间、执行fsync命令时会进行落盘。 1234# 落盘策略appendfsync always # 每条命令都刷盘appendfsync everysec # 每秒刷盘一次，默认选择，兼顾安全和速度appendfsync no # 交给操作系统 2、主从复制主从异步复制 二、ZK1、落盘策略ZK事务日志落盘策略配置 12// 默认强制落盘zookeeper.forceSync=true 2、主从复制主从同步复制：2-phase I、第一阶段： leader写入本地事务日志文件 leader发出proposal广播给follower follower收到proposal，写入本地事务日志文件，返回ACK给leader。 此时leader和follower的写入不可见。 II、第二阶段： leader收到主从总和半数以上ACK，进入commit阶段 leader将事务请求同步至内存，广播Commit命令给follower，响应给客户端。 follower收到commit请求，读取事务请求到内存 三、ES1、落盘策略 参考：https://elasticsearch.cn/article/13533 1）引入translog，追加写入。默认同步刷盘。 1index.translog.durability=fsync/async 2）先写lucene再写translog，因为luncene可能写失败，为了减少回滚开销，先写luncene。 3）写入关键流程 I、写入lucene II、写入translog III、flush translog，刷盘 - 可通过上面配置为异步 IV、发送请求给副本 V、等待副本响应 2、主从同步 四、Kafka1、落盘策略默认同步刷盘，producer.type表示mmap修改后是否立即执行flush将其刷至硬盘。 1producer.type=sync/async 2、主副本同步https://juejin.cn/post/6857514628516315149 12345# broker配置min.insync.replicas=2# producer配置acks=0/1/all","link":"/2022/03/29/%E8%90%BD%E7%9B%98%E6%9C%BA%E5%88%B6/"},{"title":"科学的引用类名和包名","text":"1. 背景近期重构项目的时候，不可避免的修改了包名，出现了服务无法注册，函数没有加载等问题。溯其根源是这些扫描注册的模块直接引用了类的字符串的硬编码，编译期无法检测出来。 2. 直接字符串引用包名/类名的缺陷 修改包名/类名时，IDE无法找出字符串引用并修改； 修改包名/类名后，相关的错误无法通过编译检测出来； 3. 原因1）粗心设计，没考虑修改时引起的不便；2）模块结构不规范,需要引用的类不在自己的依赖范围；例如模块B，C是平行关系，互相不依赖。此时如果B要应用C中的某个类，则只能通过字符串来引用才能避免编译器报错。本情况需要考虑把B依赖的部分，抽到公共模块，被B,C共享。 123 A/ \\B C 4. 科学引用类名/包名 1）示例一：设计欠考虑 注解Service第二个参数使用字符串来指定类。 不科学代码 123456 @XStreamAlias(&quot;jsf&quot;)@Service(type = &quot;jsf&quot;, provider = &quot;com.jd.edi.service.provider.JsfServiceProvider&quot;)@Node(name = &quot;jsfService&quot;, desc = &quot;JSF服务&quot;, isStart = true)public class JSfProviderConf extends AbstractProviderConfig {...} 修正代码把Service的第二个参数修改为Class类型。 123456@XStreamAlias(&quot;jsf&quot;)@Service(type = &quot;jsf&quot;, provider = JsfServiceProvider.class)@Node(name = &quot;jsfService&quot;, desc = &quot;JSF服务&quot;, isStart = true)public class JSfProviderConf extends AbstractProviderConfig {...} 2）示例二：模块结构不合理依赖了不在依赖范围的包 不科学代码 1JarScanUtil.scan(&quot;com.jd.edi.function&quot;); 修正代码抽取该包及其子类到公共依赖 1JarScanUtil.scan(CommonFunction.class.getPackage().getName());","link":"/2019/12/10/%E7%A7%91%E5%AD%A6%E7%9A%84%E5%BC%95%E7%94%A8%E7%B1%BB%E5%90%8D%E5%92%8C%E5%8C%85%E5%90%8D/"},{"title":"网络上行和下行","text":"一、上行和下行 上行：数据流出（out）当前结点。 下行：数据流入（in）当前结点。 二、引用阿里云社区的回答 参考 UpStream - wikipedia DownStream - wikipedia 上行带宽，下行带宽；上传速度，下载速度 求扫盲，服务器的上传和下载的带宽两者互相影响吗","link":"/2021/01/19/%E7%BD%91%E7%BB%9C%E4%B8%8A%E8%A1%8C%E5%92%8C%E4%B8%8B%E8%A1%8C/"},{"title":"蓝绿发布vs灰度发布vs滚动发布","text":"蓝绿发布和灰度发布都涉及路由的变更，而滚动发布则只需要逐次更新实例即可。 一、蓝绿发布1）蓝绿发布过程中，新老版本不同时工作，非此即彼。 2）部署步骤： 当要发布新版本时，部署一套新环境，集群数量和配置都不低于老版本； 修改路由，把流量由老集群全部切到新环境的集群上； 二、灰度发布（金丝雀发布）1）灰度发布过程中，新老版本会同时工作。 2）部署步骤： 当要发布新版本时，部署一套新环境，新集群容器数量可随切入的流量，由少量递增至不少于老版本的数量 修改路由，把流量灰度递增的切到新集群容器；并适时增加新集群容器数量； 三、滚动发布1）灰度发布过程中，新老版本会同时工作 2）部署步骤： 不需要部署新集群，只需要依次更新集群内实例即可。","link":"/2021/07/02/%E8%93%9D%E7%BB%BF%E5%8F%91%E5%B8%83vs%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83vs%E6%BB%9A%E5%8A%A8%E5%8F%91%E5%B8%83/"},{"title":"装饰器和代理的区别","text":"1. 相同点类图相似： 2. 不同点 功能 装饰器用于增强新的功能，如java的Stream设计，实现拦截器，职责链等； 代理用于限制或改变功能，如延迟实例化，AOP等； 关联实例的时间 装饰器的实例可在运行时动态传入； 代理的实例一般编译时确定； 客户端使用 装饰器，客户端在使用时可以自由组合，具有主动性； 代理，客户端一般处于被动，无法改变代理的逻辑； 参考： https://stackoverflow.com/questions/350404/how-do-the-proxy-decorator-adapter-and-bridge-patterns-differ","link":"/2020/03/25/%E8%A3%85%E9%A5%B0%E5%99%A8%E5%92%8C%E4%BB%A3%E7%90%86%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"负载均衡4层和7层区别","text":"一、网络协议分层图片来源：https://blog.csdn.net/dgce56105/article/details/102215403 二、负载均衡 负载均衡主要是为了使后端服务器分摊请求压力，不至使热点问题发生。 三、负载均衡四层和七层目前主流的负载均衡软件如Nginx，HAProxy等都支持配置四层和七层。 四层 七层 LB设备拆包级别 拆包到传输层 拆包到应用层 实现和配置难易 易 难 CPU消耗 小 较大 客户端请求时建立的TCP连接数 一个TCP连接，LB只做NAT功能 最少两个TCP连接（Client &lt;—&gt; LB，LB&lt;—&gt;Server）；多路复用下，会建立多个LB&lt;—&gt;Server连接 智能程度 低 高，可基于应用内容做负载均衡 安全程度 不窥探应用内容 解析应用内容 推荐 低 高（优先选择） #参考 L4 vs L7 Load Balancing load-balancing-layer-4-and-layer-7 layer-4-vs-layer-7-load-balancing","link":"/2021/02/07/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A14%E5%B1%82%E5%92%8C7%E5%B1%82%E5%8C%BA%E5%88%AB/"},{"title":"误用BlockingQueue方法导致日志丢失","text":"一、背景最近研发反映线上EDI的日志有丢失现象，经过审查代码发现，本机使用的BlockingQueue方法有误，使用的BlockingQueue#add方法，此时当队列满时会插入失败，返回false。 二、修改方案方案一、修改BlockingQueue#add为BlockingQueue#put；方案二、判断BlockingQueue#add返回值为false时，增加重试或写本地方案；三、BlockingQueue注释123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public interface BlockingQueue&lt;E&gt; extends Queue&lt;E&gt; { /** * Inserts the specified element into this queue if it is possible to do * so immediately without violating capacity restrictions, returning * {@code true} upon success and throwing an * {@code IllegalStateException} if no space is currently available. * When using a capacity-restricted queue, it is generally preferable to * use {@link #offer(Object) offer}. * * @param e the element to add * @return {@code true} (as specified by {@link Collection#add}) * @throws IllegalStateException if the element cannot be added at this * time due to capacity restrictions * @throws ClassCastException if the class of the specified element * prevents it from being added to this queue * @throws NullPointerException if the specified element is null * @throws IllegalArgumentException if some property of the specified * element prevents it from being added to this queue */ boolean add(E e); /** * Inserts the specified element into this queue if it is possible to do * so immediately without violating capacity restrictions, returning * {@code true} upon success and {@code false} if no space is currently * available. When using a capacity-restricted queue, this method is * generally preferable to {@link #add}, which can fail to insert an * element only by throwing an exception. * * @param e the element to add * @return {@code true} if the element was added to this queue, else * {@code false} * @throws ClassCastException if the class of the specified element * prevents it from being added to this queue * @throws NullPointerException if the specified element is null * @throws IllegalArgumentException if some property of the specified * element prevents it from being added to this queue */ boolean offer(E e); /** * Inserts the specified element into this queue, waiting if necessary * for space to become available. * * @param e the element to add * @throws InterruptedException if interrupted while waiting * @throws ClassCastException if the class of the specified element * prevents it from being added to this queue * @throws NullPointerException if the specified element is null * @throws IllegalArgumentException if some property of the specified * element prevents it from being added to this queue */ void put(E e) throws InterruptedException; /** * Retrieves and removes the head of this queue, waiting if necessary * until an element becomes available. * * @return the head of this queue * @throws InterruptedException if interrupted while waiting */ E take() throws InterruptedException;}","link":"/2020/12/16/%E8%AF%AF%E7%94%A8BlockingQueue%E6%96%B9%E6%B3%95%E5%AF%BC%E8%87%B4%E6%97%A5%E5%BF%97%E4%B8%A2%E5%A4%B1/"},{"title":"请求代理配置","text":"一、场景描述开发机：远程开发环境，无法访问外网 工作机：本地操作机器，链接远程开发机进行开发 二、工作机启动代理服务端 https://github.com/ginuerzh/gost 1gost -L http://:8118 如果是MacOS，使用CronTab保活： 1*/10 * * * * screen -dms proxy /opt/homebrew/bin/gost -L &quot;http://:8118&quot; 三、开发机配置请求代理1、配置SSH请求代理1）配置 ~/.ssh/config【推荐】使用corkscrew，安装命令：apt install corkscrew 12Host github.com ProxyCommand corkscrew 工作机IP 8118 %h %p 【不推荐】原因：代理时可能会出现异常，详见wrongnetcat 12Host github.com ProxyCommand nc -X connect -x 工作机IP:8118 %h %p 2）验证github联通性 1ssh -T git@github.com 3）创建代理IP刷新脚本：~/.ssh/config_refresh.sh 1234567891011121314#!/bin/bash# 检查参数是否正确if [ $# -ne 1 ]; then echo &quot;用法: $0 &lt;新IP&gt;&quot; exit 1fifile='/home/wangqiwei.bj/.ssh/config'new_ip=&quot;$1&quot;# 使用sed安全替换（先创建临时文件再覆盖）sed -i.bak &quot;s/\\(corkscrew \\)[^ ]\\+/\\1$new_ip/g&quot; &quot;$file&quot; &amp;&amp; rm -f &quot;$file.bak&quot;echo &quot;SSH Proxy Refreshed In '$file'&quot; 2、配置http请求代理1）配置 ~/.zshrc 12345678910111213141516171819# no_proxy配置开发机可访问的域名和IP段export no_proxy=&quot;localhost,127.0.0.1,127.0.0.0/8,169.254.0.0/16,172.16.0.0/12,192.168.0.0/16,10.0.0.0/8&quot;export NO_PROXY=&quot;localhost,127.0.0.1,127.0.0.0/8,169.254.0.0/16,172.16.0.0/12,192.168.0.0/16,10.0.0.0/8&quot;function Proxy() { #ip=工作机IP/其他Proxy IP ip=`sudo netstat -tpn | grep &quot;ESTABLISHED.*sshd&quot; |grep 「开发地址」 | awk '{ print $5}' | cut -d: -f1 |sort | uniq -c |sort -n| awk '{ print $2}' | head -n 1` if [ &quot;$1&quot; = &quot;on&quot; ]; then /home/wangqiwei.bj/.ssh/config_refresh.sh $ip export https_proxy=$ip:8118 export http_proxy=$ip:8118 echo Http Proxy On $ip else /home/wangqiwei.bj/.ssh/config_refresh.sh &quot;proxy_off&quot; unset https_proxy unset http_proxy echo Http Proxy Off fi } 2）启用配置 1source ~/.zshrc 3）启用代理 1Proxy on","link":"/2025/09/09/%E8%AF%B7%E6%B1%82%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/"},{"title":"返回值里藏着异常信息","text":"昨日UAT环境发现一个问题，今日想来还是有必要记录一下，毕竟有些方法执行出错时选择抛出异常，而有些方法选择把异常信息裹进返回值。如果忽略了返回值的校验，就有可能出现异常信息丢失的情况，让人摸不着头脑。 一、背景 EDI UAT环境调用jgit进行push时，始终不成功，但是日志里又没有任何异常信息。 二、原因 新建仓库的分支被设置为保护分支，不允许develop权限的用户push。 jgit把push异常信息返回，而我们的程序调用时又忽略了对返回值的校验； 三、解决 用户权限改为Maintainer 程序里增加返回值校验 四、反思如果程序执行结果非预期且日志没有异常信息，那么可能有以下可能：1）程序抛出异常，但被捕获后忘记输出任何日志——吃掉了异常2）程序把异常以返回值形式返回，程序里忘记校验返回值——丢失异常","link":"/2020/08/20/%E8%BF%94%E5%9B%9E%E5%80%BC%E9%87%8C%E8%97%8F%E7%9D%80%E5%BC%82%E5%B8%B8%E4%BF%A1%E6%81%AF/"},{"title":"进程运行信息","text":"进程运行信息一、进程运行时变量进程环境变量有时候与操作系统的环境变量不同，例如其会在其启动脚本里定义一些变量export {var}={value}。 此时可以通过如下命令查看进程的真实环境变量： cat /proc/{pid}/environ ps eww {pid} 二、进程命令行查看进程启动的命令行：cat /proc/{pid}/cmdline","link":"/2022/09/08/%E8%BF%9B%E7%A8%8B%E8%BF%90%E8%A1%8C%E4%BF%A1%E6%81%AF/"},{"title":"这不是我想要的日志","text":"一、问题描述上周三在查看线上Rest服务器后台的日志时，发现日志内容只有spring框架的日志，项目通过logger4j记录的日志则全部没有记录。 二、尝试路径 怀疑有人修改了log4j2.xml文件,定制了日志打印内容。 结果，发现log4j2.xml文件最近没有变化。 下载线上的运行的版本包在本地运行，查看nohup.out文件。结果，发现nohup.out打印正常。 检查是否slf4j绑定了log4j实现，查看nohup.out文件。结果，发现其加载了slf4j-simple的jar。如下所示： 12345SF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/home/kivi/Downloads/edi-rest_253244_T_7c14b96_2019.09.18-11.36.43/lib/slf4j-simple-1.7.22.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/home/kivi/Downloads/edi-rest_253244_T_7c14b96_2019.09.18-11.36.43/lib/log4j-slf4j-impl-2.9.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.slf4j.impl.SimpleLoggerFactory] 最后发现是项目最近新依赖了一个module，而导致间接依赖了这个包。而slf4j的SPI框架依赖jar的加载顺序来绑定实现。 三、反思 第二步走到第三步之间花费时间很多，当时假想肯定是某个log4j2.xml文件有问题，忽略了slf4j是SPI框架加载实现的原理。本质还是对slf4j的原理不清楚或理解的不深。 参考 Java的日志框架","link":"/2019/09/27/%E8%BF%99%E4%B8%8D%E6%98%AF%E6%88%91%E6%83%B3%E8%A6%81%E7%9A%84%E6%97%A5%E5%BF%97/"},{"title":"随笔","text":"宽带的边际成本 2025/05/28 本月宽带到期，计划趁机换个便宜的套餐。原来的资费是手机低消129¥/Month，包含1000M宽带，手机300分钟通话，30GB流量。然而移动APP和10086人工服务中查询的套餐价格都性价比不高，通过直接联系营业厅的人才发现一个合适的套餐59¥/Month，包含300M宽带，手机100分钟通话，20GB流量。 有两个道理：1）当网络的基础设施搭建好后，新增一个用户的边际成本为零，这必然导致价格的下降；2）如果一个边际成本为零的公示价格性价比不高，那么可能是因为垄断、信息不透明导致的。视频网站的会员也是一样的道理。 秦官方统一文字到小篆的失败 2025/09/24 秦官方想要统一文字到小篆，虽然小篆书写优美，但是其书写效率较低，后被隶书在实际上统一。这里有几点值得寻思：1）官方的人和民间的文人都会写字，但是文字的使用和推广上却不相同。官方推崇美的文字，民间推崇高效的文字。这两者无疑都是文字的重要属性，但是从大范围推广来说书写效率决定了推广的难易程度。简化、易用的文字比美的文字更能被广泛使用，是传播的底层规律。即，需要把握客观事实的规律，哪怕规律不符合人类对“好”的定义。2）认知的局限、位置的不同，可能会导致忽视客观规律。需要保持open的心态，接受新信息和新思想。3）代码和系统设计领域，好的架构或理想架构是可欲的，但是应用时要考虑客观规律，以符合当下业务、有限成本投入等客观条件，从务实的角度利用规律，不要违背它。 网信办开展2个月的“清朗 整治恶意挑动负面情绪问题”专项行动 2025/09/25 治理出发点是治理极端言论导致的对立。但是具体执行时可能面临以下问题：1）一个观点必然有支持者和否定者，造成一定程度的不同群体的对立。即观点会导致群体对立是客观事实，观点和对立是一体双生的。2）极端言论的判断标准并不明确，可能受意识形态、法治程度、人民开化程度、流弊影响等因素导致标准不统一。3）执行过程中是否稳定性高于判断的准确性，扩大治理范围，从而导致正常的观点被遏制。4）扼制语言表达，必然会扼制思想的传播和进化。文明的社会需要不同的观点和声音。如何在专项治理的同时不损害言论自由，具有很大的挑战性。5）提高国民经济水平、受教育水平、逻辑思维能力，才是解决极端观点大行其道的根本方法。 区分好的决策和好的结果 2025/10/10 《清晰思考：将平凡时刻转为非凡成果》中关于好的决策和好的结果的案例论述。今天想到一个比较贴切的例子： 天气预报 是否带伞 是否好决策 是否有雨 是否好结果 有雨 带伞 好决策 有雨 好结果 无雨 坏结果 有雨 不带伞 坏决策 有雨 坏结果 无雨 好结果 无雨 不带伞 好决策 有雨 坏结果 无雨 好结果 事情的发展及结果，除受决策外，还受一些随机因素、外部因素等影响。好的决策可以增加好结果的概率，但无法保证好结果。反过来来说，好的结果不一定是由于好的决策导致的。如果把好结果错误的归因为是因为有好的决策，因此把这个错误决策思路和经验沉淀下来，就会对后面的同类事件产生负面影响。 近日爆火的个人动画与AI赋能 2025/10/13 最近有个B站up主依靠AI创作了一个爆火的动画《欺天道君》，很多人质疑都是AI味。我认为这可能正是AI赋予的技术平权，导致更多的创意以更低的成本和更小的周期得以涌现。让人从低水平的劳动中解脱，给创意和思考以更多的时间。科技不是完全较少劳动时间，而是提高有创意劳动时间的占比，改变个人时间的构成，放大想法的价值。 导盲犬被禁止进入 2025/10/27 昨天晚上听了一期关于盲人做客的讲述导盲犬相关的播客。其中提到某博物馆不允许导盲犬进入博物馆，但是工作人员会配同游览。在“明眼人”看来这已经提供了很大的便利，盲人应该会欣然接受。但是节目中盲人朋友却说这是不可接受的，是底线问题，往大了说涉及人权，往小了说这是区别对待。另外导盲犬也可能因分离焦虑出现应激。这种方式一旦被认可就会被效仿，成为事实上的规则，导盲犬到处被限行，也就失去了意义。 事实不是想当然，站在对方角度去看待问题和思考问题。例如，提到的科技界的导盲杖，遇到障碍时会大声量提示，导致使用者在公共场合极为尴尬，这种产品就没有考虑使用者的心理感受，那么也很难有市场。 另外，导盲犬实际的作用是避障，叫避障犬更合适。 如何看待陌生人的冒犯行为 2025/11/04 近日电车在小区充电时，被人中途拔掉了，导致没有充满。类似这样的事情小区的其他业主也遇到过，并在群里讨论过。我在想应该怎么样看待这种陌生人的非犯法的冒犯行为。之前看过的一本讲情绪管理的书里提到过，你不开心是因为你潜意识里认为所有人都应该按照你所想一样去行动，所以遇到开车加塞、闯红灯、拔别人插头的行为会感到愤怒。所以该书里提到，在每天出门前告诉自己，今天会遇到无礼的人，遇到坏人。 针对此类事情可以从另一个角度来看，陌生人是一个熟人之外的更大的群体，这个群体的素质参差不齐，有道德标准高的、有文化素质低的做些损人利己的事、有纯坏的会做些损人也不利己的事、有潜在的犯罪分子、甚至还有已经犯罪的人。这些人被我们统一认定为陌生人，是模糊的，有时也是危险的。如果对一个潜在的犯罪分子较真，其后果不堪设想。法律虽在，但无法阻止被伤害。 认识陌生人的多样性，可以更好的理解周边发生的事情，以更理性的心态看待。 单元门口的挡车立柱 2025/12/31 在今年7月底我晚上被单元门口的矮的的挡车柱绊倒，然后和管家和物业沟通让他换成高的立柱并且外移，来防止绊倒和禁止车停在单元门口。但是物业不作为，在大群里发声后，物业把矮柱子给锯了，算是达成了其中一个目的。 最近新的挡车柱达成了我当时的目的。看到这个柱子我想到之前看到的一个视频，一个业主被附近健身的大爷玩弄健身器材的噪声困扰，该业主自己买了点润滑油把器材润滑了下，解决了困扰的问题。 发散下思维，面对很难驱动第三方去改善来提升自己体验时，我们能做的其实有很多。比如，门前的立柱，其实可以自己买个立柱找个师傅装一下，100块钱的事。但是分明的权责思维导致并未想到或行动，从而长久忍受、习惯。意识到“I can do something”，无法驱动环境他人改变时，多思考下我能做什么来改变，会有新的问题解决方法。","link":"/2025/12/31/%E9%9A%8F%E7%AC%94/"},{"title":"零拷贝","text":"零、零拷贝概念 “Zero-copy“ describes computer operations in which the CPU does not perform the task of copying data from one memory area to another. —— wikipedia 如维基百科所说，零拷贝是指避免CPU在不同的内存区域间拷贝数据。这可具体细分为操作系统级（OS level）别和用户态（User level）级别。 zero copy on OS level针对设备驱动，文件系统，网络协议栈等内核态资源，程序可利用操作系统提供的系统函数调用，避免数据从内核态和用户态间的拷贝，充分利用操作系统资源，获得更高的性能。 具体而言，操作系统通过相应的系统函数使CPU移交总线控制权给DMA，由DMA负责内核态间数据复制操作，不通过用户态进行中转。与此同时CPU并行去处理其他复杂的逻辑，也减少了上下文切换带来的开销。 zero copy on User level应用程序在用户态通过一些操作避免数据拷贝，也可以称为零拷贝。如Netty的CompositeByteBuf，可通过逻辑聚合多个ByteBuffer，避免物理复制多个ByteBuffer到一个大的ByteBuffer，来减少拷贝。 一、操作系统的Zero Copy1. Linux零拷贝系统函数 sys/socket.h中的sendfile，sendfile64 splice，tee，vmsplice process_vm_readv, process_vm_writev copy_file_range mmap，AF_XDP 经常有人mmap和sendfile放在一起进行比较，而忽略了他们的应用场景。 2. sendfile1）适用场景：适用于程序不参与处理数据，数据只在系统内核态间传输 不使用sendfile 使用sendfile 2）方法描述：由DMA负责在内核态进行数据拷贝，不再经过用户态中转 3）优点：减少了数据拷贝（内核态和用户态的拷贝为零）；减少了上下文切换；对文件大小没有限制；性能更好，约比使用read,write提高65%性能。 不实用sendfile时，发生了4次拷贝 使用sendfile时，发生了3次拷贝，用户态拷贝为零。（如果网络接口支持gather operations，可以再减少一次拷贝: Read buffer-&gt; Socket buffer） 不实用sendfile时，发生了四次上下文切换 使用sendfile时，只有两次上下文切换 4）缺点：程序不能参与处理 3. mmap1）适用场景：适用于程序参与处理数据，修改系统内核态的数据 2）方法描述：把文件或设备映射到内存，他通过给定的位置读取文件对应的块到内存。用户对这块内存的修改会直接反应到内核空间，与此同时，内核空间的修改，也会直接反应到用户空间。 3）优点：程序参与处理数据；处理小文件时性能高 4）缺点：没有减少上下文切换带来的开销；处理大文件时开销较大； 4. 总结 Sendfile Mmap 适用场景 程序不处理数据 程序参与数据处理 上下文切换次数 2次 4次 数据拷贝次数 3次或2次 3次 文件大小与性能 无限制 小文件性能好 Java NIO对系统调用的封装 FileChannel.transferTo(long position, long count,WritableByteChannel target) MappedByteBuffer类，可通过*FileChannel.map()*获取 其中，MappedByteBuffer是Java的一种direct byteBuffer。 二、Java direct vs non-direct byte buffer 直接缓冲区中通过文件映射创建的MappedByteBuffer与前面提到的mmap是一一对应的，体现了零拷贝的概念，其他类型缓冲区与OS level的零拷贝无关。 1. 直接缓冲区和非直接缓冲区的区别 The first difference between non-direct and direct byte buffer comes from the fact, how you create them. You can create non-direct byte buffer either by allocating space for buffer’s content or by wrapping an existing byte array into a buffer. While a Direct byte buffer may be created by calling factory method allocateDirect() or by mapping a region of a file directly into memory , known as MappedByteBuffer. In the case of Direct byte buffer, JVM performs native IO operation directly into the buffer, without copying them into any intermediate buffer, this makes it very attractive for performing high-speed IO operation on them, but this facility comes with care. If a memory mapped file is shared between multiple processes then you need to ensure that it won’t get corrupted i.e. some regions of memory mapped file not becoming unavailable. One more difference between direct and non-direct byte buffers are that former’s memory footprint may not be obvious because they are allocated outside of Java heap while non-direct buffers consume heap space and are subject to garbage collection. You can check whether a byte buffer is direct or non-direct by calling isDirect() method from java.nio.ByteBuffer class. It returns true if byte buffer is direct. Read more: https://javarevisited.blogspot.com/2015/08/difference-between-direct-non-direct-mapped-bytebuffer-nio-java.html#ixzz6lqSEEIpV 2. ByteBuffer如图所示，Java提供了三种ByteBuffer实现： 1）HeapByteBuffer 是非直接内存，用来在JVM堆上申请管理缓存，通常是字节数组的包装类。受JVM GC控制。 2）MappedByteBuffer 也是一种直接内存，是用来映射文件到直接内存中的，不受JVM GC控制。其通过系统函数mmap调用实现，利用缺页中断机制实现直接访问文件，避免数据拷贝到用户态，体现了零拷贝。 FileChannel.map最终也是调用了DirectByteBuffer的构造函数DirectByteBuffer(int cap, long addr, FileDescriptor fd, Runnable unmapper)。 3）DirectByteBuffer 是直接内存，用来在JVM堆外申请和管理内存，不受JVM GC控制。ByteBuffer.allocateDirect(int capacity)会调用构造函数DirectByteBuffer(int cap)。 123456789101112131415// Primary constructorDirectByteBuffer(int cap)// Invoked to construct a direct ByteBuffer referring to the block of// memory. A given arbitrary object may also be attached to the buffer.DirectByteBuffer(long addr, int cap, Object ob)// Invoked only by JNI: NewDirectByteBuffer(void*, long)private DirectByteBuffer(long addr, int cap)// For memory-mapped buffers -- invoked by FileChannelImpl via reflectionprotected DirectByteBuffer(int cap, long addr, FileDescriptor fd, Runnable unmapper)// For duplicates and slicesDirectByteBuffer(DirectBuffer db, int mark, int pos, int lim, int cap, int off) 三、常见Java中间件对零拷贝的使用1）Netty OS-level：FileRegion封装了FileChannel.transferTo() User-level：Transparent zero copy is achieved by built-in composite buffer type，类CompositeByteBuf避免了ByteBuf间的拷贝。 2）Kafka OS-level：Customer从broker消费数据，采用sendfile； OS-level：Producer生产的数据持久化到broker，采用mmap文件映射； 3）RocketMQ OS-level：生产和消费，采用mmap； # 参考 ✽It’s all about buffers: zero-copy, mmap and Java NIO ✽Efficient data transfer through zero copy - IBM developer ✽Difference between Direct, Non Direct and Mapped ByteBuffer in Java ✽Zero-copy - wikipedia ✽DirectByteBuffer and MappedByteBuffer Zero Copy I: User-Mode Perspective Netty与Zero Copy is-nettys-zero-copy-different-from-os-level-zero-copy 理解Netty中的Zero-copy Kafka零拷贝 零拷贝","link":"/2021/02/07/%E9%9B%B6%E6%8B%B7%E8%B4%9D/"},{"title":"非对称密码的私钥包含了公钥信息","text":"一、Jsch的UserAuthPublicKey类今日因为一个问题在看Jsch的UserAuthPublicKey源码时发现，如果我只传输私钥而不传输公钥，它会根据私钥计算出公钥，发送给服务侧。 非对称密码在实现时，会在私钥里包含完整的信息（包含生成公钥的信息），也就是说可以根据私钥计算出公钥。 二、解析引自java - JSCH addIdentity公钥参数没有任何区别 12345678910111213141516171819public class FTP { public static void main(String args[]){ JSch jsch = new JSch(); jsch.setKnownHosts(&quot;./known_hosts&quot;); Path privateKeyPath = Paths.get(&quot;./id_dsa&quot;); byte[] privateKey = Files.readAllBytes(privateKeyPath); Path publicKeyPath = Paths.get(&quot;./id_dsa.pub&quot;); byte[] publicKey = Files.readAllBytes(publicKeyPath); // Either of the lines below work... Why? // jsch.addIdentity(&quot;&quot;, privateKey, publicKey, null); // or jsch.addIdentity(&quot;&quot;, privateKey, null, null); Session session = jsch.getSession(&quot;USER&quot;, &quot;myHost.com&quot;, 22); session.connect(); }} 根据回答可知，有两种场景： 1）当私钥未加密时 以下两种方法等效，当公钥为空时，会根据私钥计算出公钥，然后发送给服务器端验证。 1234// privateKey: 未加密私钥// publicKey: 未加密公钥jsch.addIdentity(&quot;&quot;, privateKey, publicKey, null);jsch.addIdentity(&quot;&quot;, privateKey, null, null); 2）当私钥匙加密时 发送公钥给服务器验证，并仅在此密钥可用时客户端提示密码短语解密私钥获取未加密私钥。 123// privateKeyEncrypt: 加密私钥// publicKey: 未加密公钥jsch.addIdentity(&quot;&quot;, privateKeyEncrypt, publicKey, null); 三、通过私钥生成私钥1$ ssh-keygen -y -f id_rsa &gt; id_rsa.pub # 参考 can-i-get-a-public-key-from-an-rsa-private-key 知乎：RSA非对称可以通过私钥获取公钥吗？ java - JSCH addIdentity公钥参数没有任何区别","link":"/2021/03/19/%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%AF%86%E7%A0%81%E7%9A%84%E7%A7%81%E9%92%A5%E5%8C%85%E5%90%AB%E4%BA%86%E5%85%AC%E9%92%A5%E4%BF%A1%E6%81%AF/"},{"title":"顺序消费","text":"1、全局有序 一个Topic下的所有消息都需要按照生产顺序消费。 此时要求topic只有1个partion，使用1个消费者，且单线程消费模型。 2、局部有序 一个Topic下的消息，只需要满足同一业务字段的要按照生产顺序消费。 把业务标识指定为Partition Key，使相同业务数据顺序写入一个partion。 3、重试影响 max.in.flight.requests.per.connection=1，一个连接内发送中的请求数。 如果大于1，则有可能出现发送的是AB，但是由于网络延迟导致写入Broker的是BA。","link":"/2022/03/24/%E9%A1%BA%E5%BA%8F%E6%B6%88%E8%B4%B9/"}],"tags":[],"categories":[{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"TroubleShooting","slug":"TroubleShooting","link":"/categories/TroubleShooting/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"观察日志","slug":"TroubleShooting/观察日志","link":"/categories/TroubleShooting/%E8%A7%82%E5%AF%9F%E6%97%A5%E5%BF%97/"},{"name":"分布式中间件","slug":"分布式中间件","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Java并发","slug":"Java/Java并发","link":"/categories/Java/Java%E5%B9%B6%E5%8F%91/"},{"name":"网络","slug":"网络","link":"/categories/%E7%BD%91%E7%BB%9C/"},{"name":"流程分析","slug":"TroubleShooting/流程分析","link":"/categories/TroubleShooting/%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/"},{"name":"Debug","slug":"TroubleShooting/Debug","link":"/categories/TroubleShooting/Debug/"},{"name":"Maven","slug":"Java/Maven","link":"/categories/Java/Maven/"},{"name":"Dubbo","slug":"Java/Dubbo","link":"/categories/Java/Dubbo/"},{"name":"源码","slug":"Java/源码","link":"/categories/Java/%E6%BA%90%E7%A0%81/"},{"name":"Elasticsearch","slug":"分布式中间件/Elasticsearch","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%AD%E9%97%B4%E4%BB%B6/Elasticsearch/"},{"name":"Redis","slug":"分布式中间件/Redis","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"JavaSE","slug":"Java/JavaSE","link":"/categories/Java/JavaSE/"},{"name":"Mysql","slug":"Mysql","link":"/categories/Mysql/"},{"name":"Java虚拟机","slug":"Java/Java虚拟机","link":"/categories/Java/Java%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"Netty","slug":"Java/Netty","link":"/categories/Java/Netty/"},{"name":"工作","slug":"工作","link":"/categories/%E5%B7%A5%E4%BD%9C/"},{"name":"容器","slug":"容器","link":"/categories/%E5%AE%B9%E5%99%A8/"},{"name":"安全","slug":"安全","link":"/categories/%E5%AE%89%E5%85%A8/"},{"name":"Spring","slug":"Java/Spring","link":"/categories/Java/Spring/"},{"name":"Zookeeper","slug":"分布式中间件/Zookeeper","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/"},{"name":"单元测试","slug":"TroubleShooting/单元测试","link":"/categories/TroubleShooting/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"},{"name":"工具","slug":"工具","link":"/categories/%E5%B7%A5%E5%85%B7/"},{"name":"代码架构","slug":"代码架构","link":"/categories/%E4%BB%A3%E7%A0%81%E6%9E%B6%E6%9E%84/"},{"name":"学习","slug":"学习","link":"/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"工程实践","slug":"工程实践","link":"/categories/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/"},{"name":"读书笔记","slug":"学习/读书笔记","link":"/categories/%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"共识协议","slug":"分布式中间件/共识协议","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%AD%E9%97%B4%E4%BB%B6/%E5%85%B1%E8%AF%86%E5%8D%8F%E8%AE%AE/"},{"name":"思维定势","slug":"TroubleShooting/思维定势","link":"/categories/TroubleShooting/%E6%80%9D%E7%BB%B4%E5%AE%9A%E5%8A%BF/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"Kafka","slug":"分布式中间件/Kafka","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%AD%E9%97%B4%E4%BB%B6/Kafka/"}],"pages":[{"title":"留言板","text":"","link":"/about/index.html"},{"title":"目录","text":"1.TroubleShooting (43篇) 0.TroubleShooting方法论 (1,237字) 1.观察日志 (16篇) 1.为什么我的EL在测试和线上环境结果不同 (395字) 2.fastjson升级不兼容的问题 (333字) 3.这不是我想要的日志 (354字) 4.模糊的异常信息让人蒙圈 (237字) 5.刚发现的虫子原来很早之前就有了 (410字) 6.发现冲突，解决冲突 (214字) 7.小心JS中数字精度损失 (257字) 8.STFP报错Connection_reset (254字) 9.返回值里藏着异常信息 (324字) 10.看堆栈，勿急躁 (542字) 11.归约问题定位思路 (267字) 12.CA认证的证书为什么还需要手动导入？ (873字) 13.Http上传文件的Content-Type格式 (345字) 14.nginx反向代理自调用时小心Header里的host (733字) 15.Webmethod的IS加入Cluster异常 (1,114字) 16.proxool的log4j冲突 (636字) 2.Debug (5篇) 1.el中函数调用结果始终为null (275字) 2.Debug时科学观察变量 (218字) 3.Debug时加的观察变量影响了debug (751字) 4.ClassNotFound与类加载的全盘委托机制 (226字) 5.日志先行，Debug其次 (270字) 3.思维定势 (1篇) 1.对Http响应码“302”的误判 (342字) 4.流程分析 (17篇) 1.原来是IDE和Rest版本不同步 (331字) 2.FTP和sshuttle的故事 (321字) 3.方法返回集合的副本，避免污染 (798字) 4.签名验证异常 (440字) 5.HttpClient未设置connectTimeout导致线程池耗尽 (461字) 6.用tcpdump、wireShark分析sftp连接时readtimeout (703字) 7.MQ积压2亿了 (660字) 8.MQ消费出现陡增和断崖 (392字) 9.抓包分析http请求超时 (883字) 10.CPU飚高排查 (1,830字) 11.commons-io依赖冲突 (912字) 12.wsdl获取逻辑修改事故的复盘 (949字) 13.Maven间接依赖未下载 (390字) 14.内存飚高排查（一） (720字) 15.内存飚高排查（二） (403字) 16.内存飚高排查（三） (776字) 17.内存飚高排查（四） (222字) 5.单元测试 (3篇) 1.单元测试才是绩效的保命符 (430字) 2.el表达式与BigDecimal (326字) 3.因浮点精度损失了1分钱 (2,570字) 2.Golang (3篇) 1.go包和模块 (389字) 2.共享变量 (646字) 3.依赖树查看 (117字) 3.Java (88篇) 1.JavaSE (16篇) 1.包冲突 (1,301字) 2.String (282字) 3.Map (1,023字) 4.断言 (64字) 5.工厂类中使用ThreadLocal的陷阱 (505字) 6.误用BlockingQueue方法导致日志丢失 (563字) 7.SLF4J日志框架 (1,364字) 8.System.currentTimeMillis()与GMT (261字) 9.StringEscapeUtils (86字) 10.文件正确写入bom (584字) 11.echo无法清空日志 (793字) 12.Gson如何实例化类 (399字) 13.Java异常堆栈丢失仅剩一行 (661字) 14.SFTP和FTPS，HTTPS (212字) 15.使用hsdb查看运行时类 (202字) 16.ServiceLoader (548字) 2.Java并发 (9篇) 1.JMM (2,134字) 2.CPU内存模型和LOCK指令 (2,292字) 3.volatile (1,102字) 4.synchronized (1,542字) 5.AQS及其实现 (4,104字) 6.线程池剖析 (4,177字) 7.ThreadLocal内存泄漏 (195字) 8.线程同步 (265字) 9.FutureTask构建高效缓存 (177字) 3.Java虚拟机 (7篇) 1.类加载机制 (2,320字) 2.Java运行时内存区域 (648字) 3.垃圾回收 (1,480字) 4.垃圾回收器 (2,431字) 5.JDK自带的性能监控工具 (310字) 6.字节码解释器和JIT (237字) 7.JVM运行参数 (233字) 4.Spring (12篇) 0.SpringIOC (247字) 1.Spring循环依赖 (861字) 2.SpingAop (354字) 3.Spring事务 (638字) 4.SpingAopProxy (727字) 5.Spring注解Import (164字) 6.Spring集成第三方组件-JSF (1,239字) 7.Spring集成第三方组件-Mybatis (1,291字) 8.Spring集成示例组件实战 (990字) 9.Springboot配置文件读取顺序 (566字) 10.扩展接口SmartInitializingSingleton (941字) 11.Springboot自动配置 (1,288字) 5.Maven (20篇) 1.mvn_clean_deploy出错 (164字) 2.mvn_dependency_tree和assembly不一致 (500字) 3.maven插件的依赖的查找顺序 (245字) 4.Maven仓库类型 (708字) 5.Maven仓库更新策略 (561字) 6.DependencyManagment作用 (108字) 7.Maven属性替换 (789字) 8.Maven常用命令 (195字) 9.Maven依赖协调原则及依赖顺序的影响 (518字) 10.打包后-JAR包名为时间戳orSNAPSHOT (463字) 11.Maven生命周期和插件MOJO (607字) 12.Maven分类classifier使用 (368字) 13.Maven源码-模块说明 (330字) 14.Maven源码-调试方法 (169字) 15.Maven源码-主流程 (1,057字) 16.Maven源码-依赖解析 (2,152字) 17.Maven并行参数加快编译 (382字) 18.Maven如何处理循环依赖 (159字) 19.Maven查看模块依赖图 (187字) 20.Maven3.x兼容笔记 (407字) 6.Netty (6篇) 1.IO (2,642字) 2.零拷贝 (1,876字) 3.Netty聊天室Demo (997字) 4.Netty核心组件源码分析 (276字) 5.Netty高性能分析 (791字) 6.Scalable_IO_in_Java (2,532字) 7.Dubbo (8篇) 1.Dubbo速览 (710字) 2.Dubbo扩展点 (1,045字) 3.Dubbo服务发布源码分析 (1,607字) 4.Dubbo服务引入源码分析 (3,087字) 5.Dubbo服务调用源码分析 (52字) 6.RPC服务线程池大小及集群规模评估 (806字) 7.关于Dubbo的重试机制 (772字) 8.使用msgpack实体增加字段序列异常 (666字) 8.源码 (10篇) 0.看源码的姿势 (474字) 1.while(true)和for(;;)分析 (183字) 2.Junit源码分析 (748字) 3.URLClassPath源码分析 (930字) 4.Tomcat类加载器 (1,886字) 5.slf4j加载实现 (479字) 6.Camel的Exchange分析 (776字) 7.HttpClient（一）连接池 (678字) 8.HttpClient（二）结构 (452字) 9.HttpClient（三）连接池获取连接 (1,282字) 4.Mysql (15篇) 1.时区与时间：Mysql，JDBC，JVM (1,256字) 2.MySql和B+树 (2,671字) 3.Mysql_InnoDB锁 (1,378字) 4.Mysql事务及其隔离级别 (1,358字) 5.MVCC的InnoDB实现 (837字) 6.explain (1,042字) 7.Mysql优化 (1,246字) 8.InnoDb死锁分析 (978字) 9.MySQL_Workbench常用操作 (72字) 10.left_join时on后多条件AND (562字) 11.Mysql索引优化 (646字) 12.Mysql对Null的判断 (135字) 13.JDBC的时区调停 (469字) 14.分库分表 (517字) 15.Mysql如何保证数据不丢失 (794字) 5.Git (14篇) 0.Git分享 (3,353字) 1.VCS简介 (2,193字) 2.Git配置 (1,430字) 3.Git内部原理 (4,317字) 4.Git标签和分支 (3,342字) 5.Git基础操作之正常提交 (1,607字) 6.Git基础操作之撤销操作 (2,340字) 7.git工作流 (621字) 8.Git补充内容 (1,850字) 9.常见问题 (1,154字) 10.查看文件变更 (436字) 11.手动合并分支的技巧 (315字) 12.检出文件夹时注意事项 (252字) 13.合并两个仓库 (547字) 6.Linux (8篇) 1.CPU使用率和负载 (1,470字) 2.Debian包管理 (1,004字) 3.同步异步和阻塞非阻塞 (360字) 4.User_vs_Kernel (557字) 5.Vim笔记 (1,369字) 6.OOM_Killer (259字) 7.进程运行信息 (109字) 8.shell脚本编写 (388字) 7.分布式中间件 (19篇) 1.共识协议 (3篇) 1.分布式网络及共识协议 (2,302字) 2.常见分布式中间件的共识协议 (3,768字) 3.落盘机制 (498字) 2.Elasticsearch (9篇) 1.ES索引分片数设置原则 (1,075字) 2.ES倒排索引 (519字) 3.ES的乐观锁 (171字) 4.ES分片和副本 (1,781字) 5.ES脑裂问题 (766字) 6.ES分页 (374字) 7.ES_CPU飚高 (323字) 8.索引备份实践 (1,313字) 9.ES磁盘不足拒绝写 (511字) 3.Redis (4篇) 0.Consistent_Hashing_and_Random_Trees翻译 (4,916字) 1.一致性hash (1,443字) 2.缓存常见问题 (481字) 3.Redis总结 (2,136字) 4.Zookeeper (1篇) 1.Zookeeper概念 (708字) 5.Kafka (1篇) 1.顺序消费 (173字) 6.数据密集型系统设计 (7字) 8.代码架构 (7篇) 1.从一个pojo类来看单一性原则 (250字) 2.从Camel中学习FluntApi设计 (691字) 3.扩展点的设计 (473字) 4.装饰器和代理的区别 (206字) 5.拦截器实现的细节 (187字) 6.从Filter和Interceptor看责任链模式 (1,785字) 7.代码整洁之道 (17字) 9.算法 (2篇) 1.排序 (1,006字) 2.算法题型总结 (8,603字) 10.工具 (7篇) 1.日常使用-Ubuntu (2,493字) 2.日常使用-Mac (652字) 3.日常使用-IDEA&amp;Goland (869字) 4.日常使用-Chrome (438字) 5.日常使用-杂 (69字) 6.sshuttle使用 (217字) 7.openfortivpn使用 (349字) 11.网络 (9篇) 1.网络上行和下行 (136字) 2.负载均衡4层和7层区别 (307字) 3.session_cookie_token (192字) 4.笔记本通过网线分享网络给台式机 (724字) 5.DNS和URL重定向 (284字) 6.URI格式 (309字) 7.Http_trailing_slashes (131字) 8.Http_Content-Length (144字) 9.请求代理配置 (431字) 12.工程实践 (15篇) 1.多应用混合部署 (258字) 2.尽早抽象和持续重构 (517字) 3.工程命名与职责 (435字) 6.由日志框架的异常处理引发的思考 (386字) 7.替换日志框架过程中对重构的思考 (814字) 8.第三方组件的中间层 (315字) 9.科学的引用类名和包名 (497字) 10.使用CPU百分位作容器缩容的参考指标 (558字) 11.大促扩容要有数据支撑 (571字) 12.关于重构时信息量的思考 (259字) 13.你的压测结果真的符合预期吗 (278字) 14.关于配置中心设计的思考 (409字) 15.蓝绿发布vs灰度发布vs滚动发布 (336字) 16.科学的剥离其他中间件 (414字) 17.版本管理 (2,676字) 13.安全 (6篇) 1.XSRF和XSS (770字) 2.浏览器跨域 (855字) 3.非对称密码的私钥包含了公钥信息 (449字) 4.RSA与Padding模式 (310字) 5.ssh-keygen生成PEM格式密钥 (541字) 6.cacert证书查看和导入 (756字) 14.容器 (1篇) 1.Nginx架构翻译 (3,350字) 15.学习 (11篇) 1.读书笔记 (6篇) 心理 (5,470字) 其他 (199字) 传记 (5,358字) 思考 (15,468字) 学习 (20,775字) 工作 (11,674字) 2.工作和学习 (1,648字) 3.央行的基础货币怎么流入市场 (282字) 4.习惯复盘 (1,254字) 5.原则 (876字) 6.随笔 (2,498字) 16.工作 (12篇) 1.关于会议 (2,681字) 2.关于信息同步 (1,394字) 3.关于规划 (1,286字) 4.关于项目目标 (413字) 5.架构治理的若干思考 (6,093字) 6.一般的分析问题 (2,842字) 7.小数决策和审查数据 (6,181字) 8.抽象假设和验证假设 (1,461字) 9.架构度量项目复盘 (1,180字) 10.代码治理及研发心理 (1,577字) 11.LLM与架构治理 (2,037字) 12.架构治理事故复盘 (1,718字)","link":"/catalog/index.html"}]}